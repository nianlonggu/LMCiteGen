{"citing_id": "2303.17212v1", "cited_id": "1711.09020", "section_title": "I. Is Sargan Effective For Facial Attribute Manipulation?", "citation": "For comparison, StarGAN results were obtained via pre-trained model provided by their authors #REFR . The results in Fig.", "text_before_citation": ["We trained the proposed SARGAN model on CelebA dataset to assess the performance of SARGAN on facial attribute manipulation."], "text_after_citation": ["13 demonstrate that StarGAN is unable to recover the true input image overall color as well as facial details such as eye and skin colors.", "In contrast, SARGAN recovers true input image colors and facial details.", "To confirm our analysis, we compute the distance between histograms of input and StarGAN-synthesized images and input and SARGAN-synthesized images, respectively. Fig.", "13 shows that SARGAN results are closer to the input images compared to StarGAN. Further, as shown in Fig.", "13 , Column 3, StarGAN modifies the input face's hairstyle in addition to the hair color, whereas SARGAN only modifies the hair color."], "citing_paper_content": {"title": "Sargan: Spatial Attention-Based Residuals For Facial Expression Manipulation", "abstract": "Encoder-decoder based architecture has been widely used in the generator of generative adversarial networks for facial manipulation. However, we observe that the current architecture fails to recover the input image color, rich facial details such as skin color or texture and introduces artifacts as well. In this paper, we present a novel method named SARGAN that addresses the above-mentioned limitations from three perspectives. First, we employed spatial attention-based residual block instead of vanilla residual blocks to properly capture the expressionrelated features to be changed while keeping the other features unchanged. Second, we exploited a symmetric encoder-decoder network to attend facial features at multiple scales. Third, we proposed to train the complete network with a residual connection which relieves the generator of pressure to generate the input face image thereby producing the desired expression by directly feeding the input image towards the end of the generator. Both qualitative and quantitative experimental results show that our proposed model performs significantly better than state-ofthe-art methods. In addition, existing models require much larger datasets for training but their performance degrades on out-ofdistribution images. In contrast, SARGAN can be trained on smaller facial expressions datasets, which generalizes well on outof-distribution images including human photographs, portraits, avatars and statues."}, "cited_paper_content": {"title": "Stargan: Unified Generative Adversarial Networks For Multi-Domain Image-To-Image Translation", "abstract": "Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks."}, "keywords": ["StarGAN results"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We trained the proposed SARGAN model on CelebA dataset to assess the performance of SARGAN on facial attribute manipulation. Our approach addresses the limitations of existing models and achieves superior quality of translated images compared to previous methods, as demonstrated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compared the performance of our proposed SARGAN model with state-of-the-art methods on facial attribute manipulation and achieved significantly better results (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed SARGAN model outperforms existing methods on facial attribute manipulation tasks, as demonstrated by both qualitative and quantitative results on the CelebA dataset. The superior #REFR StarGAN results further support the effectiveness of our approach.", "given_citation_intent": "result", "given_keywords": ["StarGAN results"]}]}
{"citing_id": "2303.17395v1", "cited_id": "1706.03741", "section_title": "B. Data Processing", "citation": "Trained using Reinforcement Learning from Human Feedback (RLHF) #REFR , ChatGPT has been shown to excel at generating human-like responses to natural language prompts, and has garnered widespread attention for its powerful understanding, reasoning, and dialogue abilities.", "text_before_citation": ["These two filtering steps have removed about 265 000 data samples from FreeSound.", "ChatGPT-based Transformation To transform the raw descriptions into audio captions, we propose that a well-formed audio caption should possess the following characteristics:", "\u2022 Be a single, accurate description of the audio content using concise syntax; \u2022 Avoid the use of named entities such as people's names, locations, and recording devices that cannot be inferred from the audio signal alone; \u2022 Exclude any subjective sound-unrelated information such as personal feelings or opinions; However, online-harvested descriptions are extremely noisy and most of them fail to meet above requirements, particularly those from FreeSound.", "Due to the varying characteristics of raw descriptions, it is challenging to design rules that accurately convert them into captions, and doing so would result in a high discard rate similar to what was observed in CC3M.", "To tackle the challenge of converting raw descriptions into captions, we propose using ChatGPT, a powerful large language model trained by OpenAI 6 to perform this task automatically."], "text_after_citation": ["By designing prompts that account for the characteristics of different data sources, ChatGPT can effectively filter out sound-unrelated information and rewrite raw descriptions in to audio caption-like sentences that meet the requirements we proposed in prompts.", "This approach has the potential to significantly reduce the discard rate of raw descriptions and improve the quality of converted captions. Prompts we used are shown in Table I .", "In order to make use of ChatGPT's in-context learning ability, several transformation examples are also included in the prompts and they are different for each data sources (ignored in Table I ). These examples can significantly improve the caption quality.", "Table II presents examples of the raw descriptions and final processed captions.", "It can be observed that ChatGPT can transform non-sentence descriptions (i.e., nouns and phrases) into sentences, remove redundant information that is too specific or is not related to sound, and summarize long sentences into one-sentence high-level audio captions."], "citing_paper_content": {"title": "Wavcaps: A Chatgpt-Assisted Weakly-Labelled Audio Captioning Dataset For Audio-Language Multimodal Research", "abstract": "The advancement of audio-language (AL) multimodal learning tasks has been significant in recent years. However, researchers face challenges due to the costly and timeconsuming collection process of existing audio-language datasets, which are limited in size. To address this data scarcity issue, we introduce WavCaps, the first large-scale weakly-labelled audio captioning dataset, comprising approximately 400k audio clips with paired captions. We sourced audio clips and their raw descriptions from web sources and a sound event detection dataset. However, the online-harvested raw descriptions are highly noisy and unsuitable for direct use in tasks such as automated audio captioning. To overcome this issue, we propose a three-stage processing pipeline for filtering noisy data and generating highquality captions, where ChatGPT, a large language model, is leveraged to filter and transform raw descriptions automatically. We conduct a comprehensive analysis of the characteristics of WavCaps dataset and evaluate it on multiple downstream audiolanguage multimodal learning tasks. The systems trained on WavCaps outperform previous state-of-the-art (SOTA) models by a significant margin. Our aspiration is for the WavCaps dataset we have proposed to facilitate research in audio-language multimodal learning and demonstrate the potential of utilizing ChatGPT to enhance academic research. Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps."}, "cited_paper_content": {"title": "Deep Reinforcement Learning From Human Preferences", "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback."}, "keywords": ["natural language prompts", "Reinforcement Learning"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To tackle the challenge of converting raw descriptions into captions, the authors propose using ChatGPT, a powerful large language model trained by OpenAI #REFR to perform this task automatically.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To tackle the challenge of converting raw descriptions into captions, the authors propose using ChatGPT, a powerful large language model trained by OpenAI #REFR to perform this task automatically.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To tackle the challenge of converting raw descriptions into captions, the authors propose using ChatGPT, a powerful large language model trained by OpenAI #REFR to perform this task automatically, which is a promising method for generating natural language prompts and can be applied to various fields, including Reinforcement Learning.", "given_citation_intent": "method", "given_keywords": ["natural language prompts", "Reinforcement Learning"]}]}
{"citing_id": "2303.10610v1", "cited_id": "1706.02262", "section_title": "Condition-Specific Mmd Regularization", "citation": "Inspired by InfoVAE #REFR , we introduce an additional pair of condition-specific MMD regularization loss to learn mutual information between the sampled noise distribution and the Gaussian distribution.", "text_before_citation": ["Maximum-Mean Discrepancy (MMD) is to quantify the similarity between two distributions by comparing all of their moments #OTHEREFR . It can be efficiently implemented using a kernel trick."], "text_after_citation": ["To be specific, we sample the noisy variable y g t from the diffusion process at time step t conditioned only by the global prior and then compute an MMDregularization loss as:", "EQUATION", "where K(\u2022, \u2022) is a positive definite kernel to reproduce distributions in the Hilbert space.", "The condition-specific MMD regularization is also applied on the local prior, as shown in Figure 1 (a) .", "While the general noise estimation loss L captures the complementary information from both priors, the condition-specific MMD regularization maintains the mutual information between each prior and target distribution."], "citing_paper_content": {"title": "Diffmic: Dual-Guidance Diffusion Network For Medical Image Classification", "abstract": "Diffusion Probabilistic Models have recently shown remarkable performance in generative image modeling, attracting significant attention in the computer vision community. However, while a substantial amount of diffusion-based research has focused on generative tasks, few studies have applied diffusion models to general medical image classification. In this paper, we propose the first diffusion-based model (named DiffMIC) to address general medical image classification by eliminating unexpected noise and perturbations in medical images and robustly capturing semantic representation. To achieve this goal, we devise a dual conditional guidance strategy that conditions each diffusion step with multiple granularities to improve step-wise regional attention. Furthermore, we propose learning the mutual information in each granularity by enforcing Maximum-Mean Discrepancy regularization during the diffusion forward process. We evaluate the effectiveness of our DiffMIC on three medical classification tasks with different image modalities, including placental maturity grading on ultrasound images, skin lesion classification using dermatoscopic images, and diabetic retinopathy grading using fundus images. Our experimental results demonstrate that DiffMIC outperforms state-of-the-art methods by a significant margin, indicating the universality and effectiveness of the proposed model."}, "cited_paper_content": {"title": "Infovae: Information Maximizing Variational Autoencoders", "abstract": "It has been previously observed that variational autoencoders tend to ignore the latent code when combined with a decoding distribution that is too flexible. This undermines the purpose of unsupervised representation learning. We identify the reason for this short-coming in the regularization term used in the ELBO criterion to match the variational posterior to the latent prior distribution. We show that removing this regularization term leads to a model that can still discover meaningful latent features. Even though ancestral sampling is no longer tractable, sampling is possible using a Markov chain. Furthermore, we propose a class of training criteria that use alternative divergences for the regularization term, generalizing the standard ELBO which employs KL divergence. These models can discover meaningful latent features and allow for tractable ancestral sampling. In particular, we propose an alternative based on Maximum Mean Discrepancy (MMD) that is simple to implement, robust, and has similar or better performance in every quantitative and qualitative metric we experimented on."}, "keywords": ["condition-specific MMD regularization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To enforce Maximum-Mean Discrepancy regularization during the diffusion forward process, DiffMIC utilizes a class of training criteria proposed in #REFR, which allows for the discovery of meaningful latent features and tractable ancestral sampling.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To implement the Maximum-Mean Discrepancy (MMD) method for regularization during the diffusion forward process, the authors of DiffMIC referred to the work by #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enforce condition-specific MMD regularization during the diffusion forward process, DiffMIC proposed by the authors uses a class of training criteria that generalizes the standard ELBO by employing alternative divergences for the regularization term #REFR.", "given_citation_intent": "method", "given_keywords": ["condition-specific MMD regularization"]}]}
{"citing_id": "2303.01112v1", "cited_id": "1707.02968", "section_title": "Introduction", "citation": "The accuracy of vision transformers exceeds that of convolutional neural networks by a considerable margin when the model is pre-trained on huge datasets, such as JFT-300M #REFR .", "text_before_citation": ["Vision transformers #OTHEREFR have made a significant impact on the entire field of computer vision, and state of the art models in classification #OTHEREFR , object detection #OTHEREFR , and segmentation #OTHEREFR are now based on vision transformers."], "text_after_citation": ["However, the JFT-300M dataset contains 300M images and 375M labels.", "It is impossible to sin #OTHEREFR manually label all of these images.", "Efforts to automatically label such datasets is still not as accurate as manual labeling.", "Self-supervised learning (SSL) is increasing in popularity, as datasets do not need to be labeled for this mode of training #OTHEREFR .", "Although SSL removes the burden of labeling large datasets, the effort to collect/download, store, and load these large datasets remains a challenge."], "citing_paper_content": {"title": "Visual Atoms: Pre-Training Vision Transformers With Sinusoidal Waves", "abstract": "Formula-driven supervised learning (FDSL) has been shown to be an effective method for pre-training vision transformers, where ExFractalDB-21k was shown to exceed the pre-training effect of ImageNet-21k. These studies also indicate that contours mattered more than textures when pre-training vision transformers. However, the lack of a systematic investigation as to why these contour-oriented synthetic datasets can achieve the same accuracy as real datasets leaves much room for skepticism. In the present work, we develop a novel methodology based on circular harmonics for systematically investigating the design space of contour-oriented synthetic datasets. This allows us to efficiently search the optimal range of FDSL parameters and maximize the variety of synthetic images in the dataset, which we found to be a critical factor. When the resulting new dataset VisualAtom-21k is used for pre-training ViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k. This is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training, while the number of images is 1/14. Unlike JFT-300M which is a static dataset, the quality of synthetic datasets will continue to improve, and the current work is a testament to this possibility. FDSL is also free of the common issues associated with real images, e.g. privacy/copyright issues, labeling costs/errors, and ethical biases."}, "cited_paper_content": {"title": "Revisiting Unreasonable Effectiveness Of Data In Deep Learning Era", "abstract": "The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10x or 100x? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets."}, "keywords": ["vision transformers", "huge datasets"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Vision transformers have made a significant impact on the entire field of computer vision, and state of the art models in classification, object detection, and segmentation are now based on vision transformers. However, the performance of these models can be further improved by pre-training on larger datasets, as shown by recent studies on the unreasonable effectiveness of data in deep learning era #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Vision transformers have made a significant impact on the entire field of computer vision, and state of the art models in classification, object detection, and segmentation are now based on vision transformers. As highlighted in the paper by #REFR, the success of deep learning in vision can be attributed to models with high capacity, increased computational power, and availability of large-scale labeled data.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Vision transformers have become the state-of-the-art models in computer vision tasks such as classification, object detection, and segmentation, and recent studies have shown that pre-training on huge datasets can significantly improve their performance #REFR.", "given_citation_intent": "background", "given_keywords": ["vision transformers", "huge datasets"]}]}
{"citing_id": "2303.10435v1", "cited_id": "1509.07009", "section_title": "Results And Findings", "citation": "The results are still significantly inferior to that with the original high-resolution images #REFR .", "text_before_citation": ["Statistical analysis suggests that when image resolution is below 20 \u00d7 20 pixels, superresolution techniques can significantly improve human recognition performance on both activity recognition and privacy recognition tasks.", "But it is worth noting that the improvement in recognition performance brought about by super-resolution technology is still less than that brought about by increasing the resolution itself.", "Such a finding reveals that super-resolution techniques do not provide enough additional information for humans to enhance their perception ability in both activity recognition and visual privacy awareness tasks.", "In terms of the impact of the super-resolution technique on the machine's recognition performance, researchers have proved that super-resolution can slightly facilitate vision-based recognition task such as activity recognition #OTHEREFR , object and text recognition #OTHEREFR .", "However, the influence of the super-resolution technique is very limited."], "text_after_citation": ["In conclusion, the additional visual information introduced by the image super-resolution technique is insufficient to overcome the effect of resolution on the recognition performance of humans and machines.", "Therefore, we believe that the effects of image resolution on human (section 6) and the machine's (section 7) ADLs and visual privacy recognition performance are robust against image superresolution techniques."], "citing_paper_content": {"title": "Modeling The Trade-Off Of Privacy Preservation And Activity Recognition On Low-Resolution Images", "abstract": "A computer vision system using low-resolution image sensors can provide intelligent services (e.g., activity recognition) but preserve unnecessary visual privacy information from the hardware level. However, preserving visual privacy and enabling accurate machine recognition have adversarial needs on image resolution. Modeling the trade-off of privacy preservation and machine recognition"}, "cited_paper_content": {"title": "Is Image Super-Resolution Helpful For Other Vision Tasks?", "abstract": "Despite the great advances made in the field of image super-resolution (ISR) during the last years, the performance has merely been evaluated perceptually. Thus, it is still unclear whether ISR is helpful for other vision tasks. In this paper, we present the first comprehensive study and analysis of the usefulness of ISR for other vision applications. In particular, six ISR methods are evaluated on four popular vision tasks, namely edge detection, semantic image segmentation, digit recognition, and scene recognition. We show that applying ISR to input images of other vision systems does improve their performance when the input images are of low-resolution. We also study the correlation between four standard perceptual evaluation criteria (namely PSNR, SSIM, IFC, and NQM) and the usefulness of ISR to the vision tasks. Experiments show that they correlate well with each other in general, but perceptual criteria are still not accurate enough to be used as full proxies for the usefulness. We hope this work will inspire the community to evaluate ISR methods also in real vision applications, and to adopt ISR as a pre-processing step of other vision tasks if the resolution of their input images is low."}, "keywords": ["original high-resolution images"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In terms of the influence of the super-resolution technique on machine recognition performance, previous studies have shown that it can slightly facilitate vision-based recognition tasks such as activity recognition, object and text recognition #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The study presented in #REFR shows that applying ISR to low-resolution input images of other vision systems can improve their performance on various vision tasks, including edge detection and semantic image segmentation, which is consistent with the findings of this manuscript.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the study by #REFR, applying ISR to low-resolution images can improve the performance of other vision systems, which is consistent with the finding that super-resolution techniques can slightly facilitate vision-based recognition tasks such as activity recognition, object and text recognition, as mentioned in the local context.", "given_citation_intent": "result", "given_keywords": ["original high-resolution images"]}]}
{"citing_id": "2303.15414v1", "cited_id": "1703.00443", "section_title": "Differentiable Graph Matching Layer", "citation": "In our implementation, we adopt the qpth library #REFR to build the graph matching module.", "text_before_citation": ["After enhancing the vertex features and constructing the edge features on graph G D and G T , we meet the core component of our method: the differentiable graph matching layer. By optimizing the QP in Eq.", "6 from quadratic affinity matrix M and vertex affinity matrix B, we can derive the optimal matching score vector x and reshape it back to the shape n d \u00d7 n t to get the matching score map X.", "Since we finally formulate the graph matching problem as a QP, we can construct the graph matching module as a differentiable QP layer in our neural network.", "Since KKT conditions are the necessary and sufficient conditions for the optimal solution x * and its dual variables, we could derive the gradient in backward pass of our graph matching layer based on the KKT conditions and implicit function theorem, which is inspired by OptNet #OTHEREFR ."], "text_after_citation": ["In the inference stage, to reduce the computational cost and accelerate the algorithm, we solve the QP using the CVXPY library #OTHEREFR only for forward operation.", "For training, we use weighted binary cross entropy Loss:", "EQUATION", "where\u0177 i,j denotes the matching score between detection D i and tracklet T j , and y i,j is the ground truth indicating whether the object belongs to the tracklet.", "k = (n t \u2212 1) is the weight to balance the loss between positive and negative samples."], "citing_paper_content": {"title": "Learnable Graph Matching: A Practical Paradigm For Data Association", "abstract": "Data association is at the core of many computer vision tasks, e.g., multiple object tracking, image matching, and point cloud registration. Existing methods usually solve the data association problem by network flow optimization, bipartite matching, or end-to-end learning directly. Despite their popularity, we find some defects of the current solutions: they mostly ignore the intra-view context information; besides, they either train deep association models in an end-to-end way and hardly utilize the advantage of optimization-based assignment methods, or only use an off-the-shelf neural network to extract features. In this paper, we propose a general learnable graph matching method to address these issues. Especially, we model the intra-view relationships as an undirected graph. Then data association turns into a general graph matching problem between graphs. Furthermore, to make optimization end-to-end differentiable, we relax the original graph matching problem into continuous quadratic programming and then incorporate training into a deep graph neural network with KKT conditions and implicit function theorem. In MOT task, our method achieves state-of-the-art performance on several MOT datasets. For image matching, our method outperforms state-of-the-art methods with half training data and iterations on a popular indoor dataset, ScanNet. Code will be available at https://github.com/jiaweihe1996/GMTracker."}, "cited_paper_content": {"title": "Optnet: Differentiable Optimization As A Layer In Neural Networks", "abstract": "This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers allow complex dependencies between the hidden states to be captured that traditional convolutional and fully-connected layers are not able to capture. In this paper, we develop the foundations for such an architecture: we derive the equations to perform exact differentiation through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one particularly standout example, we show that the method is capable of learning to play Sudoku given just input and output games, with no a priori information about the rules of the game; this task is virtually impossible for other neural network architectures that we have experimented with, and highlights the representation capabilities of our approach."}, "keywords": ["graph matching module", "implementation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Since KKT conditions are the necessary and sufficient conditions for the optimal solution x * and its dual variables, we could derive the gradient in backward pass of our graph matching layer based on the KKT conditions and implicit function theorem, which is inspired by OptNet (Optnet: Differentiable Optimization As A Layer In Neural Networks). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Since our graph matching problem is formulated as a QP, we can construct the graph matching module as a differentiable QP layer in our neural network, which is inspired by OptNet's differentiable optimization as a layer in neural networks #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To implement the differentiable graph matching layer as a graph matching module in our neural network, we derive the gradient based on the KKT conditions and implicit function theorem, which is inspired by OptNet for the efficient solver and exact differentiation through these layers #REFR.", "given_citation_intent": "method", "given_keywords": ["graph matching module", "implementation"]}]}
{"citing_id": "2303.10692v1", "cited_id": "1602.01783", "section_title": "A. Marl Framework Of Interactive Image Segmentation", "citation": "The asynchronous advantage actorcritic (A3C) #REFR scheme is employed in BS-IRIS and further extended to a fully convolutional form, where agents can collaborate and communicate through convolutional layers. The algorithm is summarized in Alg. 1.", "text_before_citation": ["It is impractical to directly apply typical multi-agent learning algorithms such as #OTHEREFR .", "2) All voxel-type agents are neatly aligned in a 3D grid and dependent with each other for the segmentation task.", "It is necessary to require them to cooperate with each other.", "This is achieved by enforcing all voxel agents to share the same policy.", "When one agent explores a beneficial action, other agents will simultaneously acquire that knowledge, which also significantly reduces the number of parameters."], "text_after_citation": [], "citing_paper_content": {"title": "Boundary-Aware Supervoxel-Level Iteratively Refined Interactive 3D Image Segmentation With Multi-Agent Reinforcement Learning", "abstract": "Interactive segmentation has recently been explored to effectively and efficiently harvest high-quality segmentation masks by iteratively incorporating user hints. While iterative in nature, most existing interactive segmentation methods tend to ignore the dynamics of successive interactions and take each interaction independently. We here propose to model iterative interactive image segmentation with a Markov decision process (MDP) and solve it with reinforcement learning (RL) where each voxel is treated as an agent. Considering the large exploration space for voxel-wise prediction and the dependence among neighboring voxels for the segmentation tasks, multi-agent reinforcement learning is adopted, where the voxel-level policy is shared among agents. Considering that boundary voxels are more important for segmentation, we further introduce a boundary-aware reward, which consists of a global reward in the form of relative cross-entropy gain, to update the policy in a constrained direction, and a boundary reward in the form of relative weight, to emphasize the correctness of boundary predictions. To combine the advantages of different types of interactions, i.e., simple and efficient for point-clicking, and stable and robust for scribbles, we propose a supervoxel-clicking based interaction design. Experimental results on four benchmark datasets have shown that the proposed method significantly outperforms the state-of-the-arts, with the advantage of fewer interactions, higher accuracy, and enhanced robustness."}, "cited_paper_content": {"title": "Asynchronous Methods For Deep Reinforcement Learning", "abstract": "We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input."}, "keywords": ["convolutional layers", "asynchronous advantage actorcritic"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the dependence among neighboring voxels for the segmentation task, the authors propose a multi-agent reinforcement learning approach where all voxel agents share the same policy, allowing them to simultaneously acquire knowledge from beneficial actions taken by other agents, as demonstrated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model iterative interactive image segmentation with a Markov decision process (MDP) and solve it with reinforcement learning (RL), the authors adopted multi-agent reinforcement learning, where the voxel-level policy is shared among agents, and asynchronous gradient descent for optimization of deep neural network controllers, as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the deep neural network controllers, the authors propose using asynchronous gradient descent, which is a lightweight framework for deep reinforcement learning, and present asynchronous variants of four standard reinforcement learning algorithms, including asynchronous advantage actorcritic, as shown in #REFR.", "given_citation_intent": "method", "given_keywords": ["convolutional layers", "asynchronous advantage actorcritic"]}]}
{"citing_id": "2304.02932v1", "cited_id": "1905.04273", "section_title": "Conclusion", "citation": "The exponential mechanism we use at the first stage is a Gumbel noise style implementation #REFR which is analyzed with RDP via a \"Bounded Range\" property for tighter bound.", "text_before_citation": ["On the attack aspect, we have proposed three knowledge graph(KG) triple inference attacks on FKGE to expose its significant privacy vulnerability.", "On the defense aspect, DP-FLames is proposed to provide rigorous differential privacy protection for FKGE, which exploits the sparse gradient property of FKGE by designing the private active gradient selection strategy.", "An adaptive privacy budget allocation policy is further incorporated to dynamically adjust defense magnitude against the unbalanced privacy risks throughout the training procedure.", "The experiment results demonstrate that the proposed defense can effectively defend against inference attacks with a modest utility decrease.", "Proof."], "text_after_citation": ["This implementation of exponential mechanism satisfies ( , 8 2 ) \u2212 .", "We adopt a PTR variant with Gaussian noise #OTHEREFR for the second stage.", "Since there is a probability bounded by that the test in PTR may fail, the algorithm satisfies -approximate-( , 2 2 )-RDP.", "Thus, the private selection without subsampling satisfiesapproximate-( , ( 8 2 + 2 2 ))-RDP by composition.", "Since the input of Algorithm 2 is computed from a subsampled batch of the original dataset(Line 11 in Algorithm 1), the privacy guarantee can be amplified through the privacy amplification theorem for RDP with subsampled mechanism #OTHEREFR . \u25a1"], "citing_paper_content": {"title": "Quantifying And Defending Against Privacy Threats On Federated Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is a fundamental technique that extracts expressive representation from knowledge graph (KG) to facilitate diverse downstream tasks. The emerging federated KGE (FKGE) collaboratively trains from distributed KGs held among clients while avoiding exchanging clients' sensitive raw KGs, which can still suffer from privacy threats as evidenced in other federated model trainings (e.g., neural networks). However, quantifying and defending against such privacy threats remain unexplored for FKGE which possesses unique properties not shared by previously studied models. In this paper, we conduct the first holistic study of the privacy threat on FKGE from both attack and defense perspectives. For the attack, we quantify the privacy threat by proposing three new inference attacks, which reveal substantial privacy risk by successfully inferring the existence of the KG triple from victim clients. For the defense, we propose DP-Flames, a novel differentially private FKGE with private selection, which offers a better privacy-utility tradeoff by exploiting the entity-binding sparse gradient property of FKGE and comes with a tight privacy accountant by incorporating the state-of-the-art private selection technique. We further propose an adaptive privacy budget allocation policy to dynamically adjust defense magnitude across the training procedure. Comprehensive evaluations demonstrate that the proposed defense can successfully mitigate the privacy threat by effectively reducing the success rate of inference attacks from 83.1% to 59.4% on average with only a modest utility decrease."}, "cited_paper_content": {"title": "Practical Differentially Private Top-$K$ Selection With Pay-What-You-Get Composition", "abstract": "We study the problem of top-k selection over a large domain universe subject to user-level differential privacy. Typically, the exponential mechanism or report noisy max are the algorithms used to solve this problem. However, these algorithms require querying the database for the count of each domain element. We focus on the setting where the data domain is unknown, which is different than the setting of frequent itemsets where an apriori type algorithm can help prune the space of domain elements to query. We design algorithms that ensures (approximate) differential privacy and only needs access to the true top-k' elements from the data for any chosen k' \u2265 k. This is a highly desirable feature for making differential privacy practical, since the algorithms require no knowledge of the domain. We consider both the setting where a user's data can modify an arbitrary number of counts by at most 1, i.e. unrestricted sensitivity, and the setting where a user's data can modify at most some small, fixed number of counts by at most 1, i.e. restricted sensitivity. Additionally, we provide a pay-what-you-get privacy composition bound for our algorithms. That is, our algorithms might return fewer than k elements when the top-k elements are queried, but the overall privacy budget only decreases by the size of the outcome set."}, "keywords": ["\"Bounded Range\" property"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "On the defense aspect, DP-FLames is proposed to provide rigorous differential privacy protection for FKGE, which exploits the sparse gradient property of FKGE by designing the private active gradient selection strategy. An adaptive privacy budget allocation policy is further incorporated to dynamically adjust defense magnitude against the unbalanced privacy risks throughout the training procedure. The experiment results demonstrate that the proposed defense can effectively defend against inference attacks with a modest utility decrease (Li et al., 2021). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide rigorous differential privacy protection for federated knowledge graph embedding, DP-FLames is proposed, which exploits the sparse gradient property of FKGE by designing the private active gradient selection strategy and only needs access to the true top-k' elements from the data for any chosen k' \u2265 k, as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure rigorous differential privacy protection for federated knowledge graph embedding, DP-FLames is proposed, which exploits the entity-binding sparse gradient property of FKGE by designing the private active gradient selection strategy and incorporates an adaptive privacy budget allocation policy to dynamically adjust defense magnitude against the unbalanced privacy risks throughout the training procedure. DP-FLames is highly desirable for making differential privacy practical, since the algorithm requires no knowledge of the domain and satisfies the \"Bounded Range\" property. #REFR", "given_citation_intent": "method", "given_keywords": ["\"Bounded Range\" property"]}]}
{"citing_id": "2304.01434v1", "cited_id": "1701.00160", "section_title": "Gan: Preventing Mode Collapse", "citation": "The GAN training usually ends up with (partial) mode collapse #REFR , where generative models suffer lack of diversity.", "text_before_citation": ["In Section 3.3, VNE + has successfully prevented representation collapse.", "As another example for collapse prevention, we consider the mode collapse in GAN."], "text_after_citation": ["To demonstrate that this problem can be solved by VNE + , we reproduce various GAN methods based on an open source code base, StudioGAN #OTHEREFR and train all models with CIFAR-10 for 100 epochs.", "To evaluate the models, we report the Inception Score #OTHEREFR (IS, higher is better) and the Fr\u00e9chet Inception Distance #OTHEREFR (FID, lower is better).", "Although both IS and FID are the most popular metrics for evaluating generative models, FID is known to favor more diversified images #OTHEREFR .", "Table 8 demonstrate that the overall quality of the output, especially diversity, has been improved by VNE + because FID scores have been improved. IS has also been improved."], "citing_paper_content": {"title": "Vne: An Effective Method For Improving Deep Representation By Manipulating Eigenvalue Distribution", "abstract": "Since the introduction of deep learning, a wide scope of representation properties, such as decorrelation, whitening, disentanglement, rank, isotropy, and mutual information, have been studied to improve the quality of representation. However, manipulating such properties can be challenging in terms of implementational effectiveness and general applicability. To address these limitations, we propose to regularize von Neumann entropy (VNE) of representation. First, we demonstrate that the mathematical formulation of VNE is superior in effectively manipulating the eigenvalues of the representation autocorrelation matrix. Then, we demonstrate that it is widely applicable in improving stateof-the-art algorithms or popular benchmark algorithms by investigating domain-generalization, meta-learning, selfsupervised learning, and generative models. In addition, we formally establish theoretical connections with rank, disentanglement, and isotropy of representation. Finally, we provide discussions on the dimension control of VNE and the relationship with Shannon entropy. Code is available at: https://github.com/jaeill/CVPR23-VNE. * Corresponding author (a) Domain generalization (b) Meta-learning (c) Self-supervised learning (d) GAN"}, "cited_paper_content": {"title": "Nips 2016 Tutorial: Generative Adversarial Networks", "abstract": "This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises."}, "keywords": ["GAN training"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As another example for collapse prevention, we consider the mode collapse in GAN, which has been extensively studied in the literature #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide background on generative adversarial networks (GANs), we refer to the Nips 2016 Tutorial by Goodfellow et al. #REFR, which describes the details of how GANs work and compares them to other generative models.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prevent mode collapse in GAN training, it is important to consider the details of how GANs work, which are described in the tutorial presented by the author at NIPS 2016 on generative adversarial networks (#REFR).", "given_citation_intent": "background", "given_keywords": ["GAN training"]}]}
{"citing_id": "2304.05571v1", "cited_id": "1704.00390", "section_title": "Ii. Related Works", "citation": "PoseNet #REFR [15] trains a CNN to regress the 6-DOF camera pose from a single RGB image without additional engineering or graph optimization.", "text_before_citation": ["And #OTHEREFR extends the database volumes by generating the rendered synthetic images as the database.", "Active Search #OTHEREFR implements the image retrieval process followed by the direct 2D-3D matching, so it covers both advantages.", "On these bases, the applications of some excellent feature extraction #OTHEREFR , feature matching #OTHEREFR and image retrieval #OTHEREFR [3] methods can further improve the camera localization performances individually.", "End-to-End Metrics Regression.", "Metrics regression localization methods aim to regress the camera pose directly from train images with the ground truth poses."], "text_after_citation": ["And it has been extended to video mode using LSTM to extract temporal information #OTHEREFR .", "Later on, #OTHEREFR uses a Bayesian CNN implementation to obtain an estimate of the localization uncertainty and improves the accuracy on the large-scale outdoor datasets.", "AtLoc #OTHEREFR shows that the attention block can be used to force the network to focus on more geometrically robust objects and features, which can learn to reject dynamic objects and illumination conditions to achieve better performance.", "MapNet #OTHEREFR exploits other sensory inputs like visual odometry and GPS in addition to images, and fuses them together for camera localization.", "End-to-End Scene Coordinates Prediction."], "citing_paper_content": {"title": "Sgl: Structure Guidance Learning For Camera Localization", "abstract": "Camera localization is a classical computer vision task that serves various Artificial Intelligence and Robotics applications. With the rapid developments of Deep Neural Networks (DNNs), end-to-end visual localization methods are prosperous in recent years. In this work, we focus on the scene coordinate prediction ones and propose a network architecture named as Structure Guidance Learning (SGL) which utilizes the receptive branch and the structure branch to extract both high-level and low-level features to estimate the 3D coordinates. We design a confidence strategy to refine and filter the predicted 3D observations, which enables us to estimate the camera poses by employing the Perspective-n-Point (PnP) with RANSAC. In the training part, we design the Bundle Adjustment trainer to help the network fit the scenes better. Comparisons with some state-of-the-art (SOTA) methods and sufficient ablation experiments confirm the validity of our proposed architecture."}, "cited_paper_content": {"title": "Geometric Loss Functions For Camera Pose Regression With Deep Learning", "abstract": "Deep learning has shown to be effective for robust and real-time monocular image relocalisation. In particular, PoseNet [22] is a deep convolutional neural network which learns to regress the 6-DOF camera pose from a single image. It learns to localize using high level features and is robust to difficult lighting, motion blur and unknown camera intrinsics, where point based SIFT registration fails. However, it was trained using a naive loss function, with hyper-parameters which require expensive tuning. In this paper, we give the problem a more fundamental theoretical treatment. We explore a number of novel loss functions for learning camera pose which are based on geometry and scene reprojection error. Additionally we show how to automatically learn an optimal weighting to simultaneously regress position and orientation. By leveraging geometry, we demonstrate that our technique significantly improves PoseNets performance across datasets ranging from indoor rooms to a small city."}, "keywords": ["PoseNet"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Metrics regression localization methods aim to regress the camera pose directly from train images with the ground truth poses. To achieve this, novel loss functions based on geometry and scene reprojection error have been explored in #REFR, which significantly improved the performance of PoseNet across datasets ranging from indoor rooms to a small city.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Metrics regression localization methods aim to regress the camera pose directly from train images with the ground truth poses, and novel loss functions based on geometry and scene reprojection error have been proposed to improve the performance of deep learning-based camera pose regression, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "PoseNet was trained using a naive loss function, but the authors of this manuscript propose novel loss functions based on geometry and scene reprojection error to improve camera pose regression with deep learning #REFR.", "given_citation_intent": "method", "given_keywords": ["PoseNet"]}]}
{"citing_id": "2303.13769v1", "cited_id": "1506.01497", "section_title": "Results", "citation": "Observably, on the COCO-OOD dataset, the U-AP of UnSniffer outperforms the 2 nd result by more than twice, and our U-F1 is 16.2% higher than the 2 nd result, at the cost of a 1.9% drop in mAP on VOC compared to Faster-RCNN #REFR .", "text_before_citation": ["Quantitative Analysis.", "In Table 2 , we show UnSniffer's result on the UOD-Benchmark, along with the results of MSP #OTHEREFR , Mahalanobis #OTHEREFR , Energy score #OTHEREFR , ORE #OTHEREFR , OW-DETR #OTHEREFR and VOS #OTHEREFR .", "Note that OW-DETR is based on Deformable DETR #OTHEREFR with a stronger discriminative power, while other methods use Faster-RCNN.", "Since U-PRE or U-REC cannot independently reflect the model's performance, we mainly employ U-AP, U-F1, AOSE and WI."], "text_after_citation": ["On the COCO-Mix dataset, the UnSniffer still holds the lead in both U-AP and U-F1, which are 1% and 11.2% higher than the 2 nd results, respectively.", "Those comparisons demonstrate that UnSniffer outperforms the existing methods in unknown object detection, which owes to our GOC learning the overall confidence of objects from finite known objects.", "Furthermore, UnSniffer has the smallest AOSE (398) but the largest WI (0.175), which can be explained by the inverse relationship between WI and the count of known objects misclassified as an incorrect class. More details are illustrated in the supplementary material. Qualitative Analysis. Fig.", "7 visualizes the results of different methods on example images of the COCO-Mix (first two rows) and COCO-OOD dataset (last three rows).", "It can be seen that VOS #OTHEREFR , MSP #OTHEREFR , Mahalanobis distance #OTHEREFR , and Energy score #OTHEREFR miss many objects of the unknown class, such as the surfboards in the 1 st image, the keyboard and water cup in the 3 rd image, the CD case in the 4 th image."], "citing_paper_content": {"title": "Unknown Sniffer For Object Detection: Don'T Turn A Blind Eye To Unknown Objects", "abstract": "The recently proposed open-world object and open-set detection achieve a breakthrough in finding never-seenbefore objects and distinguishing them from class-known ones. However, their studies on knowledge transfer from known classes to unknown ones need to be deeper, leading to the scanty capability for detecting unknowns hidden in the background. In this paper, we propose the unknown sniffer (UnSniffer) to find both unknown and known objects. Firstly, the generalized object confidence (GOC) score is introduced, which only uses class-known samples for supervision and avoids improper suppression of unknowns in the background. Significantly, such confidence score learned from class-known objects can be generalized to unknown ones. Additionally, we propose a negative energy suppression loss to further limit the non-object samples in the background. Next, the best box of each unknown is hard to obtain during inference due to lacking their semantic information in training. To solve this issue, we introduce a graphbased determination scheme to replace hand-designed nonmaximum suppression (NMS) post-processing. Finally, we present the Unknown Object Detection Benchmark, the first publicly benchmark that encompasses precision evaluation for unknown object detection to our knowledge. Experiments show that our method is far better than the existing state-of-the-art methods."}, "cited_paper_content": {"title": "Faster R-Cnn: Towards Real-Time Object Detection With Region Proposal Networks", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features\u2014using the recently popular terminology of neural networks with \u2019attention\u2019 mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available."}, "keywords": ["COCO-OOD dataset", "Faster-RCNN"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We compare UnSniffer's results on the UOD-Benchmark with those of several state-of-the-art methods, including Faster R-CNN #REFR, and report the performance metrics U-AP, U-F1, AOSE, and WI in Table 2.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "UnSniffer's performance is compared with several state-of-the-art methods, including Faster R-CNN #REFR, on the Unknown Object Detection Benchmark.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our method achieves state-of-the-art results on the COCO-OOD dataset, outperforming Faster-RCNN #REFR and other existing methods in terms of U-AP, U-F1, AOSE, and WI.", "given_citation_intent": "result", "given_keywords": ["COCO-OOD dataset", "Faster-RCNN"]}]}
{"citing_id": "2303.05101v1", "cited_id": "2002.09018", "section_title": "Sgrld In Shampoo Metric", "citation": "To further reduce computational complexity, we can divide the tensors into smaller blocks and treat them as individual tensors instead #REFR .", "text_before_citation": ["by taking the square.", "The computational cost is then C(", "L l=1 d l m=1 (n l ) 3 m ) and the memory cost is C( L l=1 d l m=1 (n l ) 2 m )", ", for some positive constants C.", "These costs are strictly larger than those of the diagonal metrics or the Monge metric, but in practice the metric is updated only periodically (typically after each epoch), and hence the computation remains manageable."], "text_after_citation": ["The following theorem shows the validity of the sampler, with the proof in the Supplement.", "The bound depends on the EMA parameter \u03bb in the same way as the bound for the Monge metric and otherwise follows that of Theorem 2.1.", "Theorem 3.2.", "For SGRLD in the Shampoo metric, we can bound the approximation error as defined in Theo-", "rem 2.1 as E \u03c6 \u2212\u03c6 2 \u2264 C t h 2 t S 2 T E \u2206V t 2 + 1 S T + ( t=1 h 2 t ) 2 S 2 T + O(\u03c4 2 (1 \u2212 \u03bb) 2 )."], "citing_paper_content": {"title": "Scalable Stochastic Gradient Riemannian Langevin Dynamics In Non-Diagonal Metrics", "abstract": "Bayesian neural network inference is often carried out using stochastic gradient sampling methods. For best performance the methods should use a Riemannian metric that improves posterior exploration by accounting for the local curvature, but the existing methods resort to simple diagonal metrics to remain computationally efficient. This loses some of the gains. We propose two non-diagonal metrics that can be used in stochastic samplers to improve convergence and exploration but that have only a minor computational overhead over diagonal metrics. We show that for neural networks with complex posteriors, caused e.g. by use of sparsity-inducing priors, using these metrics provides clear improvements. For some other choices the posterior is sufficiently easy also for the simpler metrics."}, "cited_paper_content": {"title": "Second Order Optimization Made Practical", "abstract": "Optimization in machine learning, both theoretical and applied, is presently dominated by first-order gradient methods such as stochastic gradient descent. Second-order optimization methods that involve second-order derivatives and/or second-order statistics of the data have become far less prevalent despite strong theoretical properties, due to their prohibitive computation, memory and communication costs. ::: In an attempt to bridge this gap between theoretical and practical optimization, we present a proof-of-concept distributed system implementation of a second-order preconditioned method (specifically, a variant of full-matrix Adagrad), that along with a few yet critical algorithmic and numerical improvements, provides significant practical gains in convergence on state-of-the-art deep models and gives rise to actual wall-time improvements in practice compared to conventional first-order methods. Our design effectively utilizes the prevalent heterogeneous hardware architecture for training deep models which consists of a multicore CPU coupled with multiple accelerator units. We demonstrate superior performance on very large learning problems in machine translation where our distributed implementation runs considerably faster than existing gradient-based methods."}, "keywords": ["individual tensors"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In an attempt to bridge the gap between theoretical and practical optimization, the authors present a proof-of-concept distributed system implementation of a second-order preconditioned method that provides significant practical gains in convergence on state-of-the-art deep models and gives rise to actual wall-time improvements in practice compared to conventional first-order methods #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the prohibitive computation and memory costs of second-order optimization methods, the authors of this manuscript propose a proof-of-concept distributed system implementation of a second-order preconditioned method, which provides significant practical gains in convergence and actual wall-time improvements in practice compared to conventional first-order methods #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the computational and memory costs of second-order optimization methods, recent work has proposed a distributed system implementation of a second-order preconditioned method that provides significant practical gains in convergence on state-of-the-art deep models, as well as actual wall-time improvements in practice compared to conventional first-order methods, by utilizing the prevalent heterogeneous hardware architecture for training deep models which consists of a multicore CPU coupled with multiple accelerator units #REFR. This could potentially be useful for handling the computational costs associated with individual tensors.", "given_citation_intent": "method", "given_keywords": ["individual tensors"]}]}
{"citing_id": "2303.12999v1", "cited_id": "1703.03400", "section_title": "B. Machine Learning Model", "citation": "Meanwhile, for each UE, we consider the case that only one step of stochastic gradient descent (SGD) is performed, following the same setting as #REFR .", "text_before_citation": ["We consider the above described MAML-based FL.", "In detail, we concentrate on the situation where UEs communicate in a synchronous manner, so as to avoid using outdated parameters for global model update and make high-quality refinement in each round."], "text_after_citation": ["As for the concerned MAML-based FL, our goal is to optimize the initial model using only a few data points at each UE.", "Hence, we only obtain an estimate of the desired gradient with SGD.", "Here, the desired gradient \u2207F i (w) on UE i is computed using all data points in its dataset D i , while the estimated gradient\u2207F i (w) on UE i is computed using SGD with the sampled dataset D"], "citing_paper_content": {"title": "Automated Federated Learning In Mobile Edge Networks -Fast Adaptation And Convergence", "abstract": "Federated Learning (FL) can be used in mobile edge networks to train machine learning models in a distributed manner. Recently, FL has been interpreted within a Model-Agnostic Meta-Learning (MAML) framework, which brings FL significant advantages in fast adaptation and convergence over heterogeneous datasets. However, existing research simply combines MAML and FL without explicitly addressing how much benefit MAML brings to FL and how to maximize such benefit over mobile edge networks. In this paper, we quantify the benefit from two aspects: optimizing FL hyperparameters (i.e., sampled data size and the number of communication rounds) and resource allocation (i.e., transmit power) in mobile edge networks. Specifically, we formulate the MAML-based FL design as an overall learning time minimization problem, under the constraints of model accuracy and energy consumption. Facilitated by the convergence analysis of MAML-based FL, we decompose the formulated problem and then solve it using analytical solutions and the coordinate descent method. With the obtained FL hyperparameters and resource allocation, we design a MAML-based FL algorithm, called Automated Federated Learning (AutoFL), that is able to conduct fast adaptation and convergence. Extensive experimental results verify that AutoFL outperforms other benchmark algorithms regarding the learning time and convergence performance."}, "cited_paper_content": {"title": "Model-Agnostic Meta-Learning For Fast Adaptation Of Deep Networks", "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies."}, "keywords": ["stochastic gradient descent"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We consider the above described MAML-based FL. In detail, we concentrate on the situation where UEs communicate in a synchronous manner, so as to avoid using outdated parameters for global model update and make high-quality refinement in each round. Recent research has shown that MAML can significantly improve the fast adaptation and convergence of FL over heterogeneous datasets #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We consider the above described MAML-based FL method, which is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We consider the above described MAML-based FL, which is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning #REFR.", "given_citation_intent": "method", "given_keywords": ["stochastic gradient descent"]}]}
{"citing_id": "2304.14133v1", "cited_id": "2003.10421", "section_title": "Problem Definition", "citation": "In contrast to previous works that primarily addressed misinformation detection as a binary classification problem ( #REFR ), we address CMM as a multiclass classification task.", "text_before_citation": ["To investigate the prevalence of AMM, we sampled 200 misleading pairs from the COSMOS benchmark and examined their source articles on Snopes.", "Following the classification taxonomy of Snopes #OTHEREFR we found that 48% of COSMOS pairs are \"false claims\" (41% associative imagery and 7% reinforcing captions) while 52% were classified as \"miscaptioned\", which we consider to be CMM because it implies a relationship between the two modalities.", "After de-duplicating the images of the COSMOS benchmark, the rates were 41% miscaptioned, 35% associative imagery, 4% reinforcing captions and 20% duplicates.", "We performed the same process on Fakeddit for 300 random samples and found that roughly 45% of pairs were AMM, with 41% being manipulated images and 4% with associative imagery.", "Moreover, we consider that roughly 14% of Fakeddit's samples can actually be considered CMM since the remaining 40% were mostly funny memes, visual jokes, pareidolia imagery and other content that is not generally considered to be misinformation #OTHEREFR ."], "text_after_citation": ["In this work, we introduce a taxonomy that includes three classes:", "1.", "Truthful (True): an image-caption pair (I t , C t ) is considered True when the origin, content, and context of an image are accurately described in the accompanying caption.", "2.", "Out-Of-Context (OOC) image-text pairs: involves a deceptive combination of a truthful caption C t and an image that is out of context I x ."], "citing_paper_content": {"title": "Figments And Misalignments: A Framework For Fine-Grained Crossmodal Misinformation Detection", "abstract": "Multimedia content has become ubiquitous on social media platforms, leading to the rise of multimodal misinformation and the urgent need for effective strategies to detect and prevent its spread. This study focuses on CrossModal Misinformation (CMM) where image-caption pairs work together to spread falsehoods. We contrast CMM with Asymmetric Multimodal Misinformation (AMM), where one dominant modality propagates falsehoods while other modalities have little or no influence. We show that AMM adds noise to the training and evaluation process while exacerbating the unimodal bias, where text-only or image-only detectors can seemingly outperform their multimodal counterparts on an inherently multimodal task. To address this issue, we collect and curate FIGMENTS, a robust evaluation benchmark for CMM, which consists of real-world cases of misinformation, excludes AMM and utilizes modality balancing to successfully alleviate unimodal bias. FIGMENTS also provides a first step towards fine-grained CMM detection by including three classes: truthful, out-ofcontext, and miscaptioned image-caption pairs. Furthermore, we introduce a method for generating realistic synthetic training data that maintains crossmodal relations between legitimate images and false human-written captions that we term Crossmodal HArd Synthetic MisAlignment (CHASMA). We conduct extensive comparative study using a Transformer-based architecture. Our results show that incorporating CHASMA in conjunction with other generated datasets consistently improved the overall performance on FIGMENTS in both binary (+6.26%) and multiclass settings (+15."}, "cited_paper_content": {"title": "Multimodal Analytics For Real-World News Using Measures Of Cross-Modal Entity Consistency", "abstract": "The World Wide Web has become a popular source for gathering information and news. Multimodal information, e.g., enriching text with photos, is typically used to convey the news more effectively or to attract attention. Photo content can range from decorative, depict additional important information, or can even contain misleading information. Therefore, automatic approaches to quantify cross-modal consistency of entity representation can support human assessors to evaluate the overall multimodal message, for instance, with regard to bias or sentiment. In some cases such measures could give hints to detect fake news, which is an increasingly important topic in today's society. In this paper, we introduce a novel task of cross-modal consistency verification in real-world news and present a multimodal approach to quantify the entity coherence between image and text. Named entity linking is applied to extract persons, locations, and events from news texts. Several measures are suggested to calculate cross-modal similarity for these entities using state of the art approaches. In contrast to previous work, our system automatically gathers example data from the Web and is applicable to real-world news. Results on two novel datasets that cover different languages, topics, and domains demonstrate the feasibility of our approach. Datasets and code are publicly available to foster research towards this new direction."}, "keywords": ["misinformation detection"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To quantify cross-modal consistency of entity representation in real-world news, the authors of #REFR introduce a novel task of cross-modal consistency verification and present a multimodal approach to quantify the entity coherence between image and text, which could potentially support human assessors to evaluate the overall multimodal message and detect fake news.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our approach to quantify cross-modal similarity for entities using state of the art approaches is inspired by the work of #REFR, who introduced a novel task of cross-modal consistency verification in real-world news.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To detect and prevent the spread of multimodal misinformation, recent studies have focused on CrossModal Misinformation (CMM), where image-caption pairs work together to spread falsehoods, and this study contrasts CMM with Asymmetric Multimodal Misinformation (AMM), where one dominant modality propagates falsehoods while other modalities have little or no influence, and the authors found that AMM adds noise to the training and evaluation process while exacerbating the unimodal bias, which can be alleviated by utilizing modality balancing, as suggested in #REFR.", "given_citation_intent": "result", "given_keywords": ["misinformation detection"]}]}
{"citing_id": "2304.06351v1", "cited_id": "1703.07332", "section_title": "Face Detection", "citation": "First, we generated face annotation for RGB frames using FaceAlignment #REFR , an open-source tool for face analysis 2 .", "text_before_citation": ["Using the synthetic data from the simulator, we generated an annotated dataset in the event spectrum to train a face detector."], "text_after_citation": ["We then bound the face labels with the corresponding synthetic event frames obtained with ESIM.", "This allowed us to train a YOLOv2 #OTHEREFR on the synthetic version of NEFER.", "We found the detector to have good generalization capabilities from synthetic to real event data, which yielded high-quality annotations at a slight cost of manual validation using CVAT #OTHEREFR ."], "citing_paper_content": {"title": "Neuromorphic Event-Based Facial Expression Recognition", "abstract": "Recently, event cameras have shown large applicability in several computer vision fields especially concerning tasks that require high temporal resolution. In this work, we investigate the usage of such kind of data for emotion recognition by presenting NEFER, a dataset for Neuromorphic Event-based Facial Expression Recognition. NEFER is composed of paired RGB and event videos representing human faces labeled with the respective emotions and also annotated with face bounding boxes and facial landmarks. We detail the data acquisition process as well as providing a baseline method for RGB and event data. The collected data captures subtle micro-expressions, which are hard to spot with RGB data, yet emerge in the event domain. We report a double recognition accuracy for the event-based approach, proving the effectiveness of a neuromorphic approach for analyzing fast and hardly detectable expressions and the emotions they conceal."}, "cited_paper_content": {"title": "How Far Are We From Solving The 2D&3D Face Alignment Problem? (And A Dataset Of 230,000 3D Facial Landmarks)", "abstract": "This paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2D and 3D face alignment datasets. To this end, we make the following 5 contributions: (a) we construct, for the first time, a very strong baseline by combining a state-of-the-art architecture for landmark localization with a state-of-the-art residual block, train it on a very large yet synthetically expanded 2D facial landmark dataset and finally evaluate it on all other 2D facial landmark datasets. (b) We create a guided by 2D landmarks network which converts 2D landmark annotations to 3D and unifies all existing datasets, leading to the creation of LS3D-W, the largest and most challenging 3D facial landmark dataset to date ~230,000 images. (c) Following that, we train a neural network for 3D face alignment and evaluate it on the newly introduced LS3D-W. (d) We further look into the effect of all\"traditional\"factors affecting face alignment performance like large pose, initialization and resolution, and introduce a\"new\"one, namely the size of the network. (e) We show that both 2D and 3D face alignment networks achieve performance of remarkable accuracy which is probably close to saturating the datasets used. Training and testing code as well as the dataset can be downloaded from https://www.adrianbulat.com/face-alignment/"}, "keywords": ["face analysis", "FaceAlignment"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Using the synthetic data from the simulator, we generated an annotated dataset in the event spectrum to train a face detector, inspired by the state-of-the-art architecture for landmark localization and residual block presented in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train a face detector on the annotated dataset in the event spectrum, a state-of-the-art architecture for landmark localization combined with a residual block from the reference paper #REFR was used.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To detect faces in the event spectrum for our neuromorphic approach to facial expression recognition, we utilized a state-of-the-art architecture for landmark localization combined with a residual block, as described in the reference paper on #REFR FaceAlignment.", "given_citation_intent": "method", "given_keywords": ["face analysis", "FaceAlignment"]}]}
{"citing_id": "2303.08536v2", "cited_id": "1512.03385", "section_title": "Architecture Details", "citation": "The visual front-end module is comprised of a 3D convolutional layer with a kernel size of 5 \u00d7 7 \u00d7 7 followed by a ResNet18 #REFR .", "text_before_citation": ["We adopt the visual front-end and the audio front-end from #OTHEREFR ."], "text_after_citation": ["Then the output features are squeezed along the spatial dimension by a global average pooling layer.", "The audio front-end module consists of a 1D convolutional layer with blocks of ResNet18.", "Both visual and audio front-ends are initialized using a pre-trained model on LRW #OTHEREFR .", "For the multimodal attention with Conformer encoder #OTHEREFR , we use hidden dimensions of 256, feed-forward dimensions of 2048, 12 layers, 8 attention heads, and a convolution kernel size of 31. We utilize Transformer decoder #OTHEREFR"], "citing_paper_content": {"title": "Watch Or Listen: Robust Audio-Visual Speech Recognition With Visual Corruption Modeling And Reliability Scoring", "abstract": "This paper deals with AudioVisual Speech Recognition (AVSR) under multimodal input corruption situations where audio inputs and visual inputs are both corrupted, which is not well addressed in previous research directions. Previous studies have focused on how to complement the corrupted audio inputs with the clean visual inputs with the assumption of the availability of clean visual inputs. However, in real life, clean visual inputs are not always accessible and can even be corrupted by occluded lip regions or noises. Thus, we firstly analyze that the previous AVSR models are not indeed robust to the corruption of multimodal input streams, the audio and the visual inputs, compared to uni-modal models. Then, we design multimodal input corruption modeling to develop robust AVSR models. Lastly, we propose a novel AVSR framework, namely AudioVisual Reliability Scoring module (AV-RelScore), that is robust to the corrupted multimodal inputs. The AV-RelScore can determine which input modal stream is reliable or not for the prediction and also can exploit the more reliable streams in prediction. The effectiveness of the proposed method is evaluated with comprehensive experiments on popular benchmark databases, LRS2 and LRS3. We also show that the reliability scores obtained by AV-RelScore well reflect the degree of corruption and make the proposed model focus on the reliable multimodal representations."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["3D convolutional layer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We adopt the visual front-end and the audio front-end from #OTHEREFR (Deep Residual Learning For Image Recognition) to develop our robust AVSR models that are capable of handling corrupted multimodal inputs.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To develop a robust AVSR model, the authors utilized a multimodal input corruption modeling approach and proposed a novel AVSR framework that determines the reliability of input modal streams for prediction, which is inspired by the residual learning framework presented in Deep Residual Learning For Image Recognition #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We use 3D convolutional layers to extract spatiotemporal features from the corrupted audio and visual inputs, following the residual learning framework proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["3D convolutional layer"]}]}
{"citing_id": "2303.09295v1", "cited_id": "1812.11842", "section_title": "Generalizable Generated Image Detection", "citation": "It can generalize to unseen generation models to some extent. Marra et al. #REFR and Yu et al.", "text_before_citation": ["However, their strong generalization capability relies on their large-scale training and 20 different models each trained on a different LSUN #OTHEREFR object category.", "Besides detection by spatial artifacts, there are also frequency-based methods #OTHEREFR . Frank et al.", "#OTHEREFR present that in the frequency domain, GAN-generated images are more likely to expose severe artifacts mainly caused by upsampling operations in previous GAN architectures. Zhang et al.", "[51] propose a GAN simulator, AutoGAN, to simulate the artifacts produced by standard GAN pipelines.", "Then they train a detector on the spectrum input on the synthesized images."], "text_after_citation": ["#OTHEREFR suggest detecting generated images by fingerprints that are often produced during GAN generation.", "A recent work #OTHEREFR proposes a detector based on an ensemble of EfficientNet-B4 #OTHEREFR to alleviate the generalization problem.", "However, with the boosting development of diffusion models, a general and robust detector for detecting images generated by diffusion models has not been explored.", "We note that some recent works also notice the diffusiongenerated image detection problem #OTHEREFR .", "Different from them, the focus of our work is exploring a generalizable detector for wide-range diffusion models."], "citing_paper_content": {"title": "Dire For Diffusion-Generated Image Detection", "abstract": "Diffusion models have shown remarkable success in visual synthesis, but have also raised concerns about potential abuse for malicious purposes. In this paper, we seek to build a detector for telling apart real images from diffusiongenerated images. We find that existing detectors struggle to detect images generated by diffusion models, even if we include generated images from a specific diffusion model in their training data. To address this issue, we propose a novel image representation called DIffusion Reconstruction Error (DIRE), which measures the error between an input image and its reconstruction counterpart by a pre-trained diffusion model. We observe that diffusion-generated images can be approximately reconstructed by a diffusion model while real images cannot. It provides a hint that DIRE can serve as a bridge to distinguish generated and real images. DIRE provides an effective way to detect images generated by most diffusion models, and it is general for detecting generated images from unseen diffusion models and robust to various perturbations. Furthermore, we establish a comprehensive diffusion-generated benchmark including images generated by eight diffusion models to evaluate the performance of diffusion-generated image detectors. Extensive experiments on our collected benchmark demonstrate that DIRE exhibits superiority over previous generatedimage detectors. The code and dataset are available at https://github.com/ZhendongWang6/DIRE."}, "cited_paper_content": {"title": "Do Gans Leave Artificial Fingerprints?", "abstract": "In the last few years, generative adversarial networks (GAN) have shown tremendous potential for a number of applications in computer vision and related fields. With the current pace of progress, it is a sure bet they will soon be able to generate high-quality images and videos, virtually indistinguishable from real ones. Unfortunately, realistic GAN-generated images pose serious threats to security, to begin with a possible flood of fake multimedia, and multimedia forensic countermeasures are in urgent need. In this work, we show that each GAN leaves its specific fingerprint in the images it generates, just like real-world cameras mark acquired images with traces of their photo-response non-uniformity pattern. Source identification experiments with several popular GANs show such fingerprints to represent a precious asset for forensic analyses."}, "keywords": ["unseen generation models"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Frank et al. showed that in the frequency domain, GAN-generated images are more likely to expose severe artifacts mainly caused by upsampling operations in previous GAN architectures. Zhang et al. proposed a GAN simulator, AutoGAN, to simulate the artifacts produced by standard GAN pipelines. Then they train a detector on the spectrum input on the synthesized images. In addition, it has been shown that each GAN leaves its specific fingerprint in the images it generates, just like real-world cameras mark acquired images with traces of their photo-response non-uniformity pattern #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Generative adversarial networks (GAN) have shown tremendous potential for a number of applications in computer vision and related fields, and each GAN leaves its specific fingerprint in the images it generates, just like real-world cameras mark acquired images with traces of their photo-response non-uniformity pattern #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In addition to spatial and frequency-based methods, recent research has shown that each GAN leaves its specific fingerprint in the images it generates, which can be used for source identification of unseen generation models #REFR.", "given_citation_intent": "background", "given_keywords": ["unseen generation models"]}]}
{"citing_id": "2303.02302v1", "cited_id": "1711.11279", "section_title": "Related Works", "citation": "On the global level, TCAV #REFR constructs a set of explanatory concepts represented by vectors that are able to separate positive/negative examples in a hidden layer.", "text_before_citation": ["Visual image interpretation.", "In general, research efforts devoted to visual image interpretation can be divided into two groups, post-hoc and self-interpretable.", "Post-hoc methods #OTHEREFR open the black-box models with salient maps or key image parts after the deep network is finished training.", "Most of the interpretative models #OTHEREFR we discussed in the previous paragraph fall into this group, locally explaining a model's prediction for each individual sample.", "Extending these gradient-based methods, some works #OTHEREFR include various additional information to achieve more reasonable explanations."], "text_after_citation": ["On the other hand, self-interpretable #OTHEREFR methods generate explainable representations in an end-to-end training process.", "Recently, ProtoPNet #OTHEREFR proposed a self-interpretable global interpretation method that extracts category-specific prototype vectors associated with image patches of training samples, which serve as an example-based explanation on both global and local levels.", "Later, various methods #OTHEREFR extend ProtoPNet from different aspects, including refined prototype learning module #OTHEREFR and pruning strategies #OTHEREFR to reduce the number of prototypes.", "Unsupervised domain adaptation.", "To align the heterogeneous distributions in source and target domains, previous works focusing on domain adaptation can be roughly separated into two straits."], "citing_paper_content": {"title": "Visualizing Transferred Knowledge: An Interpretive Model Of Unsupervised Domain Adaptation", "abstract": "Many research efforts have been committed to unsupervised domain adaptation (DA) problems that transfer knowledge learned from a labeled source domain to an unlabeled target domain. Various DA methods have achieved remarkable results recently in terms of predicting ability, which implies the effectiveness of the aforementioned knowledge transferring. However, state-of-the-art methods rarely probe deeper into the transferred mechanism, leaving the true essence of such knowledge obscure. Recognizing its importance in the adaptation process, we propose an interpretive model of unsupervised domain adaptation, as the first attempt to visually unveil the mystery of transferred knowledge. Adapting the existing concept of the prototype from visual image interpretation to the DA task, our model similarly extracts shared information from the domain-invariant representations as prototype vectors. Furthermore, we extend the current prototype method with our novel prediction calibration and knowledge fidelity preservation modules, to orientate the learned prototypes to the actual transferred knowledge. By visualizing these prototypes, our method not only provides an intuitive explanation for the base model's predictions but also unveils transfer knowledge by matching the image patches with the same semantics across both source and target domains. Comprehensive experiments and in-depth explorations demonstrate the efficacy of our method in understanding the transferred mechanism and its potential in downstream tasks including model diagnosis."}, "cited_paper_content": {"title": "Interpretability Beyond Feature Attribution: Quantitative Testing With Concept Activation Vectors (Tcav)", "abstract": "The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net's internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result--for example, how sensitive a prediction of \"zebra\" is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application."}, "keywords": ["explanatory concepts"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Extending gradient-based methods for post-hoc interpretative models, some works include various additional information to achieve more reasonable explanations #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of interpreting deep learning models, Concept Activation Vectors (CAVs) were introduced as a technique that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result, which could be useful for the interpretive model of unsupervised domain adaptation proposed in this manuscript. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of interpreting deep learning models, recent research has introduced explanatory concepts such as Concept Activation Vectors (CAVs) #REFR, which provide a human-friendly interpretation of a neural net's internal state in terms of high-level concepts.", "given_citation_intent": "background", "given_keywords": ["explanatory concepts"]}]}
{"citing_id": "2303.14404v1", "cited_id": "1706.04599", "section_title": "Related Work", "citation": "A model trained with NLL provides predictions that deviate from the accuracy, leaving the model poorly calibrated #REFR .", "text_before_citation": ["To improve post-hoc calibration under out-domain scenarios, #OTHEREFR transforms the validation set prior to performing the post-hoc approach.", "In #OTHEREFR , a regression model is used to predict temperature parameter.", "Post-hoc calibration methods are simple and effective, however, they require hold-out validation data, and are dependent on architecture #OTHEREFR .", "Train-time calibration methods: Models trained with zero-entropy supervision tend to give over-confident predictions.", "An example is negative log-likelihood (NLL), which is a widely-used task-specific loss."], "text_after_citation": ["Train-time calibration methods are typically based on auxiliary loss functions, which are used in-tandem with task-specific losses.", "In #OTHEREFR , an auxiliary loss term DCA is proposed to calibrate the model.", "It is combined with a task-specific loss to penalize when it reduces but the accuracy remains unchanged.", "Likewise, #OTHEREFR proposed an auxiliary loss function that is based on a reproducing kernel in a Hilbert space #OTHEREFR .", "#OTHEREFR calibrated uncertainty based on the relationship between accuracy and uncertainty."], "citing_paper_content": {"title": "Bridging Precision And Confidence: A Train-Time Loss For Calibrating Object Detection", "abstract": "Deep neural networks (DNNs) have enabled astounding progress in several vision-based problems. Despite showing high predictive accuracy, recently, several works have revealed that they tend to provide overconfident predictions and thus are poorly calibrated. The majority of the works addressing the miscalibration of DNNs fall under the scope of classification and consider only in-domain predictions. However, there is little to no progress in studying the calibration of DNN-based object detection models, which are central to many vision-based safety-critical applications. In this paper, inspired by the train-time calibration methods, we propose a novel auxiliary loss formulation that explicitly aims to align the class confidence of bounding boxes with the accurateness of predictions (i.e. precision). Since the original formulation of our loss depends on the counts of true positives and false positives in a minibatch, we develop a differentiable proxy of our loss that can be used during training with other application-specific loss functions. We perform extensive experiments on challenging in-domain and out-domain scenarios with six benchmark datasets including MS-COCO, Cityscapes, Sim10k, and BDD100k. Our results reveal that our train-time loss surpasses strong calibration baselines in reducing calibration error for both in and out-domain scenarios. Our source code and pre-trained models are available at https:// github.com/akhtarvision/bpc_calibration"}, "cited_paper_content": {"title": "On Calibration Of Modern Neural Networks", "abstract": "Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions."}, "keywords": ["accuracy"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Train-time calibration methods tend to give over-confident predictions, and negative log-likelihood (NLL) is a widely-used task-specific loss. To address the miscalibration of DNN-based object detection models, a recent study proposed a novel auxiliary loss formulation that explicitly aims to align the class confidence of bounding boxes with the accurateness of predictions. The authors evaluated their approach on various benchmark datasets and achieved superior calibration performance compared to strong calibration baselines. #REFR provides further insights into the factors influencing calibration of modern neural networks and offers a simple and effective recipe for practical settings.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of poorly calibrated modern neural networks, previous work has shown that depth, width, weight decay, and Batch Normalization are important factors influencing calibration, as demonstrated in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent studies have shown that deep neural networks tend to provide overconfident predictions and are poorly calibrated, which can affect their accuracy in real-world applications. As noted in #REFR, modern neural networks are also poorly calibrated, and factors such as depth, width, weight decay, and Batch Normalization can influence calibration.", "given_citation_intent": "background", "given_keywords": ["accuracy"]}]}
{"citing_id": "2303.02641v1", "cited_id": "1708.02002", "section_title": "C. Model Training", "citation": "We use the binary cross-entropy loss for classification and focal loss #REFR to handle class imbalance in the localization task.", "text_before_citation": ["To identify missing signs, the model must attend to the traffic sign cues in the environment. Similar to Han et al.", "#OTHEREFR , we add CueCAn at the end of the third, fourth, and fifth blocks of the VGG-19 #OTHEREFR encoder to highlight and classify the cues.", "The next task is to localize where the sign could be placed using the segmentation model with the pre-trained VGG-19 encoder and FCN-8 #OTHEREFR decoder.", "For localization, optimal results and GradCAM visualizations are observed when the entire network is fine-tuned end-to-end."], "text_after_citation": [], "citing_paper_content": {"title": "Cuecan: Cue-Driven Contextual Attention For Identifying Missing Traffic Signs On Unconstrained Roads", "abstract": "Missing Traffic Sign Scene with Curve Cue Fig. 1: Left: Scenes with real and inpainted traffic signs (chevron-left). Middle: Intermediary GradCAM visualizations of the cue classifier (encoder) with and without CueCAn. Right: Segmentation model with CueCAn-based encoder detects missing signs (green masks overlayed over the scene on the right for CueCAn and yellow mask by the baseline) on the scene without signs (follow pink arrows) by effectively attending to the context cues, compared to weak attention without CueCAn. Segementation GradCAMs are obtained from the centroid of the predicted sign (red dot)."}, "cited_paper_content": {"title": "Focal Loss For Dense Object Detection", "abstract": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron ."}, "keywords": ["localization task", "focal loss"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Similar to Han et al. (REFERENCE PAPER), we add CueCAn at the end of the third, fourth, and fifth blocks of the VGG-19 encoder to highlight and classify the cues.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the class imbalance encountered during training of dense detectors, the authors propose a novel Focal Loss that focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform the localization task, the authors fine-tuned the segmentation model with a pre-trained VGG-19 encoder and FCN-8 decoder, and incorporated the Focal Loss proposed by Lin et al. for addressing the foreground-background class imbalance encountered during training of dense detectors #REFR.", "given_citation_intent": "method", "given_keywords": ["localization task", "focal loss"]}]}
{"citing_id": "2304.00950v1", "cited_id": "1610.06136", "section_title": "Single Camera Systems", "citation": "Currently, the best performing DL based detector is Faster Region\u2212based Convolutional Neural Network (RCNN) from #REFR .", "text_before_citation": ["The survey specifies that most MOT algorithms that are developed to be used with a single camera have four steps/stages in common: detection, feature extraction / motion prediction, affinity, and association.", "The implied aim is to implement DL at every stage and to evaluate the given algorithms as a whole on a MOTChallenge dataset #OTHEREFR . The datasets mostly consist of benchmarks for pedestrian tracking.", "Deep learning is mostly used for the first two stages, while only a few contributions implement DL approaches for affinity and association.", "From this survey #OTHEREFR , the authors emphasize three important parameters to deploy MOT algorithms: (i) the detection quality, (ii) Convolutional Neural Network (CNN) for feature extraction, and (iii) Single Object Tracking (SOT) trackers.", "In terms of detection quality, appropriate detectors must be thoroughly selected to reduce the number of False Negatives (FN) in the Multi\u2212Object Tracking Accuracy (MOTA) score."], "text_after_citation": ["In contrast, Single\u2212Shot Detector (SSD) performs worse, as presented in #OTHEREFR .", "However, SSD was almost able to work in real-time (4.5 FPS), including the detection step.", "For the feature extraction stage #OTHEREFR , the best-performing method, GoogLeNet #OTHEREFR , is applied to the datasets of MOT15 #OTHEREFR , MOT16 and MOT17 #OTHEREFR .", "Approaches that do not use appearance (whether they are deep or conventional methods) typically perform worse.", "Visual features alone, however, are insufficient to compute affinity; many of the better-performing algorithms additionally include other characteristics, particularly motion features."], "citing_paper_content": {"title": "Semi-Automated Computer Vision Based Tracking Of Multiple Industrial Entities -A Framework And Dataset Creation Approach", "abstract": "This contribution presents the TOMIE framework (Tracking Of Multiple Industrial Entities), a framework for the continuous tracking of industrial entities (e.g., pallets, crates, barrels) over a network of, in this example, six RGB cameras. This framework, makes use of multiple sensors, data pipelines and data annotation procedures, and is described in detail in this contribution. With the vision of a fully automated tracking system for industrial entities in mind, it enables researchers to efficiently capture high quality data in an industrial setting. Using this framework, an image dataset, the TOMIE dataset, is created, which at the same time is used to gauge the framework's validity. This dataset contains annotation files for 112,860 frames and 640,936 entity instances that are captured from a set of six cameras that perceive a large indoor space. This dataset out-scales comparable datasets by a factor of four and is made up of scenarios, drawn from industrial applications from the sector of warehousing. Three tracking algorithms, namely ByteTrack, Bot-Sort and SiamMOT are applied to this dataset, serving as a proof-of-concept and providing tracking results that are comparable to the state of the art."}, "cited_paper_content": {"title": "Poi: Multiple Object Tracking With High Performance Detection And Appearance Feature", "abstract": "Detection and learning based appearance feature play the central role in data association based multiple object tracking (MOT), but most recent MOT works usually ignore them and only focus on the hand-crafted feature and association algorithms. In this paper, we explore the high-performance detection and deep learning based appearance feature, and show that they lead to significantly better MOT results in both online and offline setting. We make our detection and appearance feature publicly available. In the following part, we first summarize the detection and appearance feature, and then introduce our tracker named Person of Interest (POI), which has both online and offline version."}, "keywords": ["RCNN"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the Multi-Object Tracking Accuracy (MOTA) score, appropriate detectors must be thoroughly selected to reduce the number of False Negatives (FN), as emphasized by the authors of a recent paper on high-performance detection and appearance feature for multiple object tracking #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the Multi-Object Tracking Accuracy (MOTA) score, appropriate detectors must be selected to reduce the number of False Negatives (FN), and deep learning-based appearance features should be implemented, as demonstrated in the Person of Interest (POI) tracker #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of detection quality, appropriate detectors must be thoroughly selected to reduce the number of False Negatives (FN) in the Multi\u2212Object Tracking Accuracy (MOTA) score, and recent works have shown that deep learning-based detectors such as RCNN can significantly improve the performance of multiple object tracking algorithms #REFR.", "given_citation_intent": "method", "given_keywords": ["RCNN"]}]}
{"citing_id": "2303.00192v1", "cited_id": "1704.00717", "section_title": "Toward Models Of Human Collaboration As Lenses For Studying And Designing Co-Creative Systems", "citation": "This result is in line with studies on human-AI collaboration in decision-making, suggesting that users learn to better predict the machine's behavior through inductive mechanisms (i.e., via concrete examples and hands-on testing) than via general, declarative information about internal processes #REFR .", "text_before_citation": ["Participants had trouble learning to predict how the AI might behave in response to the specified parameters.", "They struggled to make sense of the AI system's reasoning and struggled to correct unwanted design issues.", "Prior literature on group cognition suggests that to achieve effective collaboration group members should be able to interpret each other's reasoning and predict roughly how their partner might behave in response to their own actions #OTHEREFR .", "Similarly, from a team learning perspective, our findings suggest that designers who systematically explored the AI's limitations and capabilities early on were better at predicting the tool's actions in response to their own and produced more satisfactory results."], "text_after_citation": ["While explainable AI research focuses primarily on directly communicating information about the AI system to the user, recent research has suggested that more engaging and longer forms of learning and deliberate practice might improve human-AI collaboration #OTHEREFR .", "However, in addition to supporting honing the user's mental model of the AI's capabilities and limitations, it is equally important for the AI system to have an understanding of the user's capabilities, limitations, and task context to enable more effective human-AI collaboration.", "Hence, this would require the AI system to have better contextual awareness of the user and the current task at hand.", "We further discuss the resulting design opportunities in section 8.3.3.", "Most designers felt the tools were uncollaborative and had more control over the design process than they would have preferred."], "citing_paper_content": {"title": "Exploring Challenges And Opportunities To Support Designers In Learning To Co-Create With Ai-Based Manufacturing Design Tools", "abstract": "AI-based design tools are proliferating in professional software to assist engineering and industrial designers in complex manufacturing and design tasks. These tools take on more agentic roles than traditional computer-aided design tools and are often portrayed as \"co-creators. \" Yet, working effectively with such systems requires different skills than working with complex CAD tools alone. To date, we know little about how engineering designers learn to work with AI-based design tools. In this study, we observed trained designers as they learned to work with two AI-based tools on a realistic design task. We find that designers face many challenges in learning to effectively co-create with current systems, including challenges in understanding and adjusting AI outputs and in communicating their design goals. Based on our findings, we highlight several design opportunities to better support designer-AI co-creation. CCS CONCEPTS \u2022 Human-centered computing \u2192 Empirical studies in HCI; \u2022 Applied computing \u2192 Computer-aided design."}, "cited_paper_content": {"title": "It Takes Two To Tango: Towards Theory Of Ai'S Mind", "abstract": "Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. We further evaluate the role existing explanation (or interpretability) modalities play in helping humans build ToAIM. Explainable AI has received considerable scientific and popular attention in recent times. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior."}, "keywords": ["human-AI collaboration"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Prior literature on group cognition suggests that to achieve effective collaboration group members should be able to interpret each other's reasoning and predict roughly how their partner might behave in response to their own actions (It Takes Two To Tango: Towards Theory Of Ai'S Mind). Similarly, from a team learning perspective, our findings suggest that designers who systematically explored the AI's limitations and capabilities early on were better at predicting the tool's actions in response to their own and produced more satisfactory results.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our findings suggest that designers who systematically explored the AI's limitations and capabilities early on were better at predicting the tool's actions in response to their own and produced more satisfactory results, but struggled to make sense of the AI system's reasoning and correct unwanted design issues #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our findings suggest that designers who systematically explored the AI's limitations and capabilities early on were better at predicting the tool's actions in response to their own and produced more satisfactory results in human-AI collaboration #REFR.", "given_citation_intent": "result", "given_keywords": ["human-AI collaboration"]}]}
{"citing_id": "2303.05996v1", "cited_id": "1709.01015", "section_title": "I. Introduction", "citation": "Unlike Received Signal Strength Indicator (RSSI) based solutions #REFR , 802.11az combines mmWavebased angle estimations with the Time of Flight (ToF) to achieve high accuracy positioning.", "text_before_citation": ["Legacy positioning in 802.11 only knew the distance between devices, thus, there are many feasible locations (blue markers).", "802.11az uses mmWave beamforming to obtain the azimuth and elevation between devices, hence, the exact location (red marker).", "Although 802.11az provides enhancements for sub-6 GHz and Millimiter Wave (mmWave) operation at 60 GHz, the best positioning accuracy is achieved in the latter band.", "Specifically, 802.11az obtains accurate positioning information using 802.11ay Enhanced Directional Multi-Gigabit (EDMG) beamforming #OTHEREFR , along with its accurate Channel State Information (CSI) reports.", "With the orientation of the mmWave beam and CSI reports, 802.11az elaborates angle estimations funded on the ranging accuracy of multi-GHz bandwidths."], "text_after_citation": ["Both the ToF and angle estimations are exchanged using the Fine Timing Measurement (FTM) procedureintroduced in 802.11mc #OTHEREFR -, and Station (STA)s use the exchanged estimations to determine the distance, azimuth and elevation between STAssee Fig. 1 .", "Since mmWave promises to increase positioning accuracy from meter level #OTHEREFR to centimeterlevel #OTHEREFR , #OTHEREFR ; in this article we explain the main contributions of 802.11az for mmWave based positioning:", "FTM procedure over EDMG.", "In the legacy FTM procedure STAs only exchange ToF estima-arXiv:2303.05996v1 [cs.NI] 10 Mar 2023 tions, thus, obtaining just an approximation of the distance.", "802.11az performs the FTM procedure over EDMG to also exchange angle estimations obtained through CSI reports."], "citing_paper_content": {"title": "Ieee 802.11Az Indoor Positioning With Mmwave", "abstract": "Last years we have witnessed the uprising of location based applications, which depend on the devices ability to accurately obtain their position. IEEE 802.11, foretelling the need for such applications, started the IEEE 802.11az work on Next Generation Positioning. Although this standard provides positioning enhancements for sub-6 GHz and mmWave bands, high accuracy in the order of centimeters can only be obtained in the latter band, thanks to the beamforming information available at mmWave operation. This work presents a detailed analysis on the new techniques provided by IEEE 802.11az for enhanced secured positioning in the mmWave band, assessing them through experimentation."}, "cited_paper_content": {"title": "A Survey Of Indoor Localization Systems And Technologies", "abstract": "Indoor localization has recently witnessed an increase in interest, due to the potential wide range of services it can provide by leveraging Internet of Things (IoT), and ubiquitous connectivity. Different techniques, wireless technologies and mechanisms have been proposed in the literature to provide indoor localization services in order to improve the services provided to the users. However, there is a lack of an up-to-date survey paper that incorporates some of the recently proposed accurate and reliable localization systems. In this paper, we aim to provide a detailed survey of different indoor localization techniques, such as angle of arrival (AoA), time of flight (ToF), return time of flight (RTOF), and received signal strength (RSS); based on technologies, such as WiFi, radio frequency identification device (RFID), ultra wideband (UWB), Bluetooth, and systems that have been proposed in the literature. This paper primarily discusses localization and positioning of human users and their devices. We highlight the strengths of the existing systems proposed in the literature. In contrast with the existing surveys, we also evaluate different systems from the perspective of energy efficiency, availability, cost, reception range, latency, scalability, and tracking accuracy. Rather than comparing the technologies or techniques, we compare the localization systems and summarize their working principle. We also discuss remaining challenges to accurate indoor localization."}, "keywords": ["mmWavebased angle estimations", "high accuracy positioning"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Indoor localization techniques have been proposed in the literature to improve the services provided to the users, and a recent survey paper provides a detailed overview of different techniques, such as angle of arrival (AoA), time of flight (ToF), return time of flight (RTOF), and received signal strength (RSS), based on technologies such as WiFi, RFID, UWB, and Bluetooth #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "802.11az utilizes mmWave beamforming to obtain accurate positioning information, as discussed in the survey paper on indoor localization systems and technologies #REFR, which highlights the strengths of different indoor localization techniques based on technologies such as WiFi, RFID, UWB, and Bluetooth.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "802.11az achieves high accuracy positioning by using mmWave-based angle estimations, which are elaborated on the ranging accuracy of multi-GHz bandwidths #REFR.", "given_citation_intent": "method", "given_keywords": ["mmWavebased angle estimations", "high accuracy positioning"]}]}
{"citing_id": "2303.10753v1", "cited_id": "1803.04755", "section_title": "Related Works:", "citation": "Masuda and Holme #REFR used a graph distance measure and hierarchical clustering to detect and cluster evolving states in social temporal networks.", "text_before_citation": ["The authors illustrate the usefulness of their approach by applying it to synthetic datasets such as the Barabasi-Albert graphs and small world graphs.", "(3) Change Point Detection in Social Networks.", "In the field of change point detection in social networks, Wang et al.", "#OTHEREFR proposed an algorithm based on a Markov generative process to analyze graph snapshots of dynamic social networks.", "The algorithm was tested on real-world networks, including political voting networks, but it fails to account for long-term dependence and assumes rare changes."], "text_after_citation": ["Their approach assumes the entire network system is described by a single system state, which could be relaxed to multi-state setup for social networks with community structure. Zhao et al.", "#OTHEREFR introduced a model-free change point detection method for dynamic social networks that uses neighborhood smoothing to estimate edge probabilities.", "However, the algorithm is not applicable to directed networks or networks with an evolving number of nodes. Grattarola et al.", "#OTHEREFR proposed a data-driven method for detecting changes in stationarity in a stream of attributed graphs.", "They used an adversarial autoencoder to embed graphs on constant-curvature manifolds, and employed the Fr\u00e9chet mean to represent the average of networks."], "citing_paper_content": {"title": "Fr\u00e9chet Statistics Based Change Point Detection In Dynamic Social Networks", "abstract": "This paper proposes a method to detect change points in dynamic social networks using Fr\u00e9chet statistics. We address two main questions: (1) what metric can quantify the distances between graph Laplacians in a dynamic network and enable efficient computation, and (2) how can the Fr\u00e9chet statistics be extended to detect multiple change points while maintaining the significance level of the hypothesis test? Our solution defines a metric space for graph Laplacians using the Log-Euclidean metric, enabling a closed-form formula for Fr\u00e9chet mean and variance. We present a framework for change point detection using Fr\u00e9chet statistics and extend it to multiple change points with binary segmentation. The proposed algorithm uses incremental computation for Fr\u00e9chet mean and variance to improve efficiency and is validated on simulated and two real-world datasets, namely the UCI message dataset and the Enron email dataset."}, "cited_paper_content": {"title": "Detecting Sequences Of System States In Temporal Networks", "abstract": "Many time-evolving systems in nature, society and technology leave traces of the interactions within them. These interactions form temporal networks that reflect the states of the systems. In this work, we pursue a coarse-grained description of these systems by proposing a method to assign discrete states to the systems and inferring the sequence of such states from the data. Such states could, for example, correspond to a mental state (as inferred from neuroimaging data) or the operational state of an organization (as inferred by interpersonal communication). Our method combines a graph distance measure and hierarchical clustering. Using several empirical data sets of social temporal networks, we show that our method is capable of inferring the system's states such as distinct activities in a school and a weekday state as opposed to a weekend state. We expect the methods to be equally useful in other settings such as temporally varying protein interactions, ecological interspecific interactions, functional connectivity in the brain and adaptive social networks."}, "keywords": ["social temporal networks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In the field of inferring sequences of system states from temporal networks, #REFR proposed a method that combines a graph distance measure and hierarchical clustering to assign discrete states to the systems and infer the sequence of such states from the data.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To assign discrete states to temporal networks, the authors propose a method that combines a graph distance measure and hierarchical clustering, which has been shown to be effective in inferring the system's states from empirical data sets of social temporal networks such as distinct activities in a school and a weekday state as opposed to a weekend state #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Hierarchical clustering combined with a graph distance measure was used to infer the sequence of states in social temporal networks, as demonstrated by the authors in #REFR.", "given_citation_intent": "method", "given_keywords": ["social temporal networks"]}]}
{"citing_id": "2303.01667v1", "cited_id": "1501.01809", "section_title": "Ge 2", "citation": "We use Firedrake #REFR to discretize (4.1) with linear finite elements on tetrahedra, and select an average of 25 points per cluster.", "text_before_citation": ["Indeed, this is reflected in the convergence shown in Figure 11 , where we observe a dramatic reduction in the number of iterations for solvers with these clusters.", "It is, of course, important to note that not every clustering generated by standard Lloyd exhibits similarly poor performance.", "The quality of the initial clustering used to seed the algorithm plays an important role in determining the multigrid performance.", "Results seen here are for a representative, randomly generated, initial seeding. rotated about the z-axis, (see Table 1 ).", "A 3D tetrahedral mesh with 16 921 elements is generated with Gmsh #OTHEREFR through pygmsh #OTHEREFR ."], "text_after_citation": ["2D restricted channel: The 2D domain \u2126 is defined by [\u22122, 2] \u00d7 [\u22121, 1] \\ C with C = C + \u222a C \u2212 , for C \u00b1 representing discs of radius 0.8 at (0, \u00b11) (see Table 1 ).", "As for the 3D restricted channel, we use Gmsh to generate a graded, triangular mesh with 5832 elements, with a characteristic length of 0.012 at the center and growing to 0.12 at the left/right edges.", "This forces tighter clustering toward the center, as shown in Table 1 .", "The discretization matrix for (4.1) is constructed with linear finite elements, and we target clusters of size 8.", "2D anisotropic diffusion: The 2D domain is defined by the unit square, and we consider the problem \u2212\u2207 \u2022 K\u2207u = f with pure Dirchlet conditions."], "citing_paper_content": {"title": "Generalizing Lloyd'S Algorithm For Graph Clustering *", "abstract": "Clustering is a commonplace problem in many areas of data science, with applications in biology and bioinformatics, understanding chemical structure, image segmentation, building recommender systems, and many more fields. While there are many different clustering variants (based on given distance or graph structure, probability distributions, or data density), we consider here the problem of clustering nodes in a graph, motivated by the problem of aggregating discrete degrees of freedom in multigrid and domain decomposition methods for solving sparse linear systems. Specifically, we consider the challenge of forming balanced clusters in the graph of a sparse matrix for use in algebraic multigrid, although the algorithm has general applicability. Based on an extension of the Bellman-Ford algorithm, we generalize Lloyd's algorithm for partitioning subsets of R n to balance the number of nodes in each cluster; this is accompanied by a rebalancing algorithm that reduces the overall energy in the system. The algorithm provides control over the number of clusters and leads to \"well centered\" partitions of the graph. Theoretical results are provided to establish linear complexity and numerical results in the context of algebraic multigrid highlight the benefits of improved clustering."}, "cited_paper_content": {"title": "Firedrake: Automating The Finite Element Method By Composing Abstractions", "abstract": "Firedrake is a new tool for automating the numerical solution of partial differential equations. Firedrake adopts the domain-specific language for the finite element method of the FEniCS project, but with a pure Python runtime-only implementation centered on the composition of several existing and new abstractions for particular aspects of scientific computing. The result is a more complete separation of concerns that eases the incorporation of separate contributions from computer scientists, numerical analysts, and application specialists. These contributions may add functionality or improve performance. Firedrake benefits from automatically applying new optimizations. This includes factorizing mixed function spaces, transforming and vectorizing inner loops, and intrinsically supporting block matrix operations. Importantly, Firedrake presents a simple public API for escaping the UFL abstraction. This allows users to implement common operations that fall outside of pure variational formulations, such as flux limiters."}, "keywords": ["cluster", "linear finite elements"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Indeed, this is reflected in the convergence shown in Figure 11, where we observe a dramatic reduction in the number of iterations for solvers with these clusters. It is, of course, important to note that not every clustering generated by standard Lloyd exhibits similarly poor performance. The quality of the initial clustering used to seed the algorithm plays an important role in determining the multigrid performance. Results seen here are for a representative, randomly generated, initial seeding. rotated about the z-axis, (see Table 1). A 3D tetrahedral mesh with 16 921 elements is generated with Gmsh #OTHEREFR through pygmsh #OTHEREFR. Firedrake, a new tool for automating the numerical solution of partial differential equations, is a pure Python runtime-only implementation centered on the composition of several existing and new abstractions for particular aspects of scientific computing, which includes factorizing mixed function spaces, transforming and vectorizing inner loops, and intrinsically supporting block matrix operations. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To automate the numerical solution of partial differential equations, the authors of this manuscript could benefit from using Firedrake, a tool that adopts the domain-specific language for the finite element method of the FEniCS project, but with a pure Python runtime-only implementation centered on the composition of several existing and new abstractions for particular aspects of scientific computing, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To form balanced clusters in the graph of a sparse matrix for use in algebraic multigrid, the authors generalized Lloyd's algorithm for partitioning subsets of R^n to balance the number of nodes in each cluster, which is accompanied by a rebalancing algorithm that reduces the overall energy in the system, using linear finite elements, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["cluster", "linear finite elements"]}]}
{"citing_id": "2304.09648v1", "cited_id": "1511.05952", "section_title": "Reinforcement Learning", "citation": "Prioritized Experience Replay (PER) #REFR is a technique for experience replay which involves replaying transitions with a high expected learning progress, as determined by the size of their temporal-difference (TD) error, more frequently than others.", "text_before_citation": ["Directly replacing the tabular Q functions with nonlinear function approximators such neural networks sometimes makes the training of RL agents generally hard to converge #OTHEREFR .", "Potential reasons are correlated states or observations and optimization towards an unstable target. Experience replay is a successful method for addressing non-i.i.d. sampling.", "The original setting of experience replay #OTHEREFR is to sample a batch of transitions uniformly from the replay memory and optimize the model.", "Although this approach is viable, it may not be the most efficient method since the model may acquire more knowledge from certain transitions and less from others.", "For example, experiences that led to large rewards or that resulted in the agent making a significant error are likely to be more informative than experiences that had little impact on the agent's behavior."], "text_after_citation": ["The probability of sampling the transition i is defined to be", "P (i) = p \u03b1 i k p \u03b1 k", "where p i > 0 is the priority of transition i.", "The parameter \u03b1 controls how much the prioritization is used.", "It means sampling transitions uniformly from the replay memory when \u03b1 = 0."], "citing_paper_content": {"title": "Quantum Deep Q Learning With Distributed Prioritized Experience Replay", "abstract": "This paper introduces the QDQN-DPER framework to enhance the efficiency of quantum reinforcement learning (QRL) in solving sequential decision tasks. The framework incorporates prioritized experience replay and asynchronous training into the training algorithm to reduce the high sampling complexities. Numerical simulations demonstrate that QDQN-DPER outperforms the baseline distributed quantum Q learning with the same model architecture. The proposed framework holds potential for more complex tasks while maintaining training efficiency."}, "cited_paper_content": {"title": "Prioritized Experience Replay", "abstract": "Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games."}, "keywords": ["Prioritized Experience Replay"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Prioritized experience replay has been proposed to replay important transitions more frequently and learn more efficiently #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of inefficient learning from certain transitions, prioritized experience replay has been proposed to replay important transitions more frequently, as demonstrated in the state-of-the-art performance of Deep Q-Networks with prioritized experience replay #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of inefficient learning from certain transitions, the authors propose a framework for prioritizing experience, called Prioritized Experience Replay, which replays important transitions more frequently and leads to more efficient learning #REFR.", "given_citation_intent": "method", "given_keywords": ["Prioritized Experience Replay"]}]}
{"citing_id": "2304.03608v2", "cited_id": "1811.11168", "section_title": "Gflops", "citation": "Compared to the network with vanilla convolution (fifth row), the network with DCN #REFR in the last two blocks (2xDCN) increases the computation by only 0.1 GFLOPs and the running time by only 0.8 ms.", "text_before_citation": ["Feature Extraction: For accurate visual measurements, the extracted image feature should have a good localization performance and a large respective field on the image for a robust descriptor extraction.", "We expect to achieve these goals by improving the baseline network ALIKE-N #OTHEREFR .", "As shown in the first two rows of Table IX, we start by changing max-pooling to average-pooling (AVG) and ReLU to SELU #OTHEREFR .", "These changes improve the mAA(10\u00b0) on the IMW-validation #OTHEREFR by 3.43% but have limited improvements on the other metrics.", "Furthermore, for geometric invariance feature extraction, we replace the vanilla convolutions in the last two blocks with DCN #OTHEREFR as shown in the sixth and seventh rows of Table IX."], "text_after_citation": ["Besides improving the MS@3 on the Hpatches [50] by 2.81%, this change also improves the mAA(10\u00b0) and MS@3 on the IMW-validation #OTHEREFR by 4.36% and 3.28%, respectively.", "Since the first two blocks have higher feature resolution, using DCN #OTHEREFR would significantly increase the computational cost.", "Moreover, since the front blocks are responsible for low-level feature extraction, using DCN #OTHEREFR may degrade performance.", "Therefore, we use DCN #OTHEREFR only in the last two blocks.", "Score Head: Due to computational cost considerations, the baseline network has a score head of only one 1 \u00d7 1 convolutional layer."], "citing_paper_content": {"title": "Aliked: A Lighter Keypoint And Descriptor Extraction Network Via Deformable Transformation", "abstract": "Image keypoints and descriptors play a crucial role in many visual measurement tasks. In recent years, deep neural networks have been widely used to improve the performance of keypoint and descriptor extraction. However, the conventional convolution operations do not provide the geometric invariance required for the descriptor. To address this issue, we propose the Sparse Deformable Descriptor Head (SDDH), which learns the deformable positions of supporting features for each keypoint and constructs deformable descriptors. Furthermore, SDDH extracts descriptors at sparse keypoints instead of a dense descriptor map, which enables efficient extraction of descriptors with strong expressiveness. In addition, we relax the neural reprojection error (NRE) loss from dense to sparse to train the extracted sparse descriptors. Experimental results show that the proposed network is both efficient and powerful in various visual measurement tasks, including image matching, 3D reconstruction, and visual relocalization."}, "cited_paper_content": {"title": "Deformable Convnets V2: More Deformable, Better Results", "abstract": "The superior performance of Deformable Convolutional Networks arises from its ability to adapt to the geometric variations of objects. Through an examination of its adaptive behavior, we observe that while the spatial support for its neural features conforms more closely than regular ConvNets to object structure, this support may nevertheless extend well beyond the region of interest, causing features to be influenced by irrelevant image content. To address this problem, we present a reformulation of Deformable ConvNets that improves its ability to focus on pertinent image regions, through increased modeling power and stronger training. The modeling power is enhanced through a more comprehensive integration of deformable convolution within the network, and by introducing a modulation mechanism that expands the scope of deformation modeling. To effectively harness this enriched modeling capability, we guide network training via a proposed feature mimicking scheme that helps the network to learn features that reflect the object focus and classification power of R-CNN features. With the proposed contributions, this new version of Deformable ConvNets yields significant performance gains over the original model and produces leading results on the COCO benchmark for object detection and instance segmentation."}, "keywords": ["vanilla convolution"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Furthermore, for geometric invariance feature extraction, we replace the vanilla convolutions in the last two blocks with DCN (Deformable Convolutional Networks) as shown in the sixth and seventh rows of Table IX, following the reformulation proposed in Deformable Convnets V2: More Deformable, Better Results #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the geometric invariance of feature extraction, the authors replaced the vanilla convolutions with DCN, which has been shown to adapt to the geometric variations of objects #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the geometric invariance feature extraction, the authors replaced the vanilla convolutions in the last two blocks with DCN, as shown in the sixth and seventh rows of Table IX, which was proposed in Deformable Convnets V2: More Deformable, Better Results #REFR.", "given_citation_intent": "background", "given_keywords": ["vanilla convolution"]}]}
{"citing_id": "2304.01560v1", "cited_id": "1909.06492", "section_title": "I. Introduction", "citation": "Reference #REFR first reconstructs a harvesting function from samples by deep learning regression, and then, it optimizes constellation points for modulation by autoencoders based on neural networks.", "text_before_citation": ["In particular in #OTHEREFR , a nonlinear analytic model for a harvesting circuit is derived by approximating an ideal diode's characteristics via the Taylor series, and based on the model, it proposes to use multisine waveforms to deliver the largest energy.", "However, this approach has limitations because individual components' laws may not even follow ideal circuit laws due to coupling effect, parasitic capacitors, etc., and then such approximation errors could accumulate.", "For example, the parasitic components resulting from interrelationships make it difficult to analytically describe an equivalent end-to-end model for a circuit containing diodes.", "Indeed, the true end-to-end energy harvesting function may only be available through experimental samples or circuit simulations #OTHEREFR - #OTHEREFR .", "Inspired by this, recent literature attempts to take experimental samples and use a deep learning approach."], "text_after_citation": ["Reference #OTHEREFR focuses on the memory effect of harvesting circuits.", "To capture the memory effect, it proposes a Markov decision process (MDP) model for the harvesting circuit and uses neural networks to estimate the MDP's parameters from data created by a circuit simulator.", "Despite their success in practice, the deep learning approach has a critical drawback in that it generally provides no theoretical performance guarantees.", "In addition, since optimization via deep learning is a black-box algorithm, it generally provides limited insights into SIET.", "For instance, it cannot answer how many experimental samples are needed to attain a particular performance or how close our SIET design is to the optimal SIET."], "citing_paper_content": {"title": "Information And Energy Transmission With Wavelet-Reconstructed Harvesting Functions", "abstract": "In practical simultaneous information and energy transmission (SIET), the exact energy harvesting function is usually unavailable because an energy harvesting circuit is nonlinear and nonideal. In this work, we consider a SIET problem where the harvesting function is accessible only at experimentally-taken sample points and study how close we can design SIET to the optimal system with such sampled knowledge. Assuming that the harvesting function is of bounded variation that may have discontinuities, we separately consider two settings where samples are taken without and with additive noise. For these settings, we propose to design a SIET system as if a waveletreconstructed harvesting function is the true one and study its asymptotic performance loss of energy and information delivery from the true optimal one. Specifically, for noiseless samples, it is shown that designing SIET as if the wavelet-reconstructed harvesting function is the truth incurs asymptotically vanishing energy and information delivery loss with the number of samples. For noisy samples, we propose to reconstruct wavelet coefficients via soft-thresholding estimation. Then, we not only obtain similar asymptotic losses to the noiseless case but also show that the energy loss by wavelets is asymptotically optimal up to a logarithmic factor."}, "cited_paper_content": {"title": "Learning To Communicate And Energize: Modulation, Coding And Multiple Access Designs For Wireless Information-Power Transmission", "abstract": "The explosion of the number of low-power devices in the next decades calls for a re-thinking of wireless network design, namely, unifying wireless transmission of information and power so as to make the best use of the RF spectrum, radiation, and infrastructure for the dual purpose of communicating and energizing. This paper provides a novel learning-based approach towards such wireless network design. To that end, a parametric model of a practical energy harvester, accounting for various sources of nonlinearities, is proposed using a nonlinear regression algorithm applied over collected real data. Relying on the proposed model, the learning problem of modulation design for Simultaneous Wireless Information-Power Transmission (SWIPT) over a point-to-point link is studied. Joint optimization of the transmitter and the receiver is implemented using Neural Network (NN)-based autoencoders. The results reveal that by increasing the receiver power demand, the baseband transmit modulation constellation converges to an On-Off keying signalling. Utilizing the observations obtained via learning, an algorithmic SWIPT modulation design is proposed. It is observed via numerical results that the performance loss of the proposed modulations are negligible compared to the ones obtained from learning. Extension of the studied problem to learning modulation design for multi-user SWIPT scenarios and coded modulation design for point-to-point SWIPT are considered. The major conclusion of this work is to utilize learning-based results to design non learning-based algorithms, which perform as well. In particular, inspired by the results obtained via learning, an algorithmic approach for coded modulation design is proposed, which performs very close to its learning counterparts, and is significantly superior due to its high real-time adaptability to new system design parameters."}, "keywords": ["harvesting function", "autoencoders"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Inspired by recent literature that utilizes experimental samples and a deep learning approach, the authors propose a learning-based approach towards wireless network design for simultaneous wireless information-power transmission (SWIPT) in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent literature attempts to take experimental samples and use a deep learning approach to derive a parametric model of a practical energy harvester, accounting for various sources of nonlinearities, as proposed in #REFR, for modulation design in simultaneous wireless information-power transmission scenarios.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent literature attempts to take experimental samples and use a deep learning approach to derive a nonlinear analytic model for a harvesting circuit, as proposed in #REFR, and implement joint optimization of the transmitter and the receiver using autoencoders for modulation design in Simultaneous Wireless Information-Power Transmission (SWIPT) scenarios.", "given_citation_intent": "method", "given_keywords": ["harvesting function", "autoencoders"]}]}
{"citing_id": "2304.12399v1", "cited_id": "1807.02874", "section_title": "C. Outline", "citation": "In Section IV we compare our result with the converse bound which follows from #REFR , and with another code construction that does not allow for efficient encoding. Section V concludes the main part of the paper.", "text_before_citation": ["The paper is organized as follows.", "In Section II, we introduce important definitions and notations that are used throughout the paper.", "We present our code construction and explain all its components in Section III.", "The main result is formulated in Theorem 1 and its proof is divided into Lemmas 1-6."], "text_after_citation": [], "citing_paper_content": {"title": "Codes Correcting A Single Long Duplication Error", "abstract": "We consider the problem of constructing a code capable of correcting a single long tandem duplication error of variable length. As the main contribution of this paper, we present a q-ary efficiently encodable code of length n + 1 and redundancy 1 that can correct a single duplication of length at least K = 4 \u2022 log q n + 1. The complexity of encoding is O(n 2 log n) and the complexity of decoding is O(n). We also present a q-ary non-efficient code of length n + 1 correcting single long duplication of length at least K = log q n + \u03c6(n), where \u03c6(n) \u2192 \u221e as n \u2192 \u221e. This code has redundancy less than 1 for sufficiently large n. Moreover, we show that in the class of codes correcting a single long duplication with redundancy 1, the value K in our constructions is order-optimal."}, "cited_paper_content": {"title": "Bounds And Constructions For Multi-Symbol Duplication Error Correcting Codes", "abstract": "In this paper, we study codes correcting $t$ duplications of $\\ell$ consecutive symbols. These errors are known as tandem duplication errors, where a sequence of symbols is repeated and inserted directly after its original occurrence. Using sphere packing arguments, we derive non-asymptotic upper bounds on the cardinality of codes that correct such errors for any choice of parameters. Based on the fact that a code correcting insertions of $t$ zero-blocks can be used to correct $t$ tandem duplications, we construct codes for tandem duplication errors. We compare the cardinalities of these codes with their sphere packing upper bounds. Finally, we discuss the asymptotic behavior of the derived codes and bounds, which yields insights about the tandem duplication channel."}, "keywords": ["efficient encoding"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In Section III, we present our code construction and explain all its components. The main result is formulated in Theorem 1 and its proof is divided into Lemmas 1-6. To construct codes for correcting tandem duplication errors, we use the fact that a code correcting insertions of $t$ zero-blocks can be used to correct $t$ tandem duplications #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Based on sphere packing arguments, the authors of this manuscript derive non-asymptotic upper bounds on the cardinality of codes that correct tandem duplication errors, and compare them with the cardinalities of the codes they construct. The results are presented in Section III and Theorem 1, and show that their constructed codes have redundancy less than 1 for sufficiently large n, which is an improvement over the codes presented in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently encode a code capable of correcting a single long tandem duplication error, we refer to the code construction presented in the reference paper by bounding the cardinality of codes that correct tandem duplication errors using sphere packing arguments #REFR.", "given_citation_intent": "result", "given_keywords": ["efficient encoding"]}]}
{"citing_id": "2303.06907v1", "cited_id": "1905.08409", "section_title": "Proposed Method", "citation": "To improve the model performance in 360 \u2022 IQA task, we utilize tangent image representation #REFR to reduce the distortion of the viewports extracted from the ERP image.", "text_before_citation": ["Our sampling module then extracts tangent viewports from salient regions of the distorted image in ERP format.", "The main VQA module resembles the one used in #OTHEREFR , but the patch encoding block is re-modeled from the ground up to deal with the special structure of 360 \u2022 images.", "To effectively encode input viewports into a sequence of tokens, we incorporate positional, geometric and source embeddings into the extracted sequence of tokens, and add a learnable classification token (CLS) to capture the global representation for the image.", "The corresponding 360\u00b0image quality score is predicted by the output of a fully connected layer on top of the final CLS token representation at the output of the Transformer encoder. Sampling Module.", "Most 360 \u2022 IQA datasets store images in the ERP format, which is the most popular spherical image representation, but is known to have significant distortions."], "text_after_citation": ["Moreover, to distinguish visually important parts of a panoramic image, we designed a sampling strategy motivated by the human visual attention mechanism.", "In particular, we employ the 360 \u2022 image saliency prediction model named ATSal #OTHEREFR to predict salient regions of the panorama.", "In this way, one can assign a saliency score for each patch extracted from the omnidirectional image, which we utilize in our sampling module.", "Our main motivation behind our saliency-guided sampling scheme is to combine neural attention (self-attention) mechanism with human visual attention in a simple and intuitive manner.", "At the first step of the sampling module, an input image in ERP format is fed to the ATSal saliency prediction model to predict a saliency map showing which regions are most likely to attract attention."], "citing_paper_content": {"title": "St360Iq: No-Reference Omnidirectional Image Quality Assessment With Spherical Vision Transformers", "abstract": "Omnidirectional images, aka 360 \u2022 images, can deliver immersive and interactive visual experiences. As their popularity has increased dramatically in recent years, evaluating the quality of 360 \u2022 images has become a problem of interest since it provides insights for capturing, transmitting, and consuming this new media. However, directly adapting quality assessment methods proposed for standard natural images for omnidirectional data poses certain challenges. These models need to deal with very high-resolution data and implicit distortions due to the spherical form of the images. In this study, we present a method for noreference 360 \u2022 image quality assessment. Our proposed ST360IQ model extracts tangent viewports from the salient parts of the input omnidirectional image and employs a vision-transformers based module processing saliency selective patches/tokens that estimates a quality score from each viewport. Then, it aggregates these scores to give a final quality score. Our experiments on two benchmark datasets, namely OIQA and CVIQ datasets, demonstrate that as compared to the state-of-the-art, our approach predicts the quality of an omnidirectional image correlated with the human-perceived image quality. The code has been available on https://github.com/Nafiseh-Tofighi/ST360IQ"}, "cited_paper_content": {"title": "Convolutions On Spherical Images", "abstract": "Applying convolutional neural networks to spherical images requires particular considerations. We look to the millennia of work on cartographic map projections to provide the tools to define an optimal representation of spherical images for the convolution operation. We propose a representation for deep spherical image inference based on the icosahedral Snyder equal-area (ISEA) projection, a projection onto a geodesic grid, and show that it vastly exceeds the state-of-the-art for convolution on spherical images, improving semantic segmentation results by 12.6%."}, "keywords": ["tangent image representation", "360 \u2022 IQA"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To effectively encode input viewports into a sequence of tokens, the authors incorporate positional, geometric, and source embeddings into the extracted sequence of tokens, and add a learnable classification token (CLS) to capture the global representation for the image. The corresponding 360\u00b0image quality score is predicted by the output of a fully connected layer on top of the final CLS token representation at the output of the Transformer encoder. Sampling Module. Most 360 \u2022 IQA datasets store images in the ERP format, which is the most popular spherical image representation, but is known to have significant distortions. The proposed method for deep spherical image inference based on the icosahedral Snyder equal-area (ISEA) projection in #REFR vastly exceeds the state-of-the-art for convolution on spherical images, improving semantic segmentation results by 12.6%.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To effectively encode input viewports into a sequence of tokens, the authors incorporate positional, geometric, and source embeddings into the extracted sequence of tokens, and add a learnable classification token (CLS) to capture the global representation for the image, as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To effectively encode input viewports into a sequence of tokens, the authors incorporate positional, geometric, and source embeddings into the extracted sequence of tokens, and add a learnable classification token (CLS) to capture the global representation for the image, as proposed in the reference paper on convolutions on spherical images #REFR, which provides a suitable tangent image representation for 360 \u2022 IQA.", "given_citation_intent": "method", "given_keywords": ["tangent image representation", "360 \u2022 IQA"]}]}
{"citing_id": "2303.09677v1", "cited_id": "1905.10887", "section_title": "Per-Class Analysis", "citation": "These findings improve upon those of #REFR , where a pre-trained BigGAN showed little to no correlation between FID and classification accuracy in a similar setting, strengthening the position of instance-conditioned models such as (CC-)IC-GAN. We observe similar trends for DeiT-B (see Appendix B).", "text_before_citation": ["In this analysis, we shed some light on the problematic (CC-)IC-GAN modeling of certain classes.", "We believe that computing stratified results for generative models might be a good practice to be adopted by the community, as also supported by #OTHEREFR .", "Nevertheless, the observed positive correlation between high classification accuracy and (CC-)IC-GAN's generation quality -studied through the lens of per-class FID and NN corruption-constitutes a promising result to improve the effectiveness of DA IC-GAN .", "To this end, we ran an additional experiment where we avoid applying DA IC-GAN on classes having very high FID (>= 150), i.e., where (CC-)IC-GAN has very low generation quality. We report the results in Appendix B.", "Notably, the impact of leveraging DA IC-GAN could be potentially improved by increasing the generation quality of the (CC-)IC-GAN's poorly modeled classes."], "text_after_citation": [], "citing_paper_content": {"title": "Instance-Conditioned Gan Data Augmentation For Representation Learning", "abstract": "Data augmentation has become a crucial component to train state-of-the-art visual representation models. However, handcrafting combinations of transformations that lead to improved performances is a laborious task, which can result in visually unrealistic samples. To overcome these limitations, recent works have explored the use of generative models as learnable data augmentation tools, showing promising results in narrow application domains, e.g., few-shot learning and low-data medical imaging. In this paper, we introduce a data augmentation module, called DA IC-GAN , which leverages instance-conditioned GAN generations and can be used off-the-shelf in conjunction with most state-of-the-art training recipes. We showcase the benefits of DA IC-GAN by plugging it out-of-the-box into the supervised training of ResNets and DeiT models on the ImageNet dataset, and achieving accuracy boosts up to between 1%p and 2%p with the highest capacity models. Moreover, the learnt representations are shown to be more robust than the baselines when transferred to a handful of out-of-distribution datasets, and exhibit increased invariance to variations of instance and viewpoints. We additionally couple DA IC-GAN with a self-supervised training recipe and show that we can also achieve an improvement of 1%p in accuracy in some settings. With this work, we strengthen the evidence on the potential of learnable data augmentations to improve visual representation learning, paving the road towards non-handcrafted augmentations in model training."}, "cited_paper_content": {"title": "Classification Accuracy Score For Conditional Generative Models", "abstract": "Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes\u2014variational autoencoders, autoregressive models, and generative adversarial networks (GANs)\u2014to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9% and 41.6%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric."}, "keywords": ["CC-)IC-GAN"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the effectiveness of DA IC-GAN, computing stratified results for generative models might be a good practice to be adopted by the community, as also supported by #OTHEREFR. Nevertheless, the observed positive correlation between high classification accuracy and (CC-)IC-GAN's generation quality constitutes a promising result to improve the effectiveness of DA IC-GAN. (CC-)IC-GAN is a class-conditional generative model from the reference paper \"Classification Accuracy Score For Conditional Generative Models\".", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' findings on the poor performance of GANs in inferring class labels of real data are consistent with those of #REFR, which showed that conditional generative models from other model classes, such as VQ-VAE-2 and HAMs, outperformed GANs on this benchmark.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our analysis reveals that (CC-)IC-GAN modeling of certain classes is problematic, and computing stratified results for generative models might be a good practice to be adopted by the community, as also supported by #OTHEREFR. However, the observed positive correlation between high classification accuracy and (CC-)IC-GAN's generation quality constitutes a promising result to improve the effectiveness of DA IC-GAN, as shown in #REFR.", "given_citation_intent": "result", "given_keywords": ["CC-)IC-GAN"]}]}
{"citing_id": "2304.08222v1", "cited_id": "1801.00868", "section_title": "Intra-Batch Supervision", "citation": "From these results, we find that IBS yields a consistent but modest improvement on the Panoptic Quality (PQ) metric #REFR .", "text_before_citation": ["We apply our Intra-Batch Supervision (IBS) to two stateof-the-art unified panoptic segmentation methods, and evaluate the performance on two high-resolution datasets in Table 2 ."], "text_after_citation": ["This is mainly caused by a boost in the PQ for things classes, PQ th , which consistently shows considerable improvements.", "This is expected, because the aim of our IBS is to improve the confusion problem that occurs for thing segments.", "As explained in Section 3.3, however, the ability of the PQ metric to capture errors for large objects of frequently-occuring classes, such as the confusion problem that we are addressing, is limited.", "To better capture this, we also report on the pixel accuracy (Acc th ) and pixel precision (Prec th ) for things classes.", "For these metrics, we observe much more significant improvements, e.g., a +5.8 improvement for both metrics for Panoptic FCN on Cityscapes, and +4.0 and +5.3 for Mask2Former on Mapillary Vistas."], "citing_paper_content": {"title": "Intra-Batch Supervision For Panoptic Segmentation On High-Resolution Images", "abstract": "Unified panoptic segmentation methods are achieving state-of-the-art results on several datasets. To achieve these results on high-resolution datasets, these methods apply crop-based training. In this work, we find that, although crop-based training is advantageous in general, it also has a harmful side-effect. Specifically, it limits the ability of unified networks to discriminate between large object instances, causing them to make predictions that are confused between multiple instances. To solve this, we propose Intra-Batch Supervision (IBS), which improves a network's ability to discriminate between instances by introducing additional supervision using multiple images from the same batch. We show that, with our IBS, we successfully address the confusion problem and consistently improve the performance of unified networks. For the high-resolution Cityscapes and Mapillary Vistas datasets, we achieve improvements of up to +2.5 on the Panoptic Quality for thing classes, and even more considerable gains of up to +5.8 on both the pixel accuracy and pixel precision, which we identify as better metrics to capture the confusion problem. PQ th Acc th 51.1 85.1 PQ th Acc th 52.2 81.3 PQ th Acc th 54.7 87.1 (a) Full-image training (b) Crop-based training (c) Crop-based training + IBS (ours)"}, "cited_paper_content": {"title": "Panoptic Segmentation", "abstract": "We propose and study a task we name panoptic segmentation (PS). Panoptic segmentation unifies the typically distinct tasks of semantic segmentation (assign a class label to each pixel) and instance segmentation (detect and segment each object instance). The proposed task requires generating a coherent scene segmentation that is rich and complete, an important step toward real-world vision systems. While early work in computer vision addressed related image/scene parsing tasks, these are not currently popular, possibly due to lack of appropriate metrics or associated recognition challenges. To address this, we propose a novel panoptic quality (PQ) metric that captures performance for all classes (stuff and things) in an interpretable and unified manner. Using the proposed metric, we perform a rigorous study of both human and machine performance for PS on three existing datasets, revealing interesting insights about the task. The aim of our work is to revive the interest of the community in a more unified view of image segmentation. For more analysis and up-to-date results, please check the arXiv version of the paper: {\\small\\url{https://arxiv.org/abs/1801.00868}}."}, "keywords": ["consistent"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We apply our Intra-Batch Supervision (IBS) to two state-of-the-art unified panoptic segmentation methods, and evaluate the performance on two high-resolution datasets in Table 2. Our proposed method successfully addresses the confusion problem and consistently improves the performance of unified networks, achieving improvements of up to +2.5 on the Panoptic Quality for thing classes, and even more considerable gains of up to +5.8 on both the pixel accuracy and pixel precision, which we identify as better metrics to capture the confusion problem. To achieve these results, we draw inspiration from the panoptic segmentation task proposed in #REFR, which unifies the typically distinct tasks of semantic segmentation and instance segmentation.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our proposed Intra-Batch Supervision (IBS) method with two state-of-the-art unified panoptic segmentation methods on high-resolution datasets, achieving improvements of up to +5.8 on both pixel accuracy and pixel precision, as well as up to +2.5 on Panoptic Quality for thing classes, as reported in Table 2, demonstrating the effectiveness of our approach in addressing the confusion problem caused by crop-based training. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our proposed Intra-Batch Supervision (IBS) method with state-of-the-art unified panoptic segmentation methods on high-resolution datasets and achieve consistent improvements of up to +2.5 on the Panoptic Quality for thing classes, and even more considerable gains of up to +5.8 on both the pixel accuracy and pixel precision, which we identify as better metrics to capture the confusion problem (#REFR). The results are consistent with the findings in the reference paper.", "given_citation_intent": "result", "given_keywords": ["consistent"]}]}
{"citing_id": "2303.11212v1", "cited_id": "1806.02296", "section_title": "Introduction", "citation": "However, as shown in #REFR , such requirements are unrealistic on the widely-used denoisers mentioned above, as they do not have symmetric Jacobians.", "text_before_citation": ["PnP versions of proximal algorithms have been used to solve image restoration problems such as for example PnP-PGD in #OTHEREFR , PnP-ADMM and PnP-DRS in #OTHEREFR and PnP-HQS in #OTHEREFR .", "In #OTHEREFR an explicit regularisation by denoising (RED) strategy was designed in terms of an explicit function R(\u2022) defined, for generic image denoiser D, by:", "R(x) := 1 2 x T (x \u2212 D(x)).", "Under conditions of local homogeneity, non-expansiveness, and Jacobian symmetry, D was shown to be indeed equivalent to a gradient step on R #OTHEREFR , that is,", "D(x) = x \u2212 \u2207R(x)."], "text_after_citation": ["In order to overcome this limitation, in #OTHEREFR , the authors proposed to formulate, similar to RED, a gradient step denoiser of the form:", "EQUATION", "where R \u03c3 : R n 2 \u2192 R is a scalar function parameterised by a neural network", "N \u03c3 : R n 2 \u2192 R n 2 .", "Interestingly, under mild structural assumption on D \u03c3 , the authors are able to prove sound convergence guarantees for the underlying nonconvex optimisation problem defined in terms of a non-trivial (but explicit) regularisation function R(\u2022)."], "citing_paper_content": {"title": "Fluctuation-Based Deconvolution In Fluorescence Microscopy Using Plug-And-Play Denoisers", "abstract": "The spatial resolution of images of living samples obtained by fluorescence microscopes is physically limited due to the diffraction of visible light, which makes the study of entities of size less than the diffraction barrier (around 200 nm in the x-y plane) very challenging. To overcome this limitation, several deconvolution and super-resolution techniques have been proposed. Within the framework of inverse problems, modern approaches in fluorescence microscopy reconstruct a superresolved image from a temporal stack of frames by carefully designing suitable hand-crafted sparsity-promoting regularisers. Numerically, such approaches are solved by proximal gradient-based iterative schemes. Aiming at obtaining a reconstruction more adapted to sample geometries (e.g. thin filaments), we adopt a plug-and-play denoising approach with convergence guarantees and replace the proximity operator associated with the explicit image regulariser with an image denoiser (i.e. a pretrained network) which, upon appropriate training, mimics the action of an implicit prior. To account for the independence of the fluctuations between molecules, the model relies on second-order statistics. The denoiser is then trained on covariance images coming from data representing sequences of fluctuating fluorescent molecules with filament structure. The method is evaluated on both simulated and real fluorescence microscopy images, showing its ability to correctly reconstruct filament structures with high values of peak signal-to-noise ratio (PSNR)."}, "cited_paper_content": {"title": "Regularization By Denoising: Clarifications And New Interpretations", "abstract": "Regularization by denoising (RED), as recently proposed by Romano, Elad, and Milanfar, is powerful image-recovery framework that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function. Experimental evidence suggests that the RED algorithms are a state of the art. We claim, however, that explicit regularization does not explain the RED algorithms. In particular, we show that many of the expressions in the paper by Romano et al. hold only when the denoiser has a symmetric Jacobian, and we demonstrate that such symmetry does not occur with practical denoisers such as nonlocal means, BM3D, TNRD, and DnCNN. To explain the RED algorithms, we propose a new framework called Score-Matching by Denoising (SMD), which aims to match a \u201cscore\u201d (i.e., the gradient of a log-prior). We then show tight connections between SMD, kernel density estimation, and constrained minimum mean-squared error denoising. Furthermore, we interpret the RED algorithms from Romano et al. and propose new algorithms with acceleration and convergence guarantees. Finally, we show that the RED algorithms seek a consensus equilibrium solution, which facilitates a comparison to plug-and-play ADMM."}, "keywords": ["widely-used denoisers"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In a recent paper, Romano et al. proposed an explicit regularization by denoising (RED) strategy that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "An explicit regularization by denoising (RED) strategy was previously designed for image restoration problems, where the denoiser is defined as an explicit function and shown to be equivalent to a gradient step under certain conditions #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The explicit regularization by denoising (RED) strategy proposed in #REFR, which is based on a plug-in image-denoising function, has been widely used to solve image restoration problems, but it holds only when the denoiser has a symmetric Jacobian, which is not the case for practical denoisers such as nonlocal means, BM3D, TNRD, and DnCNN.", "given_citation_intent": "background", "given_keywords": ["widely-used denoisers"]}]}
{"citing_id": "2303.10949v1", "cited_id": "2002.02562", "section_title": "Introduction", "citation": "In this paper, we mainly focus on the Transformer-Transducer (T-T) architecture #REFR and investigate cross-modality learning methods to leverage text-only data for improving the performance of the Mandarin-English code-switching ASR system.", "text_before_citation": ["Selfsupervised pretraining with multi-lingual unlabeled data without code-switching speech has also been shown effective to improve the performance of Mandarin-English code-switching ASR #OTHEREFR .", "Transducer-based ASR model is very attractive in the industry since it provides a natural way for streaming.", "However, it is not so straightforward to utilize unspoken text data except converting to synthesized speech or the features from TTS with a high computational cost #OTHEREFR .", "There is no attention mechanism between the encoder and the decoder.", "Although the prediction module plays as a Language Model (LM), it is different from the conventional LM due to the blank token #OTHEREFR that makes it harder to leverage external LM."], "text_after_citation": [], "citing_paper_content": {"title": "Code-Switching Text Generation And Injection In Mandarin-English Asr", "abstract": "Code-switching speech refers to a means of expression by mixing two or more languages within a single utterance. Automatic Speech Recognition (ASR) with End-to-End (E2E) modeling for such speech can be a challenging task due to the lack of data. In this study, we investigate text generation and injection for improving the performance of an industry commonly-used streaming model, Transformer-Transducer (T-T), in Mandarin-English code-switching speech recognition. We first propose a strategy to generate codeswitching text data and then investigate injecting generated text into T-T model explicitly by Text-To-Speech (TTS) conversion or implicitly by tying speech and text latent spaces. Experimental results on the T-T model trained with a dataset containing 1,800 hours of real Mandarin-English code-switched speech show that our approaches to inject generated code-switching text significantly boost the performance of T-T models, i.e., 16% relative Token-based Error Rate (TER) reduction averaged on three evaluation sets, and the approach of tying speech and text latent spaces is superior to that of TTS conversion on the evaluation set which contains more homogeneous data with the training set."}, "cited_paper_content": {"title": "Transformer Transducer: A Streamable Speech Recognition Model With Transformer Encoders And Rnn-T Loss", "abstract": "In this paper we present an end-to-end speech recognition model with Transformer encoders that can be used in a streaming speech recognition system. Transformer computation blocks based on self-attention are used to encode both audio and label sequences independently. The activations from both audio and label encoders are combined with a feed-forward layer to compute a probability distribution over the label space for every combination of acoustic frame position and label history. This is similar to the Recurrent Neural Network Transducer (RNN-T) model, which uses RNNs for information encoding instead of Transformer encoders. The model is trained with the RNN-T loss well-suited to streaming decoding. We present results on the LibriSpeech dataset showing that limiting the left context for self-attention in the Transformer layers makes decoding computationally tractable for streaming, with only a slight degradation in accuracy. We also show that the full attention version of our model beats the-state-of-the art accuracy on the LibriSpeech benchmarks. Our results also show that we can bridge the gap between full attention and limited attention versions of our model by attending to a limited number of future frames."}, "keywords": ["Mandarin-English code-switching ASR"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Transducer-based ASR models have been shown to provide a natural way for streaming, but utilizing unspoken text data can be challenging without converting to synthesized speech or the features from TTS with a high computational cost #OTHEREFR. However, recent studies have shown that Transformer Transducer, an end-to-end speech recognition model with Transformer encoders, can be used in a streaming speech recognition system, and has achieved state-of-the-art accuracy on the LibriSpeech benchmarks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors propose a Transformer-Transducer (T-T) model for Mandarin-English code-switching speech recognition, which is improved by injecting generated code-switching text using Text-To-Speech (TTS) conversion or tying speech and text latent spaces #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The Transformer-Transducer (T-T) model proposed in #REFR is effective for Mandarin-English code-switching ASR, and the authors' approach of injecting generated code-switching text significantly improves its performance.", "given_citation_intent": "method", "given_keywords": ["Mandarin-English code-switching ASR"]}]}
{"citing_id": "2303.10611v1", "cited_id": "2001.03799", "section_title": "Ablation Study", "citation": "The effect of recurrent time is similar to DuDoRNet #REFR and results are included in supplementary materials.", "text_before_citation": ["The reason for this design is that we weigh the utility of image reconstruction network and the synergy between image and K-space reconstruction networks over K-space reconstruction.", "For K-GLIM and I-LDE, we try applying it to the other domain, both leading to performance drops. This demonstrates our design is domain-specific.", "For X-TL, \u03b8 x is set to 1 by default, corresponding to the best choice for \u03b8 i .", "As a result, only \u03b8 k is modified in the last row.", "By gradually changing DuDoRNet to ours, our method also provides a possible hybridizing strategy for current CNN models."], "text_after_citation": [], "citing_paper_content": {"title": "Dudornext: A Hybrid Model For Dual-Domain Undersampled Mri Reconstruction", "abstract": "Undersampled MRI reconstruction is crucial for accelerating clinical scanning procedures. Recent deep learning methods for MRI reconstruction adopt CNN or ViT as backbone, which lack in utilizing the complementary properties of CNN and ViT. In this paper, we propose DuDoRNeXt, whose backbone hybridizes CNN and ViT in an domainspecific, intra-stage way. Besides our hybrid vertical layout design, we introduce domain-specific modules for dual-domain reconstruction, namely image-domain parallel local detail enhancement and k-space global initialization. We evaluate different conventions of MRI reconstruction including image-domain, k-space-domain, and dual-domain reconstruction with a reference protocol on the IXI dataset and an in-house multicontrast dataset. DuDoRNeXt achieves significant improvements over competing deep learning methods."}, "cited_paper_content": {"title": "Dudornet: Learning A Dual-Domain Recurrent Network For Fast Mri Reconstruction With Deep T1 Prior", "abstract": "MRI with multiple protocols is commonly used for diagnosis, but it suffers from a long acquisition time, which yields the image quality vulnerable to say motion artifacts. To accelerate, various methods have been proposed to reconstruct full images from undersampled k-space data. However, these algorithms are inadequate for two main reasons. Firstly, aliasing artifacts generated in the image domain are structural and non-local, so that sole image domain restoration is insufficient. Secondly, though MRI comprises multiple protocols during one exam, almost all previous studies only employ the reconstruction of an individual protocol using a highly distorted undersampled image as input, leaving the use of fully-sampled short protocol (say T1) as complementary information highly underexplored. In this work, we address the above two limitations by proposing a Dual Domain Recurrent Network (DuDoRNet) with deep T1 prior embedded to simultaneously recover k-space and images for accelerating the acquisition of MRI with a long imaging protocol. Specifically, a Dilated Residual Dense Network (DRDNet) is customized for dual domain restorations from undersampled MRI data. Extensive experiments on different sampling patterns and acceleration rates demonstrate that our method consistently outperforms state-of-the-art methods, and can achieve SSIM up to 0.99 at $6 \\times$ acceleration."}, "keywords": ["DuDoRNet"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the limitations of previous studies in MRI reconstruction, the authors propose a Dual Domain Recurrent Network (DuDoRNet) with deep T1 prior embedded, which achieves superior results compared to state-of-the-art methods, as demonstrated in their experiments on different sampling patterns and acceleration rates. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our method consistently outperforms state-of-the-art methods, achieving SSIM up to 0.99 at $6 \\times$ acceleration, as demonstrated in extensive experiments on different sampling patterns and acceleration rates #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our method outperforms state-of-the-art methods, achieving SSIM up to 0.99 at $6 \\times$ acceleration, as demonstrated in extensive experiments on different sampling patterns and acceleration rates, and is based on a Dual Domain Recurrent Network (DuDoRNet) with deep T1 prior embedded for accelerating the acquisition of MRI with a long imaging protocol. #REFR", "given_citation_intent": "result", "given_keywords": ["DuDoRNet"]}]}
{"citing_id": "2305.00595v1", "cited_id": "2001.08922", "section_title": "Anomaly Detection Approaches For Univariate Time Series", "citation": "RePAD #REFR is an online real-time lightweight unsupervised time series anomaly detection approaches based on LSTM and the Look-Back and Predict-Forward strategy.", "text_before_citation": ["Greenhouse #OTHEREFR ) is a time series anomaly detection algorithm based on Long Short-Term Memory (LSTM), which is a special recurrent neural network suitable for long-term dependent tasks #OTHEREFR .", "Greenhouse adopts a Look-Back and Predict-Forward strategy to learn the distribution of the training data.", "For a given time point, a window of most recently observed data point values are used to predict future data point values.", "However, Greenhouse is not an online approach since its LSTM model is trained with a pre-collected training data.", "Besides, it requires users to determine a proper detection threshold."], "text_after_citation": ["RePAD utilizes a simple LSTM network (with only one hidden layer and ten hidden units) to train a LSTM model with shortterm historical data points, predict each upcoming data point, and then decide if each data point is anomalous based on a dynamically calculated detection threshold.", "Different from Greenhouse, RePAD does not need to go through any offline training.", "Instead, RePAD trains its LSTM model on the fly.", "RePAD will keep using the same LSTM model if the model predicts well.", "When the prediction error of the model is higher than or equal to a dynamically calculated detection threshold, RePAD will retrain another new model with recent data points."], "citing_paper_content": {"title": "Impact Of Deep Learning Libraries On Online Adaptive Lightweight Time Series Anomaly Detection", "abstract": "Providing online adaptive lightweight time series anomaly detection without human intervention and domain knowledge is highly valuable. Several such anomaly detection approaches have been introduced in the past years, but all of them were only implemented in one deep learning library. With the development of deep learning libraries, it is unclear how different deep learning libraries impact these anomaly detection approaches since there is no such evaluation available. Randomly choosing a deep learning library to implement an anomaly detection approach might not be able to show the true performance of the approach. It might also mislead users in believing one approach is better than another. Therefore, in this paper, we investigate the impact of deep learning libraries on online adaptive lightweight time series anomaly detection by implementing two state-of-the-art anomaly detection approaches in three well-known deep learning libraries and evaluating how these two approaches are individually affected by the three deep learning libraries. A series of experiments based on four real-world open-source time series datasets were conducted. The results provide a good reference to select an appropriate deep learning library for online adaptive lightweight anomaly detection. ter decisions (Kieu et al."}, "cited_paper_content": {"title": "Repad: Real-Time Proactive Anomaly Detection For Time Series", "abstract": "During the past decade, many anomaly detection approaches have been introduced in different fields such as network monitoring, fraud detection, and intrusion detection. However, they require understanding of data pattern and often need a long off-line period to build a model or network for the target data. Providing real-time and proactive anomaly detection for streaming time series without human intervention and domain knowledge is highly valuable since it greatly reduces human effort and enables appropriate countermeasures to be undertaken before a disastrous damage, failure, or other harmful event occurs. However, this issue has not been well studied yet. To address it, this paper proposes RePAD, which is a Real-time Proactive Anomaly Detection algorithm for streaming time series based on unsupervised Long Short-Term Memory (LSTM). RePAD utilizes short-term historic data points to predict and determine whether or not the upcoming data point is a sign that an anomaly is likely to happen in the near future. By dynamically adjusting the detection threshold over time, RePAD is able to tolerate minor pattern change in time series and detect anomalies either proactively or on time. Experiments based on two time series datasets collected from the Numenta Anomaly Benchmark demonstrate that RePAD is able to proactively detect anomalies and provide early warnings in real time without human intervention and domain knowledge."}, "keywords": ["LSTM", "anomaly detection approaches"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "RePAD, a Real-time Proactive Anomaly Detection algorithm for streaming time series based on unsupervised Long Short-Term Memory (LSTM), is proposed in the reference paper #REFR. RePAD utilizes short-term historic data points to predict and determine whether or not the upcoming data point is a sign that an anomaly is likely to happen in the near future.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide real-time and proactive anomaly detection for streaming time series without human intervention and domain knowledge, RePAD, a Real-time Proactive Anomaly Detection algorithm based on unsupervised Long Short-Term Memory (LSTM), was proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of real-time and proactive anomaly detection for streaming time series, RePAD, a Real-time Proactive Anomaly Detection algorithm based on unsupervised LSTM, was proposed in the reference paper #REFR, which utilizes short-term historic data points to predict and determine whether or not the upcoming data point is a sign that an anomaly is likely to happen in the near future, and is able to detect anomalies either proactively or on time by dynamically adjusting the detection threshold over time, making it a promising alternative to traditional anomaly detection approaches.", "given_citation_intent": "method", "given_keywords": ["LSTM", "anomaly detection approaches"]}]}
{"citing_id": "2304.02277v2", "cited_id": "1903.03894", "section_title": "I. Introduction", "citation": "Although there is no location information in a graph, we can still locate the most (least) important area in a graph, like in an image, by using some explanation techniques #REFR .", "text_before_citation": ["Moreover, based on the improvement of the explanation techniques in the graph domain, #OTHEREFR proposed injecting the trigger into the most important or least important area of the sample.", "However, that work does not provide any experimental analysis to confirm the assumptions made.", "Also, there is no work so far on using explanation tools to explain the backdoor attack behavior in the graph domain. This work first raises a core question:", "What is the attack performance when injecting trigger into the most or least important area of the sample?", "To answer this question, we explore the impacts of the backdoor trigger-injecting position from the perspective of the most (MIAS) or least important area of the sample (LIAS)."], "text_after_citation": ["As shown in experiments, we demonstrate that the attack performance of LIAS is better, where the difference from MIAS can even be significant. This observation inspires one further question:", "Can we explain this difference? There are already some works on explaining backdoor attacks in the image domain through visualization techniques #OTHEREFR , #OTHEREFR .", "For example, #OTHEREFR plotted the average activations of the backdoored model's last convolutional layer over clean and backdoored images to explain their attack.", "#OTHEREFR used the Grad-CAM #OTHEREFR visualization method to explain the backdoor attack in federated learning.", "One example of explaining a backdoor attack in the image domain with Grad-CAM is shown in Fig. 1 ."], "citing_paper_content": {"title": "Rethinking The Trigger-Injecting Position In Graph Backdoor Attack", "abstract": "Backdoor attacks have been demonstrated as a security threat for machine learning models. Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-ofthe-art performance on the clean inputs. While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample. There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively. Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant. Furthermore, we explain these two strategies' similar (better) attack performance through explanation techniques, which results in a further understanding of backdoor attacks in GNNs."}, "cited_paper_content": {"title": "Gnnexplainer: Generating Explanations For Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GnnExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs."}, "keywords": ["graph", "explanation techniques"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Moreover, based on the improvement of the explanation techniques in the graph domain, #OTHEREFR proposed injecting the trigger into the most important or least important area of the sample. However, that work does not provide any experimental analysis to confirm the assumptions made. Also, there is no work so far on using explanation tools to explain the backdoor attack behavior in the graph domain. This work first raises a core question: What is the attack performance when injecting trigger into the most or least important area of the sample? To answer this question, we explore the impacts of the backdoor trigger-injecting position from the perspective of the most (MIAS) or least important area of the sample (LIAS). We compare our results with the state-of-the-art approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task proposed in Gnnexplainer: Generating Explanations For Graph Neural Networks. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address this question, recent work has proposed injecting the trigger into the most or least important area of the sample, but without providing any experimental analysis to confirm the assumptions made or using explanation tools to explain the backdoor attack behavior in the graph domain (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the lack of explanation techniques for backdoor attacks in the graph domain, this work proposes a novel approach that injects the trigger into the most or least important area of the sample, and explains the backdoor attack behavior using #REFR's model-agnostic GnnExplainer method.", "given_citation_intent": "method", "given_keywords": ["graph", "explanation techniques"]}]}
{"citing_id": "2303.13555v1", "cited_id": "2001.04385", "section_title": "Hybrid Model", "citation": "Here we followed the recent literature #REFR , where one layer and no more than 50 neurons are usually required to find the missing term in the differential equation.", "text_before_citation": ["The isotherm calculation one of the nodes in the computational graph -the one located leftmost layer.", "This variable is then concatenated with the adsorbed amount and used as an input of the ANN that predicts the instantaneous uptake rate.", "The structure of the ANN is usually chosen before training it.", "In traditional deep learning, hyperparameter optimization is usually used to select the best architecture for a problem.", "However, this is rarely explored in hybrid modeling as the training procedure is significantly more computationally demanding than in traditional deep learning."], "text_after_citation": ["In the present work, one-layer ANNs with hyperbolic tangent activation were used for all cases and a varying number of neurons between 15 and 25 with grid search.", "Learning rates were set to 0.05 with Adaptive moment estimation (ADAM) optimizer #OTHEREFR and exponential learning rate decay every 20 iterations and 0.985 drop factor over 180 iterations.", "After the second fit with ADAM, the quasi-newton Broyden-Fletcher-Goldfarb-Shanno (BFGS) method #OTHEREFR was employed until convergence."], "citing_paper_content": {"title": "Efficient Hybrid Modeling And Sorption Model Discovery For Non-Linear Advection-Diffusion-Sorption Systems: A Systematic Scientific Machine Learning Approach", "abstract": "This study presents a systematic machine learning approach for creating efficient hybrid models and discovering sorption uptake models in non-linear advection-diffusion-sorption systems. It demonstrates an effective method to train these complex systems using gradientbased optimizers, adjoint sensitivity analysis, and JIT-compiled vector Jacobian products, combined with spatial discretization and adaptive integrators. Sparse and symbolic regression were employed to identify missing functions in the artificial neural network. The robustness of the proposed method was tested on an in-silico data set of noisy breakthrough curve observations of fixed-bed adsorption, resulting in a well-fitted hybrid model. The study successfully reconstructed sorption uptake kinetics using sparse and symbolic regression, and accurately predicted breakthrough curves using identified polynomials, highlighting the potential of the proposed framework for discovering sorption kinetic law structures."}, "cited_paper_content": {"title": "Universal Differential Equations For Scientific Machine Learning", "abstract": "In the context of science, the well-known adage \"a picture is worth a thousand words\" might well be \"a model is worth a thousand datasets.\" Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring \"big data\". In this work we develop a new methodology, universal differential equations (UDEs), which augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating climate simulations by 15,000x, can be handled by training UDEs."}, "keywords": ["50 neurons"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The training procedure for hybrid modeling is significantly more computationally demanding than in traditional deep learning, and the structure of the artificial neural network is usually chosen before training it. However, a recent methodology called universal differential equations (UDEs) #REFR can augment scientific models with machine-learnable structures for scientifically-based learning, allowing for the discovery of previously unknown governing equations and accurate extrapolation beyond the original data in a time and data-efficient manner.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the computational demand of traditional deep learning in hybrid modeling, sparse and symbolic regression were employed to identify missing functions in the artificial neural network, as proposed in the universal differential equations (UDEs) method #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the computational demand of hybrid modeling, sparse and symbolic regression were employed to identify missing functions in the artificial neural network, as proposed in the universal differential equations (UDEs) method #REFR, which has been shown to handle computationally-difficult modeling issues across scientific disciplines, including discovering biological mechanisms and accelerating climate simulations by 15,000x, while requiring only 50 neurons.", "given_citation_intent": "method", "given_keywords": ["50 neurons"]}]}
{"citing_id": "2304.03998v1", "cited_id": "cs/9605103", "section_title": "Introduction", "citation": "In general, the policy iteration-based algorithms converge faster than value iteration-based algorithms #REFR , which is another reason for the superior performance of our approach. Our experimental results further support our arguments.", "text_before_citation": ["NNDP attacker's policy #OTHEREFR trains the model against one defensive plan at a time, due to which it forgets the previous plan. This way, it keeps learning and forgetting the plans.", "However, we train our RL based attacker's policy against multiple defensive plans at a time, due to which it learns shared experience and performs better.", "For RL agent, diverse environment configurations are only different in the \"opening games\", whereas the \"end games\" or \"mid games\" are likely to be similar across different environments.", "The similarity in later stages can be utilized in parallel training, where the agent is trained against multiple environments simultaneously and gains shared experience, leading to faster convergence and improved performance.", "Besides, NNDP approach is value iteration-based RL algorithm, whereas our approach is policy iteration-based RL algorithm."], "text_after_citation": [], "citing_paper_content": {"title": "Evolving Reinforcement Learning Environment To Minimize Learner'S Achievable Reward: An Application On Hardening Active Directory Systems", "abstract": "We study a Stackelberg game between one attacker and one defender in a configurable environment. The defender picks a specific environment configuration. The attacker observes the configuration and attacks via Reinforcement Learning (RL trained against the observed environment). The defender's goal is to find the environment with minimum achievable reward for the attacker. We apply Evolutionary Diversity Optimization (EDO) to generate diverse population of environments for training. Environments with clearly high rewards are killed off and replaced by new offsprings to avoid wasting training time. Diversity not only improves training quality but also fits well with our RL scenario: RL agents tend to improve gradually, so a slightly worse environment earlier on may become better later. We demonstrate the effectiveness of our approach by focusing on a specific application, Active Directory (AD). AD is the default security management system for Windows domain networks. AD environment describes an attack graph, where nodes represent computers/accounts/etc., and edges represent accesses. The attacker aims to find the best attack path to reach the highest-privilege node. The defender can change the graph by removing a limited number of edges (revoke accesses). Our approach generates better defensive plans than the existing approach and scales better."}, "cited_paper_content": {"title": "Reinforcement Learning: A Survey", "abstract": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning."}, "keywords": ["policy iteration-based algorithms"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For RL agent, diverse environment configurations are only different in the \"opening games\", whereas the \"end games\" or \"mid games\" are likely to be similar across different environments. The similarity in later stages can be utilized in parallel training, where the agent is trained against multiple environments simultaneously and gains shared experience, leading to faster convergence and improved performance (REFR). Besides, NNDP approach is value iteration-based RL algorithm, whereas our approach is policy iteration-based RL algorithm.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our approach of training the RL based attacker's policy against multiple defensive plans at a time, as opposed to NNDP attacker's policy, which trains the model against one defensive plan at a time, leads to improved performance and shared experience #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our approach differs from the NNDP algorithm as it utilizes policy iteration-based RL algorithms and trains the attacker's policy against multiple defensive plans simultaneously, resulting in faster convergence and improved performance (#REFR).", "given_citation_intent": "result", "given_keywords": ["policy iteration-based algorithms"]}]}
{"citing_id": "2303.00709v1", "cited_id": "1605.02353", "section_title": "Comparison Of Algorithm Variants: Elimination Order", "citation": "The use of a completely random ordering was suggested in #REFR which introduced randomized approximate Gaussian elimination.", "text_before_citation": ["In this section, we investigate the impact of our approximate greedy elimination ordering (see Section 5.1) compared with a randomized ordering."], "text_after_citation": ["In #OTHEREFR , the random ordering plays a role in the proof that the algorithm produces a good factorization.", "This paper also showed that one can randomize among the vertices with at most twice the average unweighted degree and still get a provably correct algorithm.", "In our AC and other solvers, we instead eliminate a vertex with approximately minimum unweighted degree in each round.", "To understand the impact of this choice, we compare AC with a variant that uses uniformly random elimination order, which we call AC-random.", "In our first experiment, we reuse the setup from Section 5.4, i.e."], "citing_paper_content": {"title": "Robust And Practical Solution Of Laplacian Equations By Approximate Elimination *", "abstract": "We introduce a new algorithm and software for solving linear equations in symmetric diagonally dominant matrices with non-positive off-diagonal entries (SDDM matrices), including Laplacian matrices. We use preconditioned conjugate gradient to solve the system of linear equations. Our preconditioner is a variant of the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS 2016). Our factorization approach is simple: we eliminate matrix rows/columns one at a time, and update the remaining entries of the matrix by sampling entries to approximate the outcome of complete Cholesky factorization. Unlike earlier approaches, our sampled entries always maintain a connected graph on the neighbors of the eliminated variable. Our algorithm comes with a tuning parameter that upper bounds the number of samples made per original entry. We implement our solver algorithm in Julia, and experimentally evaluate its performance when using 1 or 2 samples for each original entry: We refer to these variants as AC and AC2 respectively. We investigate the performance of these implementations and compare their single-threaded performance to that of current stateof-the-art solvers including Combinatorial Multigrid (CMG), BoomerAMG-preconditioned Krylov solvers from HyPre and PETSc, Lean Algebraic Multigrid (LAMG), and MATLAB's preconditioned conjugate gradient with Incomplete Cholesky Factorization (ICC). Our experiments suggest that AC2 and AC attain a level of robustness and reliability not seen before in solvers for SDDM linear equations, while retaining good performance across all instances. Many large-scale evaluations of SDDM linear equation solvers have focused on solving problems on discretized 3D grids. We conduct evaluations across a much broader class of problems, including all large SDDM matrices from the SuiteSparse collection, as well as a broad array of programmatically generated instances. Our tests range up to 200 million non-zeros per system of linear equations. Our experiments show that AC and AC2 obtain good practical performance across many different types of SDDM-matrices, and significantly greater reliability than existing solvers. AC2 is the only solver that succeeds across all our tests, and it uses less than 7.2\u00b5s time per non-zero across to converge to 10 \u22128 relative residual error across all our experiments. AC is typically 1.5-2 times faster, but fails on one family of problems engineered to attack this algorithm. In our experiments using general sparse non-zero patterns, CMG, HyPre, PETSc, and ICC all fail on some instances from a majority of the families tested. Across these families, the median running time across different instances of AC2 and AC is comparable to or faster than other solvers. We also test the performance of our solvers on a wide array of Poisson problems on 3D grids, including grids with uniform, high-contrast, or anisotropic coefficients, and grids from the SPE Benchmark. Here, the CMG and HyPre solvers perform best, but AC and AC2 achieve worst case and median running times within a factor 4.1 and 6.2 of these respectively. Our code is public, and we detail precisely the set of tests we run and provide a tutorial on how to replicate the tests. We hope that others will adopt this suite of tests as a benchmark, which we refer to as SDDM2023."}, "cited_paper_content": {"title": "Approximate Gaussian Elimination For Laplacians - Fast, Sparse, And Simple", "abstract": "We show how to perform sparse approximate Gaussian elimination for Laplacian matrices. We present a simple, nearly linear time algorithm that approximates a Laplacian by a matrix with a sparse Cholesky factorization, the version of Gaussian elimination for symmetric matrices. This is the first nearly linear time solver for Laplacian systems that is based purely on random sampling, and does not use any graph theoretic constructions such as low-stretch trees, sparsifiers, or expanders. The crux of our analysis is a novel concentration bound for matrix martingales where the differences are sums of conditionally independent variables."}, "keywords": ["approximate Gaussian elimination"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this section, we investigate the impact of our approximate greedy elimination ordering (see Section 5.1) compared with a randomized ordering. Our approach is based on the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS 2016) #REFR, which eliminates matrix rows/columns one at a time and updates the remaining entries of the matrix by sampling entries to approximate the outcome of complete Cholesky factorization.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To eliminate matrix rows/columns one at a time and update the remaining entries of the matrix by sampling entries to approximate the outcome of complete Cholesky factorization, the authors used a variant of the Approximate Cholesky factorization of Kyng and Sachdeva, which is based purely on random sampling and does not use any graph theoretic constructions such as low-stretch trees, sparsifiers, or expanders (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform sparse approximate Gaussian elimination for Laplacian matrices, the authors of this manuscript refer to the simple, nearly linear time algorithm presented in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["approximate Gaussian elimination"]}]}
{"citing_id": "2303.12134v1", "cited_id": "1705.05065", "section_title": "Iv. Datasets And Experiments", "citation": "While simulators allow recording synchronized RGB-D and IMU data #REFR , manually gathering sufficient training data is difficult.", "text_before_citation": ["A key challenge in acquiring training data for the SML network is the lack of RGB-D+IMU datasets.", "In our pipeline, IMU data is needed to run VIO to generate sparse metric depth."], "text_after_citation": ["We select TartanAir #OTHEREFR for its large size and variety of outdoor and indoor sequences. IMU data is not provided in this dataset.", "To proxy sparse depth map generation, we run the VINS-Mono feature tracker front-end #OTHEREFR to obtain sparse feature locations and then sample ground truth depth at those locations.", "We use a 70%-30% train-test split for TartanAir, with 172K training and 73K test samples taken from both easy and hard sequences.", "In addition to the synthetic TartanAir dataset, we benchmark on VOID #OTHEREFR , which offers real-world data collected using an Intel RealSense D435i camera and the VIO system XIVO #OTHEREFR .", "This dataset is smaller than TartanAir, with only 47K training and 800 test samples. We use the published train-test split."], "citing_paper_content": {"title": "Monocular Visual-Inertial Depth Estimation", "abstract": "We present a visual-inertial depth estimation pipeline that integrates monocular depth estimation and visualinertial odometry to produce dense depth estimates with metric scale. Our approach performs global scale and shift alignment against sparse metric depth, followed by learning-based dense alignment. We evaluate on the TartanAir and VOID datasets, observing up to 30% reduction in inverse RMSE with dense scale alignment relative to performing just global alignment alone. Our approach is especially competitive at low density; with just 150 sparse metric depth points, our dense-to-dense depth alignment method achieves over 50% lower iRMSE over sparse-to-dense depth completion by KBNet, currently the state of the art on VOID. We demonstrate successful zero-shot transfer from synthetic TartanAir to real-world VOID data and perform generalization tests on NYUv2 and VCU-RVI. Our approach is modular and is compatible with a variety of monocular depth estimation models."}, "cited_paper_content": {"title": "Airsim: High-Fidelity Visual And Physical Simulation For Autonomous Vehicles", "abstract": "Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights."}, "keywords": ["RGB-D", "simulators"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "A key challenge in acquiring training data for the SML network is the lack of RGB-D+IMU datasets. In our pipeline, IMU data is needed to run VIO to generate sparse metric depth. To address this challenge, the authors of Airsim: High-Fidelity Visual And Physical Simulation For Autonomous Vehicles have developed a new simulator that offers physically and visually realistic simulations for developing and testing algorithms for autonomous vehicles, which can be used to collect a large amount of annotated training data in a variety of conditions and environments. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the lack of RGB-D+IMU datasets for training data, IMU data is used in the pipeline to run VIO to generate sparse metric depth, and a high-fidelity simulator such as Airsim #REFR can be utilized to collect annotated training data in a variety of conditions and environments.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the lack of RGB-D+IMU datasets, simulators have been developed to generate annotated training data for machine learning algorithms, such as the Airsim simulator presented in #REFR.", "given_citation_intent": "background", "given_keywords": ["RGB-D", "simulators"]}]}
{"citing_id": "2303.07477v1", "cited_id": "1512.03385", "section_title": "Self-Supervised Learning", "citation": "The Siamese network consists of an encoder network f and a prediction MLP h, where the encoder includes a backbone model (e.g., ResNet #REFR ) and a projection MLP.", "text_before_citation": ["Self-supervised learning aims to learn visual representation without data labeling cost.", "Recent advances #OTHEREFR show that self-supervised learning can achieve similar or even better performance than supervised representation learning.", "A common strategy of these methods is to learn representations that are invariant under different data augmentations by maximizing their similarity with contrastive loss optimization. However, these approaches require largesized batches and negative samples.", "SimSiam #OTHEREFR addresses this issue by utilizing the stop-gradient technique to prevent the collapsing of Siamese networks."], "text_after_citation": ["Given two randomly augmented views of x 1 and x 2 from an input image x, Simsiam aims to minimize the negative cosine similarity between the predictor output p 1 (p 1 = f (h(x 1 ))) and the projector output z 2 (z 2 = f (x 2 )) with a symmetrized loss as:", "LSSL = 1 2 D(p1, stopgrad(z2)) + 1 2 D(p2, stopgrad(z1)) (1)", "where D is a negative cosine similarity function.", "Given the distorted versions of an instance, BarlowTwin #OTHEREFR minimizes the redundancy between their embedding vector components while conserving the maximum information.", "This can be achieved by making the cross-correlation matrix, computed between the outputs of two identical networks, closer to the identity matrix, through the minimization of the following loss:"], "citing_paper_content": {"title": "Efficient Self-Supervised Continual Learning With Progressive Task-Correlated Layer Freezing", "abstract": "Inspired by the success of Self-supervised learning (SSL) in learning visual representations from unlabeled data, a few recent works have studied SSL in the context of continual learning (CL), where multiple tasks are learned sequentially, giving rise to a new paradigm, namely selfsupervised continual learning (SSCL). It has been shown that the SSCL outperforms supervised continual learning (SCL) as the learned representations are more informative and robust to catastrophic forgetting. However, if not designed intelligently, the training complexity of SSCL may be prohibitively high due to the inherent training cost of SSL. In this work, by investigating the task correlations in SSCL setup first, we discover an interesting phenomenon that, with the SSL-learned background model, the intermediate features are highly correlated between tasks. Based on this new finding, we propose a new SSCL method with layer-wise freezing which progressively freezes partial layers with the highest correlation ratios for each task to improve training computation efficiency and memory efficiency. Extensive experiments across multiple datasets are performed, where our proposed method shows superior performance against the SoTA SSCL methods under various SSL frameworks. For example, compared to LUMP, our method achieves 12%/14%/12% GPU training time reduction, 23%/26%/24% memory reduction, 35%/34%/33% backward FLOPs reduction, and 1.31%/1.98%/1.21% forgetting reduction without accuracy degradation on three datasets, respectively."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["Siamese network", "encoder network f"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Self-supervised learning has been shown to achieve similar or even better performance than supervised representation learning, and recent advances #OTHEREFR have made it more efficient by utilizing the stop-gradient technique to prevent the collapsing of Siamese networks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the high training complexity of self-supervised continual learning, the authors propose a new method with layer-wise freezing that progressively freezes partial layers with the highest correlation ratios for each task to improve training computation efficiency and memory efficiency #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of collapsing Siamese networks, SimSiam utilizes the stop-gradient technique, as shown in #REFR, to improve the performance of the encoder network f.", "given_citation_intent": "method", "given_keywords": ["Siamese network", "encoder network f"]}]}
{"citing_id": "2303.15409v1", "cited_id": "1801.03924", "section_title": "C.2. Distance Metrics", "citation": "We compare 2 , 1 and LPIPS #REFR distances over CIFAR10 dataset, and presente the results in Tab. 8.", "text_before_citation": ["In TETRA's second phase, we calculate the distance between the input image and the transformed images, and we classify based on the shortest one.", "Hence, the distance metric that we use for the classification is important.", "Different metrics have different properties, and we aim at a distance metric that is able to measure the semantic distance between images."], "text_after_citation": ["We compare the results using the following defense methods #OTHEREFR .", "As demonstrated, 2 distance metric performs better, therefore is a favorable choice. Table 8 . CIFAR10 results. In the first column, we state the method.", "For every base method, we report three consecutive lines of results.", "One for the base method and then two TETRA distance metric variations used for classification: L2 and LPIPS #OTHEREFR .", "In the next columns, we state the architecture, the trained threat model (TTM), and four attacks with different threat models."], "citing_paper_content": {"title": "Classifier Robustness Enhancement Via Test-Time Transformation", "abstract": "It has been recently discovered that adversarially trained classifiers exhibit an intriguing property, referred to as perceptually aligned gradients (PAG). PAG implies that the gradients of such classifiers possess a meaningful structure, aligned with human perception. Adversarial training is currently the best-known way to achieve classification robustness under adversarial attacks. The PAG property, however, has yet to be leveraged for further improving classifier robustness. In this work, we introduce Classifier Robustness Enhancement Via Test-Time Transformation (TETRA)-a novel defense method that utilizes PAG, enhancing the performance of trained robust classifiers. Our method operates in two phases. First, it modifies the input image via a designated targeted adversarial attack into each of the dataset's classes. Then, it classifies the input image based on the distance to each of the modified instances, with the assumption that the shortest distance relates to the true class. We show that the proposed method achieves state-of-the-art results and validate our claim through extensive experiments on a variety of defense methods, classifier architectures, and datasets. We also empirically demonstrate that TETRA can boost the accuracy of any differentiable adversarial training classifier across a variety of attacks, including ones unseen at training. Specifically, applying TETRA leads to substantial improvement of up to +23%, +20%, and +26% on CIFAR10, CIFAR100, and ImageNet, respectively."}, "cited_paper_content": {"title": "The Unreasonable Effectiveness Of Deep Features As A Perceptual Metric", "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on the ImageNet classification task has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called\"perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new Full Reference Image Quality Assessment (FR-IQA) dataset of perceptual human judgments, orders of magnitude larger than previous datasets. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by huge margins. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations."}, "keywords": ["dataset"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To measure the semantic distance between images, different metrics have different properties. As shown in #REFR, deep features outperform all previous metrics by huge margins, suggesting that perceptual similarity is an emergent property shared across deep visual representations.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our results suggest that deep features outperform all previous metrics by huge margins, including those that fail to account for many nuances of human perception, such as PSNR and SSIM, as shown in the study by Zhang et al. (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our results suggest that perceptual similarity is an emergent property shared across deep visual representations, as shown by the new Full Reference Image Quality Assessment (FR-IQA) #REFR dataset.", "given_citation_intent": "result", "given_keywords": ["dataset"]}]}
{"citing_id": "2303.18157v1", "cited_id": "1605.06676", "section_title": "B. Execution Framework", "citation": "On the other hand, it requires the more challenging Dec-POMDP formalization of standard MARL #REFR when letting several agents act simultaneously.", "text_before_citation": ["Let S and A represent the global state and action spaces, respectively, defined as the joint and union of the respective agents' local spaces, S = \u2208V S and A = \u2208V A .", "The theoretical framework of MAGNNETO allows to implement both Q-learning and PG methods, so for the sake of generalization let represent the global RL-based function that is aimed to learn -i.e., the global state-action value function for the former, or the global policy for the latter.", "A main contribution of MAGNNETO is that it makes all agents \u2208 V learn the global RL-based function approximator in a fully distributed fashion -i.e., all agents end up constructing and having access to the very same representation .", "In particular, and from a theoretical RL standpoint, this allows to formulate the problem within two different paradigms depending on the number of actions allowed at each time-step of the RL episode.", "On the one hand, imposing a single action per time-step enables to devise the problem as a time-homogeneous MDP of single-agent RL #OTHEREFR ."], "text_after_citation": ["Note, however, that in practice the execution pipeline of MAGNNETO is exactly the same in both cases.", "Another relevant feature of our design is that all agents \u2208 V are able to internally construct such global representation mainly through message communications with their direct neighboring agents B ( ) and their local computations, no longer needing a centralized entity responsible for collecting and processing all the global information together.", "Such a decentralized, message-based generation of the global function is achieved by modeling the global function with a MPNN (see Sec.", "III-A3), so that all agents \u2208 V deployed in the network are actually replicas of the MPNN modules (message, aggregation, update and readout functions) that perform regular message exchanges with their neighbors B ( ) following the message passing iteration procedure of MPNNs; in particular, note that such parameter sharing implies that all agents share as well the same local state and action spaces.", "This reinterpretation of a MPNN as a set of copies of its internal modules is especially important due to the fact that in our approach we directly map the graph G to a real networked scenario, deploying copies of the MPNN modules along hardware devices in the network (e.g., routers) and making all message communications involved to actually go through the real network infrastructure."], "citing_paper_content": {"title": "Magnneto: A Graph Neural Network-Based Multi-Agent System For Traffic Engineering", "abstract": "Current trends in networking propose the use of Machine Learning (ML) for a wide variety of network optimization tasks. As such, many efforts have been made to produce ML-based solutions for Traffic Engineering (TE), which is a fundamental problem in ISP networks. Nowadays, state-of-the-art TE optimizers rely on traditional optimization techniques, such as Local search, Constraint Programming, or Linear programming. In this paper, we present MAGNNETO, a distributed ML-based framework that leverages Multi-Agent Reinforcement Learning and Graph Neural Networks for distributed TE optimization. MAGNNETO deploys a set of agents across the network that learn and communicate in a distributed fashion via message exchanges between neighboring agents. Particularly, we apply this framework to optimize link weights in OSPF, with the goal of minimizing network congestion. In our evaluation, we compare MAGNNETO against several state-of-the-art TE optimizers in more than 75 topologies (up to 153 nodes and 354 links), including realistic traffic loads. Our experimental results show that, thanks to its distributed nature, MAGNNETO achieves comparable performance to state-of-the-art TE optimizers with significantly lower execution times. Moreover, our ML-based solution demonstrates a strong generalization capability to successfully operate in new networks unseen during training."}, "cited_paper_content": {"title": "Learning To Communicate With Deep Multi-Agent Reinforcement Learning", "abstract": "We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains."}, "keywords": ["challenging Dec-POMDP formalization", "several agents"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed MAGNNETO framework leverages Multi-Agent Reinforcement Learning and Graph Neural Networks for distributed Traffic Engineering optimization, and allows all agents to learn the global RL-based function approximator in a fully distributed fashion #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To solve the problem of learning communication protocols in multi-agent environments, the authors propose Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL) approaches, which leverage deep Q-learning and backpropagation of error derivatives through communication channels, respectively #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The challenging Dec-POMDP formalization of multi-agent communication and coordination has been addressed in recent works such as #REFR, where the authors propose Reinforced Inter-Agent Learning and Differentiable Inter-Agent Learning approaches for learning communication protocols in complex environments with several agents.", "given_citation_intent": "background", "given_keywords": ["challenging Dec-POMDP formalization", "several agents"]}]}
{"citing_id": "2304.13029v1", "cited_id": "1809.06705", "section_title": "Generalised Signatures", "citation": "This reinforces the findings that rotation forest is the most effective classifier for problems with continuous features #REFR .", "text_before_citation": ["A hierarchical window is run over the two augmented series, with the signature transform being applied to each window.", "The output for each window is then concatenated into a feature vector.", "Figure 6 shows the relative rank performance, and Table 3 summarises the overall performance statistics.", "All four pipelines are significantly more accurate than 1-NN DTW.", "Excluding feature extraction and using rotation forest rather than random forest with TSFresh increases accuracy by over 0.05."], "text_after_citation": ["An example of a problem where interval based approaches may be superior.", "Each series is a spectrogram from a bottle of alcohol with a different concentration of ethanol.", "The discriminatory features are in the near infrared interval (green box to the right).", "However, the confounding factors such as bottle shape, labelling and colouring cause variation in the visible range (red box to the left).", "Using intervals containing just the near infrared features is likely to make classification easier."], "citing_paper_content": {"title": "Bake Off Redux: A Review And Experimental Evaluation Of Recent Time Series Classification Algorithms", "abstract": "In 2017, a research paper (Bagnall et al., 2017) compared 18 Time Series Classification (TSC) algorithms on 85 datasets from the University of California, Riverside (UCR) archive. This study, commonly referred to as a 'bake off', identified that only nine algorithms performed significantly better than the Dynamic Time Warping (DTW) and Rotation Forest benchmarks that were used. The study categorised each algorithm by the type of feature they extract from time series data, forming a taxonomy of five main algorithm types. This categorisation of algorithms alongside the provision of code and accessible results for reproducibility has helped fuel an increase in popularity of the TSC field. Over six years have passed since this bake off, the UCR archive has expanded to 112 datasets and there have been a large number of new algorithms proposed. We revisit the bake off, seeing how each of the proposed categories have advanced since the original publication, and evaluate the performance of newer algorithms against the previous best-of-category using an expanded UCR archive. We extend the taxonomy to include three new categories to reflect recent developments. Alongside the originally proposed distance, interval, shapelet, dictionary and hybrid based algorithms, we compare newer convolution and feature based algorithms as well as deep learning approaches. We introduce 30 classification datasets either recently donated to the archive or reformatted to the TSC format, and use these to further evaluate the best performing algorithm from each category. Overall, we find that two recently proposed algorithms, Hydra+MultiROCKET Dempster et al. (2022) and HIVE-COTEv2 Middlehurst et al. (2021), perform significantly better than other approaches on both the current and new TSC problems."}, "cited_paper_content": {"title": "Is Rotation Forest The Best Classifier For Problems With Continuous Features?", "abstract": "Rotation forest is a tree based ensemble that performs transforms on subsets of attributes prior to constructing each tree. We present an empirical comparison of classifiers for problems with only real valued features. We evaluate classifiers from three families of algorithms: support vector machines; tree-based ensembles; and neural networks. We compare classifiers on unseen data based on the quality of the decision rule (using classification error) the ability to rank cases (area under the receiver operator curve) and the probability estimates (using negative log likelihood). We conclude that, in answer to the question posed in the title, yes, rotation forest, is significantly more accurate on average than competing techniques when compared on three distinct sets of datasets. The same pattern of results are observed when tuning classifiers on the train data using a grid search. We investigate why rotation forest does so well by testing whether the characteristics of the data can be used to differentiate classifier performance. We assess the impact of the design features of rotation forest through an ablative study that transforms random forest into rotation forest. We identify the major limitation of rotation forest as its scalability, particularly in number of attributes. To overcome this problem we develop a model to predict the train time of the algorithm and hence propose a contract version of rotation forest where a run time cap {\\em a priori}. We demonstrate that on large problems rotation forest can be made an order of magnitude faster without significant loss of accuracy and that there is no real benefit (on average) from tuning the ensemble. We conclude that without any domain knowledge to indicate an algorithm preference, rotation forest should be the default algorithm of choice for problems with continuous attributes."}, "keywords": ["continuous features", "rotation forest"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Using rotation forest rather than random forest with TSFresh increases accuracy by over 0.05 (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Using rotation forest instead of random forest with TSFresh significantly increases accuracy by over 0.05, as reported in a study comparing classifiers for problems with only real valued features (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Using rotation forest instead of random forest with TSFresh significantly increases accuracy by over 0.05 on problems with continuous features (#REFR).", "given_citation_intent": "result", "given_keywords": ["continuous features", "rotation forest"]}]}
{"citing_id": "2303.15651v1", "cited_id": "2003.02371", "section_title": "Related Work", "citation": "LiDAR 3D and 4D Panoptic segmentation 3D Panoptic segmentation The task of panoptic segmentation was first proposed in the image domain, and was later extended to LiDAR point clouds after a large-scale outdoor LiDAR point cloud dataset, SemanticKITTI, was published with panoptic labels #REFR .", "text_before_citation": ["2.1."], "text_after_citation": ["Similar to the semantic segmentation #OTHEREFR and panoptic segmentation techniques in the image domain #OTHEREFR , their 3D counterparts can be classified into proposal-based and proposal-free methods.", "Proposal-based methods #OTHEREFR require an object detection module to locate the objects first and then predict the instance mask for each bounding box and conduct semantic segmentation on the background pixels.", "This strategy needs to deal with potential conflicts among the segmentations.", "More methods fall into the other category, proposalfree methods, which conduct semantic segmentation first and then cluster the points belonging to different instances.", "A lot of research efforts focused on clustering strategies, as it impacts overall efficiency and performance."], "citing_paper_content": {"title": "4D Panoptic Segmentation As Invariant And Equivariant Field Prediction", "abstract": "In this paper, we develop rotation-equivariant neural networks for 4D panoptic segmentation. 4D panoptic segmentation is a recently established benchmark task for autonomous driving, which requires recognizing semantic classes and object instances on the road based on LiDAR scans, as well as assigning temporally consistent IDs to instances across time. We observe that the driving scenario is symmetric to rotations on the ground plane. Therefore, rotation-equivariance could provide better generalization and more robust feature learning. Specifically, we review the object instance clustering strategies, and restate the centerness-based approach and the offset-based approach as the prediction of invariant scalar fields and equivariant vector fields. Other sub-tasks are also unified from this perspective, and different invariant and equivariant layers are designed to facilitate their predictions. Through evaluation on the standard 4D panoptic segmentation benchmark of SemanticKITTI, we show that our equivariant models achieve higher accuracy with lower computational costs compared to their non-equivariant counterparts. Moreover, our method sets the new state-of-the-art performance and achieves 1st place on the SemanticKITTI 4D Panoptic Segmentation leaderboard."}, "cited_paper_content": {"title": "A Benchmark For Lidar-Based Panoptic Segmentation Based On Kitti", "abstract": "Panoptic segmentation is the recently introduced task that tackles semantic segmentation and instance segmentation jointly. In this paper, we present an extension of SemanticKITTI, which is a large-scale dataset providing dense point-wise semantic labels for all sequences of the KITTI Odometry Benchmark, for training and evaluation of laser-based panoptic segmentation. We provide the data and discuss the processing steps needed to enrich a given semantic annotation with temporally consistent instance information, i.e., instance information that supplements the semantic labels and identifies the same instance over sequences of LiDAR point clouds. Additionally, we present two strong baselines that combine state-of-the-art LiDAR-based semantic segmentation approaches with a state-of-the-art detector enriching the segmentation with instance information and that allow other researchers to compare their approaches against. We hope that our extension of SemanticKITTI with strong baselines enables the creation of novel algorithms for LiDAR-based panoptic segmentation as much as it has for the original semantic segmentation and semantic scene completion tasks. Data, code, and an online evaluation using a hidden test set will be published on http://semantic-kitti.org."}, "keywords": ["4D Panoptic segmentation", "3D Panoptic segmentation"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this paper, we present an extension of SemanticKITTI for training and evaluation of laser-based panoptic segmentation, which provides dense point-wise semantic labels for all sequences of the KITTI Odometry Benchmark. We hope that our extension of SemanticKITTI with strong baselines enables the creation of novel algorithms for LiDAR-based panoptic segmentation as much as it has for the original semantic segmentation and semantic scene completion tasks (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate laser-based panoptic segmentation, the authors extended SemanticKITTI with temporally consistent instance information and presented two strong baselines that combine state-of-the-art LiDAR-based semantic segmentation approaches with a state-of-the-art detector, as described in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate laser-based #REFR, the authors extended SemanticKITTI, a large-scale dataset providing dense point-wise semantic labels for all sequences of the KITTI Odometry Benchmark, with temporally consistent instance information, and presented two strong baselines that combine state-of-the-art LiDAR-based semantic segmentation approaches with a state-of-the-art detector enriching the segmentation with instance information.", "given_citation_intent": "background", "given_keywords": ["4D Panoptic segmentation", "3D Panoptic segmentation"]}]}
{"citing_id": "2304.10837v1", "cited_id": "1905.03989", "section_title": "A. Scenario-Based Validation", "citation": "Afterwards, they transform the functional scenarios into logical scenarios 2 by adding actions and events, specifying parameter ranges, as well as object and parameter dependencies #REFR .", "text_before_citation": ["Their ontology covers the road infrastructure including slope, surface and lane, as well as the ego vehicle with its position and speed.", "Similarly, Bagschick et al.", "#OTHEREFR construct an ontology which models the five layers of a scenario.", "These are the road, the traffic infrastructure, the temporary manipulation of the road and traffic infrastructure for example through construction sites, the static and dynamic objects and the environment layer.", "They define the degree of complexity, the amount of positions per lane, the amount of traffic participants and the abstraction level before they use combinatorial techniques and permutations to generate a start and an end scene of a functional scenario #OTHEREFR ."], "text_after_citation": ["Chen and Kloul #OTHEREFR use a three layered methodology for the generation of test scenarios.", "The first layer consists of a highway, a weather and a vehicle ontology to model the static and mobile concepts of a scene.", "The second layer describes the interactions between the static and mobile concepts by the use of rules expressed in first-order-logic.", "The third layer is the generation layer, which adds several scenes to a scenario by considering actions and events.", "The simulation scenario generation framework of Medrano-Berumen and Akbas #OTHEREFR uses a matrix where each row represents a road piece or actor in a semantic string."], "citing_paper_content": {"title": "A Comprehensive Review On Ontologies For Scenario-Based Testing In The Context Of Autonomous Driving", "abstract": "The verification and validation of autonomous driving vehicles remains a major challenge due to the high complexity of autonomous driving functions. Scenario-based testing is a promising method for validating such a complex system. Ontologies can be utilized to produce test scenarios that are both meaningful and relevant. One crucial aspect of this process is selecting the appropriate method for describing the entities involved. The level of detail and specific entity classes required will vary depending on the system being tested. It is important to choose an ontology that properly reflects these needs. This paper summarizes key representative ontologies for scenario-based testing and related use cases in the field of autonomous driving. The considered ontologies are classified according to their level of detail for both static facts and dynamic aspects. Furthermore, the ontologies are evaluated based on the presence of important entity classes and the relations between them."}, "cited_paper_content": {"title": "From Functional To Logical Scenarios: Detailing A Keyword-Based Scenario Description For Execution In A Simulation Environment", "abstract": "Scenario-based development and test processes are a promising approach for verifying and validating automated driving functions. For this purpose, scenarios have to be generated during the development process in a traceable manner. In early development stages, the operating scenarios of the item to be developed are usually described in an abstract, linguistic way.Within the scope of a simulation-assisted test process, these linguistically described scenarios have to be transformed into a state space representation and converted into data formats which can be used with the respective simulation environment. Currently, this step of detailing scenarios takes a considerable manual effort. Furthermore, a standardized interpretation of the linguistically described scenarios and a consistent transformation into the data formats are not guaranteed due to multiple authors as well as many constraints between the scenario parameters. In this paper, the authors present an approach to automatically detail a keyword-based scenario description for execution in a simulation environment and provide a basis for test case generation. As a first step, the keyword-based description is transformed into a parameter space representation. At the same time, constraints regarding the selection and combination of parameter values are documented for the following process steps (e. g. evolutionary or stochastic test methods). As a second step, the parameter space representation is converted into data formats required by the simulation environment. As an example, the authors use scenarios on German freeways and convert them into the data formats OpenDRIVE (description of the road) and OpenSCENARIO (description of traffic participants and environmental conditions) for execution in the simulation environment Virtual Test Drive."}, "keywords": ["functional scenarios"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Similarly, Bagschick et al. construct an approach to automatically detail a keyword-based scenario description for execution in a simulation environment and provide a basis for test case generation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To automatically detail a keyword-based scenario description for execution in a simulation environment, Bagschick et al. #REFR present an approach that transforms the keyword-based description into a parameter space representation and converts it into data formats required by the simulation environment, which can be used for test case generation.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Bagschick et al. developed an ontology that models the five layers of a scenario, including the functional scenarios, and use combinatorial techniques and permutations to generate a start and an end scene of a functional scenario, which can be useful for scenario-based testing in the context of autonomous driving #REFR.", "given_citation_intent": "method", "given_keywords": ["functional scenarios"]}]}
{"citing_id": "2303.08644v1", "cited_id": "1907.13625", "section_title": "Multi-View Representation Learning", "citation": "This scenario has two main advantages, (i) the loss is computed in the representation space, which is in general lower dimensional and avoids focusing on small details of the input and (ii) views can be defined to capture different aspects of the data #REFR .", "text_before_citation": ["The InfoMax principle is extended to a multi-view approach, in which rather than maximizing the MI between the input and output of the network, the agreement is maximized between the representations of two different views of the input."], "text_after_citation": ["Local -global MI.", "Deep InfoMax #OTHEREFR trains an encoder maximizing the average mutual information between local patches and global representations of an image.", "Deep Graph InfoMax #OTHEREFR and InfoGraph #OTHEREFR extend this work to the graph domain, targetting the MI between node and graph level embeddings.", "The graph representation is obtained with a global pooling layer applied to the local node embeddings.", "In DGI, since most datasets consist of one single graph, the authors create a corrupted version of the graph by shuffling the node features and contrasting negative and positive pairs."], "citing_paper_content": {"title": "Rgi : Regularized Graph Infomax For Self-Supervised Learning On Graphs", "abstract": "Self-supervised learning is gaining considerable attention as a solution to avoid the requirement of extensive annotations in representation learning on graphs. We introduce Regularized Graph Infomax (RGI), a simple yet effective framework for node level self-supervised learning on graphs that trains a graph neural network encoder by maximizing the mutual information between node level local and global views, in contrast to previous works that employ graph level global views. The method promotes the predictability between views while regularizing the covariance matrices of the representations. Therefore, RGI is non-contrastive, does not depend on complex asymmetric architectures nor training tricks, is augmentation-free and does not rely on a two branch architecture. We run RGI on both transductive and inductive settings with popular graph benchmarks and show that it can achieve state-of-the-art performance regardless of its simplicity."}, "cited_paper_content": {"title": "On Mutual Information Maximization For Representation Learning", "abstract": "Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods."}, "keywords": ["representation space"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The InfoMax principle is extended to a multi-view approach, in which rather than maximizing the MI between the input and output of the network, the agreement is maximized between the representations of two different views of the input. This approach has been shown to be effective in recent methods for unsupervised or self-supervised representation learning, such as the Regularized Graph Infomax (#REFR) proposed in this manuscript.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The multi-view approach in self-supervised learning, which maximizes the agreement between the representations of two different views of the input, has been shown to be effective in recent methods for unsupervised or self-supervised representation learning #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The InfoMax principle is extended to a multi-view approach, in which rather than maximizing the MI between the input and output of the network, the agreement is maximized between the representations of two different views of the input, as commonly done in recent methods for unsupervised or self-supervised representation learning #REFR, which train feature extractors by maximizing the mutual information between different views of the data in the representation space.", "given_citation_intent": "background", "given_keywords": ["representation space"]}]}
{"citing_id": "2305.00382v1", "cited_id": "1308.4941", "section_title": "Has Has", "citation": "However, their results show it is not able to reach the same level of performance as #REFR .", "text_before_citation": ["The conventional perceptron updates its weights for every prediction, which can over-weight the final example.", "The averaged perception keeps a running weighted sum of the obtained feature weights through all training examples and iterations.", "The final weights are obtained by dividing the weighted sum by the number of iterations. #OTHEREFR", "(2019) propose another NER model based on a long short-term memory (LSTM) architecture.", "The authors argue that it can be more useful when the data set has more variation, as the LSTM model does not require time-consuming feature engineering."], "text_after_citation": ["SecBERT 4 is a pre-trained encoder trained on a large corpus of cybersecurity texts.", "It is based on the BERT architecture #OTHEREFR and uses a vocabulary specialized for cybersecurity.", "SecBERT can be fine-tuned for specific tasks such as NER.", "Another pre-trained encoder similar to SecBERT is SecureBERT, proposed by #OTHEREFR .", "SecureBERT leverages a customized tokenizer and an approach to alter pre-trained weights."], "citing_paper_content": {"title": "Constructing A Knowledge Graph From Textual Descriptions Of Software Vulnerabilities In The National Vulnerability Database", "abstract": "Knowledge graphs have shown promise for several cybersecurity tasks, such as vulnerability assessment and threat analysis. In this work, we present a new method for constructing a vulnerability knowledge graph from information in the National Vulnerability Database (NVD). Our approach combines named entity recognition (NER), relation extraction (RE), and entity prediction using a combination of neural models, heuristic rules, and knowledge graph embeddings. We demonstrate how our method helps to fix missing entities in knowledge graphs used for cybersecurity and evaluate the performance."}, "cited_paper_content": {"title": "Automatic Labeling For Entity Extraction In Cyber Security", "abstract": "Timely analysis of cyber-security information necessitates automated information extraction from unstructured text. While state-of-the-art extraction methods produce extremely accurate results, they require ample training data, which is generally unavailable for specialized applications, such as detecting security related entities; moreover, manual annotation of corpora is very costly and often not a viable solution. In response, we develop a very precise method to automatically label text from several data sources by leveraging related, domainspecific, structured data and provide public access to a corpus annotated with cyber-security entities. Next, we implement a Maximum Entropy Model trained with the average perceptron on a portion of our corpus ( 750,000 words) and achieve near perfect precision, recall, and accuracy, with training times under 17 seconds."}, "keywords": ["level"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors achieve near-perfect precision, recall, and accuracy in their Maximum Entropy Model for automated labeling of cyber-security entities, using a portion of their corpus, as reported in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors achieve near perfect precision, recall, and accuracy in their Maximum Entropy Model trained with the average perceptron on a portion of their corpus (750,000 words) #REFR, which is a significant improvement over the NER model proposed by #OTHEREFR (2019) based on a long short-term memory (LSTM) architecture.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors achieved near-perfect precision, recall, and accuracy with their Maximum Entropy Model trained on a portion of their corpus, demonstrating a high level of performance in automated information extraction from unstructured text. #REFR", "given_citation_intent": "result", "given_keywords": ["level"]}]}
{"citing_id": "2303.17611v1", "cited_id": "2003.14323", "section_title": "Self-Supervised Learning Vs Supervised Learning On Limited Labeled Data", "citation": "The above findings are consistent with those reported in #REFR that the advantage of the self-supervised learning-based method is its better regularisation on low data regimes to avoid overfitting problems compared to fully-supervised methods.", "text_before_citation": ["The resulting average accuracy and the corresponding standard deviation of all compared models are illustrated in Fig. 7 .", "First, our finetuned model consistently outperforms other supervised learning-based models for sample sizes varying from 1 to 1000 on the emotion recognition tasks of all three datasets.", "Among supervised learning-based methods, SimpDCNN exhibited the poorest results, over which our SSL model could achieve significant performance gains of 6.84% -21.19% for different downstream tasks.", "Our fully-supervised model yields the highest results compared to other supervised models, whereas the fine-tuned model initialized by self-supervised learning parameters continues to enhance performance by 5.24% -13.63%.", "Second, for all downstream tasks, the standard deviation obtained by our fine-tuned model is narrower with respect to the supervised learningbased deep models, demonstrating its superior generalization ability across different samples."], "text_after_citation": ["As the amount of available labeled data increases, the difference in performance between the two types of models gradually decreases.", "Overall, the comparison results suggest that the proposed method can produce more meaningful and robust representations for wearable emotion recognition than fullysupervised methods, offering a potential solution to the problem of little labeled data."], "citing_paper_content": {"title": "Transformer-Based Self-Supervised Multimodal Representation Learning For Wearable Emotion Recognition", "abstract": "Recently, wearable emotion recognition based on peripheral physiological signals has drawn massive attention due to its less invasive nature and its applicability in real-life scenarios. However, how to effectively fuse multimodal data remains a challenging problem. Moreover, traditional fully-supervised based approaches suffer from overfitting given limited labeled data. To address the above issues, we propose a novel self-supervised learning (SSL) framework for wearable emotion recognition, where efficient multimodal fusion is realized with temporal convolution-based modality-specific encoders and a transformer-based shared encoder, capturing both intra-modal and intermodal correlations. Extensive unlabeled data is automatically assigned labels by five signal transforms, and the proposed SSL model is pre-trained with signal transformation recognition as a pretext task, allowing the extraction of generalized multimodal representations for emotion-related downstream tasks. For evaluation, the proposed SSL model was first pre-trained on a large-scale self-collected physiological dataset and the resulting encoder was subsequently frozen or fine-tuned on three public supervised emotion recognition datasets. Ultimately, our SSL-based method achieved state-of-the-art results in various emotion classification tasks. Meanwhile, the proposed model was proved to be more accurate and robust compared to fully-supervised methods on low data regimes."}, "cited_paper_content": {"title": "How Useful Is Self-Supervised Pretraining For Visual Tasks?", "abstract": "Recent advances have spurred incredible progress in self-supervised pretraining for vision. We investigate what factors may play a role in the utility of these pretraining methods for practitioners. To do this, we evaluate various self-supervised algorithms across a comprehensive array of synthetic datasets and downstream tasks. We prepare a suite of synthetic data that enables an endless supply of annotated images as well as full control over dataset difficulty. Our experiments offer insights into how the utility of self-supervision changes as the number of available labels grows as well as how the utility changes as a function of the downstream task and the properties of the training data. We also find that linear evaluation does not correlate with finetuning performance. Code and data is available at \\href{https://www.github.com/princeton-vl/selfstudy}{github.com/princeton-vl/selfstudy}."}, "keywords": ["self-supervised learning-based method", "fully-supervised methods"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our SSL-based method achieved state-of-the-art results in various emotion classification tasks, outperforming other supervised learning-based models, including SimpDCNN, by 6.84% -21.19% for different downstream tasks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The fine-tuned model initialized by self-supervised learning parameters achieved significant performance gains of 5.24% -13.63% compared to the fully-supervised model, demonstrating the effectiveness of self-supervised pretraining for downstream emotion recognition tasks (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our SSL model outperforms both SimpDCNN and fully-supervised methods on low data regimes, achieving significant performance gains of 6.84% -21.19% for different downstream tasks compared to the self-supervised learning-based method. #REFR", "given_citation_intent": "result", "given_keywords": ["self-supervised learning-based method", "fully-supervised methods"]}]}
{"citing_id": "2303.15669v1", "cited_id": "1808.10128", "section_title": "Results On Small Amount Of Fine-Tuning Data", "citation": "Both T-Dec #REFR and Tac, which do not have the opportunity to pre-learn a sufficient capability of attention alignment in pre-training, show similarly lower performance than the others.", "text_before_citation": ["Objective Evaluation.", "Table 1 presents the superior performance of the proposed methods compared to competing methods on small amounts of fine-tuning data.", "Without data augmentation during finetuning, T-SD outperforms all unsupervised pre-training methods and Tac."], "text_after_citation": ["In contrast, the proposed de-warping task encourages the model to learn both preliminary knowledge of attention alignment and autoregressive prediction.", "When data augmentation is applied during fine-tuning, T-SD with SegAug outperforms other combinations of pre-training and augmentation methods.", "SegAug even effectively improves the performance of other pre-training baselines and shows competitive performance compared to other augmentation methods.", "Subjective Evaluation.", "Table 2 shows the preference test results with competitive methods using 0.5 shards of fine-tuning data."], "citing_paper_content": {"title": "Unsupervised Pre-Training For Data-Efficient Text-To-Speech On Low Resource Languages", "abstract": "Neural text-to-speech (TTS) models can synthesize natural human speech when trained on large amounts of transcribed speech. However, collecting such large-scale transcribed data is expensive. This paper proposes an unsupervised pre-training method for a sequenceto-sequence TTS model by leveraging large untranscribed speech data. With our pre-training, we can remarkably reduce the amount of paired transcribed data required to train the model for the target downstream TTS task. The main idea is to pre-train the model to reconstruct de-warped mel-spectrograms from warped ones, which may allow the model to learn proper temporal assignment relation between input and output sequences. In addition, we propose a data augmentation method that further improves the data efficiency in finetuning. We empirically demonstrate the effectiveness of our proposed method in low-resource language scenarios, achieving outstanding performance compared to competing methods. The code and audio samples are"}, "cited_paper_content": {"title": "Semi-Supervised Training For Improving Data Efficiency In End-To-End Speech Synthesis", "abstract": "Although end-to-end text-to-speech (TTS) models such as Tacotron have shown excellent results, they typically require a sizable set of high-quality pairs for training, which are expensive to collect. In this paper, we propose a semi-supervised training framework to improve the data efficiency of Tacotron. The idea is to allow Tacotron to utilize textual and acoustic knowledge contained in large, publicly-available text and speech corpora. Importantly, these external data are unpaired and potentially noisy. Specifically, first we embed each word in the input text into word vectors and condition the Tacotron encoder on them. We then use an unpaired speech corpus to pre-train the Tacotron decoder in the acoustic domain. Finally, we fine-tune the model using available paired data. We demonstrate that the proposed framework enables Tacotron to generate intelligible speech using less than half an hour of paired training data."}, "keywords": ["attention alignment"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Without data augmentation during finetuning, T-SD outperforms all unsupervised pre-training methods and Tac (Li et al., 2020).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed framework in this manuscript enables Tacotron to generate intelligible speech using less than half an hour of paired training data, which is a significant improvement in data efficiency compared to previous methods. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed semi-supervised training framework in #REFR utilizes unpaired speech corpora to improve the data efficiency of Tacotron by embedding each word in the input text into word vectors and conditioning the Tacotron encoder on them, and pre-training the Tacotron decoder in the acoustic domain using unpaired speech data, which may improve the attention alignment between input and output sequences.", "given_citation_intent": "result", "given_keywords": ["attention alignment"]}]}
{"citing_id": "2304.01315v1", "cited_id": "1801.01290", "section_title": "Case Study: Re-Evaluating Previous Work", "citation": "In particular, SAC (EP) with seed optimization most closely matches the results reported by #REFR .", "text_before_citation": ["(2018) , we used seed optimization in Figure 15 : When searching seeds, we were able to achieve average performance and shaded regions much closer to that reported in the original SAC work.", "Solid lines denote average performance, and shaded regions denote minimum and maximum performance.", "the hyperparameter tuning process.", "As a note, this is bad practice; we only conduct seed search in the name of reproduction.", "In Figure 15 , where we chose the best 5 seeds of 30 for each algorithm, the results more closely match those from the original paper."], "text_after_citation": ["We now turn to running an experiment that more closely resembles the principles laid out in this document, especially with respect to reporting performance of tuned baselines. Although we do not know how #OTHEREFR", "(2018) tuned the baseline algorithms in their experiments, we found that the performance of DDPG on Half Cheetah was under-reported in this work.", "In the experiments here, we use the tuned hyperparameters for DDPG as reported by SpinningUp baselines 22 .", "Since Gaussian noise is known to outperform OU noise in some cases #OTHEREFR 23 , we use uncorrelated, unbounded Gaussian noise for action exploration in DDPG instead of OU noise.", "Furthermore, we try both SAC and DDPG with an exploration phase at the beginning of the experiment, where an action is drawn uniformly randomly for the first 10,000 steps."], "citing_paper_content": {"title": "Empirical Design In Reinforcement Learning", "abstract": "Empirical design in reinforcement learning is no small task. Running good experiments requires attention to detail and at times significant computational resources. While compute resources available per dollar have continued to grow rapidly, so have the scale of typical experiments in reinforcement learning. It is now common to benchmark agents with millions of parameters against dozens of tasks, each using the equivalent of 30 days of experience. The scale of these experiments often conflict with the need for proper statistical evidence, especially when comparing algorithms. Recent studies have highlighted how popular algorithms are sensitive to hyper-parameter settings and implementation details, and that common empirical practice leads to weak statistical evidence (Machado et al., 2018; Henderson et al., 2018). Here we take this one step further. This manuscript represents both a call to action, and a comprehensive resource for how to do good experiments in reinforcement learning. In particular, we cover: the statistical assumptions underlying common performance measures, how to properly characterize performance variation and stability, hypothesis testing, special considerations for comparing multiple agents, baseline and illustrative example construction, and how to deal with hyperparameters and experimenter bias. Throughout we highlight common mistakes found in the literature and the statistical consequences of those in example experiments. The objective of this document is to provide answers on how we can use our unprecedented compute to do good science in reinforcement learning, as well as stay alert to potential pitfalls in our empirical design."}, "cited_paper_content": {"title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning With A Stochastic Actor", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds."}, "keywords": ["seed optimization"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors used seed optimization to achieve better performance in hyperparameter tuning, but noted that this is bad practice and only conducted seed search for the sake of reproduction (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We conducted seed optimization to achieve better results, and our approach is similar to that used in the original SAC work (#REFR).", "given_citation_intent": "result", "given_keywords": ["seed optimization"]}]}
{"citing_id": "2303.08360v1", "cited_id": "1610.02391", "section_title": "Related Work", "citation": "It has been proven in #REFR that Grad-CAM and original CAM produce equivalent results in network with GAP layer.", "text_before_citation": ["In light of the challenge of annotating all groundtruth labels for an image, multi-label learning in the presence of missing labels (MLML) has also attracted much research attention #OTHEREFR .", "Class Activation Mapping (CAM) is a technique to obtain discriminative regions for specific classes in an image and generate class activation maps (CAMs).", "The original CAM #OTHEREFR operates a weighted sum on the feature maps extracted by the backbone network.", "It is restricted to networks with global average pooling (GAP) layer.", "Grad-CAM #OTHEREFR utilizes local gradient to generate CAMs in any architecture without the need for re-training."], "text_after_citation": ["As GAP layer is a common structure in classification model, original CAM is suitable for most scenarios.", "Furthermore, there are also explorations on gradient-free extensions #OTHEREFR .", "The CAM technique derived from classification network has been widely used for weakly supervised visual tasks, such as weakly supervised object location #OTHEREFR and object segmentation #OTHEREFR .", "In both tasks, category labels are employed as supervision, and CAM-based localization serves as supplementary information."], "citing_paper_content": {"title": "Knowledge Distillation From Single To Multi Labels: An Empirical Study", "abstract": "Knowledge distillation (KD) has been extensively studied in single-label image classification. However, its efficacy for multi-label classification remains relatively unexplored. In this study, we firstly investigate the effectiveness of classical KD techniques, including logit-based and feature-based methods, for multi-label classification. Our findings indicate that the logit-based method is not wellsuited for multi-label classification, as the teacher fails to provide inter-category similarity information or regularization effect on student model's training. Moreover, we observe that feature-based methods struggle to convey compact information of multiple labels simultaneously. Given these limitations, we propose that a suitable dark knowledge should incorporate class-wise information and be highly correlated with the final classification results. To address these issues, we introduce a novel distillation method based on Class Activation Maps (CAMs), which is both effective and straightforward to implement. Across a wide range of settings, CAMs-based distillation consistently outperforms other methods. Code is available at https://github.com/yzqinjacob/Distill-MLC."}, "cited_paper_content": {"title": "Grad-Cam: Visual Explanations From Deep Networks Via Gradient-Based Localization", "abstract": "We propose a technique for producing \u2018visual explanations\u2019 for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach\u2014Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say \u2018dog\u2019 in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a \u2018stronger\u2019 deep network from a \u2018weaker\u2019 one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265\u2013290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E."}, "keywords": ["Grad-CAM"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Class Activation Mapping (CAM) is a technique to obtain discriminative regions for specific classes in an image and generate class activation maps (CAMs). The original CAM #REFR operates a weighted sum on the feature maps extracted by the backbone network. It is restricted to networks with global average pooling (GAP) layer. Grad-CAM #REFR utilizes local gradient to generate CAMs in any architecture without the need for re-training.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Grad-CAM, a technique for producing visual explanations for decisions from a large class of Convolutional Neural Network (CNN)-based models, has been shown to be applicable to a wide variety of CNN model-families, including those used in tasks with multi-modal inputs, without architectural changes or re-training #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Grad-CAM, a technique for producing visual explanations for decisions from a large class of Convolutional Neural Network (CNN)-based models, has been shown to be effective in generating class activation maps (CAMs) in any architecture without the need for re-training #REFR.", "given_citation_intent": "result", "given_keywords": ["Grad-CAM"]}]}
{"citing_id": "2304.07503v1", "cited_id": "1606.09375", "section_title": "Static Graph Embedding", "citation": "On the one hand, graph neural networks #REFR are initially defined in the spectral space, which is inspired by the convolution operations defined on the image grid.", "text_before_citation": ["Decades ago, the emerging big graph data on the website had already attracted much concern of researchers #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR .", "The learned low-dimensional embeddings for nodes, edges, and subgraphs can be easily integrated with the machine learning algorithms like Logistic Regression, Random Forest, and Gradient Boosting Decision Trees to perform risk monitoring #OTHEREFR , link prediction #OTHEREFR , item recommendation #OTHEREFR , etc.", "Recently, researchers interested in graph mining have been motivated by the great success of deep learning methods in computer vision #OTHEREFR and natural language processing #OTHEREFR .", "The deep graph embedding methods can also be categorized into two kinds: graph convolutional networks #OTHEREFR and skip-gram models #OTHEREFR ."], "text_after_citation": ["GCN #OTHEREFR simplifies the learning framework of #OTHEREFR and shows a successful application on semi-supervised node classification tasks.", "GraphSAGE #OTHEREFR proposes an inductive learning paradigm on large-scale graphs, which samples subgraphs for each node.", "Meanwhile, GAT #OTHEREFR introduces a learnable attention mechanism to impose different importances over neighbors.", "The attention mechanism not only achieves better performance on several benchmarks but also presents an explainable result by the neighbor importances.", "On the other hand, DeepWalk #OTHEREFR is the pioneering work to introduce the skip-gram models #OTHEREFR into graph representation learning with the sampled node sequences by random walks."], "citing_paper_content": {"title": "Temporal Aggregation And Propagation Graph Neural Networks For Dynamic Representation", "abstract": "Temporal graphs exhibit dynamic interactions between nodes over continuous time, whose topologies evolve with time elapsing. The whole temporal neighborhood of nodes reveals the varying preferences of nodes. However, previous works usually generate dynamic representation with limited neighbors for simplicity, which results in both inferior performance and high latency of online inference. Therefore, in this paper, we propose a novel method of temporal graph convolution with the whole neighborhood, namely Temporal Aggregation and Propagation Graph Neural Networks (TAP-GNN). Specifically, we firstly analyze the computational complexity of the dynamic representation problem by unfolding the temporal graph in a message-passing paradigm. The expensive complexity motivates us to design the AP (aggregation and propagation) block, which significantly reduces the repeated computation of historical neighbors. The final TAP-GNN supports online inference in the graph stream scenario, which incorporates the temporal information into node embeddings with a temporal activation function and a projection layer besides several AP blocks. Experimental results on various real-life temporal networks show that our proposed TAP-GNN outperforms existing temporal graph methods by a large margin in terms of both predictive performance and online inference latency. Our code is available at https://github.com/doujiang-zheng/TAP-GNN."}, "cited_paper_content": {"title": "Convolutional Neural Networks On Graphs With Fast Localized Spectral Filtering", "abstract": "In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."}, "keywords": ["graph neural networks"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Recently, researchers interested in graph mining have been motivated by the great success of deep learning methods in computer vision and natural language processing. The deep graph embedding methods can also be categorized into two kinds: graph convolutional networks and skip-gram models. In this context, the proposed Temporal Aggregation and Propagation Graph Neural Networks (TAP-GNN) #REFR could be a promising method for dynamic representation in temporal graphs.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, deep learning methods have achieved great success in computer vision and natural language processing, and researchers interested in graph mining have been motivated to explore deep graph embedding methods, such as graph convolutional networks and skip-gram models. In particular, the proposed Temporal Aggregation and Propagation Graph Neural Networks (TAP-GNN) in this manuscript incorporate the temporal information into node embeddings with a temporal activation function and a projection layer besides several AP blocks, which outperforms existing temporal graph methods by a large margin in terms of both predictive performance and online inference latency on various real-life temporal networks. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, researchers interested in graph neural networks have been motivated by the great success of deep learning methods in computer vision and natural language processing #REFR.", "given_citation_intent": "background", "given_keywords": ["graph neural networks"]}]}
{"citing_id": "2304.06048v1", "cited_id": "1810.10659", "section_title": "Ii. Related Work", "citation": "However, the state of S2V-DQN only considers the adjacency matrix and the state of nodes, and simply follows greedy policy at every step, which results in subpar performance #REFR .", "text_before_citation": ["In general, these GNN-based approaches require either one-hot encoded vectors #OTHEREFR , #OTHEREFR , #OTHEREFR or node feature matrix #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR as initial embeddings, which can be smoothed by the neighborhood aggregation to carrier graph structure information.", "However, recent studies have highlighted the inherent over-smoothing and information loss issues of GNNs #OTHEREFR - #OTHEREFR .", "This oversmoothing problem can also affect solving combinatorial optimization problems, as the goal is to identify distinguished nodes that maximize the objective function.", "Reinforcement Learning combined with GNNs is becoming increasingly popular for solving CO problems.", "Most no-tably, #OTHEREFR proposed S2V-DQN, a GNN-based reinforcement learning approach, which uses the neighborhood aggregation to update the node representation and learns a greedy policy using Q-learning with the graph embedding vector."], "text_after_citation": ["As data size continuously increases, developing models that can scale to modern dataset sizes is imperative.", "Significant improvement in scalability can be seen in GComb #OTHEREFR .", "GComb uses a probabilistic greedy mechanism to predict the quality of the nodes by a trained GCN.", "By evaluating the quality of nodes, GComb is able to prune those unlikely to be in the solution set, allowing it to generalize to large graphs of millions or billions of nodes while maintaining the performance of S2V-DQN on Maximum Coverage on the bipartite graph (MCP), Maximum Vertex Cover (MVC), and Influence Maximization (IM).", "However, similar to S2V-DQN, it does not involve local search behavior resulting in its performance being marginally lower than S2V-DQN."], "citing_paper_content": {"title": "Rels-Dqn: A Robust And Efficient Local Search Framework For Combinatorial Optimization", "abstract": "Combinatorial optimization (CO) aims to efficiently find the best solution to NP-hard problems ranging from statistical physics to social media marketing. A wide range of CO applications can benefit from local search methods because they allow reversible action over greedy policies. Deep Q-learning (DQN) using message-passing neural networks (MPNN) has shown promise in replicating the local search behavior and obtaining comparable results to the local search algorithms. However, the over-smoothing and the information loss during the iterations of message passing limit its robustness across applications, and the large message vectors result in memory inefficiency. Our paper introduces RELS-DQN, a lightweight DQN framework that exhibits the local search behavior while providing practical scalability. Using the RELS-DQN model trained on one application, it can generalize to various applications by providing solution values higher than or equal to both the local search algorithms and the existing DQN models while remaining efficient in runtime and memory."}, "cited_paper_content": {"title": "Combinatorial Optimization With Graph Convolutional Networks And Guided Tree Search", "abstract": "We present a learning-based approach to computing solutions for certain NP-hard problems. Our approach combines deep learning techniques with useful algorithmic elements from classic heuristics. The central component is a graph convolutional network that is trained to estimate the likelihood, for each vertex in a graph, of whether this vertex is part of the optimal solution. The network is designed and trained to synthesize a diverse set of solutions, which enables rapid exploration of the solution space via tree search. The presented approach is evaluated on four canonical NP-hard problems and five datasets, which include benchmark satisfiability problems and real social network graphs with up to a hundred thousand nodes. Experimental results demonstrate that the presented approach substantially outperforms recent work, generalizes across datasets, and scales to graphs that are orders of magnitude larger than those used during training."}, "keywords": ["S2V-DQN", "nodes"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Reinforcement Learning combined with GNNs is becoming increasingly popular for solving CO problems. Most notably, the presented approach in #REFR uses a graph convolutional network to estimate the likelihood of each vertex being part of the optimal solution, and synthesizes a diverse set of solutions to enable rapid exploration of the solution space via tree search.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Reinforcement Learning combined with GNNs is becoming increasingly popular for solving CO problems, with recent studies highlighting the over-smoothing and information loss issues of GNNs #OTHEREFR - #OTHEREFR. For instance, #REFR presents a learning-based approach that combines deep learning techniques with useful algorithmic elements from classic heuristics to compute solutions for certain NP-hard problems.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Reinforcement Learning combined with GNNs has shown promise in solving CO problems, with #REFR's S2V-DQN being a notable example that updates the node representation using neighborhood aggregation to learn a greedy policy with respect to the objective function.", "given_citation_intent": "background", "given_keywords": ["S2V-DQN", "nodes"]}]}
{"citing_id": "2303.03745v1", "cited_id": "1904.10237", "section_title": "B. Automatic Piano Fingering Prediction", "citation": "This result is higher than the neural model of the same architecture that was reported by #REFR (61.3%) but 0.4% lower than their best performing model (an HMM based).", "text_before_citation": ["We note that the development set is silver data (automatically annotated) and is likely to contain mistakes. We run the model and achieve 73.2% accuracy.", "Next, to test how useful our data is to a real-world gold dataset we wish to inspect its usefulness with a transferlearning approach.", "By first pre-training a simple model on our data and then fine-tune the model on PIG.", "If our data is indeed of quality we'd expect to see performance improvements on PIG, especially as this data is relatively small.", "We begin by training the LSTM model solely on PIG, 7 which results in 64.1% accuracy."], "text_after_citation": ["We continue by using the model trained on APFD and then fine-tune it on PIG, which leads to 66.8% accuracy, an improvement of 2.7 points over the previous SOTA.", "We attribute this gain in performance to our dataset, which both increases the number of training examples and allows to train bigger neural models which excel with more training examples.", "We also experiment in the opposite direction and fine-tune the model trained on PIG with our data, which result in 73.6% accuracy, which is better than training on our data alone, achieving 73.2% accuracy."], "citing_paper_content": {"title": "At Your Fingertips: Extracting Piano Fingering Instructions From Videos", "abstract": "Piano fingering-knowing which finger to use to play each note in a musical piece, is a hard and important skill to master when learning to play the piano. While some sheet music is available with expert-annotated fingering information, most pieces lack this information, and people often resort to learning the fingering from demonstrations in online videos. We consider the AI task of automating the extraction of fingering information from videos. This is a non-trivial task as fingers are often occluded by other fingers, and it is often not clear from the video which of the keys were pressed, requiring the synchronization of hand position information and knowledge about the notes that were played. We show how to perform this task with high-accuracy using a combination of deeplearning modules, including a GAN-based approach for fine-tuning on out-of-domain data. We extract the fingering information with an f1 score of 97%. We run the resulting system on 90 videos, resulting in high-quality piano fingering information of 150K notes, the largest available dataset of piano-fingering to date."}, "cited_paper_content": {"title": "Statistical Learning And Estimation Of Piano Fingering", "abstract": "Automatic estimation of piano fingering is important for understanding the computational process of music performance and applicable to performance assistance and education systems. While a natural way to formulate the quality of fingerings is to construct models of the constraints/costs of performance, it is generally difficult to find appropriate parameter values for these models. Here we study an alternative data-driven approach based on statistical modeling in which the appropriateness of a given fingering is described by probabilities. Specifically, we construct two types of hidden Markov models (HMMs) and their higher-order extensions. We also study deep neural network (DNN)-based methods for comparison. Using a newly released dataset of fingering annotations, we conduct systematic evaluations of these models as well as a representative constraint-based method. We find that the methods based on high-order HMMs outperform the other methods in terms of estimation accuracies. We also quantitatively study individual difference of fingering and propose evaluation measures that can be used with multiple ground truth data. We conclude that the HMM-based methods are currently state of the art and generate acceptable fingerings in most parts and that they have certain limitations such as ignorance of phrase boundaries and interdependence of the two hands."}, "keywords": ["neural model"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To test how useful our data is to a real-world gold dataset we wish to inspect its usefulness with a transfer learning approach by first pre-training a simple model on our data and then fine-tune the model on PIG. If our data is indeed of quality we'd expect to see performance improvements on PIG, especially as this data is relatively small. We begin by training the LSTM model solely on PIG, 7 which results in 64.1% accuracy. It is worth noting that the authors of the reference paper, \"Statistical Learning And Estimation Of Piano Fingering,\" proposed a data-driven approach based on statistical modeling to estimate piano fingering with high-order hidden Markov models, which outperformed other methods in terms of estimation accuracies. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We find that the methods based on high-order HMMs outperform the other methods in terms of estimation accuracies, which is consistent with the results reported in the reference paper on statistical learning and estimation of piano fingering. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our LSTM model's accuracy of 64.1% on PIG with the HMM-based methods, which are currently state of the art and generate acceptable fingerings in most parts, and find that our model's performance is inferior to the neural model proposed in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": ["neural model"]}]}
{"citing_id": "2304.02860v1", "cited_id": "1807.11078", "section_title": "A. Image Deraining", "citation": "To improve generalization, SEMI #REFR exploits both synthetic and real-world rainy images to conduct supervised and unsupervised training respectively. In addition, rain presents notable diversity (e.g.", "text_before_citation": ["Recently, deep learning has been overwhelmingly successful in image restoration #OTHEREFR - #OTHEREFR , which also includes image deraining #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR - #OTHEREFR .", "DerainNet #OTHEREFR and JORDER #OTHEREFR are two of the earliest convolution-based methods for deep single image deraining."], "text_after_citation": ["density, size, distribution, etc.), thus prior learning may be helpful for accurate rain removal.", "Among these methods, DIDMDN #OTHEREFR guides the network to restore degraded image by estimating rain density.", "Furthermore, UMRL #OTHEREFR and MSPFN #OTHEREFR utilize uncertainty and multi-scale information to obtain derained images.", "Subsequently, the squeeze-excitation mechanism and progressive recursive learning are introduced in RESCAN #OTHEREFR , PReNet #OTHEREFR and DPENet #OTHEREFR to design networks.", "MSPFN #OTHEREFR introduces multi-scale information to adapt to the distribution diversity of rain streaks."], "citing_paper_content": {"title": "Towards An Effective And Efficient Transformer For Rain-By-Snow Weather Removal", "abstract": "Rain-by-snow weather removal is a specialized task in weather-degraded image restoration aiming to eliminate coexisting rain streaks and snow particles. In this paper, we propose RSFormer, an efficient and effective Transformer that addresses this challenge. Initially, we explore the proximity of convolution networks (ConvNets) and vision Transformers (ViTs) in hierarchical architectures and experimentally find they perform approximately at intra-stage feature learning. On this basis, we utilize a Transformer-like convolution block (TCB) that replaces the computationally expensive self-attention while preserving attention characteristics for adapting to input content. We also demonstrate that cross-stage progression is critical for performance improvement, and propose a global-local self-attention sampling mechanism (GLASM) that down-/up-samples features while capturing both global and local dependencies. Finally, we synthesize two novel rain-by-snow datasets, RSCityScape and RS100K, to evaluate our proposed RSFormer. Extensive experiments verify that RSFormer achieves the best trade-off between performance and time-consumption compared to other restoration methods. For instance, it outperforms Restormer with a 1.53% reduction in the number of parameters and a 15.6% reduction in inference time. Datasets, source code and pre-trained models are available at https://github.com/chdwyb/RSFormer."}, "cited_paper_content": {"title": "Semi-Supervised Transfer Learning For Image Rain Removal", "abstract": "Single image rain removal is a typical inverse problem in computer vision. The deep learning technique has been verified to be effective for this task and achieved state-of-the-art performance. However, previous deep learning methods need to pre-collect a large set of image pairs with/without synthesized rain for training, which tends to make the neural network be biased toward learning the specific patterns of the synthesized rain, while be less able to generalize to real test samples whose rain types differ from those in the training data. To this issue, this paper firstly proposes a semi-supervised learning paradigm toward this task. Different from traditional deep learning methods which only use supervised image pairs with/without synthesized rains, we further put real rainy images, without need of their clean ones, into the network training process. This is realized by elaborately formulating the residual between an input rainy image and its expected network output (clear image without rain) as a concise mixture of Gaussians distribution. The network is therefore trained to transfer to adapting the real rain pattern domain instead of only the synthesis rain domain, and thus both the short-of-training-sample and bias-to-supervised-sample issues can be evidently alleviated. Experiments on synthetic and real data verify the superiority of our model compared to the state-of-the-arts."}, "keywords": ["real-world rainy images"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Recently, deep learning has been overwhelmingly successful in image restoration #OTHEREFR - #OTHEREFR , which also includes image deraining #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR - #OTHEREFR . DerainNet #OTHEREFR and JORDER #OTHEREFR are two of the earliest convolution-based methods for deep single image deraining. To address the issue of bias towards learning specific patterns of synthesized rain, the authors proposed a semi-supervised learning paradigm for single image rain removal in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Deep learning methods for single image deraining have been shown to be effective #REFR, but they often require a large set of image pairs with/without synthesized rain for training, which can lead to bias and poor generalization to real test samples with different rain types.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Deep learning methods for single image deraining have been successful, but they tend to be biased towards learning specific patterns of synthesized rain, making them less able to generalize to real-world rainy images. To address this issue, the proposed semi-supervised learning paradigm in #REFR incorporates real rainy images into the network training process, resulting in improved performance on both synthetic and real data.", "given_citation_intent": "background", "given_keywords": ["real-world rainy images"]}]}
{"citing_id": "2305.00449v1", "cited_id": "1211.5590", "section_title": "Feature Extraction", "citation": "It is commonly believed for many machine learning researchers that the key to effectively construct a model is properly optimized feature extraction #REFR .", "text_before_citation": ["The extracted features should contain relevant information from the initial dataset so that this simplified representation can be used as the alteration of the full original dataset to perform the required task shown as figure 3.4 #OTHEREFR .", "The main task involved by feature extraction is to reduce the resource which are necessary to describe large amounts of data.", "When analyzing or learning with massive complex data, which usually requires a lot of memory and computational power, one of the main problems are caused by the number of variables involved.", "Besides, with the original dataset, a classification algorithm or model is inclined to overfit training samples and may be generalized poorly afterwards.", "In general, feature extraction is a generic term for methods combining features or variables to solve these problems with performing sufficient accuracy comparing with the initial dataset."], "text_after_citation": ["In the experiments, except for the classic dimensionality reduction technique Principal Component Analysis (PCA), several feature extraction methods are used such as permutation importance,feature importance and hierarchical clustering based on Spearman correlations."], "citing_paper_content": {"title": "Predictability Of Machine Learning Algorithms And Related Feature Extraction Techniques Master Thesis", "abstract": "To implement machine learning, it is essential to first determine an appropriate algorithm for the dataset. Different algorithms may produce a large number of different models with different hyperparameter configurations, and it usually takes a lot of time to run the model on a large dataset when the model is relatively complex. Therefore, how to predict the performance of a model on a dataset is an fundamental problem to be solved. This thesis designs a prediction system based on matrix factorization to predict the classification accuracy of a specific model on a particular dataset. In this thesis, we conduct a comprehensive empirical research on more than fifty datasets that we collected from the openml web site. We study the performance prediciton of three fundamental machine learning algorithms, namely, random forest, XGBoost, and MultiLayer Perceptron(MLP). In particular, we obtain the following results: \u2022 Predictability of fine-tuned models using coarse-tuned variants: Usually, training and testing complex machine learning models are time-consuming. Thus, we hope to predict the complicate models by their simple ones. Three machine learning algorithms are compared in experiments. We find that random forest and XGBoost have good predictability on most datasets that is, as the model becomes more complex, the performance of the model becomes better, and thus the accuracy of the complex model can be foreseen directly from its simple model. Hence, we can decide efficiently which algorithm to utilize by comparing simple models. \u2022 Predictability of MLP using feature extraction techniques: Often, real datasets have quite numerous features, from a few hundred to a few thousand features. Training models on fully-featured datasets is a very time-consuming task. We explore the idea of training a model D on datasets that are projected on a few features and use this as a hint to predict the performance of the model D when we consider all features of the dataset. We try different feature extraction techniques including techniques based on permutation importance, gain-based feature importance, hierarchical clustering based on Spearman correlation, and principal component analysis. We study the performance of techniques on the multilayer perceptron (MLP) model and observe that feature extraction with permutation importance and hierarchical clustering based on Spearman correlation has better performance. That is, on most datasets, the accuracy of the MLP improves as the number of features extracted by these techniques increases. \u2022 Predict model performance using implicit feedback: After researching the predictability of three algorithms, our goal is to discover a method that can be used to predict the specific model performance on a particular dataset. In order to predict the classification accuracy of different algorithms on different datasets with different hyperparameters, a prediction system with matrix factorization is built to predict the performance of different models on different datasets. With this system, the input accuracy's can be seen as implicit feedback because there is no more information about the cause of these performance. This system can best achieve an mean absolute error of only 6.7% in the experiment. Predictability of Machine Learning Algorithms and Related Feature Extraction Techniques iii Acknowledgement I would like to thank my supervisor Morteza for his excellent guidance and support during this process. Thanks to my friends and families as well. You kept me motivated. And My parents deserve a particular note of appreciation for always encouraging me. Last but not the least, I am grateful to professor Meng Fang and Wouter Meulemans to be the committee members for me. I hope you enjoy your reading."}, "cited_paper_content": {"title": "Theano: New Features And Speed Improvements", "abstract": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks."}, "keywords": ["many machine learning"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "When analyzing or learning with massive complex data, feature extraction is a generic term for methods combining features or variables to reduce the resource which are necessary to describe large amounts of data, and to solve the problem of overfitting. Theano, a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations, presents new features and efficiency improvements that can be used for feature extraction #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Feature extraction is a crucial step in reducing the resources required to analyze or learn from massive complex data, which usually requires a lot of memory and computational power, and one of the main problems caused by the number of variables involved is overfitting. To address this issue, the authors of Theano: New Features And Speed Improvements have presented new features and efficiency improvements to Theano, a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Many machine learning algorithms require a large number of variables to analyze or learn with massive complex data, which usually requires a lot of memory and computational power. Feature extraction is a generic term for methods combining features or variables to solve these problems with performing sufficient accuracy comparing with the initial dataset (Theano: New Features And Speed Improvements #REFR).", "given_citation_intent": "background", "given_keywords": ["many machine learning"]}]}
{"citing_id": "2305.01470v1", "cited_id": "1401.8257", "section_title": "Comparison To Other Clustering Results For Bandit Problems", "citation": "Gentile, Li, and Zappella #REFR consider a more structured setting, where users can be partitioned into m unknown clusters and the context vectors C t in each round t are generated i.i.d. (where the size can be arbitrary).", "text_before_citation": ["The graph provides structures to the parameters u i , i.e., they assume that (i,j)\u2208E u i \u2212 u j 2 are small compared to i\u2208V u i 2 . The learning proceeds in rounds.", "For each round t, the user index i t and a set of arbitrary context vectors C it = {x t,1 , . . .", ", x t,ct } is presented and the learner has to pick one actionx t \u2208 C it and receives a reward of u T ix t with an additional sub-Gaussian noise.", "Cesa-Bianchi et al #OTHEREFR maintain a set of n linear bandit algorithms and an inverse correlation matrix M t for feedback sharing between bandit algorithms.", "They obtain a regret bound that depends on \u221a nT and log determinant of the matrix M t , which can be O(n)."], "text_after_citation": ["We note that this setting is closely related to our work where m = f + 1.", "Gentile et al #OTHEREFR give a regret bound that depends on \u221a mT with additional O(n + m) terms that are constant with T .", "A recent result by Gentile et al #OTHEREFR considers various data-dependent assumptions to obtain sharper bounds that depend on \u221a T m and n \u2022 polylog(nT ).", "Another line of work, by Maillard and Munos #OTHEREFR and Hong et al #OTHEREFR , considers latent bandits where there is a partition of context types B into C clusters C = {B c }, each with known reward distribution.", "However, the learner, when receiving the context type b \u2208 B, does not know the cluster B c containing b. This is a much harder problem."], "citing_paper_content": {"title": "Stochastic Contextual Bandits With Graph-Based Contexts", "abstract": "We naturally generalize the on-line graph prediction problem to a version of stochastic contextual bandit problems where contexts are vertices in a graph and the structure of the graph provides information on the similarity of contexts. More specifically, we are given a graph G = (V, E), whose vertex set V represents contexts with unknown vertex label y. In our stochastic contextual bandit setting, vertices with the same label share the same reward distribution. The standard notion of instance difficulties in graph label prediction is the cutsize f defined to be the number of edges whose end points having different labels. For line graphs and trees we present an algorithm with regret bound of\u00d5(T 2/3 K 1/3 f 1/3) where K is the number of arms. Our algorithm relies on the optimal stochastic bandit algorithm by Zimmert and Seldin [AISTAT'19, JMLR'21]. When the best arm outperforms the other arms, the regret improves to\u00d5(\u221a KT \u2022 f). The regret bound in the later case is comparable to other optimal contextual bandit results in more general cases, but our algorithm is easy to analyze, runs very efficiently, and does not require an i.i.d. assumption on the input context sequence. The algorithm also works with general graphs using a standard random spanning tree reduction."}, "cited_paper_content": {"title": "Online Clustering Of Bandits", "abstract": "We introduce a novel algorithmic approach to content recommendation based on adaptive clustering of exploration-exploitation \"bandit\") strategies. We provide a sharp regret analysis of this algorithm in a standard stochastic noise setting, demonstrate its scalability properties, and prove its effectiveness on a number of artificial and real-world datasets. Our experiments show a significant increase in prediction performance over state-of-the-art methods for bandit problems."}, "keywords": ["context vectors", "unknown clusters"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The algorithm presented in this manuscript is based on adaptive clustering of exploration-exploitation \"bandit\" strategies, which has been shown to be effective on a number of artificial and real-world datasets, as demonstrated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the problem of content recommendation, the authors of this manuscript propose a novel algorithmic approach based on adaptive clustering of exploration-exploitation \"bandit\" strategies, which has been shown to outperform state-of-the-art methods for bandit problems in both artificial and real-world datasets #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To pick the best action from a set of arbitrary context vectors C it , the learner can use the adaptive clustering of exploration-exploitation strategies algorithm proposed in the reference paper #REFR, which provides a sharp regret analysis and has been proven effective on both artificial and real-world datasets, especially in the case of unknown clusters.", "given_citation_intent": "background", "given_keywords": ["context vectors", "unknown clusters"]}]}
{"citing_id": "2304.12154v1", "cited_id": "1804.10520", "section_title": "Prior Human-Designed Heuristics For Choosing The Ordering", "citation": "It is perhaps surprising that the original heuristic of Brown is able to perform competitively or even beat these others despite having access to less information #REFR .", "text_before_citation": ["Once the importance of variable ordering was established, researchers began looking for strategies to choose a good variable ordering. The first attempts consisted of designing human-made heuristics.", "In 2004 Brown #OTHEREFR documented a heuristic based on three simple hand-picked features of the set of polynomials, for the software QEPCAD. We call this heuristic Brown.", "There have been other heuristics produced which can offer greater accuracy but at greater expense, performing increasing numbers of steps in the CAD algorithm: Dolzmann et al.", "#OTHEREFR concluded it best to perform the projection stage of CAD and compare sums of the total degree of the polynomials produced (sotd); Bradford et al.", "#OTHEREFR considered the initial decomposition of the real line; and Wilson et al. #OTHEREFR the open cells in the decomposition."], "text_after_citation": ["This suggests the necessary information to identify a good ordering may be available from the input alone.", "Most recently del R\u00edo and England #OTHEREFR designed a new simple heuristic gmods based on properties of the input polynomials, selected by studying which features of the input polynomials have the greatest impact on the complexity analysis of CAD."], "citing_paper_content": {"title": "Explainable Ai Insights For Symbolic Computation: A Case Study On Selecting The Variable Ordering For Cylindrical Algebraic Decomposition", "abstract": "In recent years there has been increased use of machine learning (ML) techniques within mathematics, including symbolic computation where it may be applied safely to optimise or select algorithms. This paper explores whether using explainable AI (XAI) techniques on such ML models can offer new insight for symbolic computation, inspiring new implementations within computer algebra systems that do not directly call upon AI tools. We present a case study on the use of ML to select the variable ordering for cylindrical algebraic decomposition. It has already been demonstrated that ML can make the choice well, but here we show how the SHAP tool for explainability can be used to inform new heuristics of a size and complexity similar to those human-designed heuristics currently commonly used in symbolic computation."}, "cited_paper_content": {"title": "Using Machine Learning To Improve Cylindrical Algebraic Decomposition", "abstract": "Cylindrical Algebraic Decomposition (CAD) is a key tool in computational algebraic geometry, best known as a procedure to enable Quantifier Elimination over real-closed fields. However, it has a worst case complexity doubly exponential in the size of the input, which is often encountered in practice. It has been observed that for many problems a change in algorithm settings or problem formulation can cause huge differences in runtime costs, changing problem instances from intractable to easy. A number of heuristics have been developed to help with such choices, but the complicated nature of the geometric relationships involved means these are imperfect and can sometimes make poor choices. We investigate the use of machine learning (specifically support vector machines) to make such choices instead. Machine learning is the process of fitting a computer model to a complex function based on properties learned from measured data. In this paper we apply it in two case studies: the first to select between heuristics for choosing a CAD variable ordering; the second to identify when a CAD problem instance would benefit from Grobner Basis preconditioning. These appear to be the first such applications of machine learning to Symbolic Computation. We demonstrate in both cases that the machine learned choice outperforms human developed heuristics."}, "keywords": ["original heuristic"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the variable ordering selection process, machine learning techniques have been explored, and recent studies have shown that machine learning can outperform human-designed heuristics in this task #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Machine learning has been investigated as a means of making choices between heuristics for choosing a CAD variable ordering, and it has been demonstrated that the machine learned choice outperforms human-developed heuristics, as shown in the study by Brown et al. #OTHEREFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The use of machine learning to select the variable ordering for cylindrical algebraic decomposition has been explored in recent years, with the first attempts consisting of designing human-made heuristics based on simple hand-picked features of the set of polynomials; however, these heuristics are imperfect and can sometimes make poor choices, as noted by the authors of the original heuristic #OTHEREFR.", "given_citation_intent": "background", "given_keywords": ["original heuristic"]}]}
{"citing_id": "2305.01974v1", "cited_id": "1802.06305", "section_title": "Edge Analytics", "citation": "The ML models and their corresponding functions such as clustering, classification and feature extraction, in the context of IoT are extensively investigated in #REFR .", "text_before_citation": ["Distributed data processing frameworks such as Hadoop MapReduce and in-memory alternatives such as Apache Spark, can be employed for this sensor data analytics on the cloud.", "Moreover, since IoT mostly deals with big streaming data, message queues such as Apache Kafka can be used to buffer and feed the data into stream data processing systems such as Apache Storm and Apache Spark streaming #OTHEREFR .", "Additionally, the edge analytics performed can be based on machine learning (ML). E.g. Drolia et al.", "#OTHEREFR , proposed a Pre-Cog system on fog devices that recognizes images rapidly through catching and prefetching. Abdulkareem et al.", "#OTHEREFR , provides a detailed review of approaches performing edge analytics using ML on fog infrastructure."], "text_after_citation": ["There are some generic distributable algorithms such as k-nearest neighbors (k-NN) and other special neural network methods, which can directly be used in resource constrained fog devices for performing ML tasks.", "These studies lead to the development of frameworks such as CANTO #OTHEREFR , that can be used to train neural networks on fog nodes for performing edge analytics.", "However, performing sophisticated ML algorithms in resource and power constrained fog nodes is still a major challenge.", "Support for ML enabling hardware such as ENVISION, that can be used in fog networks, is summarized in 112 ."], "citing_paper_content": {"title": "A Decade Of Research In Fog Computing: Relevance, Challenges, And Future Directions", "abstract": "Recent developments in the Internet of Things (IoT) and real-time applications, have led to the unprecedented growth in the connected devices and their generated data. Traditionally, this sensor data is transferred and processed at the cloud, and the control signals are sent back to the relevant actuators, as part of the IoT applications. This cloud-centric IoT model, resulted in increased latencies and network load, and compromised privacy. To address these problems, Fog Computing was coined by Cisco in 2012, a decade ago, which utilizes proximal computational resources for processing the sensor data. Ever since its proposal, fog computing has attracted significant attention and the research fraternity focused at addressing different challenges such as fog frameworks, simulators, resource management, placement strategies, quality of service aspects, fog economics etc. However, after a decade of research, we still do not see large-scale deployments of public/private fog networks, which can be utilized in realizing interesting IoT applications. In the literature, we only see pilot case studies and small-scale testbeds, and utilization of simulators for demonstrating scale of the specified models addressing the respective technical challenges. There are several reasons for this, and most importantly, fog computing did not present a clear business case for the companies and participating individuals yet. This paper summarizes challenges, state-of-the-art and future research directions in realizing real-time fog computing applications. Contrary to other survey papers, that exhaustively address a specific set of aspects of fog computing, this work discusses the fog research challenges and solutions in much broader scope and thus provides a thorough opinion about progressing the research and quickly adapting fog computing in real-world applications."}, "cited_paper_content": {"title": "Machine Learning For Internet Of Things Data Analysis: A Survey", "abstract": "Rapid developments in hardware, software, and communication technologies have facilitated the emergence of Internet-connected sensory devices that provide observations and data measurements from the physical world. By 2020, it is estimated that the total number of Internet-connected devices being used will be between 25 and 50 billion. As these numbers grow and technologies become more mature, the volume of data being published will increase. The technology of Internet-connected devices, referred to as Internet of Things (IoT), continues to extend the current Internet by providing connectivity and interactions between the physical and cyber worlds. In addition to an increased volume, the IoT generates big data characterized by its velocity in terms of time and location dependency, with a variety of multiple modalities and varying data quality. Intelligent processing and analysis of this big data are the key to developing smart IoT applications. This article assesses the various machine learning methods that deal with the challenges presented by IoT data by considering smart cities as the main use case. The key contribution of this study is the presentation of a taxonomy of machine learning algorithms explaining how different techniques are applied to the data in order to extract higher level information. The potential and challenges of machine learning for IoT data analytics will also be discussed. A use case of applying a Support Vector Machine (SVM) to Aarhus smart city traffic data is presented for a more detailed exploration."}, "keywords": ["IoT"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Moreover, the edge analytics performed can be based on machine learning (ML). E.g. Drolia et al. proposed a Pre-Cog system on fog devices that recognizes images rapidly through catching and prefetching. Abdulkareem et al. provides a detailed review of approaches performing edge analytics using ML on fog infrastructure. Machine learning methods are crucial for intelligent processing and analysis of big data generated by IoT, and this article by Borgia et al. #REFR assesses various machine learning methods that deal with the challenges presented by IoT data by considering smart cities as the main use case.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To extract higher level information from big data generated by IoT, machine learning methods have been assessed, and a taxonomy of machine learning algorithms has been presented in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenges of processing big streaming data generated by IoT, machine learning algorithms have been applied to edge analytics, as demonstrated by Abdulkareem et al. #REFR.", "given_citation_intent": "background", "given_keywords": ["IoT"]}]}
{"citing_id": "2304.03694v1", "cited_id": "1506.04696", "section_title": "Sampling From The Posterior Distribution", "citation": "Furthermore, this typically requires the calculation of higher-order derivatives #REFR which is computationally expensive.", "text_before_citation": ["Generating high-quality sample weights from the posterior distribution is usually done via the simulation of a Markov chain which converges in distribution to the posterior.", "While several Markov chains methods have been constructed for neural network applications, we found them unsuitable for this use case.", "The main difficulty we encountered was, that the scale of the gradients with respect to the different sets of parameters corresponding to the different layers of the neural network vary by several orders of magnitude.", "This makes the use of a single step size for all parameters impossible, as it would cause the sets of parameters with smaller gradients to be frozen during the optimization.", "While modern neural network optimizers circumvent this problem through an adaptive step size for each parameter #OTHEREFR , this is only possible to a very limited degree for Markov chains #OTHEREFR without changing the stationary distribution to which they converge."], "text_after_citation": ["To deal with these challenges, we develop here a new approach to sampling the posterior distribution based on the Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) algorithm introduced by Chen et al. #OTHEREFR .", "In its basic form, the algorithm is given by the Markov chain", "\u2206w t = \u2212 \u2207 \u03b8t u(\u03b8 t ) + M \u22121 Cw t\u22121 \u2206t+ \u221a 2C\u2206tN t (0, I), \u2206\u03b8 t = M \u22121 w t \u2206t.", "where", "u(\u03b8) := \u2212 ln p(\u03b8) \u2212 l i=1 ln p(y i |x i , \u03b8),"], "citing_paper_content": {"title": "High Accuracy Uncertainty-Aware Interatomic Force Modeling With Equivariant Bayesian Neural Networks", "abstract": "Even though Bayesian neural networks offer a promising framework for modeling uncertainty, active learning and incorporating prior physical knowledge, few applications of them can be found in the context of interatomic force modeling. One of the main challenges in their application to learning interatomic forces is the lack of suitable Monte Carlo Markov chain sampling algorithms for the posterior density, as the commonly used algorithms do not converge in a practical amount of time for many of the state-of-the-art architectures. As a response to this challenge, we introduce a new Monte Carlo Markov chain sampling algorithm in this paper which can circumvent the problems of the existing sampling methods. In addition, we introduce a new stochastic neural network model based on the NequIP architecture and demonstrate that, when combined with our novel sampling algorithm, we obtain predictions with state-of-the-art accuracy as well as a good measure of uncertainty."}, "cited_paper_content": {"title": "A Complete Recipe For Stochastic Gradient Mcmc", "abstract": "Many recent Markov chain Monte Carlo (MCMC) samplers leverage continuous dynamics to define a transition kernel that efficiently explores a target distribution. In tandem, a focus has been on devising scalable variants that subsample the data and use stochastic gradients in place of full-data gradients in the dynamic simulations. However, such stochastic gradient MCMC samplers have lagged behind their full-data counterparts in terms of the complexity of dynamics considered since proving convergence in the presence of the stochastic gradient noise is non-trivial. Even with simple dynamics, significant physical intuition is often required to modify the dynamical system to account for the stochastic gradient noise. In this paper, we provide a general recipe for constructing MCMC samplers--including stochastic gradient versions--based on continuous Markov processes specified via two matrices. We constructively prove that the framework is complete. That is, any continuous Markov process that provides samples from the target distribution can be written in our framework. We show how previous continuous-dynamic samplers can be trivially\"reinvented\"in our framework, avoiding the complicated sampler-specific proofs. We likewise use our recipe to straightforwardly propose a new state-adaptive sampler: stochastic gradient Riemann Hamiltonian Monte Carlo (SGRHMC). Our experiments on simulated data and a streaming Wikipedia analysis demonstrate that the proposed SGRHMC sampler inherits the benefits of Riemann HMC, with the scalability of stochastic gradient methods."}, "keywords": ["higher-order derivatives"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Generating high-quality sample weights from the posterior distribution is usually done via the simulation of a Markov chain which converges in distribution to the posterior. While several Markov chains methods have been constructed for neural network applications, we found them unsuitable for this use case. The main difficulty we encountered was, that the scale of the gradients with respect to the different sets of parameters corresponding to the different layers of the neural network vary by several orders of magnitude. This makes the use of a single step size for all parameters impossible, as it would cause the sets of parameters with smaller gradients to be frozen during the optimization. While modern neural network optimizers circumvent this problem through an adaptive step size for each parameter (Ruder et al., 2016), this is only possible to a very limited degree for Markov chains #REFR without changing the stationary distribution to which they converge.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of unsuitable Monte Carlo Markov chain sampling algorithms for neural network applications, a recent paper proposed a general recipe for constructing MCMC samplers, including stochastic gradient versions, based on continuous Markov processes specified via two matrices #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of constructing a suitable Monte Carlo Markov chain sampling algorithm for neural network applications, recent research has proposed a recipe for constructing MCMC samplers based on continuous Markov processes specified via two matrices, as demonstrated in #REFR.", "given_citation_intent": "background", "given_keywords": ["higher-order derivatives"]}]}
{"citing_id": "2303.05000v1", "cited_id": "1511.05644", "section_title": "D. Adversarial Autoencoder", "citation": "In contrast to VAE that uses KL divergence and evidence lower bound, adversarial autoencoder (AAE) #REFR uses adversarial learning to impose a specific distribution on the latent variables, making itself superior to VAE in terms of imposing complicated distributions and shaping the latent space.", "text_before_citation": ["The variational autoencoder (VAE) #OTHEREFR provides a principled method for jointly learning deep latent-variable models and corresponding inference models using stochastic gradient descent #OTHEREFR , which is commonly used to generate samples in the target space from pre-defined latent distribution.", "Training a VAE model consists of two kinds of loss: regularization and reconstruction.", "The regularization is aimed to encode the input as certain distributions over the latent space using Kullback-Leibler (KL) divergence, while the reconstruction is to decode the latent variables to the target or original space."], "text_after_citation": ["In our work, we utilize an AAE architecture to model the semantics in the driving scenario."], "citing_paper_content": {"title": "Learning Representation For Anomaly Detection Of Vehicle Trajectories", "abstract": "Predicting the future trajectories of surrounding vehicles based on their history trajectories is a critical task in autonomous driving. However, when small crafted perturbations are introduced to those history trajectories, the resulting anomalous (or adversarial) trajectories can significantly mislead the future trajectory prediction module of the ego vehicle, which may result in unsafe planning and even fatal accidents. Therefore, it is of great importance to detect such anomalous trajectories of the surrounding vehicles for system safety, but few works have addressed this issue. In this work, we propose two novel methods for learning effective and efficient representations for online anomaly detection of vehicle trajectories. Different from general time-series anomaly detection, anomalous vehicle trajectory detection deals with much richer contexts on the road and fewer observable patterns on the anomalous trajectories themselves. To address these challenges, our methods exploit contrastive learning techniques and trajectory semantics to capture the patterns underlying the driving scenarios for effective anomaly detection under supervised and unsupervised settings, respectively. We conduct extensive experiments to demonstrate that our supervised method based on contrastive learning and unsupervised method based on reconstruction with semantic latent space can significantly improve the performance of anomalous trajectory detection in their corresponding settings over various baseline methods. We also demonstrate our methods' generalization ability to detect unseen patterns of anomalies."}, "cited_paper_content": {"title": "Adversarial Autoencoders", "abstract": "In this paper, we propose the\"adversarial autoencoder\"(AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks."}, "keywords": ["autoencoder"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The variational autoencoder (VAE) provides a principled method for jointly learning deep latent-variable models and corresponding inference models using stochastic gradient descent, which is commonly used to generate samples in the target space from pre-defined latent distribution. Training a VAE model consists of two kinds of loss: regularization and reconstruction. The regularization is aimed to encode the input as certain distributions over the latent space using Kullback-Leibler (KL) divergence, while the reconstruction is to decode the latent variables to the target or original space. Recently, adversarial autoencoders (AAEs) #REFR have been proposed to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution, which ensures generating from any part of prior space results in meaningful samples.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution, the adversarial autoencoder (AAE) was proposed in #REFR, which is a probabilistic autoencoder that uses generative adversarial networks (GAN) and can be used in various applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction, and data visualization.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The adversarial autoencoder (AAE) #REFR, a probabilistic autoencoder that uses generative adversarial networks (GAN) for variational inference, has been proposed to match the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution, ensuring that generating from any part of prior space results in meaningful samples.", "given_citation_intent": "method", "given_keywords": ["autoencoder"]}]}
{"citing_id": "2303.02418v1", "cited_id": "1905.08108", "section_title": "Gradient Conflict Analysis.", "citation": "For fair comparison, we select a subset from each user group to keep the interaction number for each user fixed, thus preventing the potential impact of node degree to results #REFR . Figure 8 presents the results.", "text_before_citation": ["To verify that our model can alleviate potential gradient conflict, we perform experiments on user groups with different behavior relevance levels.", "In particular, we divide the test set into six user groups according to the average Pearson correlation #OTHEREFR among all behaviors.", "The calculation of average Pearson correlation can be referred to Appendix A.4."], "text_after_citation": ["We omit the results on the IJCAI dataset due to space limitation, which have consistent trends.", "For more rigorous results, we run each experiment 5 times and draw the mean and fluctuation range on the figure.", "We find that MESI consistently outperforms all baselines among all user groups, which further demonstrates the superiority of MESI for MTL.", "Besides, with the increase of behavior correlations, MESI gets better performances, while the performances of other baselines fluctuate or even decrease.", "A possible reason is the negative transfer caused by potential gradient conflict when knowledge is transferred across different tasks."], "citing_paper_content": {"title": "Compressed Interaction Graph Based Framework For Multi-Behavior Recommendation", "abstract": "Multi-types of user behavior data (e.g., clicking, adding to cart, and purchasing) are recorded in most real-world recommendation scenarios, which can help to learn users' multi-faceted preferences. However, it is challenging to explore multi-behavior data due to the unbalanced data distribution and sparse target behavior, which lead to the inadequate modeling of high-order relations when treating multi-behavior data \"as features\" and gradient conflict in multitask learning when treating multi-behavior data \"as labels\". In this paper, we propose CIGF, a Compressed Interaction Graph based Framework, to overcome the above limitations. Specifically, we design a novel Compressed Interaction Graph Convolution Network (CIGCN) to model instance-level high-order relations explicitly. To alleviate the potential gradient conflict when treating multi-behavior data \"as labels\", we propose a Multi-Expert with Separate Input (MESI) network with separate input on the top of CIGCN for multi-task learning. Comprehensive experiments on three large-scale real-world datasets demonstrate the superiority of CIGF. Ablation studies and in-depth analysis further validate * Both authors contributed equally to this research. \u2020 Work done when they were research interns at Huawei Noah's Ark Lab. \u2021 Corresponding author. This work is licensed under a Creative Commons Attribution International 4.0 License."}, "cited_paper_content": {"title": "Neural Graph Collaborative Filtering", "abstract": "Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec [39] and Collaborative Memory Network [5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural_graph_collaborative_filtering."}, "keywords": ["interaction number", "node degree"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To alleviate the potential gradient conflict when treating multi-behavior data \"as labels\", we propose a Multi-Expert with Separate Input (MESI) network with separate input on the top of CIGCN for multi-task learning (Wang et al., 2019).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the effectiveness of our proposed model, we compare it with several state-of-the-art models, including HOP-Rec and Collaborative Memory Network, and demonstrate significant improvements in terms of performance metrics such as precision and recall #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed CIGF framework achieves state-of-the-art performance on three large-scale real-world datasets, demonstrating the superiority of the Compressed Interaction Graph Convolution Network (CIGCN) in modeling instance-level high-order relations explicitly, as well as the effectiveness of integrating user-item interactions into the embedding process to capture the collaborative filtering effect #REFR.", "given_citation_intent": "result", "given_keywords": ["interaction number", "node degree"]}]}
{"citing_id": "2303.01687v1", "cited_id": "1802.06739", "section_title": "Generating Mnist And Fashionmnist Images", "citation": "Table 2 also compares with several existing models, while Figure 3 visually compares results with DP-GAN #REFR , DP-MERF (Harder et al., 2021) and DP-HP (Vinaroz et al., 2022) .", "text_before_citation": ["This necessitates a trade-off in the feature dimensionality: large dimensions can lead to overwhelming amounts of added noise, while small dimensions may be inadequate to serve as a loss for image generation.", "Figure 1 and Table 1 show that for both MNIST and Fashion-MNIST, changing the width does somewhat affect the final accuracy and image quality, but this effect is very minimal.", "Therefore, for subsequent experiments, we choose a width of 800 as a good compromise.", "Varying privacy levels Table 2 and Figure 2 show our model's performance under different levels of privacy.", "Other than for FashionMNIST with = 0.2, the performance of our model does not degrade significantly as the privacy requirement becomes more stringent."], "text_after_citation": ["We see that even with simple architectures, DP-NTK broadly performs better than other high-accuracy models, and generates comprehensible images."], "citing_paper_content": {"title": "Differentially Private Neural Tangent Kernels For Privacy-Preserving Data Generation", "abstract": "Maximum mean discrepancy (MMD) is a particularly useful distance metric for differentially private data generation: when used with finitedimensional features it allows us to summarize and privatize the data distribution once, which we can repeatedly use during generator training without further privacy loss. An important question in this framework is, then, what features are useful to distinguish between real and synthetic data distributions, and whether those enable us to generate quality synthetic data. This work considers the using the features of neural tangent kernels (NTKs), more precisely empirical NTKs (e-NTKs). We find that, perhaps surprisingly, the expressiveness of the untrained e-NTK features is comparable to that of the features taken from pre-trained perceptual features using public data. As a result, our method improves the privacy-accuracy trade-off compared to other state-of-the-art methods, without relying on any public data, as demonstrated on several tabular and image benchmark datasets."}, "cited_paper_content": {"title": "Differentially Private Generative Adversarial Network", "abstract": "Generative Adversarial Network (GAN) and its variants have recently attracted intensive research interests due to their elegant theoretical foundation and excellent empirical performance as generative models. These tools provide a promising direction in the studies where data availability is limited. One common issue in GANs is that the density of the learned generative distribution could concentrate on the training data points, meaning that they can easily remember training samples due to the high model complexity of deep networks. This becomes a major concern when GANs are applied to private or sensitive data such as patient medical records, and the concentration of distribution may divulge critical patient information. To address this issue, in this paper we propose a differentially private GAN (DPGAN) model, in which we achieve differential privacy in GANs by adding carefully designed noise to gradients during the learning procedure. We provide rigorous proof for the privacy guarantee, as well as comprehensive empirical evidence to support our analysis, where we demonstrate that our method can generate high quality data points at a reasonable privacy level."}, "keywords": ["DP-GAN"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the issue of privacy in generative models, the authors proposed a differentially private Generative Adversarial Network (DPGAN) model, which achieves differential privacy by adding carefully designed noise to gradients during the learning procedure #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors demonstrate that their differentially private generative adversarial network (DPGAN) model can generate high quality data points at a reasonable privacy level, which is consistent with the findings in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors address the issue of privacy concerns when applying GANs to sensitive data by proposing a differentially private GAN (DP-GAN) model, which adds carefully designed noise to gradients during the learning procedure to achieve differential privacy in GANs, as demonstrated in #REFR.", "given_citation_intent": "result", "given_keywords": ["DP-GAN"]}]}
{"citing_id": "2303.18005v1", "cited_id": "1911.08736", "section_title": "Data In Included Literature", "citation": "The number of participants in internal datasets varied by orders of magnitude, with each study including 1 to 664 ovarian cancer patients, and one study including over 10,000 total patients across a range of 32 malignancies #REFR .", "text_before_citation": [], "text_after_citation": ["Only the five most common subtypes of ovarian carcinoma were used, with no study reporting the inclusion of less common carcinomas or non-epithelial ovarian cancers.", "Only one study explicitly included any prospective data collection, and this was only for a small subset which was not used for external validation #OTHEREFR .", "As shown in Figure 3 , the number of pathology slides used was often much greater than the number of patients included, with three studies using over 1000 slides from ovarian cancer patients #OTHEREFR .", "Most of the studies used WSIs for model development (27/36) , with others using tissue microarrays (TMAs) (4/36) or pre-cropped digital pathology images (2/36).", "Most studies used H&E-stained tissue (27/36) and the others used a variety of IHC stains (9/36), with no two papers reporting the use of the same IHC stains."], "citing_paper_content": {"title": "Artificial Intelligence In Ovarian Cancer Histopathology: A Systematic Review", "abstract": "To characterise and assess the quality of published research evaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or prognosis using histopathology data. Methods A search of PubMed, Scopus, Web of Science, Cochrane Central Register of Controlled Trials, and WHO International Clinical Trials Registry Platform was conducted up to 01/12/2022. The inclusion criteria required that research evaluated AI on histopathology images for diagnostic or prognostic inferences in ovarian cancer, including primary tumours of the ovaries, fallopian tubes, and peritoneum. Reviews and non-English language articles were excluded. The risk of bias was assessed for every model that met the inclusion criteria using the Prediction model Risk Of Bias ASsessment Tool (PROBAST). Information about each model of interest was tabulated and summary statistics were reported. Based on the results, we provided recommendations to improve study design and reporting to reduce the risk of bias and improve the reproducibility of future research in the field. The study protocol was registered on PROSPERO (CRD42022334730). PRISMA 2020 reporting guidelines were followed. Results A total of 1434 research articles were identified, of which 36 were eligible for inclusion. These studies reported 62 models of interest, including 35 classifiers, 14 survival prediction models, 7 segmentation models, and 6 regression models. Models were developed using 1-1375 slides from 1-664 ovarian cancer patients. A wide array of outcomes were predicted, including overall survival (9/62), histological subtypes (7/62), stain quantity (6/62), malignancy (5/62), primary cancer (4/62), and tumour region (4/62). Older studies used traditional machine learning (ML) models with hand-crafted features, while newer studies typically employed deep learning (DL) to automatically learn features and predict the outcome(s) of interest. All models were found to be at high or unclear risk of bias overall, with most research having a high risk of bias in the analysis and a lack of clarity regarding participants and predictors in the study. Research was frequently limited by insufficient reporting, small sample sizes, and insufficient validation, with external validation being particularly rare. Conclusion Limited research has been conducted on the application of AI to histopathology images for diagnostic or prognostic purposes in ovarian cancer, and none of the associated models have been demonstrated to be ready for real-world implementation. Recommendations are provided addressing underlying biases and flaws in study design, which should help inform higher-quality reproducible future research. Key aspects to help ensure clinical translation include more transparent and comprehensive reporting of data provenance and modelling approaches, as well as improved quantitative performance evaluation using cross-validation and external validations."}, "cited_paper_content": {"title": "Pan-Cancer Diagnostic Consensus Through Searching Archival Histopathology Images Using Artificial Intelligence", "abstract": "The emergence of digital pathology has opened new horizons for histopathology. Artificial intelligence (AI) algorithms are able to operate on digitized slides to assist pathologists with different tasks. Whereas AI-involving classification and segmentation methods have obvious benefits for image analysis, image search represents a fundamental shift in computational pathology. Matching the pathology of new patients with already diagnosed and curated cases offers pathologists a new approach to improve diagnostic accuracy through visual inspection of similar cases and computational majority vote for consensus building. In this study, we report the results from searching the largest public repository (The Cancer Genome Atlas, TCGA) of whole-slide images from almost 11,000 patients. We successfully indexed and searched almost 30,000 high-resolution digitized slides constituting 16 terabytes of data comprised of 20 million 1000 \u00d7 1000 pixels image patches. The TCGA image database covers 25 anatomic sites and contains 32 cancer subtypes. High-performance storage and GPU power were employed for experimentation. The results were assessed with conservative \"majority voting\" to build consensus for subtype diagnosis through vertical search and demonstrated high accuracy values for both frozen section slides (e.g., bladder urothelial carcinoma 93%, kidney renal clear cell carcinoma 97%, and ovarian serous cystadenocarcinoma 99%) and permanent histopathology slides (e.g., prostate adenocarcinoma 98%, skin cutaneous melanoma 99%, and thymoma 100%). The key finding of this validation study was that computational consensus appears to be possible for rendering diagnoses if a sufficiently large number of searchable cases are available for each cancer subtype."}, "keywords": ["664 ovarian cancer", "32 malignancies"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' study on searching archival histopathology images using artificial intelligence demonstrates the potential for computational consensus in rendering diagnoses for cancer subtypes, as shown by high accuracy values for frozen section and permanent histopathology slides of various cancer types. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The emergence of digital pathology has opened new horizons for histopathology, and AI algorithms are able to operate on digitized slides to assist pathologists with different tasks, including image search, which represents a fundamental shift in computational pathology. Matching the pathology of new patients with already diagnosed and curated cases offers pathologists a new approach to improve diagnostic accuracy through visual inspection of similar cases and computational majority vote for consensus building (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In their study, the authors of #REFR successfully indexed and searched almost 30,000 high-resolution digitized slides from almost 11,000 patients with 32 malignancies, demonstrating high accuracy values for both frozen section slides and permanent histopathology slides, which could be useful for future research in the field of AI-assisted ovarian cancer diagnosis.", "given_citation_intent": "background", "given_keywords": ["664 ovarian cancer", "32 malignancies"]}]}
{"citing_id": "2303.16322v1", "cited_id": "1802.02611", "section_title": "Reducing Training Time", "citation": "We observe that FMAS can reproduce the baseline accuracy of DL3+ #REFR , achieving MIoU errors of 23% (e.g., FMAS-FP1), compared to a reported error of 21% on the validation set.", "text_before_citation": ["Figures 2, 3, and 4 plot the MIoU error of the Pareto non-dominated front of the corresponding generation against the FLOPs count, network parameters count, and latency respectively.", "We explore the capacity of FMAS to cut GPU time by evaluating a total of 240 modified Xception variants developed over 20 generations targeting FLOPs, and parameters; and a total of 300 MobileNetV2 variants developed over 25 generations targeting latency.", "Table 3 reports the network structures, GPU time consumption, computational cost, accuracy evaluated on a subset of the validation set, and post-fine-tuning accuracy on the entire validation set of selected networks using the Xception backbone. It presents a #OTHEREFR ."], "text_after_citation": ["Similar to Table 3 , Table 4 reports results when using the Mo-bileNetV2 backbone and searching for 25 generations.", "In addition to FLOPs and parameters, we also report inference latency on the GAP8 for the original model, FCN-VGG16, and selected search results.", "Note that while FCN-VGG16 uses only GAP8-supported operations, making it a suitable baseline, it requires more than 8\u00d7 more RAM than the GAP8 has, and therefore cannot be deployed. Table 1 reports their hyperparameters.", "FMAS-F1 cuts the number of FLOPs by 43% with respect to DL3+, and network parameters by 7.9%, for a relative increase of 5.2% in MIoU error; it was discovered in 0.68 GPU days (generation 17).", "FMAS-F2 trades off only 2.5% of the MIoU error of DL3+ for reducing FLOPs by 10%, and network parameters by 20%, in 0.52 GPU days (generation 13)."], "citing_paper_content": {"title": "Fmas: Fast Multi-Objective Supernet Architecture Search For Semantic Segmentation", "abstract": "We present FMAS, a fast multi-objective neural architecture search framework for semantic segmentation. FMAS subsamples the structure and pre-trained parameters of DeepLabV3+, without finetuning, dramatically reducing training time during search. To further reduce candidate evaluation time, we use a subset of the validation dataset during the search. Only the final, Pareto non-dominated, candidates are ultimately fine-tuned using the complete training set. We evaluate FMAS by searching for models that effectively trade accuracy and computational cost on the PASCAL VOC 2012 dataset. FMAS finds competitive designs quickly, e.g., taking just 0.5 GPU days to discover a DeepLabV3+ variant that reduces FLOPs and parameters by 10% and 20% respectively, for less than 3% increased error. We also search on an edge device called GAP8 and use its latency as the metric. FMAS is capable of finding 2.2\u00d7 faster network with 7.61% MIoU loss."}, "cited_paper_content": {"title": "Encoder-Decoder With Atrous Separable Convolution For Semantic Image Segmentation", "abstract": "Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the effectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89.0\\% and 82.1\\% without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at \\url{https://github.com/tensorflow/models/tree/master/research/deeplab}."}, "keywords": ["baseline accuracy"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. Our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. Table 3 reports the network structures, GPU time consumption, computational cost, accuracy evaluated on a subset of the validation set, and post-fine-tuning accuracy on the entire validation set of selected networks using the Xception backbone. It presents a #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed FMAS framework achieves competitive results with significantly reduced computational cost, as demonstrated by the selected networks in Table 3, which show up to 20% reduction in parameters and FLOPs with less than 3% increased error compared to DeepLabV3+; moreover, the use of Xception and depthwise separable convolution in FMAS is inspired by #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed FMAS framework achieves competitive results with reduced computational cost compared to the baseline accuracy, as demonstrated on the PASCAL VOC 2012 dataset, and the authors attribute this success in part to the use of the DeepLabv3+ model as a starting point #REFR.", "given_citation_intent": "result", "given_keywords": ["baseline accuracy"]}]}
{"citing_id": "2303.00128v1", "cited_id": "1805.12152", "section_title": "Prediction And Transfer", "citation": "This behavior, consistant with findings by #REFR showing that highly predictive non-robust features in the data tend to reduce learner performance when presented with out-of-distribution examples.", "text_before_citation": ["In contrast, Figs.4b,4f ,4c,4g shows significant differences in performance for out-of-distribution (OOD) example testing.", "ReI presents better behaved performance and outperforms by larger margins compared to the standard in all cases.", "106.23 U-Net +FC 55.12 Transformer + FC 106.12 VAE + FC 104.51 ReI-VAE+FC 12.45", "Note that even though the standard methods present a performance advantage over ReI for in-distribution examples, that this is not the case for out-of-distribution examples collected in the wild from Mars.", "ReI learns representations with disentangled variables that show better generalizations against the tested out-of-distribution examples."], "text_after_citation": ["Table 1 provides addditional results comparing performance on Earth-to-Mars transfer on a variety of DL architectures and averaged over all elements y \u2208 R n with n = 11.", "Comparisons include fully connected (FC), multilayer perceptron (MLP), MLP Mixer #OTHEREFR , ResNet #OTHEREFR , U-Net #OTHEREFR , Transformers #OTHEREFR and again the standard VAE #OTHEREFR .", "Note that some of the architectures do not produce a latent representation explicitly, these are however rather trained end-to-end for prediction.", "The number in parenthesis next to each architecture name (e.g., FC(10)) expresses the corresponding depth of layers."], "citing_paper_content": {"title": "Representation Disentaglement Via Regularization By Identification", "abstract": "This work focuses on the problem of learning disentangled representations from observational data. Given observations {x (i) } N i=1 drawn from p(x|y) with generative variables y admitting the distribution factorization p(y) = c p(y c), we ask whether learning disentangled representations matching the space of observations with identification guarantees on the posterior p(z|x,\u0177 c) for each c, is plausible. We argue modern deep representation learning models are ill-posed with collider bias behaviour; a source of bias producing entanglement between generating variables. Under the rubric of causality, we show this issue can be explained and reconciled under the condition of identifiability; attainable under supervision or a weak-form of it. For this, we propose regularization by identification (ReI), a regularization framework defined by the identification of the causal queries involved in the learning problem. Empirical evidence shows that enforcing ReI in a variational framework results in disentangled representations equipped with generalization capabilities to out-of-distribution examples and that aligns nicely with the true expected effect between generating variables and measurement apparatus."}, "cited_paper_content": {"title": "Robustness May Be At Odds With Accuracy", "abstract": "We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed in practice. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception."}, "keywords": ["highly predictive non-robust"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In contrast, Figs.4b,4f ,4c,4g shows significant differences in performance for out-of-distribution (OOD) example testing. ReI presents better behaved performance and outperforms by larger margins compared to the standard in all cases. 106.23 U-Net +FC 55.12 Transformer + FC 106.12 VAE + FC 104.51 ReI-VAE+FC 12.45 Note that even though the standard methods present a performance advantage over ReI for in-distribution examples, that this is not the case for out-of-distribution examples collected in the wild from Mars. ReI learns representations with disentangled variables that show better generalizations against the tested out-of-distribution examples. This phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers, as shown in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the findings in \"Robustness May Be At Odds With Accuracy\" #REFR, the trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting, which is consistent with the better generalizations against the tested out-of-distribution examples achieved by ReI in this work.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The findings in this manuscript are consistent with those in the reference paper #REFR, which demonstrate that highly predictive non-robust models may outperform robust models in out-of-distribution testing scenarios.", "given_citation_intent": "result", "given_keywords": ["highly predictive non-robust"]}]}
{"citing_id": "2303.05228v1", "cited_id": "1906.08249", "section_title": "Related Work", "citation": "This result was later developed in #REFR by counting the number of pairs of coprime polynomials with a nonzero constant term, and by providing a construction for maximal families of Mutually Orthogonal Latin Squares (MOLS) generated by linear bipermutive CA.", "text_before_citation": ["#OTHEREFR studied the analogies between the Lattice Gas Automata (LGA) model for fluids and the SPN paradigm.", "In particular, the authors proposed to use the collision operator of the LGA model to implement the substitution layer of a block cipher.", "We conclude this section with a brief outlook of the research line devoted to orthogonal cellular automata, which has been mostly investigated by the second author of this manuscript. Mariot et al.", "first proved in #OTHEREFR a necessary and sufficient condition for a pair of linear bipermutive CA to generate orthogonal Latin squares.", "The characterization is quite simple, since it consists in checking whether the polynomials associated to the local rules of the CA are relatively prime."], "text_after_citation": ["These results have been subsequently used by Gadouleau et al.", "#OTHEREFR to devise a new construction of bent Boolean functions, which reach the highest possible nonlinearity.", "Later, it turned out that the construction could be greatly simplified through the formalism of linear recurring sequences, instead of using orthogonal CA #OTHEREFR . Formenti et al.", "#OTHEREFR devised a combinatorial algorithm to enumerate all pairs of coprime polynomials with nonzero constant term, and thus all linear OCA of a given diameter.", "Finally, Mariot #OTHEREFR considered orthogonal CA as pseudorandom generators, and devised an algorithm to compute the period of the resulting sequences when the underlying CA are linear."], "citing_paper_content": {"title": "A Classification Of S-Boxes Generated By Orthogonal Cellular Automata", "abstract": "Most of the approaches published in the literature to construct Sboxes via Cellular Automata (CA) work by either iterating a finite CA for several time steps, or by a one-shot application of the global rule. The main characteristic that brings together these works is that they employ a single CA rule to define the vectorial Boolean function of the S-box. In this work, we explore a different direction for the design of S-boxes that leverages on Orthogonal CA (OCA), i.e. pairs of CA rules giving rise to orthogonal Latin squares. The motivation stands on the facts that an OCA pair already defines a bijective transformation, and moreover the orthogonality property of the resulting Latin squares ensures a minimum amount of diffusion. We exhaustively enumerate all S-boxes generated by OCA pairs of diameter 4 \u2264 d \u2264 6, and measure their nonlinearity. Interestingly, we observe that for d = 4 and d = 5 all S-boxes are linear, despite the underlying CA local rules being nonlinear. The smallest nonlinear S-boxes emerges for d = 6, but their nonlinearity is still too low to be used in practice. Nonetheless, we unearth an interesting structure of linear OCA S-boxes, proving that their Linear Components Space (LCS) is itself the image of a linear CA, or equivalently a polynomial code. We finally classify all linear OCA S-boxes in terms of their generator polynomials."}, "cited_paper_content": {"title": "Mutually Orthogonal Latin Squares Based On Cellular Automata", "abstract": "We investigate sets of mutually orthogonal latin squares (MOLS) generated by cellular automata (CA) over finite fields. After introducing how a CA defined by a bipermutive local rule of diameter d over an alphabet of q elements generates a Latin square of order \\(q^{d-1}\\), we study the conditions under which two CA generate a pair of orthogonal Latin squares. In particular, we prove that the Latin squares induced by two Linear Bipermutive CA (LBCA) over the finite field \\(\\mathbb {F}_q\\) are orthogonal if and only if the polynomials associated to their local rules are relatively prime. Next, we enumerate all such pairs of orthogonal Latin squares by counting the pairs of coprime monic polynomials with nonzero constant term and degree n over \\(\\mathbb {F}_q\\). Finally, we present a construction for families of MOLS based on LBCA, and prove that their cardinality corresponds to the maximum number of pairwise coprime polynomials with nonzero constant term. Although our construction does not yield all such families of MOLS, we show that the resulting lower bound is asymptotically close to their actual number."}, "keywords": ["Mutually Orthogonal Latin"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The necessary and sufficient condition for a pair of linear bipermutive CA to generate orthogonal Latin squares was first proved by Mariot et al. in #REFR, where they showed that the polynomials associated with the local rules of the CA must be relatively prime.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Mariot et al. provided a necessary and sufficient condition for a pair of linear bipermutive CA to generate orthogonal Latin squares, which consists of checking whether the polynomials associated to the local rules of the CA are relatively prime #REFR. This background information sheds light on the research line devoted to orthogonal cellular automata.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Mariot et al. provided a necessary and sufficient condition for a pair of linear bipermutive CA to generate Mutually Orthogonal Latin squares, which consists in checking whether the polynomials associated to the local rules of the CA are relatively prime (#REFR).", "given_citation_intent": "background", "given_keywords": ["Mutually Orthogonal Latin"]}]}
{"citing_id": "2303.14969v1", "cited_id": "1804.08328", "section_title": "C.3 Additional Qualitative Comparison With Baselines", "citation": "In Figure 12 , even the GT label for semantic segmentation (\"couch\" class) is noisy as it is a pseudolabel generated by a pre-trained segmentation model #REFR , our model successfully segments two couches present in the figure.", "text_before_citation": ["We provide additional results on the qualitative evaluation of our model and the baselines.", "Figure 11 -14 show visualizations on different query image and support set, where we vary the class of semantic segmentation task included in each support.", "The result shows consistent trends of that we discussed in Section 5.", "Ours is competitive to the fully supervised baselines (DPT and InvPT), while the other few-shot baselines (HSNet, VAT, DGPNet) fail to learn different dense prediction tasks."], "text_after_citation": ["This can be attributed to the task-agnostic architecture of VTM based on non-parametric matching."], "citing_paper_content": {"title": "Universal Few-Shot Learning Of Dense Predic-Tion Tasks With Visual Token Matching", "abstract": "Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted set of tasks such as semantic segmentation, presumably due to challenges in designing a general and unified model that is able to flexibly and efficiently adapt to arbitrary tasks of unseen semantics. We propose Visual Token Matching (VTM), a universal few-shot learner for arbitrary dense prediction tasks. It employs non-parametric matching on patchlevel embedded tokens of images and labels that encapsulates all tasks. Also, VTM flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm. We implement VTM as a powerful hierarchical encoder-decoder architecture involving ViT backbones where token matching is performed at multiple feature hierarchies. We experiment VTM on a challenging variant of Taskonomy dataset and observe that it robustly few-shot learns various unseen dense prediction tasks. Surprisingly, it is competitive with fully supervised baselines using only 10 labeled examples of novel tasks (0.004% of full supervision) and sometimes outperforms using 0.1% of full supervision. Codes are available at https://github.com/GitGyun/visual_token_matching."}, "cited_paper_content": {"title": "Taskonomy: Disentangling Task Transfer Learning", "abstract": "Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and probing this taxonomical structure including a solver that users can employ to devise efficient supervision policies for their use cases."}, "keywords": ["semantic segmentation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our model achieves competitive results compared to fully supervised baselines on various unseen dense prediction tasks, as shown in Figure 11-14. The other few-shot baselines, including HSNet, VAT, and DGPNet, fail to learn different tasks. This demonstrates the effectiveness of our approach, which is based on Visual Token Matching (VTM) #REFR, a universal few-shot learner for arbitrary dense prediction tasks that employs non-parametric matching on patch-level embedded tokens of images and labels.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model the structure of the space of visual tasks, the authors of this paper proposed a fully computational approach that finds transfer learning dependencies across a dictionary of tasks, resulting in a computational taxonomic map for task transfer learning, which could be useful for reducing the demand for labeled data in few-shot learning scenarios such as the one presented in this manuscript. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn different dense prediction tasks, the proposed Visual Token Matching (VTM) method employs non-parametric matching on patch-level embedded tokens of images and labels that encapsulates all tasks, and flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm, as shown in the experiments on a challenging variant of Taskonomy dataset, where VTM is competitive with fully supervised baselines using only 10 labeled examples of novel tasks (0.004% of full supervision) and sometimes outperforms using 0.1% of full supervision, while the other few-shot baselines (HSNet, VAT, DGPNet) fail to learn different dense prediction tasks (#REFR).", "given_citation_intent": "method", "given_keywords": ["semantic segmentation"]}]}
{"citing_id": "2303.11816v1", "cited_id": "1910.06711", "section_title": "Setup", "citation": "To transform the models' output Mel-spectrograms into waveforms, we use MelGAN #REFR as our vocoder.", "text_before_citation": ["We utilize LibriTTS #OTHEREFR as our pre-training dataset and VCTK #OTHEREFR as our voice-cloning dataset."], "text_after_citation": ["The implementation of our FastSpeech 2 model and the training/pruning details can be found in our GitHub repository #OTHEREFR .", "In our experiments, we mainly focus on 8-shot voice cloning, where only 8 audio samples of the target speaker are used for finetuning and pruning.", "For each speaker in VCTK, we randomly sample 8 recordings for a voice cloning task.", "We pre-train the TTS models for 40k steps with LibriTTS, followed by fine-tuning/pruning the model with 8-shot voice cloning tasks until convergence.", "The remaining recordings and their corresponding transcripts are utilized for evaluation."], "citing_paper_content": {"title": "Personalized Lightweight Text-To-Speech: Voice Cloning With Adaptive Structured Pruning", "abstract": "Personalized TTS is an exciting and highly desired application that allows users to train their TTS voice using only a few recordings. However, TTS training typically requires many hours of recording and a large model, making it unsuitable for deployment on mobile devices. To overcome this limitation, related works typically require fine-tuning a pre-trained TTS model to preserve its ability to generate high-quality audio samples while adapting to the target speaker's voice. This process is commonly referred to as \"voice cloning.\" Although related works have achieved significant success in changing the TTS model's voice, they are still required to fine-tune from a large pre-trained model, resulting in a significant size for the voicecloned model. In this paper, we propose applying trainable structured pruning to voice cloning. By training the structured pruning masks with voice-cloning data, we can produce a unique pruned model for each target speaker. Our experiments demonstrate that using learnable structured pruning, we can compress the model size to 7 times smaller while achieving comparable voice-cloning performance."}, "cited_paper_content": {"title": "Melgan: Generative Adversarial Networks For Conditional Waveform Synthesis", "abstract": "Previous works (Donahue et al., 2018a; Engel et al., 2019a) have found that generating coherent raw audio waveforms with GANs is challenging. In this paper, we show that it is possible to train GANs reliably to generate high quality coherent waveforms by introducing a set of architectural changes and simple training techniques. Subjective evaluation metric (Mean Opinion Score, or MOS) shows the effectiveness of the proposed approach for high quality mel-spectrogram inversion. To establish the generality of the proposed techniques, we show qualitative results of our model in speech synthesis, music domain translation and unconditional music synthesis. We evaluate the various components of the model through ablation studies and suggest a set of guidelines to design general purpose discriminators and generators for conditional sequence synthesis tasks. Our model is non-autoregressive, fully convolutional, with significantly fewer parameters than competing models and generalizes to unseen speakers for mel-spectrogram inversion. Our pytorch implementation runs at more than 100x faster than realtime on GTX 1080Ti GPU and more than 2x faster than real-time on CPU, without any hardware specific optimization tricks."}, "keywords": ["vocoder"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To train our TTS model, we draw inspiration from recent works on generating coherent raw audio waveforms with GANs (Donahue et al., 2018a; Engel et al., 2019a). Specifically, we utilize the techniques proposed in Melgan: Generative Adversarial Networks For Conditional Waveform Synthesis #REFR to reliably generate high quality coherent waveforms.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train our structured pruning masks, we use the method proposed in Melgan: Generative Adversarial Networks For Conditional Waveform Synthesis #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To generate high-quality audio samples, the authors of this paper utilized a set of architectural changes and simple training techniques with GANs, as described in Melgan: Generative Adversarial Networks For Conditional Waveform Synthesis #REFR.", "given_citation_intent": "method", "given_keywords": ["vocoder"]}]}
{"citing_id": "2303.16694v1", "cited_id": "1403.6199", "section_title": "Introduction", "citation": "Some expand on the ideas of influence prediction discussed previously to give an estimate of the level of activity a particular topic will receive, rather than a binary indicator for whether the campaign was successful (e.g. #REFR ).", "text_before_citation": ["Complementary to attempts to understand popular topics is the identification of individual user accounts that drive these trends.", "Previous efforts have considered user metadata and posting habits online #OTHEREFR or social network position #OTHEREFR to predict user influence.", "Most such efforts are hampered, however, by weak definitions (that use a partial substitute or proxy for influence) or incomplete data (since most data samples do not capture all interactions between individuals or content exposure due to practicalities and privacy constraints).", "Thus the challenge of measuring influence remains unsolved and new efforts are required to offer a more complete picture of interpersonal and organisational influence in online spaces.", "Attempts to quantify information contagion or influence campaigns on contact networks have seen success."], "text_after_citation": ["Many studies of information diffusion online rely on the use of specific parameters such as users, keywords, hashtags and URLs (see e.g. #OTHEREFR", "2020 ; Cruickshank and Carley 2020)) but these necessarily miss relevant discussions that do not use the predetermined search parameters.", "Work by #OTHEREFR is of particular relevance to the aims of this manuscript.", "Their research presented a means of quantifying the flow of attention between different conversational formats, using averaged word co-occurrence of texts to measure the change in agreement after the publication of a reference text.", "Regression analysis revealed that a small, but significant, flow of words emerged from news articles shared on Facebook to speeches made by MPs in the UK Houses of Parliament."], "citing_paper_content": {"title": "Using Semantic Similarity And Text Embedding To Measure The Social Media Echo Of Strategic Communications", "abstract": "Online discourse covers a wide range of topics and many actors tailor their content to impact online discussions through carefully crafted messages and targeted campaigns. Yet the scale and diversity of online media content make it difficult to evaluate the impact of a particular message. In this paper, we present a new technique that leverages semantic similarity to quantify the change in the discussion after a particular message has been published. We use a set of press releases from environmental organisations and tweets from the climate change debate to show that our novel approach reveals a heavy-tailed distribution of response in online discourse to strategic communications."}, "cited_paper_content": {"title": "Predicting Successful Memes Using Network And Community Structure", "abstract": "We investigate the predictability of successful memes using their early spreading patterns in the underlying social networks. We propose and analyze a comprehensive set of features and develop an accurate model to predict future popularity of a meme given its early spreading patterns. Our paper provides the first comprehensive comparison of existing predictive frameworks. We categorize our features into three groups: influence of early adopters, community concentration, and characteristics of adoption time series. We find that features based on community structure are the most powerful predictors of future success. We also find that early popularity of a meme is not a good predictor of its future popularity, contrary to common belief. Our methods outperform other approaches, particularly in the task of detecting very popular or unpopular memes."}, "keywords": ["influence prediction"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Attempts to quantify information contagion or influence campaigns on contact networks have seen success. Community structure has been found to be the most powerful predictor of future success of memes in social networks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Complementary to attempts to understand popular topics is the identification of individual user accounts that drive these trends. Previous efforts have considered user metadata and posting habits online to predict user influence. Most such efforts are hampered, however, by weak definitions or incomplete data. Thus the challenge of measuring influence remains unsolved and new efforts are required to offer a more complete picture of interpersonal and organisational influence in online spaces. Attempts to quantify information contagion or influence campaigns on contact networks have seen success. In this regard, the work by the authors of \"Predicting Successful Memes Using Network And Community Structure\" provides a comprehensive comparison of existing predictive frameworks and proposes a set of features that are based on community structure and are the most powerful predictors of future success. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Complementary to attempts to understand popular topics is the identification of individual user accounts that drive these trends, with previous efforts considering user metadata and posting habits online or social network position to predict user #KEYWORD1. However, as most such efforts are hampered by weak definitions or incomplete data, new efforts are required to offer a more complete picture of interpersonal and organizational #KEYWORD1 in online spaces. A recent study on predicting successful memes using network and community structure could provide valuable insights into this challenge #REFR.", "given_citation_intent": "background", "given_keywords": ["influence prediction"]}]}
{"citing_id": "2303.16485v1", "cited_id": "2003.08934", "section_title": "Approach", "citation": "Finally, we combine NeRF #REFR by querying point features from TriVol at sampled locations to render the final images. An overview of our method is illustrated in Fig. 2 .", "text_before_citation": ["We aim to train a category-specific point renderer R to directly generate photo-realistic images I (the image height and width are denoted as H and W ) from the colored point cloud P , given camera parameters (intrinsic parameter K and extrinsic parameters R and t).", "When rendering novel point clouds of the same category, no fine-tuning process is required. The rendering process can be represented as", "EQUATION", "where P is usually obtained from MVS #OTHEREFR , LiDAR scanners #OTHEREFR , or sampled from synthesized mesh models.", "In this section, we first encode the point cloud as the proposed TriVol, then utilize three 3D UNet to decode it into the feature representation."], "text_after_citation": [], "citing_paper_content": {"title": "Trivol: Point Cloud Rendering Via Triple Volumes", "abstract": "Figure 1. Given the colored point cloud of a category-specific scene or object, our TriVol can render photo-realistic images."}, "cited_paper_content": {"title": "Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis", "abstract": "We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing direction $(\\theta, \\phi)$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons."}, "keywords": ["point features"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To render photo-realistic images from colored point clouds, we propose TriVol, which utilizes three 3D UNet to decode the point cloud into the feature representation. The rendering process can be represented as EQUATION where P is usually obtained from MVS #OTHEREFR, LiDAR scanners #OTHEREFR, or sampled from synthesized mesh models. Our approach achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve photo-realistic rendering of complex scenes from a colored point cloud, TriVol utilizes a fully-connected deep network and classic volume rendering techniques, which are optimized using a set of images with known camera poses #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To decode the proposed TriVol into point features, the authors utilized three 3D UNet, as described in their method for synthesizing novel views of complex scenes using neural radiance fields #REFR.", "given_citation_intent": "method", "given_keywords": ["point features"]}]}
{"citing_id": "2303.15585v1", "cited_id": "1905.12843", "section_title": "Conducting The Literature Review", "citation": "Specifically, Google's #REFR and Meta's 3 RAI principles talk about \"fairness and inclusion\", Amazon's 4 RAI principles promote \"diversity, equity, and inclusion\" through \"detecting bias\".", "text_before_citation": ["That excludes the first part of the query, which tries to match terms such as wearable(s) or mobile(s) only in the papers' meta-data, as seen in Figure 3 .", "Query Definition.", "For the definition of our query, we followed similar terminology with relevant review papers in the fairness literature #OTHEREFR .", "Additionally, according to Fjeld et al.'s analysis of prominent AI principles documents, #OTHEREFR , \"the fairness and non-discrimination theme is the most highly represented theme in our dataset, with every document referencing at least one of its six principles: \"non-discrimination and the prevention of bias\", \"representative and high-quality data\", \"fairness\", \"equality\", \"inclusiveness in impact\", and \"inclusiveness in design\", mostly included in our query's coverage.", "To capture the industrial perspective, we consulted the Responsible Artificial Intelligence (RAI) white papers issued by large tech companies."], "text_after_citation": ["Similarly, Nokia's #OTHEREFR RAI fairness pillar talks about \"fairness, non-discrimination, accessibility, and inclusivity\", and Intel's RAI pillars mention \"enabling ethical and equitable AI\".", "Thus, an iterative refinement process resulted in the query shown in Figure 3 .", "Eligibility Assessment.", "To further validate our query, we manually inspected all publications from the latest IMWUT proceedings (Volume 6, Issue 4, published in January 2023) ( = 56) to identify eligible papers for inclusion (see inclusion and exclusion criteria below).", "In total, we identified seven relevant publications, all of which were also returned by our query."], "citing_paper_content": {"title": "Beyond Accuracy: A Critical Review Of Fairness In Machine Learning For Mobile And Wearable Computing", "abstract": "The field of mobile, wearable, and ubiquitous computing (UbiComp) is undergoing a revolutionary integration of machine learning. Devices can now diagnose diseases, predict heart irregularities, and unlock the full potential of human cognition. However, the underlying algorithms are not immune to biases with respect to sensitive attributes (e.g., gender, race), leading to discriminatory outcomes. The research communities of HCI and AI-Ethics have recently started to explore ways of reporting information about datasets to surface and, eventually, counter those biases. The goal of this work is to explore the extent to which the UbiComp community has adopted such ways of reporting and highlight potential shortcomings. Through a systematic review of papers published in the Proceedings of the ACM Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) journal over the past 5 years (2018-2022), we found that progress on algorithmic fairness within the UbiComp community lags behind. Our findings show that only a small portion (5%) of published papers adheres to modern fairness reporting, while the overwhelming majority thereof focuses on accuracy or error metrics. In light of these findings, our work provides practical guidelines for the design and development of ubiquitous technologies that not only strive for accuracy but also for fairness. CCS Concepts: \u2022 Human-centered computing \u2192 Ubiquitous and mobile computing; \u2022 Applied computing \u2192 Consumer health; \u2022 Computing methodologies \u2192 Artificial intelligence; \u2022 Social and professional topics \u2192 Codes of ethics."}, "cited_paper_content": {"title": "Fair Regression: Quantitative Definitions And Reduction-Based Algorithms", "abstract": "In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems \\emph{fair regression}. We propose general schemes for fair regression under two notions of fairness: (1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitz-continuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness--accuracy frontiers on several standard datasets."}, "keywords": ["fairness"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose general schemes for fair regression under two notions of fairness, statistical parity and bounded group loss, which only require access to standard risk minimization algorithms and provide theoretical guarantees on the optimality and fairness of the obtained solutions #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address biases in machine learning algorithms with respect to sensitive attributes, such as gender and race, recent research has proposed the concept of fair regression, which guarantees a quantitative notion of fairness while predicting a real-valued target, as discussed in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors propose general schemes for fair regression under two notions of fairness, namely statistical parity and bounded group loss, which guarantee a quantitative notion of fairness with respect to a protected attribute such as gender or race, as described in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["fairness"]}]}
{"citing_id": "2304.04559v1", "cited_id": "1911.10414", "section_title": "Proof Of Concept (Tracking)", "citation": "We confirmed that the pose is successfully tracked without drifting #REFR . Finally, the pose estimation error was (0.13\u00b0, 0.0003).", "text_before_citation": ["For the POC of the proposed idea, we applied TeGRA for tracking. We used seq0 from mix scene.", "We use estimated pose & motion from the previous timestep to initialize (S ini t ,\u1e60 ini t ) in the next timestep as discussed in Sec.3.3. The results are shown in Fig.6 ."], "text_after_citation": ["The average number of events per pose update was 0.2% of the entire pixel."], "citing_paper_content": {"title": "Event-Based Camera Tracker By \u2207 T Nerf", "abstract": "When a camera travels across a 3D world, only a fraction of pixel value changes; an event-based camera observes the change as sparse events. How can we utilize sparse events for efficient recovery of the camera pose? We show that we can recover the camera pose by minimizing the error between sparse events and the temporal gradient of the scene represented as a neural radiance field (NeRF). To enable the computation of the temporal gradient of the scene, we augment NeRF's camera pose as a time function. When the input pose to the NeRF coincides with the actual pose, the output of the temporal gradient of NeRF equals the observed intensity changes on the event's points. Using this principle, we propose an event-based camera pose tracking framework called TeGRA which realizes the pose update by using the sparse event's observation. To the best of our knowledge, this is the first camera pose estimation algorithm using the scene's implicit representation and the sparse intensity change from events."}, "cited_paper_content": {"title": "Sal: Sign Agnostic Learning Of Shapes From Raw Data", "abstract": "Recently, neural networks have been used as implicit representations for surface reconstruction, modelling, learning, and generation. So far, training neural networks to be implicit representations of surfaces required training data sampled from a ground-truth signed implicit functions such as signed distance or occupancy functions, which are notoriously hard to compute. In this paper we introduce Sign Agnostic Learning (SAL), a deep learning approach for learning implicit shape representations directly from raw, unsigned geometric data, such as point clouds and triangle soups. We have tested SAL on the challenging problem of surface reconstruction from an un-oriented point cloud, as well as end-to-end human shape space learning directly from raw scans dataset, and achieved state of the art reconstructions compared to current approaches. We believe SAL opens the door to many geometric deep learning applications with real-world data, alleviating the usual painstaking, often manual pre-process."}, "keywords": ["pose estimation error", "pose"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To enable the computation of the temporal gradient of the scene, we augment NeRF's camera pose as a time function. When the input pose to the NeRF coincides with the actual pose, the output of the temporal gradient of NeRF equals the observed intensity changes on the event's points. Using this principle, we propose an event-based camera pose tracking framework called TeGRA which realizes the pose update by using the sparse event's observation. This approach has shown state-of-the-art reconstructions compared to current approaches #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn implicit shape representations directly from raw, unsigned geometric data, such as point clouds and triangle soups, the authors proposed Sign Agnostic Learning (SAL) which achieved state of the art reconstructions compared to current approaches, as described in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the camera pose, we utilized a deep learning approach called TeGRA, which updates the pose using sparse event observations and the scene's implicit representation, as discussed in Sec.3.3. This approach has shown promising results in minimizing the pose estimation error, and we believe it can be further improved by incorporating the Sign Agnostic Learning (SAL) method proposed in #REFR for learning implicit shape representations directly from raw, unsigned geometric data such as point clouds and triangle soups.", "given_citation_intent": "background", "given_keywords": ["pose estimation error", "pose"]}]}
{"citing_id": "2303.12255v1", "cited_id": "1711.00848", "section_title": "Background And Related Work", "citation": "DIP-VAE #REFR uses the concept of \"moment\" to predict the future posterior, and uses this extra information to move the prior towards the approximate posterior.", "text_before_citation": ["We only show two out of infinite true posteriors here to simplify the representation.", "(iii) Reducing the size of Gap 3 with adaptable priors: GMVAE #OTHEREFR creates a finite set of candidate priors.", "disentangling \u03b2-VAE #OTHEREFR creates an infinite set of candidate priors on an \"equal KL-divergence\" line (see Figure 3 row 2 column 1 all dashed curves for clarity).", "(iv) Reducing the size of Gap 3 by adapting the prior to approximate the posterior: VAMP #OTHEREFR has a mixture prior, and uses aggregate posterior #OTHEREFR to move prior towards the approximated posterior during training.", "\u03b2-TCVAE #OTHEREFR adds a regularization term to optimize the prior towards the posterior during training."], "text_after_citation": ["FactorVAE #OTHEREFR adds a regularization term to factorize prior to adapt to low-variance posterior.", "(v) Reducing the size of Gap 2R and Gap 3R with a low-variance local prior: To achieve this goal without increasing Gap 2L and 3L, having many low-variance approximate posteriors is necessary to approximate the highvariance distribution.", "These posteriors result in an inaccurate approximation of hte high-level factors when a model is small. The extreme case is Autoencoders #OTHEREFR .", "WAE #OTHEREFR only maintains prior-like global approximate posteriors, but reduces the variance of local posteriors.", "VQVAE #OTHEREFR nears the extreme with a no-variance quantized latent prior."], "citing_paper_content": {"title": "Encoding Binary Concepts In The Latent Space Of Generative Models For Enhancing Data Representation", "abstract": "Binary concepts 1 are empirically used by humans to generalize efficiently. And they are based on Bernoulli distribution which is the building block of information. These concepts span both low-level and high-level features such as \"large vs small\" and \"a neuron is active or inactive\". Binary concepts are ubiquitous features and can be used to transfer knowledge to improve model generalization. We propose a novel binarized regularization to facilitate learning of binary concepts to improve the quality of data generation in autoencoders. We introduce a binarizing hyperparameter r in data generation process to disentangle the latent space symmetrically. We demonstrate that this method can be applied easily to existing variational autoencoder (VAE) variants to encourage symmetric disentanglement, improve reconstruction quality, and prevent posterior collapse without computation overhead. We also demonstrate that this method can boost existing models to learn more transferable representations and generate more representative samples for the input distribution which can alleviate catastrophic forgetting using generative replay under continual learning settings."}, "cited_paper_content": {"title": "Variational Inference Of Disentangled Latent Concepts From Unlabeled Observations", "abstract": "Disentangled representations, where the higher level data generative factors are reflected in disjoint latent dimensions, offer several benefits such as ease of deriving invariant representations, transferability to other tasks, interpretability, etc. We consider the problem of unsupervised learning of disentangled representations from large pool of unlabeled observations, and propose a variational inference based approach to infer disentangled latent factors. We introduce a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement. We evaluate the proposed approach using several quantitative metrics and empirically observe significant gains over existing methods in terms of both disentanglement and data likelihood (reconstruction quality)."}, "keywords": ["approximate posterior"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Reducing the size of Gap 3 with adaptable priors can be achieved by creating a finite set of candidate priors as in GMVAE, or by creating an infinite set of candidate priors on an \"equal KL-divergence\" line as in disentangling \u03b2-VAE (see Figure 3 row 2 column 1 all dashed curves for clarity), while VAMP has a mixture prior and uses aggregate posterior to move prior towards the approximated posterior during training, and \u03b2-TCVAE adds a regularization term to optimize the prior towards the posterior during training #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Disentangled representations have been shown to offer several benefits such as ease of deriving invariant representations, transferability to other tasks, and interpretability, and recent work has proposed a variational inference based approach to infer disentangled latent factors from large pool of unlabeled observations #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Variational inference based approaches have been proposed to infer disentangled latent factors, with a regularizer on the expectation of the approximate posterior over observed data that encourages the disentanglement #REFR.", "given_citation_intent": "background", "given_keywords": ["approximate posterior"]}]}
{"citing_id": "2305.00606v1", "cited_id": "1804.08771", "section_title": "Experiments", "citation": "We used the SacreBLEU #REFR implementation 9 of the BLUE metric to evaluate the models.", "text_before_citation": ["We split our dataset into different size configurations and in each configuration, the model is trained in the directions Fr\u2192Wo and Fr\u2192En until it reaches convergence.", "Convergence is considered to be reached when no improvement is observed on the validation set after 6 checkpoints.", "For data subwording, we used SentencePiece #OTHEREFR with Byte-Pair Encoding (BPE) which offers interesting performance gains in agglutinative languages like Wolof #OTHEREFR .", "We then generated a vocabulary on all segments of the considered size configuration's training set and performed an automatic model evaluation using BLEU #OTHEREFR .", "BLEU is the most widely used metric in NMT in view of the fairly high correlation it has with human evaluations."], "text_after_citation": [], "citing_paper_content": {"title": "Low-Resourced Machine Translation For Senegalese Wolof Language", "abstract": "Natural Language Processing (NLP) research has made great advancements in recent years with major breakthroughs that have established new benchmarks. However, these advances have mainly benefited a certain group of languages commonly referred to as resource-rich such as English and French. Majority of other languages with weaker resources are then left behind which is the case for most African languages including Wolof. In this work, we present a parallel Wolof/French corpus of 123,000 sentences on which we conducted experiments on machine translation models based on Recurrent Neural Networks (RNN) in different data configurations. We noted performance gains with the models trained on subworded data as well as those trained on the French-English language pair compared to those trained on the French-Wolof pair under the same experimental conditions."}, "cited_paper_content": {"title": "A Call For Clarity In Reporting Bleu Scores", "abstract": "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to\"the\"BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SacreBLEU, to facilitate this."}, "keywords": ["SacreBLEU implementation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We then generated a vocabulary on all segments of the considered size configuration's training set and performed an automatic model evaluation using BLEU, the most widely used metric in NMT in view of the fairly high correlation it has with human evaluations #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure consistency in reporting BLEU scores, the authors suggest using the BLEU scheme employed by the annual Conference on Machine Translation (WMT) and provide a new tool, SacreBLEU, to facilitate this #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure consistency in reporting BLEU scores, the authors suggest using the SacreBLEU implementation proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["SacreBLEU implementation"]}]}
{"citing_id": "2303.17707v1", "cited_id": "2002.01650", "section_title": "Plausibility Is A Misaligned Objective For Xai Evaluation And Optimization", "citation": "This may be due to the fact that post-hoc XAI algorithms only summarize partial decision information from the model, whereas information on the full decision process is scattered throughout the model #REFR .", "text_before_citation": ["Doing so is misleading, harmful, and cannot achieve its expected explanation goals of understandability, trustworthiness, and transparency.", "The reasons are as follows: First, using plausibility to evaluate XAI algorithms is based on the assumption that the explanation truthfully reflects the AI model decision process #OTHEREFR .", "Users (including both technical users and non-technical users) hold this implicit assumption for AI explanations when interpreting them and assessing their plausibility.", "But explanation truthfulness or faithfulness is not an intrinsic or de facto property of XAI algorithms, and this assumption may not hold true unless it is explicitly validated #OTHEREFR .", "Indeed, prior systematic evaluations on posthoc XAI algorithms #OTHEREFR -algorithms that act as surrogate models to explain for a black-box AI model -show that post-hoc XAI algorithms do not truthfully reflect the decision process of the to-be-explained AI models #OTHEREFR ."], "text_after_citation": ["Intrinsically interpretable AI models -models that incorporate interpretability into their decision processdo not guarantee the truthfulness assumption, and should be explicitly validated for truthfulness of its explanations as well #OTHEREFR .", "If we select or optimize XAI algorithms solely for their plausibility while violating the truthfulness assumption, the resultant explanation can be misleading: without the truthfulness constraint, the XAI algorithm can be purposely optimized to generate explanations that are close to those of humans, at a time when the model's explanation is not even relevant to its underlying decision process.", "Such explanation cannot provide users with any insightful information about the model decision process to make the AI model more transparent.", "Furthermore, since users still hold the truthfulness assumption for AI explanation, the seemingly plausible explanation may deceitfully persuade users to trust the AI model and adopt its decisions, despite being potentially wrong #OTHEREFR .", "In highstakes applications, this may even lead to harmful consequences."], "citing_paper_content": {"title": "Rethinking Ai Explainability And Plausibility", "abstract": "Setting proper evaluation objectives for explainable artificial intelligence (XAI) is vital for making XAI algorithms follow human communication norms, support human reasoning processes, and fulfill human needs for AI explanations. In this article, we examine explanation plausibility, which is the most pervasive human-grounded concept in XAI evaluation. Plausibility measures how reasonable the machine explanation is compared to the human explanation. Plausibility has been conventionally formulated as an important evaluation objective for AI explainability tasks. We argue against this idea, and show how optimizing and evaluating XAI for plausibility is sometimes harmful, and always ineffective to achieve model understandability, transparency, and trustworthiness. Specifically, evaluating XAI algorithms for plausibility regularizes the machine explanation to express exactly the same content as human explanation, which deviates from the fundamental motivation for humans to explain: expressing similar or alternative reasoning trajectories while conforming to understandable forms or language. Optimizing XAI for plausibility regardless of the model decision correctness also jeopardizes model trustworthiness, as doing so breaks an important assumption in human-human explanation namely that plausible explanations typically imply correct decisions, and violating this assumption eventually leads to either undertrust or overtrust of AI models. Instead of being the end goal in XAI evaluation, plausibility can serve as an intermediate computational proxy for the human process of interpreting explanations to optimize the utility of XAI. We further highlight the importance of explainability-specific evaluation objectives by differentiating the AI explanation task from the object localization task."}, "cited_paper_content": {"title": "Concept Whitening For Interpretable Image Recognition", "abstract": "What does a neural network encode about a concept as we traverse through the layers? Interpretability in machine learning is undoubtedly important, but the calculations of neural networks are very challenging to understand. Attempts to see inside their hidden layers can either be misleading, unusable, or rely on the latent space to possess properties that it may not have. In this work, rather than attempting to analyze a neural network posthoc, we introduce a mechanism, called concept whitening (CW), to alter a given layer of the network to allow us to better understand the computation leading up to that layer. When a concept whitening module is added to a CNN, the axes of the latent space can be aligned with concepts of interest. By experiment, we show that CW can provide us a much clearer understanding for how the network gradually learns concepts over layers without hurting predictive performance."}, "keywords": ["partial decision information"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' proposed concept whitening (CW) mechanism can be used to better understand the computation leading up to a given layer of a neural network #REFR, which can be challenging to interpret otherwise.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Attempts to understand the computations of neural networks have been challenging, but a mechanism called concept whitening (CW) has been introduced to alter a given layer of the network and provide a clearer understanding of how the network gradually learns concepts over layers without hurting predictive performance #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Prior systematic evaluations on posthoc XAI algorithms, which act as surrogate models to explain for a black-box AI model, show that these algorithms do not truthfully reflect the partial decision information of the to-be-explained AI models (Concept Whitening For Interpretable Image Recognition). #REFR", "given_citation_intent": "background", "given_keywords": ["partial decision information"]}]}
{"citing_id": "2304.07175v1", "cited_id": "1710.08092", "section_title": "Skin Tone And False Match Pairs", "citation": "It is based on the popular ResNet-50 network structure and trained on the VGGFace2 dataset #REFR with standard softmax loss.", "text_before_citation": ["(In light of the recent work of Albiero #OTHEREFR , we might now add that differing social conventions for hairstyle present another confounding effect.) In Issues Related to Face Recognition Accuracy Varying Based on Race and Skin Tone, Krishnapriya et al.", "#OTHEREFR published the first experiment intended to isolate the effect of skin tone alone on accuracy.", "To directly test the premise that face recognition is less accurate for darker skin tones, they examined a #OTHEREFR .) range of tones within the single demographic of African American male (AAM) using the MORPH dataset.", "They used two matchers to produce AAM impostor distributions: ArcFace (as described in Section 0.2) and a publicly-available VGGFace2 model #OTHEREFR .", "VGGFace2 is representative of the state-of-the-art in CNN matchers prior to ArcFace."], "text_after_citation": ["Faces are detected, aligned, and resized to 224\u00d7224 pixels, and a 2048-d feature vector is taken from the next-to-last layer.", "As with ArcFace, cosine similarity is measured between feature vectors.", "Krishnapriya et al.", "compared the frequency of images with darker skin tone in two regions of the AAM impostor distribution.", "The high-similarity tail (HST) is the region containing the non-mated image pairs that are most likely to cause false matches."], "citing_paper_content": {"title": "Exploring Causes Of Demographic Variations In Face Recognition Accuracy", "abstract": "FIGURE 1 Apple's Face ID ad campaign touted ease of use and improved security for face recognition over the prior fingerprint standard, and made bold promises. 0.1 Introduction Automated facial recognition (FR) technology dates back to the early 1970s, with Takeo Kanade's 1973 Ph.D. thesis Picture Processing System by Computer Complex and Recognition of Human Faces [1] often cited as an early landmark work. However, it was not until the late 2010s that increased availability and power of FR technology increased its routine usage. In 2017, Apple introduced the iPhone X as the \"smartphone industry's benchmark\" [2], with their new facial identification system, Face ID, as a primary innovation and selling point [3, 4] (Figure 1). The corresponding security guide [5] even claimed \"the probability that a random person in the population could look at your iPhone X and unlock it using Face ID is approximately 1 in 1,000,000 (versus 1 in 50,000 for Touch ID).\" Yet a security flaw was quickly publicized: some Chinese users reported that their iPhones opened for other, non-authorized individuals [6, 7]. The underpinnings of these incidents would soon be explored by the research community, leading to a major question: does face recognition perform equally across all demographics? In 2018, Buolamwini and Gebru explored a related question in Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification [8]. Their work evaluated the accuracy of commercial gender classification software. For one classifier, they reported that error rates for lighter-skinned males were only 0.8%, while error rates for darker-skinned females were dramatically higher, at 34.7%. Provocative headlines like \"Facial Recognition Is Accurate, if You're a White Guy\" [9] sparked public interest in Buolamwini and Gebru's work. Media coverage generally failed to make any distinction between gender classification, the task of assigning a gender label to one face image, and face recognition, the task of deciding whether or not two face images are from the same person. Government research organizations quickly addressed the growing public concern around possible \"bias\" in face recognition accuracy. As part of their 2018 biometric technology rally, the Department of Homeland Security assessed the effect of demographic factors on performance of commercial face biometric systems, as measured by transaction times and by similarity scores of pairs of images of the same person [10]."}, "cited_paper_content": {"title": "Vggface2: A Dataset For Recognising Faces Across Pose And Age", "abstract": "In this paper, we introduce a new large-scale face dataset named VGGFace2. The dataset contains 3.31 million images of 9131 subjects, with an average of 362.6 images for each subject. Images are downloaded from Google Image Search and have large variations in pose, age, illumination, ethnicity and profession (e.g. actors, athletes, politicians). The dataset was collected with three goals in mind: (i) to have both a large number of identities and also a large number of images for each identity; (ii) to cover a large range of pose, age and ethnicity; and (iii) to minimize the label noise. We describe how the dataset was collected, in particular the automated and manual filtering stages to ensure a high accuracy for the images of each identity. To assess face recognition performance using the new dataset, we train ResNet-50 (with and without Squeeze-and-Excitation blocks) Convolutional Neural Networks on VGGFace2, on MS- Celeb-1M, and on their union, and show that training on VGGFace2 leads to improved recognition performance over pose and age. Finally, using the models trained on these datasets, we demonstrate state-of-the-art performance on the IJB-A and IJB-B face recognition benchmarks, exceeding the previous state-of-the-art by a large margin. Datasets and models are publicly available."}, "keywords": ["VGGFace2 dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To directly test the premise that face recognition is less accurate for darker skin tones, they examined a range of tones within the single demographic of African American male (AAM) using the MORPH dataset. They used two matchers to produce AAM impostor distributions: ArcFace (as described in Section 0.2) and a publicly-available VGGFace2 model #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To produce AAM impostor distributions, Krishnapriya et al. used two matchers, including a publicly-available VGGFace2 model #REFR, which was representative of the state-of-the-art in CNN matchers prior to ArcFace.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To produce AAM impostor distributions, Krishnapriya et al. used two matchers, including a publicly-available VGGFace2 model #REFR, which was representative of the state-of-the-art in CNN matchers prior to ArcFace.", "given_citation_intent": "method", "given_keywords": ["VGGFace2 dataset"]}]}
{"citing_id": "2303.04573v1", "cited_id": "1811.11597", "section_title": "Conclusions And Future Work", "citation": "One aspect in which they can prove useful is in the training of algorithm selection models #REFR , as they can significantly increase the size and variety of training data, which is an important consideration towards testing generalizability.", "text_before_citation": ["This is achieved through several transformations, the most common of which is moving the optimum to a different location in the domain.", "The results we present show that the way in which these optimal locations are chosen can have a large impact on the performance of optimization algorithms.", "Since the optima are not distributed uniformly in the domain, some functions have different kinds of bias, which can be exploited by an algorithm.", "The question on how to fairly consider different instance generation mechanisms when making use of function combination is thus highly interlinked with questions about how well performance observed on a set of BBOB instances generalizes.", "Even with these challenges in mind, there are many potential use cases for these affine function combinations."], "text_after_citation": ["One final aspect in which the benchmark data on these function combinations can be further utilized is by linking it back to the exploratory landscape analysis which inspired their creation.", "Since the combinations can smoothly fill the landscape feature space, this can be combined with algorithm performance to get a more fine-grained view of the way in which the landscape interacts with different algorithms #OTHEREFR ."], "citing_paper_content": {"title": "Using Affine Combinations Of Bbob Problems For Performance Assessment", "abstract": "Benchmarking plays a major role in the development and analysis of optimization algorithms. As such, the way in which the used benchmark problems are defined significantly affects the insights that can be gained from any given benchmark study. One way to easily extend the range of available benchmark functions is through affine combinations between pairs of functions. From the perspective of landscape analysis, these function combinations smoothly transition between the two base functions. In this work, we show how these affine function combinations can be used to analyze the behavior of optimization algorithms. In particular, we highlight that by varying the weighting between the combined problems, we can gain insights into the effects of added global structure on the performance of optimization algorithms. By analyzing performance trajectories on more function combinations, we also show that aspects such as the scaling of objective functions and placement of the optimum can greatly impact how these results are interpreted."}, "cited_paper_content": {"title": "Automated Algorithm Selection: Survey And Perspectives", "abstract": "It has long been observed that for practically any computational problem that has been intensely studied, different instances are best solved using different algorithms. This is particularly pronounced for computationally hard problems, where in most cases, no single algorithm defines the state of the art; instead, there is a set of algorithms with complementary strengths. This performance complementarity can be exploited in various ways, one of which is based on the idea of selecting, from a set of given algorithms, for each problem instance to be solved the one expected to perform best. The task of automatically selecting an algorithm from a given set is known as the per-instance algorithm selection problem and has been intensely studied over the past 15 years, leading to major improvements in the state of the art in solving a growing number of discrete combinatorial problems, including propositional satisfiability and AI planning. Per-instance algorithm selection also shows much promise for boosting performance in solving continuous and mixed discrete/continuous optimisation problems. This survey provides an overview of research in automated algorithm selection, ranging from early and seminal works to recent and promising application areas. Different from earlier work, it covers applications to discrete and continuous problems, and discusses algorithm selection in context with conceptually related approaches, such as algorithm configuration, scheduling or portfolio selection. Since informative and cheaply computable problem instance features provide the basis for effective per-instance algorithm selection systems, we also provide an overview of such features for discrete and continuous problems. Finally, we provide perspectives on future work in the area and discuss a number of open research challenges."}, "keywords": ["algorithm selection models"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The question on how to fairly consider different instance generation mechanisms when making use of function combination is thus highly interlinked with questions about how well performance observed on a set of BBOB instances generalizes. Even with these challenges in mind, there are many potential use cases for these affine function combinations, such as the per-instance algorithm selection problem which has been intensely studied over the past 15 years #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Automated algorithm selection has been intensely studied over the past 15 years, leading to major improvements in the state of the art in solving a growing number of discrete combinatorial problems, including propositional satisfiability and AI planning, and shows much promise for boosting performance in solving continuous and mixed discrete/continuous optimization problems #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Automated algorithm selection models have been intensely studied over the past 15 years, leading to major improvements in the state of the art in solving a growing number of discrete combinatorial problems, including propositional satisfiability and AI planning #REFR.", "given_citation_intent": "background", "given_keywords": ["algorithm selection models"]}]}
{"citing_id": "2303.09530v1", "cited_id": "1708.02002", "section_title": "B. Network Architectures And Setup", "citation": "And we employ focal loss #REFR to increase weighting of detections that are especially hard to classify correctly and to better address the severe class imbalance.", "text_before_citation": ["We choose to use the position in the Cartesian vehicle coordinate system (CS) at the time of recording the most recent scan in the point cloud. The timestamp is relative to that moment.", "Moreover, we add the detection's position in the polar sensor CS, which is more useful in some cases, and the measuring sensor's ID.", "When upsampling of the input point cloud is required, that is done by duplicating randomly selected detections. Replicas Finally, we also adjust the training setup. Input data is normalized via standardization.", "To prevent a distortion of following distance calculations, the variances of the Cartesian coordinates are averaged before scaling.", "The learning rate is varied between 10 \u22129 and 10 \u22123 according to a cyclical learning rate policy."], "text_after_citation": ["The remaining training parameters are as described in #OTHEREFR ."], "citing_paper_content": {"title": "Tackling Clutter In Radar Data -Label Generation And Detection Using Pointnet++", "abstract": "Radar sensors employed for environment perception, e.g. in autonomous vehicles, output a lot of unwanted clutter. These points, for which no corresponding real objects exist, are a major source of errors in following processing steps like object detection or tracking. We therefore present two novel neural network setups for identifying clutter. The input data, network architectures and training configuration are adjusted specifically for this task. Special attention is paid to the downsampling of point clouds composed of multiple sensor scans. In an extensive evaluation, the new setups display substantially better performance than existing approaches. Because there is no suitable public data set in which clutter is annotated, we design a method to automatically generate the respective labels. By applying it to existing data with object annotations and releasing its code, we effectively create the first freely available radar clutter data set representing realworld driving scenarios. Code and instructions are accessible at www.github.com/kopp-j/clutter-ds."}, "cited_paper_content": {"title": "Focal Loss For Dense Object Detection", "abstract": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron ."}, "keywords": ["detections", "focal loss"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the issue of extreme foreground-background class imbalance encountered during training of dense detectors, the authors of RetinaNet proposed a novel Focal Loss that down-weights the loss assigned to well-classified examples and focuses training on a sparse set of hard examples, preventing the vast number of easy negatives from overwhelming the detector during training #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the class imbalance encountered during training of dense detectors, the authors propose a novel Focal Loss that focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prevent the vast number of easy negatives from overwhelming the detector during training, the authors propose a novel Focal Loss that focuses training on a sparse set of hard examples, which could be useful for improving the detection of #KEYWORD1 in cluttered radar data (#REFR).", "given_citation_intent": "method", "given_keywords": ["detections", "focal loss"]}]}
{"citing_id": "2303.12319v1", "cited_id": "1902.04043", "section_title": "A. Marl Benchmarks", "citation": "For example, SMAC #REFR is based on the popular real-time strategy game StarCraft II, focuses on micromanagement challenges, and is applicable to studying cooperative MARL.", "text_before_citation": ["Multifarious emerging benchmarks have accelerated MARL research in recent years and provide various evaluation criteria for different application scenarios and research domains.", "Some game platforms have been the most popular benchmarks for evaluating MARL algorithms."], "text_after_citation": ["GRF #OTHEREFR , an environment for playing football tasks of varying difficulty in a physics-based 3D simulation, focuses on multi-level, multi-agent learning.", "Wimblepong #OTHEREFR is a 2-player version of the Atari game Pong, where each player controls a paddle to play a ball with the other, and it is a purely competitive scenario.", "Some environments evolve from single-agent tasks, which decompose single-agent control tasks into multi-agent tasks.", "For instance, MaMujoco #OTHEREFR , based on a single-agent robotic MuJoCo control suite, provides a wide variety of continuous multi-agent robotic control scenarios in which multiple agents within a single robot try to complete a task cooperatively.", "DM Control #OTHEREFR is a set of Python RL environments powered by the MuJoCo physics engine and includes multi-agent soccer simulation environments."], "citing_paper_content": {"title": "Neuronsmae: A Novel Multi-Agent Reinforcement Learning Environment For Cooperative And Competitive Multi-Robot Tasks", "abstract": "Multi-agent reinforcement learning (MARL) has achieved remarkable success in various challenging problems. Meanwhile, more and more benchmarks have emerged and provided some standards to evaluate the algorithms in different fields. On the one hand, the virtual MARL environments lack knowledge of real-world tasks and actuator abilities, and on the other hand, the current task-specified multi-robot platform has poor support for the generality of multi-agent reinforcement learning algorithms and lacks support for transferring from simulation to the real environment. Bridging the gap between the virtual MARL environments and the real multi-robot platform becomes the key to promoting the practicability of MARL algorithms. This paper proposes a novel MARL environment for real multi-robot tasks named NeuronsMAE (Neurons Multi-Agent Environment). This environment supports cooperative and competitive multi-robot tasks and is configured with rich parameter interfaces to study the multi-agent policy transfer from simulation to reality. With this platform, we evaluate various popular MARL algorithms and build a new MARL benchmark for multi-robot tasks. We hope that this platform will facilitate the research and application of MARL algorithms for real robot tasks. Information about the benchmark and the open-source code will be released. Index Terms-multi-agent reinforcement learning, benchamark, multi-robot."}, "cited_paper_content": {"title": "The Starcraft Multi-Agent Challenge", "abstract": "In the last few years, deep multi-agent reinforcement learning (RL) has become a highly active area of research. A particularly challenging class of problems in this area is partially observable, cooperative, multi-agent learning, in which teams of agents must learn to coordinate their behaviour while conditioning only on their private observations. This is an attractive research area since such problems are relevant to a large number of real-world systems and are also more amenable to evaluation than general-sum problems. Standardised environments such as the ALE and MuJoCo have allowed single-agent RL to move beyond toy domains, such as grid worlds. However, there is no comparable benchmark for cooperative multi-agent RL. As a result, most papers in this field use one-off toy problems, making it difficult to measure real progress. In this paper, we propose the StarCraft Multi-Agent Challenge (SMAC) as a benchmark problem to fill this gap. SMAC is based on the popular real-time strategy game StarCraft II and focuses on micromanagement challenges where each unit is controlled by an independent agent that must act based on local observations. We offer a diverse set of challenge maps and recommendations for best practices in benchmarking and evaluations. We also open-source a deep multi-agent RL learning framework including state-of-the-art algorithms. We believe that SMAC can provide a standard benchmark environment for years to come. Videos of our best agents for several SMAC scenarios are available at: https://youtu.be/VZ7zmQ_obZ0."}, "keywords": ["cooperative MARL", "StarCraft II"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Multifarious emerging benchmarks have accelerated MARL research in recent years and provide various evaluation criteria for different application scenarios and research domains. Some game platforms have been the most popular benchmarks for evaluating MARL algorithms. In particular, the StarCraft Multi-Agent Challenge (SMAC) proposed by Samvelyan et al. (#REFR) provides a standardized benchmark for partially observable, cooperative, multi-agent learning, which is a challenging class of problems in this area.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Multifarious emerging benchmarks have accelerated MARL research in recent years and provide various evaluation criteria for different application scenarios and research domains. Some game platforms have been the most popular benchmarks for evaluating MARL algorithms. To this end, the Starcraft Multi-Agent Challenge proposed in \"#REFR\" can serve as a benchmark problem for partially observable, cooperative, multi-agent learning, which is relevant to a large number of real-world systems and is more amenable to evaluation than general-sum problems.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The StarCraft Multi-Agent Challenge proposed by Samvelyan et al. provides a benchmark for evaluating cooperative MARL algorithms in micromanagement challenges, which can be used to measure real progress in this field. #REFR", "given_citation_intent": "method", "given_keywords": ["cooperative MARL", "StarCraft II"]}]}
{"citing_id": "2303.14184v1", "cited_id": "1906.08240", "section_title": "B.2. Refine Stage", "citation": "Following #REFR , we rasterize neural points V to multi-scale feature maps S(i, V ), i \u2208 [0, K), K = 3.", "text_before_citation": ["Point cloud rasterization."], "text_after_citation": ["We use a differentiable point rasterizer implemented by PyTorch3D #OTHEREFR to assign every pixel a neural descriptor and a binary scalar that indicates a non-empty pixel.", "We consider the binary mask as a point-based occupancy mask. Background regularization.", "To handle pixels without corresponding point cloud projection, we assign a learnable descriptor as the background.", "During texture enhancement optimization, we additionally add a regularization to encourage the scene to be rendered with a white background according to the binary occupancy mask mentioned above. Deferred neural rendering.", "For deferred rendering of the point clouds, we use a 2D U-Net architecture with gated convolutions #OTHEREFR ."], "citing_paper_content": {"title": "Make-It-3D: High-Fidelity 3D Creation From A Single Image With Diffusion Prior", "abstract": "Reference Normal Novel Views Reference Normal Novel Views Figure 1: Make-It-3D can create high-fidelity 3D content from only a single image. We show the normal map and novel-view renderings of created 3D content, showcasing fine geometry and faithful textures with stunning quality at novel views."}, "cited_paper_content": {"title": "Neural Point-Based Graphics", "abstract": "We present a new point-based approach for modeling the appearance of real scenes. The approach uses a raw point cloud as the geometric representation of a scene, and augments each point with a learnable neural descriptor that encodes local geometry and appearance. A deep rendering network is learned in parallel with the descriptors, so that new views of the scene can be obtained by passing the rasterizations of a point cloud from new viewpoints through this network. The input rasterizations use the learned descriptors as point pseudo-colors. We show that the proposed approach can be used for modeling complex scenes and obtaining their photorealistic views, while avoiding explicit surface estimation and meshing. In particular, compelling results are obtained for scene scanned using hand-held commodity RGB-D sensors as well as standard RGB cameras even in the presence of objects that are challenging for standard mesh-based modeling."}, "keywords": ["multi-scale feature maps"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose a point-based approach for modeling scenes using a raw point cloud and learnable neural descriptors that encode local geometry and appearance, which can be rendered from new viewpoints using a deep rendering network #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain point pseudo-colors for the input rasterizations, the authors used a learnable neural descriptor that encodes local geometry and appearance, as proposed in the method presented in Neural Point-Based Graphics #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain multi-scale feature maps from point cloud rasterizations, the authors of Make-It-3D utilized a deep rendering network that was learned in parallel with learnable neural descriptors, as proposed in the Neural Point-Based Graphics paper #REFR.", "given_citation_intent": "method", "given_keywords": ["multi-scale feature maps"]}]}
{"citing_id": "2303.09956v1", "cited_id": "1810.00826", "section_title": "Embedding Generation", "citation": "Then, we adopt a GNN model, namely graph isomorphism network (GIN) #REFR , to extract the structural information of cell graphs.", "text_before_citation": ["After constructing the cell graphs, we generate the embeddings of cell nodes and input images for the report generation task.", "For embedding generation of cell nodes, we first use a trainable CNN to process the extracted cell nodes in Section 3.1 and obtain the output", "EQUATION", "|V| ] , which captures morphology features of cell nodes.", "In this way, the network can learn to extract essential morphology features for report generation during training."], "text_after_citation": ["Specifically, one layer of the GNN model is defined as follows:", "EQUATION", "where h ( ) i denotes the hidden embedding of cell node i in a cell graph at the th layer.", "( ) is a learnable parameter to distinguish central nodes from neighbors.", "N i denotes the set of neighbors of cell node i. MLP denotes a multi-layer perceptron. H (0) is the input of the GNN model."], "citing_paper_content": {"title": "Gnnformer: A Graph-Based Framework For Cytopathology Report Generation Technical Report", "abstract": "Cytopathology report generation is a necessary step for the standardized examination of pathology images. However, manually writing detailed reports brings heavy workloads for pathologists. To improve efficiency, some existing works have studied automatic generation of cytopathology reports, mainly by applying image caption generation frameworks with visual encoders originally proposed for natural images. A common weakness of these works is that they do not explicitly model the structural information among cells, which is a key feature of pathology images and provides significant information for making diagnoses. In this paper, we propose a novel graph-based framework called GNNFormer, which seamlessly integrates graph neural network (GNN) and Transformer into the same framework, for cytopathology report generation. To the best of our knowledge, GNNFormer is the first report generation method that explicitly models the structural information among cells in pathology images. It also effectively fuses structural information among cells, fine-grained morphology features of cells and background features to generate high-quality reports. Experimental results on the NMI-WSI dataset show that GNNFormer can outperform other state-of-the-art baselines."}, "cited_paper_content": {"title": "How Powerful Are Graph Neural Networks?", "abstract": "Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance."}, "keywords": ["cell graphs", "namely graph isomorphism"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For embedding generation of cell nodes, we first use a trainable CNN to process the extracted cell nodes in Section 3.1 and obtain the output EQUATION |V| ], which captures morphology features of cell nodes. In this way, the network can learn to extract essential morphology features for report generation during training (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model the structural information among cells in pathology images, the authors propose a novel graph-based framework called GNNFormer, which seamlessly integrates graph neural network (GNN) and Transformer into the same framework #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model the structural information among cells in pathology images, the proposed GNNFormer framework seamlessly integrates graph neural network (GNN) and Transformer, which is as powerful as the Weisfeiler-Lehman graph isomorphism test, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": ["cell graphs", "namely graph isomorphism"]}]}
{"citing_id": "2303.05205v1", "cited_id": "1801.01290", "section_title": "Gridzero", "citation": "Additionally, we incorporate the entropy loss term H(p k \u03b8 ), following the SAC's settings, to encourage exploration in the learning process #REFR .", "text_before_citation": ["The loss function is computed over a horizon of K unrolled steps.", "The reward loss l r measures the difference between the estimated reward r k and target reward u k .", "Similarly, The value loss l v indicates the difference between the estimated value v k and bootstrapped target value z k .", "The policy loss l p represents the distance between the output policy p k and the root visit distribution of MCTS \u03c0 k .", "In order to address the challenge of insufficient supervisory signal in dynamic networks in MuZero, we introduce consistency loss l c which maximizes the similarity between the predicted next-state\u015d k+1 and the ground-truth next-state s k+1 ."], "text_after_citation": [], "citing_paper_content": {"title": "Real-Time Scheduling Of Renewable Power Systems Through Planning-Based Reinforcement Learning", "abstract": "The growing renewable energy sources have posed significant challenges to traditional power scheduling. It is difficult for operators to obtain accurate day-ahead forecasts of renewable generation, thereby requiring the future scheduling system to make real-time scheduling decisions aligning with ultra-short-term forecasts. Restricted by the computation speed, traditional optimization-based methods can not solve this problem. Recent developments in reinforcement learning (RL) have demonstrated the potential to solve this challenge. However, the existing RL methods are inadequate in terms of constraint complexity, algorithm performance, and environment fidelity. We are the first to propose a systematic solution 1"}, "cited_paper_content": {"title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning With A Stochastic Actor", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds."}, "keywords": ["learning process", "entropy loss term"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The soft actor-critic algorithm based on the maximum entropy reinforcement learning framework proposed in #REFR achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of insufficient supervisory signal in dynamic networks, the authors propose a consistency loss that maximizes the similarity between the predicted next-state and the ground-truth next-state, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The soft actor-critic algorithm proposed in #REFR, which maximizes the entropy loss term during the learning process, has achieved state-of-the-art performance on a range of continuous control benchmark tasks, making it a promising method for real-time scheduling of renewable power systems through planning-based reinforcement learning.", "given_citation_intent": "method", "given_keywords": ["learning process", "entropy loss term"]}]}
{"citing_id": "2303.14082v1", "cited_id": "1907.00123", "section_title": "I. Introduction", "citation": "Specifically, the authors in #REFR consider a two-cell network and propose a centralized DRL-based approach, where only a single agent is employed to control the beamformers and transmit power of both the two cells.", "text_before_citation": ["In #OTHEREFR - #OTHEREFR , the DL-based approaches exploiting expert knowledge, i.e., the known structure of optimal solutions, are studied for the beamforming optimization in a single-cell MU-MISO downlink system.", "Particularly, the exploitation of expert knowledge can improve the performance of the DL-based approaches #OTHEREFR .", "In #OTHEREFR , a bipartite graph neural network based approach is further developed to realize a scalable DL-based solution.", "In #OTHEREFR , a deep unrolling approach is proposed to reduce the number of required iterations by unfolding the iterative optimization procedures as graph neural networks, however, it still requires the real-time global CSI and some iterations to obtain near-optimal beamformers.", "In #OTHEREFR , #OTHEREFR , the joint beamforming, power control and interference coordination problem in cellular networks is investigated."], "text_after_citation": ["For the more general multi-cell networks, a distributed beamforming coordination approach based on multi-agent DRL is proposed in #OTHEREFR .", "It is worth noting that the DRL-based schemes in #OTHEREFR , #OTHEREFR are designed for cellular networks with only a single user per cell, and thus can not be directly extended to more general multi-cell multi-user cellular networks.", "Moreover, the codebook-based method is adopted in #OTHEREFR , #OTHEREFR , where the optimal beamformers can only be selected from a predefined set of available beamformers.", "As such, when the channel characteristics are more complex, e.g., the channels in a lower frequency band instead of the millimeter wave band considered in #OTHEREFR , the optimal beamformers may not fall into the predefined set, and it is almost impossible to obtain the optimal beamformers with the codebook-based method due to the mismatch between the channel characteristics and the codebook.", "Inspired by the huge potential of ML-based beamforming optimization approaches, we propose a DRL-based distributed dynamic coordinated beamforming (DDCBF) framework for a massive MIMO mobile cellular network."], "citing_paper_content": {"title": "Deep Reinforcement Learning For Distributed Dynamic Coordinated Beamforming In Massive Mimo Cellular Networks", "abstract": "To accommodate the explosive wireless traffics, massive multiple-input multiple-output (MIMO) is regarded as one of the key enabling technologies for next-generation communication systems. In massive MIMO cellular networks, coordinated beamforming (CBF), which jointly designs the beamformers of multiple base stations (BSs), is an efficient method to enhance the network performance. In this paper, we investigate the sum rate maximization problem in a massive MIMO mobile cellular network, where in each cell a multi-antenna BS serves multiple mobile users simultaneously via downlink beamforming. Although existing optimization-based CBF algorithms can provide near-optimal solutions, they require realtime and global channel state information (CSI), in addition to their high computation complexity. It is almost impossible to apply them in practical wireless networks, especially highly dynamic mobile cellular networks. Motivated by this, we propose a deep reinforcement learning based distributed dynamic coordinated beamforming (DDCBF) framework, which enables each BS to determine the beamformers with only local CSI and some historical information from other BSs.Besides, the beamformers can be calculated with a considerably lower computational complexity by exploiting neural networks and expert knowledge, i.e., a solution structure observed from the iterative procedure of the weighted minimum mean square error (WMMSE) algorithm. Moreover, we provide extensive numerical simulations to validate the effectiveness of the proposed DRL-based approach. With lower computational complexity"}, "cited_paper_content": {"title": "Deep Reinforcement Learning For 5G Networks: Joint Beamforming, Power Control, And Interference Coordination", "abstract": "The fifth generation of wireless communications (5G) promises massive increases in traffic volume and data rates, as well as improved reliability in voice calls. Jointly optimizing beamforming, power control, and interference coordination in a 5G wireless network to enhance the communication performance to end users poses a significant challenge. In this paper, we formulate the joint design of beamforming, power control, and interference coordination as a non-convex optimization problem to maximize the signal to interference plus noise ratio (SINR) and solve this problem using deep reinforcement learning. By using the greedy nature of deep Q-learning to estimate future rewards of actions and using the reported coordinates of the users served by the network, we propose an algorithm for voice bearers and data bearers in sub-6 GHz and millimeter wave (mmWave) frequency bands, respectively. The algorithm improves the performance measured by SINR and sum-rate capacity. In realistic cellular environments, the simulation results show that our algorithm outperforms the link adaptation industry standards for sub-6 GHz voice bearers. For data bearers in the mmWave frequency band, our algorithm approaches the maximum sum rate capacity, but with less than 4% of the required run time."}, "keywords": ["two-cell network"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In #OTHEREFR - #OTHEREFR , the joint beamforming, power control, and interference coordination problem in cellular networks is investigated. The authors propose a deep reinforcement learning algorithm to jointly optimize beamforming, power control, and interference coordination in a 5G wireless network, which maximizes the signal to interference plus noise ratio (SINR) and outperforms the link adaptation industry standards for sub-6 GHz voice bearers in realistic cellular environments. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In #OTHEREFR - #OTHEREFR , the joint design of beamforming, power control, and interference coordination in a 5G wireless network to enhance the communication performance to end users is formulated as a non-convex optimization problem to maximize the signal to interference plus noise ratio (SINR) and solved using deep reinforcement learning. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In #OTHEREFR, the joint design of beamforming, power control, and interference coordination in a 5G wireless network is formulated as a non-convex optimization problem to maximize the signal to interference plus noise ratio (SINR) and solved using deep reinforcement learning, which can be extended to the two-cell network scenario studied in this manuscript. #REFR", "given_citation_intent": "background", "given_keywords": ["two-cell network"]}]}
{"citing_id": "2303.05269v1", "cited_id": "1702.05464", "section_title": "Supervised Cell Detection", "citation": "In addition, annotating the image for each condition is very laborious when the individual images contain many cells. 2015; #REFR .", "text_before_citation": ["proposed Mask R-CNN, which enables instance segmentation by adding mask branches to the head of the Faster R-CNN architecture #OTHEREFR", "(2015) and thereby allowing segmentation of each detected object #OTHEREFR . Fujita et al.", "utilized Mask R-CNN for cell detection and segmentation #OTHEREFR . To reduce annotation costs, Nishimura et al. proposed U-Net Ronneberger et al.", "(2015) , which uses a heatmap as training data #OTHEREFR .", "However, these methods would not work well at cell detection if the domains of the training data (source domain) and test data (target domain) are different (domain shift)."], "text_after_citation": ["This method uses a domain discriminator that distinguishes the source and target domain and, for adaptation, it tries to fool the discriminator into not distinguishing between domains. For the cell segmentation task, Haq et al.", "utilized adversarial learning for domain adaption and introduced an autoencoder to extract invariant features between the source and target domains #OTHEREFR .", "However, this approach does not consider essential features e.g.,(class features in classification task) and only tries to match features between domains. To solve this problem, Saito et al.", "proposed to use the maximum classifier discrepancy that matches features among classes between domains #OTHEREFR .", "The design of an adversarial domain adaptation is more complex for the heatmap prediction task since the network has both an encoder and decoder."], "citing_paper_content": {"title": "Medical Image Analysis", "abstract": "Cell detection is an important task in biomedical research. Recently, deep learning methods have made it possible to improve the performance of cell detection. However, a detection network trained with training data under a specific condition (source domain) may not work well on data under other conditions (target domains), which is called the domain shift problem. In particular, cells are cultured under different conditions depending on the purpose of the research. Characteristics, e.g., the shapes and density of the cells, change depending on the conditions, and such changes may cause domain shift problems. Here, we propose an unsupervised domain adaptation method for cell detection using a pseudo-cell-position heatmap, where the cell centroid is at the peak of a Gaussian distribution in the map and selective pseudo-labeling. In the prediction result for the target domain, even if the peak location is correct, the signal distribution around the peak often has a non-Gaussian shape. The pseudo-cell-position heatmap is thus regenerated using the peak positions in the predicted heatmap to have a clear Gaussian shape. Our method selects confident pseudo-cell-position heatmaps based on uncertainty and curriculum learning. We conducted numerous experiments showing that, compared with the existing methods, our method improved detection performance under different conditions."}, "cited_paper_content": {"title": "Adversarial Discriminative Domain Adaptation", "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task."}, "keywords": ["many cells", "individual images"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the domain shift problem in cell detection, Nishimura et al. proposed a method that uses a heatmap as training data, but this method may not work well if the domains of the training data and test data are different. To overcome this limitation, Fujita et al. utilized Adversarial Discriminative Domain Adaptation (ADDA) for cell detection and segmentation, which showed improved performance compared to existing methods #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Adversarial Discriminative Domain Adaptation (ADDA) is a promising approach to training robust deep networks that can improve recognition despite the presence of domain shift or dataset bias, and has been shown to be more effective yet considerably simpler than competing domain-adversarial methods #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Many deep learning methods have been proposed to improve the performance of cell detection, but they may not work well on data under other conditions, which is called the domain shift problem. To address this issue, adversarial learning methods have been proposed to reduce the difference between the training and test domain distributions and thus improve generalization performance #REFR.", "given_citation_intent": "background", "given_keywords": ["many cells", "individual images"]}]}
{"citing_id": "2304.06440v1", "cited_id": "1705.07750", "section_title": "Advancement In Visual Networks", "citation": "Remarkably, I3D #REFR reveals that successful 2D networks could be seamlessly inflated to corresponding 3D networks and even their parameter.", "text_before_citation": ["The advancement of visual backbone networks prospers various downstream tasks tremendously #OTHEREFR .", "Based on the modality of input data, visual networks can be classified into two types, image networks (i.e. 2D networks) and video networks (i.e. 3D networks).", "C3D #OTHEREFR pioneeringly devises an 11-layer CNN with 3D-CNN to adapt to video inputs.", "Subsequent P3D #OTHEREFR , S3D #OTHEREFR and R(2+1)D #OTHEREFR observe that disentangled spatial and temporal convolutions results in a more favorable speed-accuracy trade-off than the pure 3D convolution."], "text_after_citation": ["In recent days, a shift in backbone architecture, from CNNs to Transformers (ViT) #OTHEREFR , has begun.", "Especially, Swin Transformer #OTHEREFR reintroduces the inductive bias of convolutions (i.e., locality, translation invariance and hierarchy), which enables it to serve as a general-purpose backbone.", "The success of image Transformer leads to further investigation of Transformer-based video networks (e.g., ViViT #OTHEREFR , MViT #OTHEREFR , Video Swin Transformer #OTHEREFR ).", "Among all characteristics of Transformers, the patch-wise operations inherently differentiate the edges of patches, thus making them ideal for handling input sampled by GMS. Figure 2 . Illustration of the framework of Zoom-VQA. The overall architecture consists of two parts.", "One part is a perception network based on image input that obtains global information."], "citing_paper_content": {"title": "Zoom-Vqa: Patches, Frames And Clips Integration For Video Quality Assessment", "abstract": "Video quality assessment (VQA) aims to simulate the human perception of video quality, which is influenced by factors ranging from low-level color and texture details to high-level semantic content. To effectively model these complicated quality-related factors, in this paper, we decompose video into three levels (i.e., patch level, frame level, and clip level), and propose a novel Zoom-VQA architecture to perceive spatio-temporal features at different levels. It integrates three components: patch attention module, frame pyramid alignment, and clip ensemble strategy, respectively for capturing region-of-interest in the spatial dimension, multi-level information at different feature levels, and distortions distributed over the temporal dimension. Owing to the comprehensive design, Zoom-VQA obtains state-of-the-art results on four VQA benchmarks and achieves 2nd place in the NTIRE 2023 VQA challenge. Notably, Zoom-VQA has outperformed the previous best results on two subsets of LSVQ, achieving 0.8860 (+1.0%) and 0.7985 (+1.9%) of SRCC on the respective subsets. Adequate ablation studies further verify the effectiveness of each component. Codes and models are released in https://github.com/k-zha14/Zoom-VQA."}, "cited_paper_content": {"title": "Quo Vadis, Action Recognition? A New Model And The Kinetics Dataset", "abstract": "The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architectures in light of the new Kinetics Human Action Video dataset. Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos. We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics. ::: We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters. We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.9% on HMDB-51 and 98.0% on UCF-101."}, "keywords": ["corresponding 3D networks"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The advancement of visual backbone networks prospers various downstream tasks tremendously #OTHEREFR. Based on the modality of input data, visual networks can be classified into two types, image networks (i.e. 2D networks) and video networks (i.e. 3D networks). C3D #OTHEREFR pioneeringly devises an 11-layer CNN with 3D-CNN to adapt to video inputs. Subsequent P3D #OTHEREFR, S3D #OTHEREFR and R(2+1)D #OTHEREFR observe that disentangled spatial and temporal convolutions results in a more favorable speed-accuracy trade-off than the pure 3D convolution. To evaluate the performance of these methods, the authors in the manuscript need to cite the reference paper Quo Vadis, Action Recognition? A New Model And The Kinetics Dataset #REFR, which provides a new dataset and a new model for action recognition.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To adapt to video inputs, C3D pioneeringly devises an 11-layer CNN with 3D-CNN, while subsequent methods such as P3D, S3D, and R(2+1)D observe that disentangled spatial and temporal convolutions result in a more favorable speed-accuracy trade-off than the pure 3D convolution #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To adapt to video inputs, corresponding 3D networks have been proposed, such as C3D pioneeringly devising an 11-layer CNN with 3D-CNN #REFR.", "given_citation_intent": "background", "given_keywords": ["corresponding 3D networks"]}]}
{"citing_id": "2303.01111v1", "cited_id": "2002.11569", "section_title": "Iii. The Model", "citation": "Overfitting is a general issue in the domain of supervised machine learning and cannot be avoided #REFR .", "text_before_citation": ["The top performing model achieved 49.36% accuracy at the validation level.", "Given three balanced classes of the input data, the result outperforms random guessing by 48% at the aggregate level.", "The shape of both curves indicate that the training was a subject of overfitting.", "An overfitted model may fail to properly generalize features that it is supposed to learn and instead fits the idiosyncrasies of the training sample itself.", "Such model would perform well during the training but unsatisfactorily to any other data but the one on which it was trained."], "text_after_citation": ["To contain the effect of overfitting, we added a dropout layer that discarded 20% of random units to the end of the network just prior to the classification.", "Dropout is generally considered very effective technique against overfitting #OTHEREFR , #OTHEREFR ."], "citing_paper_content": {"title": "Predicting Stock Price Movement As An Image Classification Problem", "abstract": "The paper studies intraday price movement of stocks that is considered as an image classification problem. Using a CNN-based model we make a compelling case for the highlevel relationship between the first hour of trading and the close. The algorithm managed to adequately separate between the two opposing classes and investing according to the algorithm's predictions outperformed all alternative constructs but the theoretical maximum. To support the thesis, we ran several additional tests. The findings in the paper highlight the suitability of computer vision techniques for studying financial markets and in particular prediction of stock price movements."}, "cited_paper_content": {"title": "Overfitting In Adversarially Robust Deep Learning", "abstract": "It is common practice in deep learning to use overparameterized networks and train for as long as possible; there are numerous studies that show, both theoretically and empirically, that such practices surprisingly do not unduly harm the generalization performance of the classifier. In this paper, we empirically study this phenomenon in the setting of adversarially trained deep networks, which are trained to minimize the loss under worst-case adversarial perturbations. We find that overfitting to the training set does in fact harm robust performance to a very large degree in adversarially robust training across multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and perturbation models ($\\ell_\\infty$ and $\\ell_2$). Based upon this observed effect, we show that the performance gains of virtually all recent algorithmic improvements upon adversarial training can be matched by simply using early stopping. We also show that effects such as the double descent curve do still occur in adversarially trained models, yet fail to explain the observed overfitting. Finally, we study several classical and modern deep learning remedies for overfitting, including regularization and data augmentation, and find that no approach in isolation improves significantly upon the gains achieved by early stopping. All code for reproducing the experiments as well as pretrained model weights and training logs can be found at this https URL."}, "keywords": ["supervised machine learning"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The shape of both curves indicate that the training was a subject of overfitting. An overfitted model may fail to properly generalize features that it is supposed to learn and instead fits the idiosyncrasies of the training sample itself. Such model would perform well during the training but unsatisfactorily to any other data but the one on which it was trained. This phenomenon has been empirically studied in the setting of adversarially trained deep networks, which are trained to minimize the loss under worst-case adversarial perturbations, and it has been found that overfitting to the training set does in fact harm robust performance to a very large degree in adversarially robust training across multiple datasets and perturbation models (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Overfitting is a common problem in deep learning, where a model may fail to properly generalize features that it is supposed to learn and instead fits the idiosyncrasies of the training sample itself, as shown in recent studies #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Overfitting is a common issue in supervised machine learning, where a model may fail to generalize well to new data. Recent studies have shown that overparameterized networks trained for a longer time do not harm the generalization performance of the classifier. However, a recent paper by #REFR empirically studied this phenomenon in the setting of adversarially trained deep networks and found that overfitting to the training set harms robust performance to a very large degree.", "given_citation_intent": "background", "given_keywords": ["supervised machine learning"]}]}
{"citing_id": "2303.05455v1", "cited_id": "1902.01108", "section_title": "2.", "citation": "Meanwhile, the augmented kNN-graph has approximately L\u223cn vi \u2022M edges, where n vi =nn+rn > 2 #REFR .", "text_before_citation": [" 4.5b) , and the ordering of NN can result from measurement errors.", "We assume that the number of neighbors nn must meet two conditions.", "First, the kNN-graph should be fully connected (or approximately, that is, the size of the largest component should be comparable to the size of the entire graph).", "Second, the kNN-graph augmented with approximately rn edges should be at least a minimal n-rigid graph (in 2D: 2-rigid).", "The lower band of the number of connections L, required to make the 2-rigid augmented k NN-graph, is L\u223c2\u2022M."], "text_after_citation": ["As our experience shows, the probability that the largest connected component is rigid (or approximately rigid) is very high.", "In summary, to obtain the largest connected component approximately equal to the full kNN-graph, the number of nearest neighbors nn can be very low (mostly nn = 2, but for some specific datasets with very similar samples, it can be a bit larger).", "Assuming additionally that rn = 1, we can obtain a stable and rigid 2-D embedding of the kNN-graph.", "This way, instead of the O(M 2 ) floating point D matrix, we have as input data O(nn \u2022 M) integers -the list of edges of kNN graph.", "The indices of rn random neighbors can be generated ad hoc during the embedding process."], "citing_paper_content": {"title": "", "abstract": "Interactive visual exploration of large, high-dimensional datasets plays a very important role in various fields of science, which requires aggregated information about mutual relationships between numerous objects. It enables not only to recognize their important structural features and forms, such as clusters of vertices and their connectivity patterns, but also to assess their mutual relationships in terms of position, distance, shape, and connection density. The structural properties of these large datasets can be scrutinized throughout their interactive visualization. We argue that the visualization of very high-dimensional data is well approximated by the two-dimensional (2D) problem of embedding undirected kNN-graphs. In the advent of the big data era, the size of complex networks (datasets) G(V, E) (|V|=M\u223c10 6+) represents a great challenge for today's computer systems and still requires more efficient ND\u21922D dimensionality reduction (DR) algorithms. The existing DR methods, which involve more computational and memory complexities than O(M), are too slow for interactive manipulation on large networks that involve millions of vertices. We show that high-quality embeddings can be produced with minimal time&memory complexity. Very efficient IVHD (interactive visualization of high-dimensional data) and IVHD-CUDA algorithms are presented and then compared to the state-of-the-art DR methods (both CPU and GPU versions): t-SNE, UMAP, TriMAP, PaCMAP, BH-SNE-CUDA, and AtSNE-CUDA. We show that the memory and time requirements for IVHD are radically lower than those for the baseline codes. For example, IVHD-CUDA is almost 30 times faster in embedding (without the kNN graph generation procedure, which is the same for all methods) of one of the largest datasets used, YAHOO (M=1.4 \u2022 10 6), than AtSNE-CUDA. We conclude that at the expense of a minor deterioration of embedding quality, compared to baseline algorithms, IVHD well preserves the main structural properties of ND data in 2D for a significantly lower computational budget. We also present a meta-algorithm that enables using any unsupervised DR method in supervised fashion and as a result allows for flexible control of global and local properties of the embedding. Thus, our methods can be a good candidate for an interactive visualization of truly big data (M=10 8+) and can be further used to inspect and interpret relationships between alternative representations of observations learned by artificial neural networks (ANN). Additionally, we have provided a framework for testing the trade-off between preservation of global structure and local structure of DR."}, "cited_paper_content": {"title": "2-D Embedding Of Large And High-Dimensional Data With Minimal Memory And Computational Time Requirements", "abstract": "In the advent of big data era, interactive visualization of large data sets consisting of M*10^5+ high-dimensional feature vectors of length N (N ~ 10^3+), is an indispensable tool for data exploratory analysis. The state-of-the-art data embedding (DE) methods of N-D data into 2-D (3-D) visually perceptible space (e.g., based on t-SNE concept) are too demanding computationally to be efficiently employed for interactive data analytics of large and high-dimensional datasets. Herein we present a simple method, ivhd (interactive visualization of high-dimensional data tool), which radically outperforms the modern data-embedding algorithms in both computational and memory loads, while retaining high quality of N-D data embedding in 2-D (3-D). We show that DE problem is equivalent to the nearest neighbor nn-graph visualization, where only indices of a few nearest neighbors of each data sample has to be known, and binary distance between data samples -- 0 to the nearest and 1 to the other samples -- is defined. These improvements reduce the time-complexity and memory load from O(M log M) to O(M), and ensure minimal O(M) proportionality coefficient as well. We demonstrate high efficiency, quality and robustness of ivhd on popular benchmark datasets such as MNIST, 20NG, NORB and RCV1."}, "keywords": ["augmented kNN-graph"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We show that high-quality embeddings can be produced with minimal time&memory complexity using the ivhd method (#REFR), which outperforms the state-of-the-art data-embedding algorithms in both computational and memory loads, while retaining high quality of N-D data embedding in 2-D (3-D).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors proposed a simple method, ivhd, for interactive visualization of high-dimensional data that outperforms modern data-embedding algorithms in both computational and memory loads, while retaining high quality of N-D data embedding in 2-D (3-D) with minimal time and memory complexity, as demonstrated on popular benchmark datasets such as MNIST, 20NG, NORB and RCV1 (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors assume that the number of neighbors nn must meet two conditions to make the 2-rigid augmented kNN-graph, and the kNN-graph augmented with approximately rn edges should be at least a minimal n-rigid graph (in 2D: 2-rigid) with the lower band of the number of connections L, required to make the 2-rigid augmented kNN-graph, is L\u223c2\u2022M (#REFR).", "given_citation_intent": "background", "given_keywords": ["augmented kNN-graph"]}]}
{"citing_id": "2304.02263v1", "cited_id": "1503.02531", "section_title": "Comparisons On Downstream Tasks", "citation": "After conducting linear probing, the vanilla knowledge distillation #REFR method is used to train students with hard and soft labels.", "text_before_citation": ["Our model reprogramming in TDMR is to design a proper reprogramming space for KD, that is, a projector with a classifier is simple yet well-suited for the KD on downstream task.", "(ii) In distillation phase, the KD in MRKD usually leverages one-stage distillation, a brute-forced transfer, while our KD in TDMR is a twostage progressive distillation, a mild and more efficient way, which will be demonstrated in the following.", "(iii) More importantly, we reprogram students according to the proxy space, i.e., we consider the knowledge of the reprogrammed teacher classifier, which is missing in MRKD. Comparison with Linear Probing.", "For the foundation model application to downstream tasks, a common transfer method is the linear probing #OTHEREFR , #OTHEREFR which just modifies the output dimension of the teacher classifier to the total number of categories of the target data.", "Then, the classifier is trained from scratch with the feature extractor frozen instead of fully fine-tuning the source model with high computation cost."], "text_after_citation": ["The whole process above is denoted by \"Lin.\" We conduct experiments with various combinations of teachers and students on Caltech-256-60 and Oxford-102 to compare the common method with ours.", "From the results in Table 6 , we can see that our method outperforms the common method \"Lin.\".", "Moreover, our method exhibits a better improvement on the Oxford-102 dataset than the Caltech-256 dataset.", "It can be attributed to the larger gap between the Oxford dataset and the pretraining dataset.", "These results provide further evidence of the superior performance of our proposed method, especially in scenarios with larger domain gaps."], "citing_paper_content": {"title": "Towards Efficient Task-Driven Model Reprogramming With Foundation Models", "abstract": "Vision foundation models exhibit impressive power, benefiting from the extremely large model capacity and broad training data. However, in practice, downstream scenarios may only support a small model due to the limited computational resources or efficiency considerations. Moreover, the data used for pretraining foundation models are usually invisible and very different from the target data of downstream tasks. This brings a critical challenge for the real-world application of foundation models: one has to transfer the knowledge of a foundation model to the downstream task that has a quite different architecture with only downstream target data. Existing transfer learning or knowledge distillation methods depend on either the same model structure or finetuning of the foundation model. Thus, naively introducing these methods can be either infeasible or very inefficient. How to leverage the knowledge from the foundation model to boost the small model has not been well studied. To address this, we propose a Task-Driven Model Reprogramming (TDMR) framework. Specifically, we reprogram the foundation model to project the knowledge into a proxy space, which alleviates the adverse effect of task mismatch and domain inconsistency. In this stage, we maintain the foundation model as a powerful feature extractor frozen. Then, we reprogram the target model via progressive distillation from the proxy space to efficiently learn the knowledge from the reprogrammed foundation model. TDMR is compatible with different pre-trained model types (CNN, transformer or their mix) and limited target data, and promotes the wide applications of vision foundation models to downstream tasks in a cost-effective manner. Extensive experiments on different downstream classification tasks and target model structures demonstrate the effectiveness of our methods with both CNNs and transformer foundation models. For example, on CUB-200, TDMR improves the accuracy of MobileNetV2 from 62.90% to 72.60% using the ResNet-50 as a teacher and to 76.04% using the Swin transformer as a teacher."}, "cited_paper_content": {"title": "Distilling The Knowledge In A Neural Network", "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."}, "keywords": ["vanilla knowledge distillation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our KD in TDMR is a two-stage progressive distillation, a mild and more efficient way, which will be demonstrated in the following. More importantly, we reprogram students according to the proxy space, i.e., we consider the knowledge of the reprogrammed teacher classifier, which is missing in MRKD. Comparison with Linear Probing. For the foundation model application to downstream tasks, a common transfer method is the linear probing (Caruana et al., 2015), which just modifies the output dimension of the teacher classifier to the total number of categories of the target data. Then, the classifier is trained from scratch with the feature extractor frozen instead of fully fine-tuning the source model with high computation cost. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently learn the knowledge from the reprogrammed foundation model, we adopt a two-stage progressive distillation method, which is different from the brute-forced transfer used in MRKD #REFR, and reprogram students according to the proxy space, which is missing in MRKD and helps alleviate the adverse effect of task mismatch and domain inconsistency.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently learn the knowledge from the reprogrammed foundation model, our proposed Task-Driven Model Reprogramming (TDMR) framework uses a two-stage progressive distillation method, which is a mild and more efficient way than the brute-forced transfer used in vanilla knowledge distillation #REFR.", "given_citation_intent": "method", "given_keywords": ["vanilla knowledge distillation"]}]}
{"citing_id": "2303.16833v1", "cited_id": "1802.03515", "section_title": "C. Multi-View Detection", "citation": "Another method proposes the use of multiple monocular 2D keypoint estimates from spread out viewpoints to estimate the poses of vehicles #REFR .", "text_before_citation": ["A recent work combines Stereo 2D keypoint detections within a trained network to estimate the 3D positions of each keypoint for transparent and translucent objects #OTHEREFR .", "The results show an improvement over the state of the art by a factor of 1.5-3.5, using only two known views from a stereo camera.", "The objects are unoccluded as opposed to placed in bins, however, and only one instance of the object can be present in the scene.", "While this approach is faster, the network architecture is fixed to take in exactly two stereo images as input, and to output exactly one keypoint prediction.", "Multi-object detection will likely prove difficult as repeated features and occlusions from different instances of the same object may confuse the depth estimation within the network."], "text_after_citation": ["The transformations between these viewpoints are unknown; instead the approach adds constraints based on object rigidity and the relative positions of different keypoints in the image to solve for the vehicle poses.", "We borrow the object rigidity contraint from this paper, but also make use of known transformations between viewpoints from a robot arm, to allow more precise fusion of estimates between views.", "CosyPose is able to achieve higher performance in more cluttered scenes by utilizing a larger number of views #OTHEREFR .", "The scene is assumed to be static across the different viewpoints, and the poses of all objects within the scene are estimated.", "This is then used to estimate the camera pose across different viewpoints, followed by bundle adjustment to refine the estimates and generate a globally consistent scene across all views."], "citing_paper_content": {"title": "Multi-View Keypoints For Reliable 6D Object Pose Estimation", "abstract": "6D Object pose estimation is a fundamental component in robotics enabling efficient interaction with the environment. It is particularly challenging in bin-picking applications, where many objects are low-feature and reflective, and self-occlusion between objects of the same type is common. We propose a novel multi-view approach leveraging known camera transformations from an eye-in-hand setup to combine heatmap and keypoint estimates into a probability density map over 3D space. The result is a robust approach that is scalable in the number of views. It relies on a confidence score composed of keypoint probabilities and point-cloud alignment error, which allows reliable rejection of false positives. We demonstrate an average pose estimation error of approximately 0.5 mm and 2 degrees across a variety of difficult low-feature and reflective objects in the ROBI dataset, while also surpassing the stateof-art correct detection rate, measured using the 10% object diameter threshold on ADD error."}, "cited_paper_content": {"title": "Vehicle Pose And Shape Estimation Through Multiple Monocular Vision", "abstract": "In this paper, we present a method to estimate a vehicle's pose and shape from off-board multi-view images. These images are taken from monocular cameras with small overlaps. We utilize state-of-the-art Convolutional Neural Networks (CNNs) to extract vehicles' semantic keypoints and introduce a Cross Projection Optimization (CPO) method to estimate the 3D pose. During the iterative CPO process, an adaptive shape adjustment method named Hierarchical Wireframe Constraint (HWC) is implemented to estimate the shape. Our approach is evaluated under both simulated and real-world scenes for performance verification. It's shown that our algorithm outperforms other existing monocular and stereo methods for vehicles' pose and shape estimation. This approach provides a new and robust solution for off-board visual vehicle localization and tracking, which can be applied to massive surveillance camera networks for intelligent transportation."}, "keywords": ["multiple monocular 2D"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "A recent work combines Stereo 2D keypoint detections within a trained network to estimate the 3D positions of each keypoint for transparent and translucent objects #OTHEREFR. The results show an improvement over the state of the art by a factor of 1.5-3.5, using only two known views from a stereo camera. The objects are unoccluded as opposed to placed in bins, however, and only one instance of the object can be present in the scene. While this approach is faster, the network architecture is fixed to take in exactly two stereo images as input, and to output exactly one keypoint prediction. Multi-object detection will likely prove difficult as repeated features and occlusions from different instances of the same object may confuse the depth estimation within the network. In a related work, a method to estimate a vehicle's pose and shape from off-board multi-view images is presented #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "A novel method for estimating a vehicle's pose and shape from off-board multi-view images is presented in #REFR, which utilizes state-of-the-art Convolutional Neural Networks (CNNs) to extract vehicles' semantic keypoints and introduces a Cross Projection Optimization (CPO) method to estimate the 3D pose.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the 3D pose and shape of vehicles from multiple monocular 2D images, the authors of this manuscript could utilize the method proposed in \"Vehicle Pose And Shape Estimation Through Multiple Monocular Vision\" #REFR, which employs Convolutional Neural Networks and a Cross Projection Optimization method to achieve superior performance compared to existing monocular and stereo methods.", "given_citation_intent": "method", "given_keywords": ["multiple monocular 2D"]}]}
{"citing_id": "2303.02874v1", "cited_id": "1412.6572", "section_title": "A. Current Adversarial Techniques 1) Gradient-Based Evasion Attack:", "citation": "Adversarial sampling based on addition of perturbation #REFR We can carry out this type of attack by trial and error method as we don't know in advance, the exact data manipulation that will break the model and make it to classify.", "text_before_citation": ["In gradient base evasion attack, a perturbed image which seems like untampered to human eyes is made to be misclassified by neural network model (Fig. 1 ) #OTHEREFR . Fig. 1 ."], "text_after_citation": ["Let say we want to probe the boundaries of a machine learning model designed to filter out spam emails, it is possible for us to experiment by sending different emails to see what gets through.", "And so, a model has been trained for certain words like \"momentum\", and now we want to make an exceptions for emails that contains other words, if we want to attack, we can craft email with enough extraneous words which will eventually make the model to misclassify it."], "citing_paper_content": {"title": "Adversarial Sampling For Fairness Testing In Deep Neural Network", "abstract": "In this research, we focus on the usage of adversarial sampling to test for the fairness in the prediction of deep neural network model across different classes of image in a given dataset. While several framework had been proposed to ensure robustness of machine learning model against adversarial attack, some of which includes adversarial training algorithm. There is still the pitfall that adversarial training algorithm tends to cause disparity in accuracy and robustness among different group. Our research is aimed at using adversarial sampling to test for fairness in the prediction of deep neural network model across different classes or categories of image in a given dataset. We successfully demonstrated a new method of ensuring fairness across various group of input in deep neural network classifier. We trained our neural network model on the original image, and without training our model on the perturbed or attacked image. When we feed the adversarial samplings to our model, it was able to predict the original category/ class of the image the adversarial sample belongs to. We also introduced and used the separation of concern concept from software engineering whereby there is an additional standalone filter layer that filters perturbed image by heavily removing the noise or attack before automatically passing it to the network for classification, we were able to have accuracy of 93.3%. Cifar-10 dataset have ten categories of dataset, and so, in order to account for fairness, we applied our hypothesis across each categories of dataset and were able to get a consistent result and accuracy."}, "cited_paper_content": {"title": "Explaining And Harnessing Adversarial Examples", "abstract": "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset."}, "keywords": ["attack", "perturbation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In gradient base evasion attack, a perturbed image which seems like untampered to human eyes is made to be misclassified by neural network model (Fig. 1) (Papernot et al., 2017). Fig. 1. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors successfully generated adversarial examples using a simple and fast method proposed in the reference paper, which supports the argument that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The linear nature of neural networks is the primary cause of their vulnerability to adversarial perturbation, as argued by the authors of the reference paper #REFR. This method of generating adversarial examples was used in the gradient-based evasion attack, where a perturbed image is misclassified by the neural network model, as described in the local context.", "given_citation_intent": "method", "given_keywords": ["attack", "perturbation"]}]}
{"citing_id": "2304.04734v1", "cited_id": "1901.07718", "section_title": "V. Discussion", "citation": "Future research will focus on implementing an SNN version of CMLs based on resonate-and-fire (RF) neurons #REFR .", "text_before_citation": ["b) The EXP model for CML A can be trained with task-agnostic proxy symbols, which are then mapped to application specific inputs x and s D .", "A major challenge to the greater adoption of HDC is the need for algorithms to map real-valued sensor data to hypervector symbols #OTHEREFR .", "Yet since ANNs have a rich history in classification: mapping raw sensor data to arbitrary class labels, there is recent work training ANNs as task-agnostic feature extractors #OTHEREFR then mapping these sparse feature vectors to arbitrary hypervector symbols for subsequent HDC computation #OTHEREFR .", "This approach, in effect, turns ANNs themselves into modular ML components, functioning as the ML equivalent of analog to digital (A2D) converters.", "Lastly, the CML algorithm operates over real-valued neural networks; but the illustrative biology examples described are based on spiking neural networks (SNN)."], "text_after_citation": ["These types of SNNs encode information based on the time a neuron spikes within period \u03c4 as opposed to rate encoding, measuring the number of spikes within a time window.", "Importantly, a spike at time t with respect to a local oscillator of period \u03c4 may be expressed as a complex valued phasor (or phase vector).", "RF neurons therefore also facilitate HDC interfacing via Holographic Reduced Representations (HRR), based on complex phasors #OTHEREFR ."], "citing_paper_content": {"title": "Modularizing And Assembling Cognitive Map Learners Via Hyperdimensional Computing", "abstract": "Biological organisms must learn how to control their own bodies to achieve deliberate locomotion, that is, predict their next body position based on their current position and selected action. Such learning is goal-agnostic with respect to maximizing (minimizing) an environmental reward (penalty) signal. A cognitive map learner (CML) is a collection of three separate yet collaboratively trained artificial neural networks which learn to construct representations for the node states and edge actions of an arbitrary bidirectional graph. In so doing, a CML learns how to traverse the graph nodes; however, the CML does not learn when and why to move from one node state to another. This work created CMLs with node states expressed as high dimensional vectors suitable for hyperdimensional computing (HDC), a form of symbolic machine learning (ML). In so doing, graph knowledge (CML) was segregated from target node selection (HDC), allowing each ML approach to be trained independently. The first approach used HDC to engineer an arbitrary number of hierarchical CMLs, where each graph node state specified target node states for the next lower level CMLs to traverse to. Second, an HDC-based stimulus-response experience model was demonstrated per CML. Because hypervectors may be in superposition with each other, multiple experience models were added together and run in parallel without any retraining. Lastly, a CML-HDC ML unit was modularized: trained with proxy symbols such that arbitrary, application-specific stimulus symbols could be operated upon without retraining either CML or HDC model. These methods provide a template for engineering heterogenous ML systems."}, "cited_paper_content": {"title": "Robust Computation With Rhythmic Spike Patterns", "abstract": "Information coding by precise timing of spikes can be faster and more energy efficient than traditional rate coding. However, spike-timing codes are often brittle, which has limited their use in theoretical neuroscience and computing applications. Here, we propose a type of attractor neural network in complex state space and show how it can be leveraged to construct spiking neural networks with robust computational properties through a phase-to-timing mapping. Building on Hebbian neural associative memories, like Hopfield networks, we first propose threshold phasor associative memory (TPAM) networks. Complex phasor patterns whose components can assume continuous-valued phase angles and binary magnitudes can be stored and retrieved as stable fixed points in the network dynamics. TPAM achieves high memory capacity when storing sparse phasor patterns, and we derive the energy function that governs its fixed-point attractor dynamics. Second, we construct 2 spiking neural networks to approximate the complex algebraic computations in TPAM, a reductionist model with resonate-and-fire neurons and a biologically plausible network of integrate-and-fire neurons with synaptic delays and recurrently connected inhibitory interneurons. The fixed points of TPAM correspond to stable periodic states of precisely timed spiking activity that are robust to perturbation. The link established between rhythmic firing patterns and complex attractor dynamics has implications for the interpretation of spike patterns seen in neuroscience and can serve as a framework for computation in emerging neuromorphic devices."}, "keywords": ["resonate-and-fire (RF) neurons"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The approach of mapping task-agnostic feature extractors to arbitrary hypervector symbols for subsequent HDC computation has been recently proposed #REFR, effectively turning ANNs into modular ML components, similar to analog to digital (A2D) converters.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To map real-valued sensor data to hypervector symbols, recent work has trained artificial neural networks as task-agnostic feature extractors and then mapped these sparse feature vectors to arbitrary hypervector symbols for subsequent hyperdimensional computing computation, effectively turning artificial neural networks into modular machine learning components, analogous to analog to digital converters #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The reductionist model proposed in #REFR employs resonate-and-fire (RF) neurons to approximate the complex algebraic computations in threshold phasor associative memory networks.", "given_citation_intent": "method", "given_keywords": ["resonate-and-fire (RF) neurons"]}]}
{"citing_id": "2303.01999v1", "cited_id": "1903.11228", "section_title": "Related Work", "citation": "BAE-Net trains an implicit shape representation that uses multiple decoder \"heads,\" where each head tends to represent the same localized part across many shape instances #REFR .", "text_before_citation": ["Several methods focus on convex polyhedra, either decomposing individual shapes in isolation #OTHEREFR or training a neural network to produce similar convex decompositions for similar shapes from a category #OTHEREFR .", "Another option is to decompose the input shape into pieces which can be represented as generalized cylinders #OTHEREFR .", "These approaches produce clean geometry with a better fit to the input shape than paramatric primitives allow, but they offer no control over the type of decomposition produced.", "They also typically need many primitives to fit the input shape well, making them non-compact and not well-suited for shape editing.", "Recent research in this space has focused on decomposing shapes using neural primitives."], "text_after_citation": ["Other approaches represent neural parts as star domains #OTHEREFR or deformed sphere meshes #OTHEREFR .", "These approaches produce decompositions that fit the input shape well using a small number of primitives.", "However, their output geometry can exhibit undesirable artifacts, and they provide no control over the type of decomposition produced.", "We compare our algorithm to one of these approaches later in the paper and show that ours achieves even better reconstruction accuracy while also producing qualitatively better decompositions.", "Modeling by retrieval and assembly: A large body of work in computer graphics has considered computerassisted or fully-automated 3D modeling via retrieving and assembling pre-existing 3D shapes."], "citing_paper_content": {"title": "Unsupervised 3D Shape Reconstruction By Part Retrieval And Assembly", "abstract": "Figure 1. Our system takes target 3D shapes together with a 3D part library as input and outputs a set of retrieved and transformed parts from the part library that recreates the input target shapes."}, "cited_paper_content": {"title": "Bae-Net: Branched Autoencoder For Shape Co-Segmentation", "abstract": "We treat shape co-segmentation as a representation learning problem and introduce BAE-NET, a branched autoencoder network, for the task. The unsupervised BAE-NET is trained with all shapes in an input collection using a shape reconstruction loss, without ground-truth segmentations. Specifically, the network takes an input shape and encodes it using a convolutional neural network, whereas the decoder concatenates the resulting feature code with a point coordinate and outputs a value indicating whether the point is inside/outside the shape. Importantly, the decoder is branched: each branch learns a compact representation for one commonly recurring part of the shape collection, e.g., airplane wings. By complementing the shape reconstruction loss with a label loss, BAE-NET is easily tuned for one-shot learning. We show unsupervised, weakly supervised, and one-shot learning results by BAE-NET, demonstrating that using only a couple of exemplars, our network can generally outperform state-of-the-art supervised methods trained on hundreds of segmented shapes."}, "keywords": ["implicit shape representation"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Recent research in this space has focused on decomposing shapes using neural primitives, such as the branched autoencoder network introduced in BAE-NET for shape co-segmentation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent research in shape co-segmentation has introduced BAE-NET, a branched autoencoder network, for the task, which has shown impressive results in unsupervised, weakly supervised, and one-shot learning scenarios #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent research in implicit shape representation has shown promising results in unsupervised, weakly supervised, and one-shot learning tasks #REFR.", "given_citation_intent": "background", "given_keywords": ["implicit shape representation"]}]}
{"citing_id": "2304.12036v1", "cited_id": "1903.03894", "section_title": "Comparison Of Models Used To Determine Node Importance", "citation": "Although GNNExplainer #REFR was also not designed for unsupervised node embeddings, we could still use the same objective function to quantify the importance of each node by leveraging the available labels.", "text_before_citation": ["However, LIME is not designed for generating global node-level explanations for unsupervised node embeddings.", "For a fair comparison, similar to our GRAPH-wGD, we computed MEAN{LIME", "(v c |v i ), v c \u2208 N(v i )} by regarding v c as local features for v i . N G (v i |\u03c8)", "also returns the neighbors with the same size of neighbor set, \u03c8.", "GNNExplainer."], "text_after_citation": ["Thus, the mutual information between predictions from an input graph and a perturbed graph by v i was leveraged for the importance score of v i .", "In this case, we assumed that nodes that return low mutual information values were more important."], "citing_paper_content": {"title": "Generating Post-Hoc Explanations For Skip-Gram-Based Node Embeddings By Identifying Important Nodes With Bridgeness", "abstract": "Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk [1], LINE [2], struc2vec [3], PTE [4], UserItem2vec [5], and RWJBG [6] have emerged from the Skip-gram model [7] and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing posthoc explanations of Skip-gram-based embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top-q global explanations about learned graph embedding vectors more efficiently. Experiments show that the ranking of nodes by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We also observe that the top-q node-level explanations selected by GRAPH-wGD have higher importance scores and produce more changes in class label prediction when perturbed, compared with the nodes selected by recent alternatives, using five real-world graphs."}, "cited_paper_content": {"title": "Gnnexplainer: Generating Explanations For Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GnnExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs."}, "keywords": ["unsupervised node embeddings"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For a fair comparison, similar to our GRAPH-wGD, we computed MEAN{LIME (v c |v i ), v c \u2208 N(v i )} by regarding v c as local features for v i. N G (v i |\u03c8) also returns the neighbors with the same size of neighbor set, \u03c8. GNNExplainer provides a model-agnostic approach for generating interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task, by identifying a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of generating global node-level explanations for unsupervised node embeddings, the authors propose a novel gradient-based explanation method called GRAPH-wGD, which allows for the efficient selection of top-q global explanations about learned graph embedding vectors, and show that it outperforms recent alternatives by up to 43.0% in explanation accuracy #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide global node-level explanations for #KEYWORD1, we need to use a method specifically designed for unsupervised node embeddings, such as GnnExplainer proposed by GNNExplainer. #REFR", "given_citation_intent": "method", "given_keywords": ["unsupervised node embeddings"]}]}
{"citing_id": "2303.11160v1", "cited_id": "1810.04805", "section_title": "Related Works In Counterfactual Explanations", "citation": "Many works have addressed the issue of generating natural-sounding counterfactual explanations in text using language representation models such as BERT #REFR .", "text_before_citation": ["Simply removing words from the text to generate counterfactual explanations is not effective. #OTHEREFR", "(2020) addressed this issue by ensuring that replaced words are grammatically correct.", "They demonstrate their approach on a sentiment analysis task, introducing two lists of words: one containing words that are suitable for replacement based on grammar, and another containing words with opposite senses to those in the sentiment dictionary.", "They then identified the intersection of these two lists and replaced words in the main text with words from this intersection until the predicted class was changed.", "This approach helps to generate counterfactual explanations that are more understandable to humans."], "text_after_citation": ["#OTHEREFR proposed one example of such an approach.", "They first generated a candidate set of words to replace each word in the text.", "They then used BERT as a language model to determine the probability of each candidate token for a given position.", "In the second step, they found the best combination of changes using shapley values #OTHEREFR and generated the explanations using beam search.", "This approach allows the generation of more coherent and understandable counterfactual explanations in text."], "citing_paper_content": {"title": "Explaining Recommendation System Using Counterfactual Textual Explanations", "abstract": "Currently, there is a significant amount of research being conducted in the field of artificial intelligence to improve the explainability and interpretability of deep learning models. It is found that if end-users understand the reason for the production of some output, it is easier to trust the system. Recommender systems are one example of systems that great efforts have been conducted to make their output more explainable. One method for producing a more explainable output is using counterfactual reasoning, which involves altering minimal features to generate a counterfactual item that results in changing the output of the system. This process allows the identification of input features that have a significant impact on the desired output, leading to effective explanations. In this paper, we present a method for generating counterfactual explanations for both tabular and textual features. We evaluated the performance of our proposed method on three real-world datasets and demonstrated a +5% improvement on finding effective features (based on model-based measures) compared to the baseline method."}, "cited_paper_content": {"title": "Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ::: BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."}, "keywords": ["natural-sounding counterfactual explanations", "language representation models"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "#OTHEREFR (2020) ensured that replaced words in counterfactual explanations are grammatically correct and semantically opposite to those in the sentiment dictionary. Their approach was demonstrated on a sentiment analysis task, and they achieved improved results. To achieve this, they used a language representation model called BERT, which pre-trains deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "BERT (Bidirectional Encoder Representations from Transformers) is a powerful language representation model that can be fine-tuned for various natural language processing tasks with state-of-the-art results. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To generate natural-sounding counterfactual explanations, #OTHEREFR (2020) ensured that replaced words are grammatically correct and semantically opposite to those in the sentiment dictionary, a method that has been successfully applied in sentiment analysis. This approach is similar to the language representation models, such as BERT, which pre-train deep bidirectional representations from unlabeled text by conditioning on both left and right context in all layers, resulting in state-of-the-art performance on various natural language processing tasks. #REFR", "given_citation_intent": "background", "given_keywords": ["natural-sounding counterfactual explanations", "language representation models"]}]}
{"citing_id": "2303.08935v1", "cited_id": "1202.5619", "section_title": "Proposition", "citation": "The cost of the walk S in G is at most OPT G + 2 max k S k (see Lemma 5.1 in #REFR ).", "text_before_citation": ["Therefore, an optimal solution to RMCCP on V i will have a total length at most 2 i OPT G (otherwise, the optimal solution to min-max weighted latency problem has cost more than OPT G ).", "As the solution to RMCCP is partitioned into 2 i walks in Line 6, length of the walk W i,j is at most \u03b1OPT G where \u03b1 is the approximation ratio of RMCCP.", "The walk S k is given by [W 0,j0 , \u03bd, W 1,j1 , \u03bd, . . .", ", \u03bd, W log t,j log t ] where k = j i ( mod 2 i ) for 0 \u2264 i < log t.", "Since, there are log \u03c1 G walks in S k , and those walks are connected using the recharging vertex, and (\u03bd, v) < OPT G /2 for all v \u2208 V , the length of the walk S k is at most O(\u03b1 log \u03c1 G )OPT G ."], "text_after_citation": ["Also OPT G \u2264 OPT G \u2264 2OPT G (see Lemma 3.2 in #OTHEREFR ).", "Using the approximation ratio of RMCCP, the maximum weighted latency of the walk returned by algorithm 3 is O(min{log n, log D log log D } log \u03c1)OPT G .", "Algorithm 3 is used as a subroutine in Algorithm 4 to find walks for R robots.", "The following result characterizes the cost of the solution returned by Algorithm 4.", "Proposition VI.5."], "citing_paper_content": {"title": "Multi-Robot Persistent Monitoring: Minimizing Latency And Number Of Robots With Recharging Constraints", "abstract": "In this paper we study multi-robot path planning for persistent monitoring tasks. We consider the case where robots have a limited battery capacity with a discharge time D. We represent the areas to be monitored as the vertices of a weighted graph. For each vertex, there is a constraint on the maximum allowable time between robot visits, called the latency. The objective is to find the minimum number of robots that can satisfy these latency constraints while also ensuring that the robots periodically charge at a recharging depot. The decision version of this problem is known to be PSPACE-complete. We present a O(log D log log D log \u03c1) approximation algorithm for the problem where \u03c1 is the ratio of the maximum and the minimum latency constraints. We also present an orienteering based heuristic to solve the problem and show empirically that it typically provides higher quality solutions than the approximation algorithm. We extend our results to provide an algorithm for the problem of minimizing the maximum weighted latency given a fixed number of robots. We evaluate our algorithms on large problem instances in a patrolling scenario and in a wildfire monitoring application. We also compare the algorithms with an existing solver on benchmark instances."}, "cited_paper_content": {"title": "Persistent Monitoring In Discrete Environments: Minimizing The Maximum Weighted Latency Between Observations", "abstract": "In this paper, we consider the problem of planning a path for a robot to monitor a known set of features of interest in an environment. We represent the environment as a graph with vertex weights and edge lengths. The vertices represent regions of interest, edge lengths give travel times between regions, and the vertex weights give the importance of each region. As the robot repeatedly performs a closed walk on the graph, we define the weighted latency of a vertex to be the maximum time between visits to that vertex, weighted by the importance (vertex weight) of that vertex. Our goal is to find a closed walk that minimizes the maximum weighted latency of any vertex. We show that there does not exist a polynomial time algorithm for the problem. We then provide two approximation algorithms; an $O(\\log n)$-approximation algorithm and an $O(\\log \\rho_G)$-approximation algorithm, where $\\rho_G$ is the ratio between the maximum and minimum vertex weights. We provide simulation results which demonstrate that our algorithms can be applied to problems consisting of thousands of vertices, and a case study for patrolling a city for crime."}, "keywords": ["walk"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Therefore, an optimal solution to RMCCP on V i will have a total length at most 2 i OPT G (otherwise, the optimal solution to min-max weighted latency problem has cost more than OPT G ). As the solution to RMCCP is partitioned into 2 i walks in Line 6, length of the walk W i,j is at most \u03b1OPT G where \u03b1 is the approximation ratio of RMCCP. The walk S k is given by [W 0,j0 , \u03bd, W 1,j1 , \u03bd, . . . , \u03bd, W log t,j log t ] where k = j i ( mod 2 i ) for 0 \u2264 i < log t. Since, there are log \u03c1 G walks in S k , and those walks are connected using the recharging vertex, and (\u03bd, v) < OPT G /2 for all v \u2208 V , the length of the walk S k is at most O(\u03b1 log \u03c1 G )OPT G. This problem is known to be PSPACE-complete, and the authors of the manuscript present an O(log D log log D log \u03c1) approximation algorithm for the problem where \u03c1 is the ratio of the maximum and the minimum latency constraints. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The problem of planning a path for a robot to monitor a known set of features of interest in an environment has been studied in the literature, where the environment is represented as a graph with vertex weights and edge lengths, and the goal is to find a closed walk that minimizes the maximum weighted latency of any vertex #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The walk S_k is given by [W_0,j0, \u03bd, W_1,j1, \u03bd, ..., \u03bd, W_log t,j log t] where k = j_i (mod 2_i) for 0 \u2264 i < log t, and since the length of the walk S_k is at most O(\u03b1 log \u03c1_G)OPT_G, where \u03b1 is the approximation ratio of RMCCP, it is clear that the approach presented in this paper is highly effective for solving the problem of minimizing the maximum weighted latency given a fixed number of robots while ensuring that the robots periodically charge at a recharging depot during the walk. #REFR", "given_citation_intent": "background", "given_keywords": ["walk"]}]}
{"citing_id": "2304.04612v1", "cited_id": "0909.4061", "section_title": "Algorithm 1 Randomized Svd", "citation": "Although this is the same as the complexity of a tSVD algorithm based on the rank-revealing QR decomposition, the Randomized SVD has been shown to be experimentally faster than that algorithm #REFR .", "text_before_citation": ["EQUATION", "where E X is the expectation with respect to X, and || \u2022 || F is the Frobenius norm.", "We show the algorithm of the Randomized SVD in Algorithm 1.", "In the algorithm, the asymptotic computational complexity of the QR factorization (Line 2) and SVD (Line 4) are O(mp 2 ) and O(np 2 ), respectively, and the random projection (Line 1) is O(mnp).", "Therefore, since p m, n typically, the random projection is the most expensive computation in the algorithm, and the total asymptotic complexity of the Randomized SVD is O(mnp)."], "text_after_citation": ["Furthermore, to reduce the complexity of the random projection, there are some studies on using random matrices instead of the Gaussian random matrix.", "For instance, when using subsampled random Fourier transform, the computational complexity is O(mn \u2022 log(p)) #OTHEREFR .", "We can also use sparse random matrices for the random projection, although they were not originally proposed in the context of RandNLA.", "These matrices are sparse from the perspective of non-zero elements and the choice of element values.", "For instance, Achlioptas proposes a random matrix \u2126 \u2208 R n\u00d7q where the (i, j) element is decided as follows #OTHEREFR :"], "citing_paper_content": {"title": "Mixed-Precision Random Projection For Randnla On Tensor Cores", "abstract": "Random projection can reduce the dimension of data while capturing its structure and is a fundamental tool for machine learning, signal processing, and information retrieval, which deal with a large amount of data today. RandNLA (Randomized Numerical Linear Algebra) leverages random projection to reduce the computational complexity of low-rank decomposition of tensors and solve least-square problems. While the computation of the random projection is a simple matrix multiplication, its asymptotic computational complexity is typically larger than other operations in a RandNLA algorithm. Therefore, various studies propose methods for reducing its computational complexity. We propose a fast mixed-precision random projection method on NVIDIA GPUs using Tensor Cores for single-precision tensors. We exploit the fact that the random matrix requires less precision, and develop a highly optimized matrix multiplication between FP32 and FP16 matrices-SHGEMM (Single and Half GEMM)-on Tensor Cores, where the random matrix is stored in FP16. Our method can compute Randomized SVD 1.28 times faster and Random projection high order SVD 1.75 times faster than baseline single-precision implementations while maintaining accuracy."}, "cited_paper_content": {"title": "Finding Structure With Randomness: Probabilistic Algorithms For Constructing Approximate Matrix Decompositions", "abstract": "Low-rank matrix approximations, such as the truncated singular value decomposition and the rank-revealing QR decomposition, play a central role in data analysis and scientific computing. This work surveys and extends recent research which demonstrates that randomization offers a powerful tool for performing low-rank matrix approximation. These techniques exploit modern computational architectures more fully than classical methods and open the possibility of dealing with truly massive data sets. This paper presents a modular framework for constructing randomized algorithms that compute partial matrix decompositions. These methods use random sampling to identify a subspace that captures most of the action of a matrix. The input matrix is then compressed---either explicitly or implicitly---to this subspace, and the reduced matrix is manipulated deterministically to obtain the desired low-rank factorization. In many cases, this approach beats its classical competitors in terms of accuracy, speed, and robustness. These claims are supported by extensive numerical experiments and a detailed error analysis."}, "keywords": ["Randomized SVD", "rank-revealing QR decomposition"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We propose a fast mixed-precision random projection method on NVIDIA GPUs using Tensor Cores for single-precision tensors, which can compute Randomized SVD 1.28 times faster and Random projection high order SVD 1.75 times faster than baseline single-precision implementations while maintaining accuracy (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the computational complexity of low-rank decomposition of tensors and solve least-square problems, various studies propose methods for reducing the computational complexity of the random projection, which is typically the most expensive computation in the algorithm. Therefore, the proposed fast mixed-precision random projection method on NVIDIA GPUs using Tensor Cores for single-precision tensors exploits the fact that the random matrix requires less precision and develops a highly optimized matrix multiplication between FP32 and FP16 matrices-SHGEMM-on Tensor Cores, where the random matrix is stored in FP16 (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the computational complexity of low-rank decomposition of tensors, various studies propose methods for reducing the computational complexity of the random projection, which is typically the most expensive computation in the algorithm. One such method is the Randomized SVD algorithm, which uses a rank-revealing QR decomposition and a random projection to compute partial matrix decompositions, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["Randomized SVD", "rank-revealing QR decomposition"]}]}
{"citing_id": "2303.15991v3", "cited_id": "1503.07612", "section_title": "C. Performance Evaluation Of The Proposed Resource Management Strategy", "citation": "Specifically, we compare the random realization of channel model #REFR in each training round and the ideal static channel channel model (i.e.", "text_before_citation": ["Furthermore, with a more powerful server, the performance improvements brought by power control and subchannel allocation grow.", "This is because, in this case, the training latency is primarily limited by the computing latency of the client devices and data exchange latency.", "Again, we observe that optimizing the cut layer selection brings better performance improvement than power control and subchannel allocation when the server's computing capability varies. Fig.", "13 shows the effect of channel variation on the performance of the proposed solution.", "Our layer split decision remains unchanged for a period (in the simulations, it remains the same until the model converges), and therefore it is important to evaluate how channel variation would impact its performance."], "text_after_citation": ["channel gain remain unchanged, which is unrealistic but used as the benchmark).", "We observe that channel variation has little impact on the performance of the proposed solution, which demonstrates its robustness in dynamic wireless channel conditions."], "citing_paper_content": {"title": "Efficient Parallel Split Learning Over Resource-Constrained Wireless Edge Networks", "abstract": "The increasingly deeper neural networks hinder the democratization of privacy-enhancing distributed learning, such as federated learning (FL), to resource-constrained devices. To overcome this challenge, in this paper, we advocate the integration of edge computing paradigm and parallel split learning (PSL), allowing multiple client devices to offload substantial training workloads to an edge server via layer-wise model split. By observing that existing PSL schemes incur excessive training latency and large volume of data transmissions, we propose an innovative PSL framework, namely, efficient parallel split learning (EPSL), to accelerate model training. To be specific, EPSL parallelizes client-side model training and reduces the dimension of activations' gradients for back propagation (BP) via last-layer gradient aggregation, leading to a significant reduction in server-side training and communication latency. Moreover, by considering the heterogeneous channel conditions and computing capabilities at client devices, we jointly optimize subchannel allocation, power control, and cut layer selection to minimize the per-round latency. Simulation results show that the proposed EPSL framework significantly decreases the training latency needed to achieve a target accuracy compared with the stateof-the-art benchmarks, and the tailored resource management and layer split strategy can considerably reduce latency than the counterpart without optimization."}, "cited_paper_content": {"title": "Probabilistic Omnidirectional Path Loss Models For Millimeter-Wave Outdoor Communications", "abstract": "This paper presents a probabilistic omnidirectional millimeter-wave path loss model based on real-world 28 GHz and 73 GHz measurements collected in New York City. The probabilistic path loss approach uses a free space line-of-sight propagation model, and for non-line-of-sight conditions uses either a close-in free space reference distance path loss model or a floating-intercept path loss model. The probabilistic model employs a weighting function that specifies the line-of-sight probability for a given transmitter-receiver separation distance. Results show that the probabilistic path loss model offers virtually identical results whether one uses a non-line-of-sight close-in free space reference distance path loss model, with a reference distance of 1 meter, or a floating-intercept path loss model. This letter also shows that site-specific environmental information may be used to yield the probabilistic weighting function for choosing between line-of-sight and non-line-of-sight conditions."}, "keywords": ["channel model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Again, we observe that optimizing the cut layer selection brings better performance improvement than power control and subchannel allocation when the server's computing capability varies (Li et al., 2018). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the subchannel allocation, power control, and cut layer selection, the authors of [1] proposed a joint optimization scheme that significantly reduces the per-round latency, as shown in Fig. 13. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed solution takes into account the heterogeneous channel conditions and computing capabilities at client devices, and jointly optimizes subchannel allocation, power control, and cut layer selection to minimize the per-round latency, as shown in Fig. 13. This approach is similar to the probabilistic omnidirectional millimeter-wave path loss model presented in #REFR, which also considers the channel model to optimize the path loss approach.", "given_citation_intent": "method", "given_keywords": ["channel model"]}]}
{"citing_id": "2304.14939v1", "cited_id": "1908.05901", "section_title": "Related Work", "citation": "In a systematic review of user studies of multi-factor authentication, Das et al. consistently find low adoption #REFR .", "text_before_citation": ["Researchers have also found that in practice, users conflate encryption and authentication in their mental models of security indicators in the website security context #OTHEREFR .", "Our work parallels extensive research into these passive authentication indicators in browsers, and brings a user-and data-driven analysis of passive verification indicators on social media.", "User perception of online security.", "User perception of security has been studied in a wide variety of online contexts. For example, Dechand et al.", "study user perception of endto-end encryption on WhatsApp and find that users largely do not trust it #OTHEREFR ."], "text_after_citation": ["Alshamsi and Andras study perception of Bitcoin usability among novice users and find that they find credit or debit cards to be more usable #OTHEREFR . Ur et al.", "investigate whether user perception of password security match reality and find significant differences across users' understanding of possible attacks #OTHEREFR . Perceptions of social media users have also been studied.", "However, work in this area has focused on perceptions of social media website quality #OTHEREFR , level of control over information shared #OTHEREFR , and protection from abuse and harrassment #OTHEREFR .", "Usability of security features on social media platforms has only been analyzed in the context of security notices. Benson et al.", "find that users disclose more information in their presence #OTHEREFR . : News consumption and social media usage."], "citing_paper_content": {"title": "Account Verification On Social Media: User Perceptions And Paid Enrollment", "abstract": "We study the gap between user perceptions of social media verification indicators and their actual meaning, and the type of behavior that emerges when such a gap is present. We use recent changes to Twitter's verification process as a unique case study wherein the meaning of a verification indicator has rapidly shifted. The study consists of a U.S. demographicallyrepresentative survey of 300 respondents and quantitative and qualitative analyses of results, and an analysis of verified Twitter accounts sampled from a large-scale dataset of 15 million Tweets collected in October 2022. The survey addresses differences in user-perceived and actual requirements for verification marks on popular social media platforms, with a focus on evolving perceptions of verification marks on Twitter. We find that more than half of survey respondents misunderstood Twitter's criteria for assigning blue verification check marks to user accounts; more than 80% of survey respondents did not understand what differentiated blue check marks from gold and grey check marks. We also note interesting correlations between respondent age and perception of verification marks. From our qualitative analysis of verified user accounts, we find that cryptocurrency promotion accounts constitute significantly more Blue subscribers than our randomly sampled control dataset, indicating that a significant number of Blue users may be leveraging the confusion between legacy and Blue verification to promote their own commodities. Finally, we provide recommendations for improving verification indicators and processes on social media."}, "cited_paper_content": {"title": "Evaluating User Perception Of Multi-Factor Authentication: A Systematic Review", "abstract": "Security vulnerabilities of traditional single factor authentication has become a major concern for security practitioners and researchers. To mitigate single point failures, new and technologically advanced Multi-Factor Authentication (MFA) tools have been developed as security solutions. However, the usability and adoption of such tools have raised concerns. An obvious solution can be viewed as conducting user studies to create more user-friendly MFA tools. To learn more, we performed a systematic literature review of recently published academic papers (N = 623) that primarily focused on MFA technologies. While majority of these papers (m = 300) proposed new MFA tools, only 9.1% of papers performed any user evaluation research. Our meta-analysis of user focused studies (n = 57) showed that researchers found lower adoption rate to be inevitable for MFAs, while avoidance was pervasive among mandatory use. Furthermore, we noted several reporting and methodological discrepancies in the user focused studies. We identified trends in participant recruitment that is indicative of demographic biases."}, "keywords": ["multi-factor authentication"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "User perception of Multi-Factor Authentication (MFA) has raised concerns about its usability and adoption, with only 9.1% of recently published academic papers performing any user evaluation research #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Researchers have also found that in practice, users conflate encryption and authentication in their mental models of security indicators in the website security context (Dechand et al., #OTHEREFR). Our work parallels extensive research into these passive authentication indicators in browsers, and brings a user-and data-driven analysis of passive verification indicators on social media. User perception of online security. User perception of security has been studied in a wide variety of online contexts, including Multi-Factor Authentication (MFA) technologies (Evaluating User Perception Of Multi-Factor Authentication: A Systematic Review, #REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Research has shown that the usability and adoption of Multi-Factor Authentication (MFA) tools have raised concerns, with only 9.1% of papers performing any user evaluation research #REFR.", "given_citation_intent": "background", "given_keywords": ["multi-factor authentication"]}]}
{"citing_id": "2303.12445v1", "cited_id": "1910.10683", "section_title": "Experiments & Results", "citation": "The second one uses an existing NLP model (T5 #REFR ) to produce sentences from structural data.", "text_before_citation": ["Overall, MEDIMP with all medical prompts results in the best predictions at 2 and 4 years post-transplantation.", "Medical Prompt generation.", "To demonstrate the relevance of the proposed approach for medical prompt generation, we compare our main model with two other approaches that produce text information.", "The first one is noted as \"Manual\" and comprises all the templates indicated by the medical experts, corresponding to only one sentence per variable of interest.", "Note that this is the base of our proposed medical prompting without using the prompt expansion method described in Section 2.2."], "text_after_citation": ["For a fair comparison, we train the T5 model on the WebNLG 2020 data #OTHEREFR and infer it on our data to generate text, denoted as \"T5 WebNLG\".", "The results are summarised in Table 2 , highlighting the superiority of our method.", "The \"T5 WebNLG\" approach offers a competitive F1 for all the predictions, although the AUC is the lowest except for the 2 years prediction.", "We show in Appendix B examples of generated texts from these three approaches.", "\"Manual\" approach lacks diversity in the text data, and therefore the training process of our proposed approach without text augmentations is more challenging."], "citing_paper_content": {"title": "Medimp: Medical Images And Prompts For Renal Transplant Representation Learning", "abstract": "Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multidisciplinary , notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP-Medical Images and Prompts-a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging task. Moreover, we propose a framework that generates medical prompts using automatic textual data augmentations from LLMs. Our goal is to learn meaningful manifolds of renal transplant DCE MRI, interesting for the prognosis of the transplant or patient status (2, 3, and 4 years after the transplant), fully exploiting the available multi-modal data in the most efficient way. Extensive experiments and comparisons with other renal transplant representation learning methods with limited data prove the effectiveness of MEDIMP in a relevant clinical setting, giving new directions toward medical prompts. Our code is available at https://github.com/leomlck/MEDIMP."}, "cited_paper_content": {"title": "Exploring The Limits Of Transfer Learning With A Unified Text-To-Text Transformer", "abstract": "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code."}, "keywords": ["existing NLP model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To demonstrate the relevance of the proposed approach for medical prompt generation, we compare our main model with two other approaches that produce text information, including a manual approach and a unified framework that converts every language problem into a text-to-text format #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To explore the landscape of transfer learning techniques for natural language processing, the authors of MEDIMP refer to a unified framework that converts every language problem into a text-to-text format proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the performance of the proposed MEDIMP model, the authors incorporate a unified text-to-text transformer, which has been shown to be effective in existing NLP models, as reported in #REFR.", "given_citation_intent": "method", "given_keywords": ["existing NLP model"]}]}
{"citing_id": "2303.17475v1", "cited_id": "2002.12317", "section_title": "Conclusion", "citation": "The simplicity of our framework makes it also easier to study than negative sampling with the techniques described in #REFR , for instance.", "text_before_citation": ["In the earlier case all the information related to the corpus (the graph) is represented in the form of a sparse matrix, hence the offline implementation of EDRep works optimally and significantly outperformed Node2Vec both in terms of speed and of accuracy.", "In the latter case, when encoding the text into a matrix, all the complex relations between the words should be captured by the matrix structure.", "This is a non-trivial task that might penalize infrequent co-occurrences between pairs of words.", "We believe, however, that a crucial advantage of our approach lies in its high interpretability.", "For a given practical deployment of our algorithm, a practitioner only needs to define a sampling strategy that meaningfully encodes proximity for the problem at hand."], "text_after_citation": ["Moreover, our main result holds in a wider range of settings with respect to the one explored and it can be easily generalized to non symmetric, or non normalized P matrices."], "citing_paper_content": {"title": "Efficient Distributed Representations Beyond Negative Sampling", "abstract": "This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our approximation on two popular applications related to word and node embeddings. The results evidence competing performance in terms of accuracy with respect to negative sampling with a remarkably lower computational time."}, "cited_paper_content": {"title": "The Spectral Underpinning Of Word2Vec", "abstract": "word2vec due to Mikolov \\textit{et al.} (2013) is a word embedding method that is widely used in natural language processing. Despite its great success and frequent use, theoretical justification is still lacking. The main contribution of our paper is to propose a rigorous analysis of the highly nonlinear functional of word2vec. Our results suggest that word2vec may be primarily driven by an underlying spectral method. This insight may open the door to obtaining provable guarantees for word2vec. We support these findings by numerical simulations. One fascinating open question is whether the nonlinear properties of word2vec that are not captured by the spectral method are beneficial and, if so, by what mechanism."}, "keywords": ["negative sampling", "framework"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "When encoding text into a matrix, capturing all the complex relations between words can be a non-trivial task that might penalize infrequent co-occurrences between pairs of words. However, the authors of Efficient Distributed Representations Beyond Negative Sampling propose an efficient method to learn distributed representations by estimating the softmax normalization constants in linear time, which allows for a remarkably lower computational time while still achieving competing performance in terms of accuracy with respect to negative sampling. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of calculating the softmax normalization constants in large datasets, the authors propose an efficient optimization strategy to learn distributed representations, which estimates the constants in linear time and achieves competitive performance with negative sampling in terms of accuracy and computational time (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the softmax normalization constants in linear time, the authors propose an efficient optimization strategy for learning distributed representations, which outperforms negative sampling in terms of accuracy and computational time, as demonstrated in their experiments on word and node embeddings #REFR. The proposed framework could potentially alleviate the computational bottleneck of negative sampling.", "given_citation_intent": "method", "given_keywords": ["negative sampling", "framework"]}]}
{"citing_id": "2304.08320v1", "cited_id": "1801.01290", "section_title": "Rl Method Selection For Tsc-Opf", "citation": "Since the SAC algorithm is very sensitive to hyperparameters #REFR , the following study is performed based on the DDPG and TD3 algorithms.", "text_before_citation": ["In addition, the TRPO and PPO algorithms limit the policy updates based on policy similarity, slowing and stabilizing policy updates.", "On the other hand, there is currently a lack of quantitative evaluation of power flow nonconvergence, e.g., the reward in (18) is always equal to -1000 when the power flow does not converge, which cannot provide guiding information for policy updates.", "In contrast, off-policy DRL algorithms store historical experience, which has a chance to influence the training of the current policy before being removed from the replay buffer.", "Therefore, as the exploration continues, the number of experiences corresponding to convergent power flows in the replay buffer increases and the agent can easily learn how to generate actions that lead to convergent power flows.", "Therefore, off-policy DRL algorithms are selected to solve the TSC-OPF problem in this paper."], "text_after_citation": ["The application of the SAC algorithm will be one of the future research directions.", "In the DDPG and TD3 algorithms, during the training process, exploration noise is added to the actions generated by the agent, as shown in #OTHEREFR where o denotes the observation vector, a and a are vectors representing the upper and lower bounds for the action respectively, denotes the exploration rate, \u03c3 represents the noise vector that follows a normal distribution with a mean of zero and a variance of , and the clip function restricts the action with exploration noise to be within its upper and lower bounds.", "The exploration noise is added to explore the action space and obtain transitions The agent structure of the DDPG algorithm is shown in Fig.", "3 (a) , which consists of two sets of actorcritic formats.", "The dotted lines mean that the modules and vectors are obsolete, which will be explained later."], "citing_paper_content": {"title": "On Fast-Converged Reinforcement Learning For Optimal Dispatch Of Large-Scale Power Systems Under Transient Security Constraints", "abstract": "Deep Reinforcement Learning (DRL)-based power system optimal dispatch, which is often modeled as Transient Security-Constrained Optimal Power Flow (TSC-OPF), trains efficient dispatching agents that can adapt to different scenarios and provide control strategies quickly. However, three typical issues seriously affect the training efficiency and the performance of the dispatch agent, namely, the difficulty of quantifying the transient instability level, the high dimensionality of the state space and action space, and the frequent generation of actions that correspond to non-convergent power flows during the early training stage. To address these issues, a fast-converged DRL method for TSC-OPF is proposed in this paper. Firstly, a transient security constraint transcription method based on the simulation time duration of instability is proposed to quantify the instability level. Secondly, a general method for Markov decision process modeling of TSC-OPF is proposed to decrease the dimensionality of the observation space. Finally, two general improvement techniques for off-policy DRL algorithms are proposed. A warm-up training technique is introduced to improve the efficiency of agents learning how to generate actions that lead to convergent power flows. A parallel exploration technique is adopted to improve the efficiency of agents exploring the action space. Based on the above studies, environments for TSC-OPF with the objectives of minimizing generation cost and minimizing control cost are constructed and dispatch agents are built and trained. The proposed method is tested in the IEEE 39-bus system and a practical 710-bus regional power grid. Test results show that the training process converges rapidly, the success rate of dispatch in both cases exceeds 99.70 percent, and the decision-making costs very little time, which verifies the effectiveness and efficiency of the proposed method."}, "cited_paper_content": {"title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning With A Stochastic Actor", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds."}, "keywords": ["TD3 algorithms", "hyperparameters"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In addition, the TRPO and PPO algorithms limit the policy updates based on policy similarity, slowing and stabilizing policy updates. On the other hand, there is currently a lack of quantitative evaluation of power flow nonconvergence, e.g., the reward in (18) is always equal to -1000 when the power flow does not converge, which cannot provide guiding information for policy updates. In contrast, off-policy DRL algorithms store historical experience, which has a chance to influence the training of the current policy before being removed from the replay buffer. Therefore, as the exploration continues, the number of experiences corresponding to convergent power flows in the replay buffer increases and the agent can easily learn how to generate actions that lead to convergent power flows. Therefore, off-policy DRL algorithms are selected to solve the TSC-OPF problem in this paper. #REFR proposed a soft actor-critic algorithm that combines off-policy updates with a stable stochastic actor-critic formulation, achieving state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Off-policy deep reinforcement learning algorithms, which store historical experience and have a chance to influence the training of the current policy before being removed from the replay buffer, are selected to solve the TSC-OPF problem in this paper, as demonstrated in the state-of-the-art performance achieved by soft actor-critic algorithm proposed in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of hyperparameter tuning in deep reinforcement learning algorithms, the authors propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework, which achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. #REFR", "given_citation_intent": "method", "given_keywords": ["TD3 algorithms", "hyperparameters"]}]}
{"citing_id": "2303.11323v1", "cited_id": "1805.09170", "section_title": "A. Connection Laplacian", "citation": "As reported in #REFR , an intuitive interpretation of (4) is imagining the evolution of the vector field U(x, t) over time as a \"smearing out\" of the initial vector field F(x).", "text_before_citation": ["EQUATION", "EQUATION", "where", "U : M \u00d7 R + 0 \u2192 T M and U(\u2022, t) \u2208 L 2 (T M) \u2200t \u2208 R +", "0 ; we denote the initial condition condition with U(x, 0) = F(x)."], "text_after_citation": ["In this interpretation, the role of the Connection Laplacian can be understood as a means to diffuse vectors from one tangent space to another (indeed, in the \"flat\" case it is sufficient to independently diffuse each scalar component, however, this approach fails for curved space). The solution of (4) is", "EQUATION", "which provides a way to construct tangent bundle convolution, as explained in the following section."], "citing_paper_content": {"title": "Tangent Bundle Convolutional Learning: From Manifolds To Cellular Sheaves And Back", "abstract": "In this work we introduce a convolution operation over the tangent bundle of Riemann manifolds in terms of exponentials of the Connection Laplacian operator. We define tangent bundle filters and tangent bundle neural networks (TNNs) based on this convolution operation, which are novel continuous architectures operating on tangent bundle signals, i.e. vector fields over the manifolds. Tangent bundle filters admit a spectral representation that generalizes the ones of scalar manifold filters, graph filters and standard convolutional filters in continuous time. We then introduce a discretization procedure, both in the space and time domains, to make TNNs implementable, showing that their discrete counterpart is a novel principled variant of the very recently introduced sheaf neural networks. We formally prove that this discretized architecture converges to the underlying continuous TNN. Finally, we numerically evaluate the effectiveness of the proposed architecture on various learning tasks, both on synthetic and real data."}, "cited_paper_content": {"title": "The Vector Heat Method", "abstract": "This paper describes a method for efficiently computing parallel transport of tangent vectors on curved surfaces, or more generally, any vector-valued data on a curved manifold. More precisely, it extends a vector field defined over any region to the rest of the domain via parallel transport along shortest geodesics. This basic operation enables fast, robust algorithms for extrapolating level set velocities, inverting the exponential map, computing geometric medians and Karcher/Fr\\'echet means of arbitrary distributions, constructing centroidal Voronoi diagrams, and finding consistently ordered landmarks. Rather than evaluate parallel transport by explicitly tracing geodesics, we show that it can be computed via a short-time heat flow involving the connection Laplacian. As a result, transport can be achieved by solving three prefactored linear systems, each akin to a standard Poisson problem. Moreover, to implement the method we need only a discrete connection Laplacian, which we describe for a variety of geometric data structures (point clouds, polygon meshes, etc.). We also study the numerical behavior of our method, showing empirically that it converges under refinement, and augment the construction of intrinsic Delaunay triangulations (iDT) so that they can be used in the context of tangent vector field processing."}, "keywords": ["vector field"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The method proposed in this manuscript extends a vector field defined over any region to the rest of the domain via parallel transport along shortest geodesics, which can be efficiently computed via a short-time heat flow involving the connection Laplacian #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The method proposed in this manuscript for efficiently computing parallel transport of tangent vectors on curved surfaces builds upon the Vector Heat Method described in #REFR, which extends a vector field defined over any region to the rest of the domain via parallel transport along shortest geodesics.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The method proposed in this manuscript extends a vector field defined over any region to the rest of the domain via parallel transport along shortest geodesics, enabling fast algorithms for extrapolating level set velocities, computing geometric medians, and finding consistently ordered landmarks, among others. This approach is based on a short-time heat flow involving the connection Laplacian, which can be computed via three prefactored linear systems, and only requires a discrete connection Laplacian for implementation on various geometric data structures, including #REFR.", "given_citation_intent": "background", "given_keywords": ["vector field"]}]}
{"citing_id": "2304.08114v1", "cited_id": "1506.01497", "section_title": "Two-Stage Methods", "citation": "The two-stage HOI detection framework detects human and object with an off-the-shelf detector #REFR and then classifies the interaction label for each human-object pair.", "text_before_citation": [], "text_after_citation": ["After the appearance of HO-RCNN #OTHEREFR , which is a widely used multi-stream framework, many recent studies use a variety of additional information to get richer contextual features for the interaction classifier, such as spatial features #OTHEREFR , pose features #OTHEREFR , and linguistic features #OTHEREFR .", "Several studies #OTHEREFR attempted to encode global contextual information using a message passing mechanism in a graph structure. Figure 2 . Overview of our ViPLO network.", "We first detect human and objects in a given image with Faster-RCNN #OTHEREFR , then estimate each human pose with an off-the-shelf pose estimator.", "Then, we extract features for each human and object using a ViT backbone and our novel MOA module.", "We also extract local features for each human with the estimated pose and ROIAlign #OTHEREFR ."], "citing_paper_content": {"title": "Viplo: Vision Transformer Based Pose-Conditioned Self-Loop Graph For Human-Object Interaction Detection", "abstract": "Human-Object Interaction (HOI) detection, which localizes and infers relationships between human and objects, plays an important role in scene understanding. Although two-stage HOI detectors have advantages of high efficiency in training and inference, they suffer from lower performance than one-stage methods due to the old backbone networks and the lack of considerations for the HOI perception process of humans in the interaction classifiers. In this paper, we propose Vision Transformer based Pose-Conditioned Self-Loop Graph (ViPLO) to resolve these problems. First, we propose a novel feature extraction method suitable for the Vision Transformer backbone, called masking with overlapped area (MOA) module. The MOA module utilizes the overlapped area between each patch and the given region in the attention function, which addresses the quantization problem when using the Vision Transformer backbone. In addition, we design a graph with a pose-conditioned self-loop structure, which updates the human node encoding with local features of human joints. This allows the classifier to focus on specific human joints to effectively identify the type of interaction, which is motivated by the human perception process for HOI. As a result, ViPLO achieves the state-of-the-art results on two public benchmarks, especially obtaining a +2."}, "cited_paper_content": {"title": "Faster R-Cnn: Towards Real-Time Object Detection With Region Proposal Networks", "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features\u2014using the recently popular terminology of neural networks with \u2019attention\u2019 mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available."}, "keywords": ["human-object pair"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We propose a novel feature extraction method suitable for the Vision Transformer backbone, called masking with overlapped area (MOA) module, which addresses the quantization problem when using the Vision Transformer backbone. In addition, we design a graph with a pose-conditioned self-loop structure, which updates the human node encoding with local features of human joints. This allows the classifier to focus on specific human joints to effectively identify the type of interaction, which is motivated by the human perception process for HOI. As a result, ViPLO achieves the state-of-the-art results on two public benchmarks, especially obtaining a +2 ( #REFR ).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the quantization problem when using the Vision Transformer backbone, the authors proposed a novel feature extraction method called masking with overlapped area (MOA) module, which utilizes the overlapped area between each patch and the given region in the attention function #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To effectively identify the type of interaction between the #KEYWORDS(human-object pair), ViPLO utilizes a pose-conditioned self-loop structure in its graph, which updates the human node encoding with local features of human joints, as proposed in Faster R-Cnn: Towards Real-Time Object Detection With Region Proposal Networks #REFR.", "given_citation_intent": "method", "given_keywords": ["human-object pair"]}]}
{"citing_id": "2304.05007v2", "cited_id": "1903.02837", "section_title": "Related Work", "citation": "For general LDP randomizers, the #REFR shows the input-independent part is sampled by each user with probability at least e \u2212 0 (they term it as total variation similarity).", "text_before_citation": ["In this model, a shuffler breaks the association between messages and their owners' identities, which allows for lower levels of randomization in the local model.", "An important aspect of the shuffle model is the analysis of privacy amplification guarantee for shuffled messages, with tighter guarantees leading to better trade-offs between privacy and utility.", "Privacy amplification of LDP randomizers.", "The seminal work #OTHEREFR utilizes the privacy amplification via subsampling #OTHEREFR to analyze the privacy amplification of shuffling, and shows n shuffled messages satisfies ( 0 144 log(1/\u03b4)/n, \u03b4)-DP.", "Latterly, the privacy blanket #OTHEREFR proposes extracting an input-independent part from the output distribution, to work as a \"blanket\" to amplify privacy."], "text_after_citation": ["For specific LDP randomizers (e.g., Laplace #OTHEREFR and generalized randomized response #OTHEREFR ), the total variation similarity can be larger.", "We note that our framework also utilizes the total variation information about output distributions.", "Compared to the total variation similarity that must be shared by all output distributions, we care about the pairwise total variation bound of output distributions, which is at most e 0 \u22121 e 0 +1 #OTHEREFR Theorem 2.4] .", "Recently, the works #OTHEREFR and #OTHEREFR decompose output distributions into mixture distributions with 3 options, and interprets messages from other users as clones of victim user.", "They show the shuffled messages can be deemed as post-processed information on the multiplicity of the 3 options, thus reduces the analyses of privacy amplification on shuffled messages to the indistinguishability of the multiplicities. This clone reduction is near-optimal w.r.t. the dependence on 0 for general LDP randomizers."], "citing_paper_content": {"title": "Privacy Amplification Via Shuffling: Unified, Simplified, And Tightened", "abstract": "In decentralized settings, the shuffle model of differential privacy has emerged as a promising alternative to the classical local model. Analyzing privacy amplification via shuffling is a critical component in both single-message and multi-message shuffle protocols. However, current methods used in these two areas are distinct and specific, making them less convenient for protocol designers and practitioners. In this work, we introduce variation-ratio reduction as a unified framework for privacy amplification analyses in the shuffle model. This framework utilizes total variation bounds of local messages and probability ratio bounds of other users' blanket messages, converting them to indistinguishable levels. Our results indicate that the framework yields tighter bounds for both singlemessage and multi-message encoders (e.g., with local DP, local metric DP, or general multi-message randomizers). Specifically, for a broad range of local randomizers having extremal probability design, our amplification bounds are precisely tight. We also demonstrate that variation-ratio reduction is well-suited for parallel composition in the shuffle model and results in stricter privacy accounting for common sampling-based local randomizers. Our experimental findings show that, compared to existing amplification bounds, our numerical amplification bounds can save up to 30% of the budget for singlemessage protocols, 75% of the budget for multi-message protocols, and 75%-95% of the budget for parallel composition. Additionally, our implementation for numerical amplification bounds has only\u00d5(n) complexity and is highly efficient in practice, taking just 2 minutes for n = 10 8 users. The code for our implementation can be found at https://github.com/wangsw/PrivacyAmplification."}, "cited_paper_content": {"title": "The Privacy Blanket Of The Shuffle Model", "abstract": "This work studies differential privacy in the context of the recently proposed shuffle model. Unlike in the local model, where the server collecting privatized data from users can track back an input to a specific user, in the shuffle model users submit their privatized inputs to a server anonymously. This setup yields a trust model which sits in between the classical curator and local models for differential privacy. The shuffle model is the core idea in the Encode, Shuffle, Analyze (ESA) model introduced by Bittau et al. (SOPS 2017). Recent work by Cheu et al. (EUROCRYPT 2019) analyzes the differential privacy properties of the shuffle model and shows that in some cases shuffled protocols provide strictly better accuracy than local protocols. Additionally, Erlingsson et al. (SODA 2019) provide a privacy amplification bound quantifying the level of curator differential privacy achieved by the shuffle model in terms of the local differential privacy of the randomizer used by each user. In this context, we make three contributions. First, we provide an optimal single message protocol for summation of real numbers in the shuffle model. Our protocol is very simple and has better accuracy and communication than the protocols for this same problem proposed by Cheu et al. Optimality of this protocol follows from our second contribution, a new lower bound for the accuracy of private protocols for summation of real numbers in the shuffle model. The third contribution is a new amplification bound for analyzing the privacy of protocols in the shuffle model in terms of the privacy provided by the corresponding local randomizer. Our amplification bound generalizes the results by Erlingsson et al. to a wider range of parameters, and provides a whole family of methods to analyze privacy amplification in the shuffle model."}, "keywords": ["general LDP randomizers"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "An important aspect of the shuffle model is the analysis of privacy amplification guarantee for shuffled messages, with tighter guarantees leading to better trade-offs between privacy and utility. The seminal work by Bittau et al. (#OTHEREFR) analyzes the differential privacy properties of the shuffle model and introduces the Encode, Shuffle, Analyze (ESA) model, which utilizes the shuffle model as its core idea.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The shuffle model, which breaks the association between messages and their owners' identities, allows for lower levels of randomization in the local model. Recent work by Cheu et al. (EUROCRYPT 2019) analyzes the differential privacy properties of the shuffle model and shows that in some cases shuffled protocols provide strictly better accuracy than local protocols, making it a promising alternative to the classical local model. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The privacy amplification of shuffled messages has been extensively studied in the literature, with seminal work utilizing the privacy amplification via subsampling to analyze the privacy amplification of shuffling #REFR. The privacy amplification bounds proposed in #REFR are applicable to general LDP randomizers and provide a useful tool for analyzing the privacy guarantees of shuffled protocols.", "given_citation_intent": "background", "given_keywords": ["general LDP randomizers"]}]}
{"citing_id": "2303.10650v1", "cited_id": "1809.08098", "section_title": "Conclusions, Related And Future Work", "citation": "It has been observed in verification literature that neural networks often fail to satisfy logical constraints #REFR .", "text_before_citation": ["Analysis of properties of loss functions, especially smoothness #OTHEREFR or bilateral properties #OTHEREFR , is a prominent field #OTHEREFR .", "One of LDL's achievements is to expose trade-offs between satisfying desired geometric and logic properties of a loss functions.", "In the future, we plan to explore further technical ideas from this field.", "Neural Network Verification.", "While this work does not attempt to verify neural networks, we draw our motivation from this area of research."], "text_after_citation": ["One of proposed solutions is training the NN to satisfy a constraint prior to verifying them #OTHEREFR 44] , referred to as continuous verification #OTHEREFR . LDL fits into this trend.", "Indeed, the tool Vehicle that implements LDL is also built to work with SMT-solvers and NN verifiers #OTHEREFR .", "Logics for Uncertainty and Probabilistic Logics.", "LDLs have a strong connection to fuzzy logic #OTHEREFR , as we have shown.", "Via the use of probability distributions and expectations, we draw our connection to Probabilistic Prolog and similar languages #OTHEREFR ."], "citing_paper_content": {"title": "Logic Of Differentiable Logics: Towards A Uniform Semantics Of Dl", "abstract": "Differentiable logics (DL) have recently been proposed as a method of training neural networks to satisfy logical specifications. A DL consists of a syntax in which specifications are stated and an interpretation function that translates expressions in the syntax into loss functions. These loss functions can then be used during training with standard gradient descent algorithms. The variety of existing DLs and the differing levels of formality with which they are treated makes a systematic comparative study of their properties and implementations difficult. This paper remedies this problem by suggesting a metalanguage for defining DLs that we call the Logic of Differentiable Logics, or LDL. Syntactically, it generalises the syntax of existing DLs to FOL, and for the first time introduces the formalism for reasoning about vectors and learners. Semantically, it introduces a general interpretation function that can be instantiated to define loss functions arising from different existing DLs. We use LDL to establish several theoretical properties of existing DLs, and to conduct their empirical study in neural network verification."}, "cited_paper_content": {"title": "Efficient Formal Safety Analysis Of Neural Networks", "abstract": "Neural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crash. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain $L$-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10$\\times$ larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks."}, "keywords": ["neural networks"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "One of LDL's achievements is to expose trade-offs between satisfying desired geometric and logic properties of a loss function. In the future, we plan to explore further technical ideas from this field. Neural Network Verification. While this work does not attempt to verify neural networks, we draw our motivation from this area of research, where formal safety analysis systems are urgently needed to rigorously check neural networks for violations of different safety properties. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations has been highlighted in recent research #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Neural networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations, which can have disastrous consequences, as shown by the recent Tesla autopilot crash #REFR.", "given_citation_intent": "background", "given_keywords": ["neural networks"]}]}
{"citing_id": "2303.06458v1", "cited_id": "1810.04805", "section_title": "Language Reconstruction", "citation": "For input corruption, we adopt the masking strategy as in BERT #REFR to randomly mask r% tokens of the input sentences S i , obtaining the corrupted input sentences S i .", "text_before_citation": [", y |Si| }, where y 0 and |S i | denote the beginof-sentence token and the number of tokens, respectively, and utilize the cross-entropy loss, which is widely used in natural language generation problems:", "EQUATION", "where we implement y 0 as a language-specific token following #OTHEREFR , #OTHEREFR so that the decoder can be aware of which language to be generated.", "Data Corruption For vision-to-text, due to (i) the large variations of images and videos caused by different object attributes, occlusion, motion blur and etc #OTHEREFR ; (ii) the great disparities between the vision and the language domains #OTHEREFR , we propose two data corruption strategies to further improve the performance and robustness of our ZeroNLG.", "In implementations, we simultaneously consider the input and feature corruptions."], "text_after_citation": ["As a result, the language reconstruction process is defined as follows:", "EQUATION", "For the feature corruption, we propose to add Gaussian noise n \u223c N (0, ) into the text features E m (S i ) (i.e., the coordinates) of input sentences S i , acquiring the corrupted features of input sentences E m (S i ) = E m (S i )+n. Therefore, the reconstruction process is defined as follows:", "EQUATION", "Through data corruption, we can encourage the model to learn more robust latent representations, achieving strong performances on zero-shot natural language generation."], "citing_paper_content": {"title": "Zeronlg: Aligning And Autoencoding Domains For Zero-Shot Multimodal And Multilingual Natural Language Generation", "abstract": "Natural Language Generation (NLG) accepts input data in the form of images, videos, or text and generates corresponding natural language text as output. Existing NLG methods mainly adopt a supervised approach and rely heavily on coupled data-to-text pairs. However, for many targeted scenarios and for non-English languages, sufficient quantities of labeled data are often not available. As a result, it is necessary to collect and label data-text pairs for training, which is both costly and time-consuming. To relax the dependency on labeled data of downstream tasks, we propose an intuitive and effective zero-shot learning framework, ZeroNLG, which can deal with multiple NLG tasks, including image-to-text (image captioning), video-to-text (video captioning), and text-to-text (neural machine translation), across English, Chinese, German, and French within a unified framework. ZeroNLG does not require any labeled downstream pairs for training. During training, ZeroNLG (i) projects different domains (across modalities and languages) to corresponding coordinates in a shared common latent space; (ii) bridges different domains by aligning their corresponding coordinates in this space; and (iii) builds an unsupervised multilingual auto-encoder to learn to generate text by reconstructing the input text given its coordinate in shared latent space. Consequently, during inference, based on the data-to-text pipeline, ZeroNLG can generate target sentences across different languages given the coordinate of input data in the common space. Within this unified framework, given visual (imaging or video) data as input, ZeroNLG can perform zero-shot visual captioning; given textual sentences as input, ZeroNLG can perform zero-shot machine translation. We present the results of extensive experiments on twelve NLG tasks, showing that, without using any labeled downstream pairs for training, ZeroNLG generates high-quality and \"believable\" outputs and significantly outperforms existing zero-shot methods."}, "cited_paper_content": {"title": "Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ::: BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."}, "keywords": ["input sentences"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the great disparities between the vision and language domains, ZeroNLG proposes two data corruption strategies to improve performance and robustness, as described in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To align different domains in a shared latent space, ZeroNLG utilizes a method called \"Bidirectional Encoder Representations from Transformers\" (#REFR), which enables the model to pre-train deep bidirectional representations from unlabeled text by conditioning on both left and right context in all layers.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of insufficient labeled data for downstream tasks, the authors propose an unsupervised multilingual auto-encoder that learns to generate text by reconstructing the input text given its coordinate in shared latent space, as described in #REFR.", "given_citation_intent": "method", "given_keywords": ["input sentences"]}]}
{"citing_id": "2304.12584v1", "cited_id": "1405.0312", "section_title": "A. Pimae Model.", "citation": "The Vision Transformer (ViT) based encoder in Pi-MAE is pre-trained on the COCO dataset #REFR to improve performance.", "text_before_citation": ["The PiMAE model ( Figure 1 ) consists of three key components: (1) a Vision Transformer-based #OTHEREFR encoder-decoder architecture with a mask layer to prevent trivial solutions while estimating emitters, (2) a Convolutional Neural Network as a prior for PSF estimation #OTHEREFR , and (3) a microscopic imaging process that enforces adherence to the microscopy principle.", "Appendix A provides detailed information on the network architecture and the embedding of physical principle.", "PiMAE requires only a few raw images for training, which is attributed to the carefully designed loss function.", "The loss function consists of two parts: one measures the difference between the raw and the reconstruction images, including the mean of the absolute difference and the multiscale structure similarity; the other part is a constraint on the PSF, including the total variation loss measuring the PSF continuity and the offset distance of the PSF's center of mass. Appendix B contains the expressions for the loss functions."], "text_after_citation": ["This pre-training relies on the selfsupervised learning of a masked autoencoder, but does not incorporate any physical information (detailed in Appendix C).", "After pre-training, PiMAE loads the trained encoder parameters and undergoes self-supervised training using raw microscopic images.", "The input image size is 144 pixels, and we use the RAdam optimizer #OTHEREFR with a learning rate of 1e \u22124 and a batch size of 18. The training runs for 5e 4 steps.", "Within PiMAE, the convolutional neural network, depicted in Figure 1 , is initialized randomly and takes a fixed random vector as input, outputting the predicted PSF. Relevant details can be found in Appendix A.", "As Pi-MAE undergoes self-supervised training, the CNN's predicted PSF continually becomes more accurate, moving closer to the true PSF as shown in Figure 2 . The experimental setup is shown in Figure 3 ."], "citing_paper_content": {"title": "Learning Imaging Mechanism Directly From Optical Microscopy Observations", "abstract": "Optical microscopy image plays an important role in scientific research through the direct visualization of the nanoworld, where the imaging mechanism is described as the convolution of the point spread function (PSF) and emitters. Based on a priori knowledge of the PSF or equivalent PSF, it is possible to achieve more precise exploration of the nanoworld. However, it is an outstanding challenge to directly extract the PSF from microscopy images. Here, with the help of self-supervised learning, we propose a physics-informed masked autoencoder (PiMAE) that enables a learnable estimation of the PSF and emitters directly from the raw microscopy images. We demonstrate our method in synthetic data and real-world experiments with significant accuracy and noise robustness. PiMAE outperforms DeepSTORM and the Richardson-Lucy algorithm in synthetic data tasks with an average improvement of 19.6% and 50.7% (35 tasks), respectively, as measured by the normalized root mean square error (NRMSE) metric. This is achieved without prior knowledge of the PSF, in contrast to the supervised approach used by DeepSTORM and the known PSF assumption in the Richardson-Lucy algorithm. Our method, PiMAE, provides a feasible scheme for achieving the hidden imaging mechanism in optical microscopy and has the potential to learn hidden mechanisms in many more systems."}, "cited_paper_content": {"title": "Microsoft Coco: Common Objects In Context", "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."}, "keywords": ["COCO dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To estimate the point spread function (PSF) and emitters directly from raw microscopy images, the authors proposed a physics-informed masked autoencoder (PiMAE) that outperforms DeepSTORM and the Richardson-Lucy algorithm in synthetic data tasks with an average improvement of 19.6% and 50.7%, respectively, as measured by the normalized root mean square error (NRMSE) metric #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the point spread function (PSF) and emitters directly from raw microscopy images, the authors propose a physics-informed masked autoencoder (PiMAE) that outperforms DeepSTORM and the Richardson-Lucy algorithm in synthetic data tasks, as measured by the normalized root mean square error (NRMSE) metric, without prior knowledge of the PSF #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve precise object localization, the authors utilized per-instance segmentations and drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting, and instance segmentation, as described in the COCO dataset #REFR.", "given_citation_intent": "method", "given_keywords": ["COCO dataset"]}]}
{"citing_id": "2303.07224v1", "cited_id": "1904.02216", "section_title": "Related Works", "citation": "DFANet #REFR adopted a lightweight backbone to reduce computational cost and designed crosslevel aggregation for feature refinement.", "text_before_citation": ["As a fundamental task of scene understanding, semantic segmentation has been an active research area for many years #OTHEREFR , which also attracts considerable attention in the study of deep neural networks, e.g., FCN #OTHEREFR , DeepLabs #OTHEREFR and PSPNet #OTHEREFR .", "In order to obtain accurate results in real-time applications, several methods have been proposed to improve the efficiency of semantic segmentation, which we summarize as follows.", "Efficient Image Segmentation Methods.", "Many compact architectures have been proposed for efficient image segmentation."], "text_after_citation": ["DFNet #OTHEREFR utilized a partial order pruning algorithm to search segmentation models for a good trade-off between speed and accuracy.", "ICNet #OTHEREFR used a cascade fusion module and transformed part of the computation from high-resolution to low-resolution. Wang et al. #OTHEREFR designed superresolution learning to improve image segmentation performance.", "BiSeNets #OTHEREFR used two-stream paths for lowlevel details and high-level context information, respectively.", "ESPNet #OTHEREFR used an efficient spatial pyramid to accelerate the convolution computation.", "These efficient backbone networks reduce the computational burden of singleimage segmentation, and can be applied to temporal or spatial frameworks in VSS."], "citing_paper_content": {"title": "Efficient Semantic Segmentation By Altering Resolutions For Compressed Videos", "abstract": "Video semantic segmentation (VSS) is a computationally expensive task due to the per-frame prediction for videos of high frame rates. In recent work, compact models or adaptive network strategies have been proposed for efficient VSS. However, they did not consider a crucial factor that affects the computational cost from the input side: the input resolution. In this paper, we propose an altering resolution framework called AR-Seg for compressed videos to achieve efficient VSS. AR-Seg aims to reduce the computational cost by using low resolution for non-keyframes. To prevent the performance degradation caused by downsampling, we design a Cross Resolution Feature Fusion (CR-eFF) module, and supervise it with a novel Feature Similarity Training (FST) strategy. Specifically, CReFF first makes use of motion vectors stored in a compressed video to warp features from high-resolution keyframes to low-resolution non-keyframes for better spatial alignment, and then selectively aggregates the warped features with local attention mechanism. Furthermore, the proposed FST supervises the aggregated features with high-resolution features through an explicit similarity loss and an implicit constraint from the shared decoding layer. Extensive experiments on CamVid and Cityscapes show that AR-Seg achieves state-of-the-art performance and is compatible with different segmentation backbones. On CamVid, AR-Seg saves 67% computational cost (measured in GFLOPs) with the PSPNet18 backbone while maintaining high segmentation accuracy."}, "cited_paper_content": {"title": "Dfanet: Deep Feature Aggregation For Real-Time Semantic Segmentation", "abstract": "This paper introduces an extremely efficient CNN architecture named DFANet for semantic segmentation under resource constraints. Our proposed network starts from a single lightweight backbone and aggregates discriminative features through sub-network and sub-stage cascade respectively. Based on the multi-scale feature propagation, DFANet substantially reduces the number of parameters, but still obtains sufficient receptive field and enhances the model learning ability, which strikes a balance between the speed and segmentation performance. Experiments on Cityscapes and CamVid datasets demonstrate the superior performance of DFANet with 8$\\times$ less FLOPs and 2$\\times$ faster than the existing state-of-the-art real-time semantic segmentation methods while providing comparable accuracy. Specifically, it achieves 70.3\\% Mean IOU on the Cityscapes test dataset with only 1.7 GFLOPs and a speed of 160 FPS on one NVIDIA Titan X card, and 71.3\\% Mean IOU with 3.4 GFLOPs while inferring on a higher resolution image."}, "keywords": ["crosslevel aggregation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Efficient semantic segmentation has been an active research area for many years, with several methods proposed to improve its efficiency. One such method is DFANet, an extremely efficient CNN architecture for semantic segmentation under resource constraints, which aggregates discriminative features through sub-network and sub-stage cascade respectively #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the efficiency of semantic segmentation, DFANet, an extremely efficient CNN architecture for semantic segmentation under resource constraints, has been proposed, which aggregates discriminative features through sub-network and sub-stage cascade respectively #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve efficient semantic segmentation, recent methods have proposed using compact architectures or adaptive network strategies, but they did not consider crosslevel aggregation, which is a crucial factor that affects the computational cost from the input side #REFR.", "given_citation_intent": "method", "given_keywords": ["crosslevel aggregation"]}]}
{"citing_id": "2303.11381v1", "cited_id": "1411.7766", "section_title": "Introduction", "citation": "If \"people\" exists, we may select the celebrity model #REFR to further understand whether a celebrity appears and who he/she is.", "text_before_citation": ["Recent years have seen significant advancement for computer vision, thanks to improved network architecture #OTHEREFR , large-scale model training #OTHEREFR , and other factors.", "However, different vision problems typically require different models, which often require manual selection and composition of individual models for each use case.", "For example, when determining if an image contains \"people\", we may choose the image tagging model #OTHEREFR and check if the predicted tag list contains \"people\"."], "text_after_citation": ["One research direction is to combine the vision and language modules as one end-to-end model, such as Flamingo #OTHEREFR , PaLM-E #OTHEREFR , to provide a dialogue-based experience to the end user.", "That is, the user can use natural language to interact with the model around the image content.", "The vision module encodes vision signals into special text tokens or features that the language module can understand, enabling the system to utilize the language module for understanding user queries and providing responses.", "However, these joint finetuning approaches require a large amount of computing resources and annotated data to enable specific capabilities.", "In this work, we aim to combine existing individual vision models with the language model in a more flexible manner to tackle complicated visual understanding problems, e.g., the ones illustrated in Figure 1 ."], "citing_paper_content": {"title": "Mm-React : Prompting Chatgpt For Multimodal Reasoning And Action", "abstract": "Figure 1. MM-REACT allocates specialized vision experts with ChatGPT to solve challenging visual understanding tasks through multimodal reasoning and action. For example, the system could associate information from multiple uploaded receipts and calculate the total travel cost (\"Multi-Image Reasoning\"). We only highlight key information here and postpone full MM-REACT responses to Figures 4-14."}, "cited_paper_content": {"title": "Deep Learning Face Attributes In The Wild", "abstract": "Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts."}, "keywords": ["people", "celebrity model"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "When predicting face attributes in the wild, deep learning frameworks have shown to be effective #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In recent years, deep learning frameworks have been proposed to predict face attributes in the wild, which have shown significant improvement in performance compared to traditional methods #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "When determining if an image contains \"people\", we may choose the image tagging model #REFR and check if the predicted tag list contains \"people\", as demonstrated in the state-of-the-art deep learning framework for attribute prediction in the wild proposed by the authors of the reference paper, which outperforms the existing methods by a large margin and reveals valuable facts on learning face representation, such as the automatic discovery of semantic concepts by the high-level hidden neurons of the ANet after pre-training with massive face identities and the improvement of face localization and attribute prediction performances by different pre-training strategies.", "given_citation_intent": "background", "given_keywords": ["people", "celebrity model"]}]}
{"citing_id": "2303.10816v1", "cited_id": "1906.01195", "section_title": "Related Work 5.1 Knowledge Embedding Methods", "citation": "KBAT #REFR employ Graph Neural Networks (GNN) as the encoder to aggregate multi-hop neighborhood information.", "text_before_citation": ["Knowledge embedding methods have been widely used in graph representation learning tasks and have achieved great success on knowledge base completion (a.k.a link prediction).", "Translationbased methods aim at finding the transformation relationships from source to target.", "TransE #OTHEREFR , the most representative translationbased model, projects entities and relations into a unified vector space and minimizes the energy function of triples. Following this route, many translation-based methods have emerged. TransH #OTHEREFR formulates the translating process on relation-specific hyperplanes. TransR #OTHEREFR projects entities and relations into separate spaces.", "Recently, some neural network methods have shown promising results in this task.", "ConvE #OTHEREFR and ConvKB #OTHEREFR utilize Convolutional Neural Network (CNN) to increase parameter interaction between entities and relations."], "text_after_citation": [], "citing_paper_content": {"title": "Imf: Interactive Multimodal Fusion Model For Link Prediction", "abstract": "Link prediction aims to identify potential missing triples in knowledge graphs. To get better results, some recent studies have introduced multimodal information to link prediction. However, these methods utilize multimodal information separately and neglect the complicated interaction between different modalities. In this paper, we aim at better modeling the inter-modality information and thus introduce a novel Interactive Multimodal Fusion (IMF) model to integrate knowledge from different modalities. To this end, we propose a two-stage multimodal fusion framework to preserve modality-specific knowledge as well as take advantage of the complementarity between different modalities. Instead of directly projecting different modalities into a unified space, our multimodal fusion module limits the representations of different modalities independent while leverages bilinear pooling for fusion and incorporates contrastive learning as additional constraints. Furthermore, the decision fusion module delivers the learned weighted average over the predictions of all modalities to better incorporate the complementarity of different modalities. Our approach has been demonstrated to be effective through empirical evaluations on several real-world datasets. The implementation code"}, "cited_paper_content": {"title": "Learning Attention-Based Embeddings For Relation Prediction In Knowledge Graphs", "abstract": "The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets."}, "keywords": ["Graph Neural Networks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Recently, attention-based models have been proposed to capture the complex and hidden information in the local neighborhood surrounding a triple for knowledge base completion. The proposed attention-based feature embedding in #REFR captures both entity and relation features in any given entity's neighborhood, and encapsulates relation clusters and multihop relations in the model, resulting in marked performance gains compared to state-of-the-art methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture complex and hidden information in the local neighborhood surrounding a triple, attention-based feature embedding has been proposed in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, attention-based feature embeddings have been proposed to capture both entity and relation features in any given entity's neighborhood in knowledge graphs, which have shown promising results in comparison to state of the art methods on all datasets. #REFR", "given_citation_intent": "method", "given_keywords": ["Graph Neural Networks"]}]}
{"citing_id": "2304.08283v1", "cited_id": "1802.06993", "section_title": "Blockchain Type", "citation": "Additionally, as distributed ledgers can be publicly accessed, concerns about privacy and anonymity are duly noted #REFR .", "text_before_citation": ["Public blockchains are also termed as permissionless blockchains, while private and consortium blockchains are permissioned.", "\u2022 Public Blockchains: Public blockchains, with Bitcoin and Ethereum as two typical examples, are decentralized, open to the public, and self-governed.", "Anyone can join or leave a public blockchain at any time, and all can participate in the consensus process as validators.", "Public blockchains often use incentives, such as transaction fees and mining rewards, to encourage nodes to maintain the normal operations of the network.", "However, they face challenges from malicious nodes that can launch token stealing #OTHEREFR , selfish mining #OTHEREFR , Sybil #OTHEREFR , eclipse #OTHEREFR , and various other attacks."], "text_after_citation": ["Power consumption is another significant issue in public proof-of-work-based blockchains, especially when they are deployed in a large scale.", "\u2022 Private Blockchains: Private blockchains, with Multichain #OTHEREFR , Monax [136] , and Blockstack [1] as typical examples, are used and governed by single organizations.", "Instead of being open to anyone, the access to a private blockchain is restricted and requires a verified invitation.", "As a result, private blockchains are not decentralized, but permission-based and closed, which makes it easier to manage them and provides better privacy, but sacrifices decentralization and openness.", "The operator of a private blockchain has the ability to override, roll back, delete, and edit blocks, which undermines blockchain's trustless property."], "citing_paper_content": {"title": "Exploring Blockchain Technology Through A Modular Lens: A Survey", "abstract": "Blockchain has attracted significant attention in recent years due to its potential to revolutionize various industries by providing trustlessness. To comprehensively examine blockchain systems, this article presents both a macro-level overview on the most popular blockchain systems, and a micro-level analysis on a general blockchain framework and its crucial components. The macro-level exploration provides a big picture on the endeavors made by blockchain professionals over the years to enhance the blockchain performance while the micro-level investigation details the blockchain building blocks for deep technology comprehension. More specifically, this article introduces a general modular blockchain analytic framework that decomposes a blockchain system into interacting modules and then examines the major modules to cover the essential blockchain components of network, consensus, and distributed ledger at the micro-level. The framework as well as the modular analysis jointly build a foundation for designing scalable, flexible, and application-adaptive blockchains that can meet diverse requirements. Additionally, this article explores popular technologies that can be integrated with blockchain to expand functionality and highlights major challenges. Such a study provides critical insights to overcome the obstacles in designing novel blockchain systems and facilitates the further development of blockchain as a digital infrastructure to service new applications. CCS Concepts: \u2022 General and reference \u2192 Surveys and overviews."}, "cited_paper_content": {"title": "A Survey On The Security Of Blockchain Systems", "abstract": "Since its inception, the blockchain technology has shown promising application prospects. From the initial cryptocurrency to the current smart contract, blockchain has been applied to many fields. Although there are some studies on the security and privacy issues of blockchain, there lacks a systematic examination on the security of blockchain systems. In this paper, we conduct a systematic study on the security threats to blockchain and survey the corresponding real attacks by examining popular blockchain systems. We also review the security enhancement solutions for blockchain, which could be used in the development of various blockchain systems, and suggest some future directions to stir research efforts into this area."}, "keywords": ["distributed ledgers"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Public blockchains often face challenges from malicious nodes that can launch various attacks, as discussed in a systematic study on the security threats to blockchain systems by #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the survey on the security of blockchain systems #REFR, public blockchains such as Bitcoin and Ethereum are decentralized and open to the public, but they face challenges from various attacks including Sybil and eclipse.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Distributed ledgers are essential components of blockchain systems, and their security threats have been systematically studied in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["distributed ledgers"]}]}
{"citing_id": "2304.08466v1", "cited_id": "1905.10887", "section_title": "Model", "citation": "The performance boost remains significant with fine-tuned diffusion models for synthetic data up to a factor of 4 or 5 times the size of the real ImageNet training set, a significant improvement over results reported in #REFR .", "text_before_citation": ["Models trained solely on generated samples perform worse than models trained on real data.", "Nevertheless, augmenting the real data with data generated from the fine-tuned diffusion model provides a substantial boost in performance across many different classifiers.", "creases up to nine times the amount of real data, to a total dataset size of 12M images.", "Performance with higher resolution images, however, does not continue to improve with similarly large amounts of generative data augmentation.", "Table 4 reports performance as the amount of generated data increased over the same range, up to 9\u00d7 the amount of real data, at resolutions 256\u00d7256 and 1024\u00d71024."], "text_after_citation": [], "citing_paper_content": {"title": "Synthetic Data From Diffusion Models Improves Imagenet Classification", "abstract": "Deep generative models are becoming increasingly powerful, now generating diverse high fidelity photo-realistic samples given text prompts. Have they reached the point where models of natural images can be used for generative data augmentation, helping to improve challenging discriminative tasks? We show that large-scale text-toimage diffusion models can be fine-tuned to produce classconditional models with SOTA FID (1.76 at 256\u00d7256 resolution) and Inception Score (239 at 256 \u00d7 256). The model also yields a new SOTA in Classification Accuracy Scores (64.96 for 256\u00d7256 generative samples, improving to 69.24 for 1024\u00d71024 samples). Augmenting the ImageNet training set with samples from the resulting models yields significant improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines."}, "cited_paper_content": {"title": "Classification Accuracy Score For Conditional Generative Models", "abstract": "Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes\u2014variational autoencoders, autoregressive models, and generative adversarial networks (GANs)\u2014to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9% and 41.6%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric."}, "keywords": ["real ImageNet training"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Models trained solely on generated samples perform worse than models trained on real data. Nevertheless, augmenting the real data with data generated from the fine-tuned diffusion model provides a substantial boost in performance across many different classifiers (Shmelkov et al., 2020). The proposed Classification Accuracy Score (CAS) metric reveals surprising results not identified by traditional metrics and constitutes the authors' contributions. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of the manuscript report that traditional GAN metrics such as Inception Score (IS) and FID are neither predictive of Classification Accuracy Score (CAS) nor useful when evaluating non-GAN models, which is consistent with the findings in #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of the manuscript demonstrate that augmenting real data with data generated from a fine-tuned diffusion model significantly improves ImageNet classification accuracy, even though models trained solely on generated samples perform worse than models trained on real data. This result is consistent with the findings in the reference paper, which show that traditional GAN metrics such as Inception Score (IS) and Frechet Inception Distance (FID) are neither predictive of nor useful when evaluating non-GAN models, and that conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on the Classification Accuracy Score (CAS) benchmark. #REFR", "given_citation_intent": "result", "given_keywords": ["real ImageNet training"]}]}
{"citing_id": "2304.13771v1", "cited_id": "1507.07775", "section_title": "Concluding Remarks", "citation": "He used this generalized bound to improve a uniform continuity bound for the entanglement of formation originally given by Winter in #REFR .", "text_before_citation": ["We have presented a proof of a tight uniform continuity bound for the conditional Shannon entropy.", "The bound is independent of the alphabet size of the conditioning system.", "However, we have assumed in the proof that the conditioning system has finite support.", "We proved a conjectured bound for the conditional von Neumann entropy in the special case where the two systems have the same dimension and the state with lower conditional entropy is diagonal in a maximally entangled basis.", "In #OTHEREFR , Wilde generalized our bound Eq. 3.3.7 to quantum-classical states."], "text_after_citation": ["In #OTHEREFR , using an approach based on our proof techniques,", "Jabbour"], "citing_paper_content": {"title": "Some Problems Concerning Quantum Channels And Entropies", "abstract": "Finally, I do not believe it is possible for me to include everybody who ought to be included. To insulate myself, I declare that I am grateful for people."}, "cited_paper_content": {"title": "Tight Uniform Continuity Bounds For Quantum Entropies: Conditional Entropy, Relative Entropy Distance And Energy Constraints", "abstract": "We present a bouquet of continuity bounds for quantum entropies, falling broadly into two classes: first, a tight analysis of the Alicki\u2013Fannes continuity bounds for the conditional von Neumann entropy, reaching almost the best possible form that depends only on the system dimension and the trace distance of the states. Almost the same proof can be used to derive similar continuity bounds for the relative entropy distance from a convex set of states or positive operators. As applications, we give new proofs, with tighter bounds, of the asymptotic continuity of the relative entropy of entanglement, ER, and its regularization \\({E_R^{\\infty}}\\), as well as of the entanglement of formation, EF. Using a novel \u201cquantum coupling\u201d of density operators, which may be of independent interest, we extend the latter to an asymptotic continuity bound for the regularized entanglement of formation, aka entanglement cost, \\({E_C=E_F^{\\infty}}\\). Second, we derive analogous continuity bounds for the von Neumann entropy and conditional entropy in infinite dimensional systems under an energy constraint, most importantly systems of multiple quantum harmonic oscillators. While without an energy bound the entropy is discontinuous, it is well-known to be continuous on states of bounded energy. However, a quantitative statement to that effect seems not to have been known. Here, under some regularity assumptions on the Hamiltonian, we find that, quite intuitively, the Gibbs entropy at the given energy roughly takes the role of the Hilbert space dimension in the finite-dimensional Fannes inequality."}, "keywords": ["entanglement"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We have presented a proof of a tight uniform continuity bound for the conditional Shannon entropy, which is independent of the alphabet size of the conditioning system, but with the assumption that the conditioning system has finite support. As a related work, the authors in the reference paper presented continuity bounds for quantum entropies, including the conditional von Neumann entropy, and derived similar continuity bounds for the relative entropy distance from a convex set of states or positive operators. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We have employed a tight analysis of the Alicki-Fannes continuity bounds for the conditional von Neumann entropy, which is independent of the alphabet size of the conditioning system and reaches almost the best possible form that depends only on the system dimension and the trace distance of the states. Almost the same proof can be used to derive similar continuity bounds for the relative entropy distance from a convex set of states or positive operators, as shown in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We have employed a tight analysis of the Alicki-Fannes continuity bounds for the conditional von Neumann entropy, which is independent of the alphabet size of the conditioning system, and assumed that the conditioning system has finite support. As a result, we have derived a continuity bound for the relative entropy distance from a convex set of states or positive operators, which can be applied to the asymptotic continuity of the relative entropy of entanglement, ER, and its regularization, as well as of the entanglement of formation, EF. #REFR", "given_citation_intent": "method", "given_keywords": ["entanglement"]}]}
{"citing_id": "2304.13980v1", "cited_id": "1812.02713", "section_title": "Bottom-Up Strategies", "citation": "Zhang and Wonka (2021) introduce a probabilistic embedding instead of a deterministic one, and also propose a new loss function for the clustering step, with which they achieved good performance on the PartNet dataset #REFR .", "text_before_citation": ["(2019b) introduce a linking module between the two decoder branches to exploit synergies between semantic and instance segmentation. Pham et al.", "(2019) employ a multi-value conditional random field model to jointly optimise instance and semantic labels. #OTHEREFR", "(2019) estimate vectors pointing to the potential instance centers, as in the generalised Hough transform, to support the subsequent clustering step.", "In addition to the 3D offset vector, OccuSeg #OTHEREFR also learns occupancy signals, which can guide the subsequent graph-based clustering towards better instance segmentation. #OTHEREFR", "(2019) integrate 2D birds-eye-view information into a network for joint 3D semantic and instance segmentation, in order to better exploit global context."], "text_after_citation": ["In order to mitigate imbalances in the data, which tend to harm the instance segmentation for rare categories, He et al. (2020) propose a memory-augmented network to memorise representative patterns.", "Recently, a number of studies have applied the bottom-up approach to outdoor dataset #OTHEREFR .", "In general, these are variants of the two-branch architecture described above. For instance #OTHEREFR", "(2020) and used spherical projection to implement a real-time, panoptic segmentation algorithm for the autonomous driving setting, while Panoptic-PolarNet #OTHEREFR used a polar bird's eye view. Their instance branch directly regresses the instance's center.", "DS-Net #OTHEREFR utilizes a dynamic shift module that can automatically adjust the kernel function to different point densities and instance sizes."], "citing_paper_content": {"title": "A Review Of Panoptic Segmentation For Mobile Mapping Point Clouds", "abstract": "3D point cloud panoptic segmentation is the combined task to (i) assign each point to a semantic class and (ii) separate the points in each class into object instances. Recently there has been an increased interest in such comprehensive 3D scene understanding, building on the rapid advances of semantic segmentation due to the advent of deep 3D neural networks. Yet, to date there is very little work about panoptic segmentation of outdoor mobile-mapping data, and no systematic comparisons. The present paper tries to close that gap. It reviews the building blocks needed to assemble a panoptic segmentation pipeline and the related literature. Moreover, a modular pipeline is set up to perform comprehensive, systematic experiments to assess the state of panoptic segmentation in the context of street mapping. As a byproduct, we also provide the first public dataset for that task, by extending the NPM3D dataset to include instance labels."}, "cited_paper_content": {"title": "Partnet: A Large-Scale Benchmark For Fine-Grained And Hierarchical Part-Level 3D Object Understanding", "abstract": "We present PartNet: a consistent, large-scale dataset of 3D objects annotated with fine-grained, instance-level, and hierarchical 3D part information. Our dataset consists of 573,585 part instances over 26,671 3D models covering 24 object categories. This dataset enables and serves as a catalyst for many tasks such as shape analysis, dynamic 3D scene modeling and simulation, affordance analysis, and others. Using our dataset, we establish three benchmarking tasks for evaluating 3D part recognition: fine-grained semantic segmentation, hierarchical semantic segmentation, and instance segmentation. We benchmark four state-of-the-art 3D deep learning algorithms for fine-grained semantic segmentation and three baseline methods for hierarchical semantic segmentation. We also propose a baseline method for part instance segmentation and demonstrate its superior performance over existing methods."}, "keywords": ["PartNet dataset"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To support the subsequent clustering step, #OTHEREFR (2019) estimate vectors pointing to the potential instance centers, as in the generalised Hough transform, and could be used in conjunction with the PartNet dataset for fine-grained and hierarchical part-level 3D object understanding.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "PartNet is a consistent, large-scale dataset of 3D objects annotated with fine-grained, instance-level, and hierarchical 3D part information, which enables and serves as a catalyst for many tasks such as shape analysis, dynamic 3D scene modeling and simulation, affordance analysis, and others (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The PartNet dataset provides fine-grained, instance-level, and hierarchical 3D part information for 573,585 part instances over 26,671 3D models, enabling many tasks such as shape analysis and affordance analysis, as mentioned in (2019b). #REFR", "given_citation_intent": "background", "given_keywords": ["PartNet dataset"]}]}
{"citing_id": "2304.03580v1", "cited_id": "1512.03385", "section_title": "Experimental Setup", "citation": "We use ResNet50 #REFR as the backbone with an ImageNet-pretrained model from TORCHVISION in all experiments unless specified otherwise. The AdamW [23] optimizer is used.", "text_before_citation": ["Note that we replace the official noisy annotation that contains 10% labels generated semi-automatically using #OTHEREFR with the one released by BigDetection #OTHEREFR .", "Ob-ject365 is another large-scale dataset, and it contains around 1.72M images with more than 22.8M bounding boxes over 365 categories.", "Then we finetune the pre-trained models on the COCO 2017 dataset. Implementation details.", "The classification head of METR is the form of the dot-product layer #OTHEREFR and the detailed algorithm will be summarized in supplementary materials.", "We conduct our experiments using the PyTorch #OTHEREFR deep learning framework."], "text_after_citation": ["The learning rates for the backbone and the transformer are initially set to be 1e\u22125 and 1e\u22124, respectively.", "The learning rate is dropped by a factor of 10 after 11 epochs for 12 training epochs, and after 40 epochs for 50 training epochs. The weight decay is set to be 1e\u22124.", "We train METR on COCO using 8 Nvidia A100 40G GPUs, and each GPU has a local batch size of 1 image only.", "For language embeddings, we select CLIP-B/16 #OTHEREFR text encoder throughout this study.", "We adopt most of the default hyper-parameters and data augmentation same as DINO."], "citing_paper_content": {"title": "Language-Aware Multiple Datasets Detection Pretraining For Detrs", "abstract": "Pretraining on large-scale datasets can boost the performance of object detectors while the annotated datasets for object detection are hard to scale up due to the high labor cost. What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly pretrain models across aggregation of datasets to enhance data volume and diversity. In this paper, we propose a strong framework for utilizing Multiple datasets to pretrain DETR-like detectors, termed METR, without the need for manual label spaces integration. It converts the typical multi-classification in object detection into binary classification by introducing a pre-trained language model. Specifically, we design a category extraction module for extracting potential categories involved in an image and assign these categories into different queries by language embeddings. Each query is only responsible for predicting a class-specific object. Besides, to adapt our novel detection paradigm, we propose a group bipartite matching strategy that limits the ground truths to match queries assigned to the same category. Extensive experiments demonstrate that METR achieves extraordinary results on either multi-task joint training or the pretrain & finetune paradigm. Notably, our pre-trained models have high flexible transferability and increase the performance upon various DETR-like detectors on COCO val2017 benchmark. Codes will be available after this paper is published."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["ImageNet-pretrained model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To pretrain DETR-like detectors, the authors proposed a framework called METR that utilizes multiple datasets and a pre-trained language model for category extraction and binary classification #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To extract potential categories involved in an image and assign them into different queries, the authors utilized a pre-trained language model as proposed in Deep Residual Learning For Image Recognition #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We pretrain our METR model using an ImageNet-pretrained model #REFR, which is based on the residual learning framework proposed in \"Deep Residual Learning For Image Recognition\" for ease of optimization and accuracy improvement.", "given_citation_intent": "method", "given_keywords": ["ImageNet-pretrained model"]}]}
{"citing_id": "2303.07592v1", "cited_id": "1608.03983", "section_title": "Experimental Setup", "citation": "An initial learning rate was 0.001, exponentially decayed with a factor of 0.95 during the distillation step, and varied by SGDR #REFR during the fine-tuning step (T 0 = 2, T mult = 2).", "text_before_citation": ["Analogous to the previous works #OTHEREFR , we trained the model in an end-to-end manner by using a binary target.", "Specifically, we assigned 1 to the n frames around the end-point of wake-up word and 0 to the remainder.", "Here, the end-point was obtained by using a simple energy-based voice activity detector (VAD).", "We decided to use n = 41 (i.e., 20 additional frames each before and after the end-point of the wake-up word) based on the development set result.", "We trained the model during 5 epochs for distillation step and 50 epochs for fine-tuning step with the Adam optimizer #OTHEREFR . A batch size was set to 32 utterances."], "text_after_citation": ["We set the width multiplier \u03b1 = 1/8 and an interpolation coefficient \u03bb = 0.5. Pytorch framework #OTHEREFR was used for all experiments."], "citing_paper_content": {"title": "Lightweight Feature Encoder For Wake-Up Word Detection Based On Self-Supervised Speech Representation", "abstract": "Self-supervised learning method that provides generalized speech representations has recently received increasing attention. Wav2vec 2.0 is the most famous example, showing remarkable performance in numerous downstream speech processing tasks. Despite its success, it is challenging to use it directly for wake-up word detection on mobile devices due to its expensive computational cost. In this work, we propose LiteFEW, a lightweight feature encoder for wake-up word detection that preserves the inherent ability of wav2vec 2.0 with a minimum scale. In the method, the knowledge of the pre-trained wav2vec 2.0 is compressed by introducing an autoencoder-based dimensionality reduction technique and distilled to LiteFEW. Experimental results on the open-source \"Hey Snips\" dataset show that the proposed method applied to various model structures significantly improves the performance, achieving over 20% of relative improvements with only 64k parameters."}, "cited_paper_content": {"title": "Sgdr: Stochastic Gradient Descent With Warm Restarts", "abstract": "Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at https://github.com/loshchil/SGDR"}, "keywords": ["initial learning rate"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Analogous to the previous works (Loshchilov & Hutter, 2017), we trained the model in an end-to-end manner by using a binary target. Specifically, we assigned 1 to the n frames around the end-point of wake-up word and 0 to the remainder. Here, the end-point was obtained by using a simple energy-based voice activity detector (VAD). We decided to use n = 41 (i.e., 20 additional frames each before and after the end-point of the wake-up word) based on the development set result. We trained the model during 5 epochs for distillation step and 50 epochs for fine-tuning step with the Adam optimizer (Loshchilov & Hutter, 2017). A batch size was set to 32 utterances.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the performance of stochastic gradient descent, we employed a warm restart technique proposed in #REFR, which has been shown to be effective in training deep neural networks.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the performance of the wake-up word detection model, we utilized a simple warm restart technique for stochastic gradient descent proposed in #REFR, which has been shown to improve the anytime performance of deep neural networks by adjusting the initial learning rate.", "given_citation_intent": "method", "given_keywords": ["initial learning rate"]}]}
{"citing_id": "2304.08811v1", "cited_id": "1803.06978", "section_title": "Experiment Setting", "citation": "In the choice of attack targets, we picked some representative commands as attack targets, #REFR .", "text_before_citation": ["To evaluate the transferability of our proposed combined adversarial attack strategy, we conducted experiments on commercial speech recognition APIs, such as those provided by iFlytek, Alibaba, and Baidu.", "These APIs provide high-level English speech recognition services that directly impact the user experience of millions of people.", "Attacks against these commercial APIs are closer to real-world attack patterns and are more sophisticated."], "text_after_citation": ["In this context, higher transferability implies a greater potential for danger.", "Also, as shown in the previous experiments, the carrier of AEs plays a significant role in transferability.", "The generation and transferability of AEs are directly influenced by the choice of carrier. In CommanderSong #OTHEREFR , Cheng Yuxuan et al.", "first used music segments as the carrier of AEs in attacks, arguing that music has the nature of common consumption, giving it native opportunities in attacks with its popularity and extensive reach.", "Attacks on music segments are likely to raise public concern."], "citing_paper_content": {"title": "Towards The Transferable Audio Adversarial Attack Via Ensemble Methods", "abstract": "In recent years, deep learning (DL) models have achieved significant progress in many domains, such as autonomous driving, facial recognition, and speech recognition. However, the vulnerability of deep learning models to adversarial attacks has raised serious concerns in the community because of their insufficient robustness and generalization. Also, transferable attacks have become a prominent method for black-box attacks. In this work, we explore the potential factors that impact adversarial examples (AEs) transferability in DL-based speech recognition. We also discuss the vulnerability of different DL systems and the irregular nature of decision boundaries. Our results show a remarkable difference in the transferability of AEs between speech and images, with the data relevance being low in images but opposite in speech recognition. Motivated by dropout-based ensemble approaches, we propose random gradient ensembles and dynamic gradient-weighted ensembles, and we evaluate the impact of ensembles on the transferability of AEs. The results show that the AEs created by both approaches are valid for transfer to the black box API."}, "cited_paper_content": {"title": "Improving Transferability Of Adversarial Examples With Input Diversity", "abstract": "Though CNNs have achieved the state-of-the-art performance on various vision tasks, they are vulnerable to adversarial examples --- crafted by adding human-imperceptible perturbations to clean images. However, most of the existing adversarial attacks only achieve relatively low success rates under the challenging black-box setting, where the attackers have no knowledge of the model structure and parameters. To this end, we propose to improve the transferability of adversarial examples by creating diverse input patterns. Instead of only using the original images to generate adversarial examples, our method applies random transformations to the input images at each iteration. Extensive experiments on ImageNet show that the proposed attack method can generate adversarial examples that transfer much better to different networks than existing baselines. By evaluating our method against top defense solutions and official baselines from NIPS 2017 adversarial competition, the enhanced attack reaches an average success rate of 73.0%, which outperforms the top-1 attack submission in the NIPS competition by a large margin of 6.6%. We hope that our proposed attack strategy can serve as a strong benchmark baseline for evaluating the robustness of networks to adversaries and the effectiveness of different defense methods in the future. Code is available at https://github.com/cihangxie/DI-2-FGSM."}, "keywords": ["attack targets"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To evaluate the impact of ensembles on the transferability of adversarial examples, we propose random gradient ensembles and dynamic gradient-weighted ensembles, inspired by dropout-based ensemble approaches #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the transferability of adversarial examples in speech recognition, the authors propose a method that applies random transformations to input images at each iteration, which is inspired by the method proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the transferability of adversarial examples, the proposed attack method in this manuscript applies random transformations to the input images at each iteration, which can serve as a strong benchmark baseline for evaluating the robustness of networks to adversaries and the effectiveness of different defense methods in the future, and is relevant to our study on attacking commercial speech recognition APIs. #REFR", "given_citation_intent": "method", "given_keywords": ["attack targets"]}]}
{"citing_id": "2304.00157v1", "cited_id": "1910.02550", "section_title": "A. Datasets", "citation": "ClearGrasp #REFR dataset includes both a highly realistic synthetic dataset and a real-world benchmark.", "text_before_citation": ["Transparent object reconstruction requires the ground truth of the reconstructed depth or 3D shape for evaluation.", "Therefore, datasets with ground truth of depth or 3D shapes are required for model training and evaluation.", "In the subsection, we thoroughly summarise datasets published since 2020 for transparent object reconstruction, regarding year, place of publication (Pub.), number of objects in the images (#Obj.), dataset size (#Imgs), devices, auto-collection ability and special features."], "text_after_citation": ["The synthetic dataset is rendered by using the ray-tracing Cycles rendering engine integrated into Blender, which can provide important effects for transparent objects, such as refraction and soft shadow.", "To capture the depth of transparent objects in the real world, transparent objects are sprayed with rough stone textures that can reflect light evenly and lead to better depth estimates from RGB-D cameras.", "It should be noted that Clear-Grasp is the first large-scale dataset including 50k synthetic images and 286 real images for the depth reconstruction of transparent objects.", "OOD #OTHEREFR : Omniverse Object Dataset consists of 60k synthetic images of five transparent objects from ClearGrasp #OTHEREFR .", "The Omniverse Platform and NVIDIA PhysX engine are used for rendering those images and getting natural poses of objects."], "citing_paper_content": {"title": "Robotic Perception Of Transparent Objects: A Review", "abstract": "Fig. 1. Typical applications of transparent object perception. (a) Robot assistant [1](\u00a9[2021] IEEE); (b) Autonomous robot navigation [2]; (c) Laboratory automation [3]; (d) Waste sorting and recycling [4]."}, "cited_paper_content": {"title": "Cleargrasp: 3D Shape Estimation Of Transparent Objects For Manipulation", "abstract": "Transparent objects are a common part of everyday life, yet they possess unique visual properties that make them incredibly difficult for standard 3D sensors to produce accurate depth estimates for. In many cases, they often appear as noisy or distorted approximations of the surfaces that lie behind them. To address these challenges, we present ClearGrasp -- a deep learning approach for estimating accurate 3D geometry of transparent objects from a single RGB-D image for robotic manipulation. Given a single RGB-D image of transparent objects, ClearGrasp uses deep convolutional networks to infer surface normals, masks of transparent surfaces, and occlusion boundaries. It then uses these outputs to refine the initial depth estimates for all transparent surfaces in the scene. To train and test ClearGrasp, we construct a large-scale synthetic dataset of over 50,000 RGB-D images, as well as a real-world test benchmark with 286 RGB-D images of transparent objects and their ground truth geometries. The experiments demonstrate that ClearGrasp is substantially better than monocular depth estimation baselines and is capable of generalizing to real-world images and novel objects. We also demonstrate that ClearGrasp can be applied out-of-the-box to improve grasping algorithms' performance on transparent objects. Code, data, and benchmarks will be released. Supplementary materials available on the project website: this https URL"}, "keywords": ["ClearGrasp dataset"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Transparent object reconstruction requires the ground truth of the reconstructed depth or 3D shape for evaluation. Therefore, datasets with ground truth of depth or 3D shapes are required for model training and evaluation. In the subsection, we thoroughly summarise datasets published since 2020 for transparent object reconstruction, regarding year, place of publication (Pub.), number of objects in the images (#Obj.), dataset size (#Imgs), devices, auto-collection ability and special features. ClearGrasp, a deep learning approach for estimating accurate 3D geometry of transparent objects from a single RGB-D image for robotic manipulation, is a valuable tool for generating such datasets and has been shown to substantially outperform monocular depth estimation baselines, as demonstrated in the study by the authors of ClearGrasp (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate models for transparent object reconstruction, datasets with ground truth of depth or 3D shapes are required, such as the large-scale synthetic dataset of over 50,000 RGB-D images presented in ClearGrasp by the authors in \"#REFR\".", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate the deep learning approach for estimating accurate 3D geometry of transparent objects, the authors constructed a large-scale synthetic dataset of over 50,000 RGB-D images, as well as a real-world test benchmark with 286 RGB-D images of transparent objects and their ground truth geometries, known as the ClearGrasp dataset. #REFR", "given_citation_intent": "background", "given_keywords": ["ClearGrasp dataset"]}]}
{"citing_id": "2304.06719v1", "cited_id": "1903.11027", "section_title": "Main Benchmarking Results", "citation": "The performance on nuScenes-C is improved as the performance on the \"clean\" nuScenes #REFR dataset. The relation of absolute performance is close to linear.", "text_before_citation": ["In this study, we conduct a comprehensive benchmarking analysis of 26 existing BEV detectors on the nuScenes-C dataset.", "The main results of our experiments are presented in Tables 2 and 3.", "Our findings indicate that all models exhibit varying degrees of performance declines on the corruption set.", "We observed that Bright, which causes a much larger shift in pixel distribution than Motion Blur, resulted (b) mRR vs. NDS Figure 3 ."], "text_after_citation": ["However, when considering the relative performance, the mRR metric is more randomly distributed without a clear trend to increase. in the smallest performance drop.", "For most of the models, the resilience rate of Bright remains the highest.", "We notice a strong correlation of the absolute performances between nuScenes-C and the \"clean\" dataset.", "Specifically, BEV detectors that perform well on the standard dataset are also likely to perform better on the out-ofdistribution dataset, as illustrated in Figure 3 (a).", "However, a closer examination of the results revealed a more complex situation."], "citing_paper_content": {"title": "Robobev: Towards Robust Bird'S Eye View Perception Under Corruptions", "abstract": "The recent advances in camera-based bird's eye view (BEV) representation exhibit great potential for in-vehicle 3D perception. Despite the substantial progress achieved on standard benchmarks, the robustness of BEV algorithms has not been thoroughly examined, which is critical for safe operations. To bridge this gap, we introduce RoboBEV, a comprehensive benchmark suite that encompasses eight distinct corruptions, including Bright, Dark, Fog, Snow, Motion Blur, Color Quant, Camera Crash, and Frame Lost. Based on it, we undertake extensive evaluations across a wide range of BEV-based models to understand their resilience and reliability. Our findings indicate a strong correlation between absolute performance on in-distribution and out-of-distribution datasets. Nonetheless, there are considerable variations in relative performance across different approaches. Our experiments further demonstrate that pre-training and depth-free BEV transformation has the potential to enhance out-of-distribution robustness. Additionally, utilizing long and rich temporal information largely helps with robustness. Our findings provide valuable insights for designing future BEV models that can achieve both accuracy and robustness in real-world deployments. 1"}, "cited_paper_content": {"title": "Nuscenes: A Multimodal Dataset For Autonomous Driving", "abstract": "Robust detection and tracking of objects is crucial for the deployment of autonomous vehicle technology. Image-based benchmark datasets have driven development in computer vision tasks such as object detection, tracking and segmentation of agents in the environment. Most autonomous vehicles, however, carry a combination of cameras and range sensors such as lidar and radar. As machine learning based methods for detection and tracking become more prevalent, there is a need to train and evaluate such methods on datasets containing range sensor data along with images. In this work we present nuTonomy scenes (nuScenes), the first published dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view. nuScenes comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as many annotations and 100x as many images as the pioneering KITTI dataset. We define novel 3D detection and tracking metrics. We also provide careful dataset analysis as well as baselines for lidar and image based detection and tracking. Data, development kit and more information are available online at this http URL."}, "keywords": ["absolute performance", "nuScenes-C"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this study, we conduct a comprehensive benchmarking analysis of 26 existing BEV detectors on the nuScenes-C dataset, which is the first published dataset to carry the full autonomous vehicle sensor suite, including 6 cameras, 5 radars, and 1 lidar, all with full 360-degree field of view #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We benchmarked 26 existing BEV detectors on the nuScenes-C dataset and observed varying degrees of performance declines on the corruption set, including Bright and Motion Blur (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We evaluated the performance of 26 existing BEV detectors on the nuScenes-C dataset, and our findings indicate that there are considerable variations in relative performance across different approaches, with a strong correlation between absolute performance on in-distribution and out-of-distribution datasets. (#REFR)", "given_citation_intent": "result", "given_keywords": ["absolute performance", "nuScenes-C"]}]}
{"citing_id": "2303.07224v1", "cited_id": "2004.01800", "section_title": "Related Works", "citation": "With global attention mechanism, TD-Net #REFR aggregated the features from different time stamps and replaced the deep model with several shallow models distributed across the timeline.", "text_before_citation": ["Noticing the lack of information from nonkeyframes, Li et al.", "#OTHEREFR extracted shallow features from non-keyframes, and fused them into the propagated deep features by spatially variant convolution.", "To compensate for the spatial misalignment between video frames, Zhu et al. #OTHEREFR and Xu et al.", "#OTHEREFR warped the intermediate features from keyframes by optical flow to produce segmentation results for non-keyframes. Jain et al.", "#OTHEREFR fused the shallow features of non-keyframe into the warped features, and decoded them into better results."], "text_after_citation": ["All the above methods mainly reduced the depth of backbone networks, but neglected the factor of input resolution considered in this paper.", "Instead of processing the image frames as a whole, Verelst et al.", "#OTHEREFR split the frame into blocks and chose to copy or process them by a policy network.", "This block-based method reduces computational overhead from the spatial dimension, but lacks global information on nonkeyframes. Kim et al. #OTHEREFR attempted to improve efficiency by reducing resolution.", "But they directly used the LR segmentation results, thus suffering from severe performance degradation."], "citing_paper_content": {"title": "Efficient Semantic Segmentation By Altering Resolutions For Compressed Videos", "abstract": "Video semantic segmentation (VSS) is a computationally expensive task due to the per-frame prediction for videos of high frame rates. In recent work, compact models or adaptive network strategies have been proposed for efficient VSS. However, they did not consider a crucial factor that affects the computational cost from the input side: the input resolution. In this paper, we propose an altering resolution framework called AR-Seg for compressed videos to achieve efficient VSS. AR-Seg aims to reduce the computational cost by using low resolution for non-keyframes. To prevent the performance degradation caused by downsampling, we design a Cross Resolution Feature Fusion (CR-eFF) module, and supervise it with a novel Feature Similarity Training (FST) strategy. Specifically, CReFF first makes use of motion vectors stored in a compressed video to warp features from high-resolution keyframes to low-resolution non-keyframes for better spatial alignment, and then selectively aggregates the warped features with local attention mechanism. Furthermore, the proposed FST supervises the aggregated features with high-resolution features through an explicit similarity loss and an implicit constraint from the shared decoding layer. Extensive experiments on CamVid and Cityscapes show that AR-Seg achieves state-of-the-art performance and is compatible with different segmentation backbones. On CamVid, AR-Seg saves 67% computational cost (measured in GFLOPs) with the PSPNet18 backbone while maintaining high segmentation accuracy."}, "cited_paper_content": {"title": "Temporally Distributed Networks For Fast Video Semantic Segmentation", "abstract": "We present TDNet, a temporally distributed network designed for fast and accurate video semantic segmentation. We observe that features extracted from a certain high-level layer of a deep CNN can be approximated by composing features extracted from several shallower sub-networks. Leveraging the inherent temporal continuity in videos, we distribute these sub-networks over sequential frames. Therefore, at each time step, we only need to perform a lightweight computation to extract a sub-features group from a single sub-network. The full features used for segmentation are then recomposed by application of a novel attention propagation module that compensates for geometry deformation between frames. A grouped knowledge distillation loss is also introduced to further improve the representation power at both full and sub-feature levels. Experiments on Cityscapes, CamVid, and NYUD-v2 demonstrate that our method achieves state-of-the-art accuracy with significantly faster speed and lower latency."}, "keywords": ["deep model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To achieve efficient video semantic segmentation, Li et al. extracted shallow features from non-keyframes and fused them into the propagated deep features by spatially variant convolution, while Zhu et al. and Xu et al. warped the intermediate features from keyframes by optical flow to produce segmentation results for non-keyframes. Jain et al. fused the shallow features of non-keyframes into the warped features and decoded them into better results. In a similar vein, the proposed TDNet #REFR leverages the inherent temporal continuity in videos by distributing sub-networks over sequential frames, achieving state-of-the-art accuracy with significantly faster speed and lower latency.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the computational cost of video semantic segmentation, Li et al. extracted shallow features from non-keyframes and fused them into the propagated deep features by spatially variant convolution, while Zhu et al. and Xu et al. warped the intermediate features from keyframes by optical flow to produce segmentation results for non-keyframes, and Jain et al. fused the shallow features of non-keyframes into the warped features and decoded them into better results. In a similar vein, the proposed TDNet #REFR utilizes the inherent temporal continuity in videos by distributing sub-networks over sequential frames, achieving state-of-the-art accuracy with significantly faster speed and lower latency.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the computational cost issue in video semantic segmentation, Li et al. extracted shallow features from non-keyframes and fused them into the propagated deep features by spatially variant convolution, while Zhu et al. and Xu et al. warped the intermediate features from keyframes by optical flow to produce segmentation results for non-keyframes, and Jain et al. fused the shallow features of non-keyframes into the warped features and decoded them into better results. In contrast, the proposed TDNet #REFR leverages the inherent temporal continuity in videos by distributing sub-networks over sequential frames, achieving state-of-the-art accuracy with significantly faster speed and lower latency, making it a promising deep model for efficient VSS.", "given_citation_intent": "method", "given_keywords": ["deep model"]}]}
{"citing_id": "2304.13114v1", "cited_id": "1206.2944", "section_title": "I. Introduction", "citation": "Bayesian optimization is a global optimization scheme that has been commonly used to optimize neural network training parameters #REFR .", "text_before_citation": ["Other methods have utilized global optimization techniques such as branch and bound to determine the optimal transform in certain situations such as scan to model matching #OTHEREFR .", "In situations where outliers, dynamic obstacles, or noisy sensor measurements exist, these global methods cannot guarantee an optimal solution #OTHEREFR .", "The lack of consistently reliable methods for global registration motivates research targeted at more robust initialization techniques.", "In this paper, we outline a framework based on Bayesian optimization (BO) #OTHEREFR , a global optimization method, to systematically compute T 0 , and find this approach produces more accurate alignments than state-of-the-art methods.", "It is fundamentally compatible with variants of ICP that address point correspondences, the weighting of correspondences, and other methods that focus on adjusting how the objective is constructed."], "text_after_citation": ["In practice, BO aims to find the minima or maxima of an objective function and is effective in situations where the objective is either complex, noisy, or expensive to calculate, such as in the case of minimizing the point-topoint correspondence distance.", "BO utilizes a computationally efficient probabilistic model of the objective function (see Figure 1 ) that is inexpensive to evaluate.", "As the point cloud registration problem as formulated by ICP is inherently a non-convex problem that requires expensive iterations for each initial T 0 estimate, it is an ideal candidate for BO.", "We demonstrate that our approach outperforms exhaustive searches for this initial estimate, as well as other \"globally optimal\" methods.", "In this work, we present an open-source Bayesian optimization-based method (BO-ICP) for determining the crucial initial condition for ICP problems."], "citing_paper_content": {"title": "Bo-Icp: Initialization Of Iterative Closest Point Based On Bayesian Optimization", "abstract": "Typical algorithms for point cloud registration such as Iterative Closest Point (ICP) require a favorable initial transform estimate between two point clouds in order to perform a successful registration. State-of-the-art methods for choosing this starting condition rely on stochastic sampling or global optimization techniques such as branch and bound. In this work, we present a new method based on Bayesian optimization for finding the critical initial ICP transform. We provide three different configurations for our method which highlights the versatility of the algorithm to both find rapid results and refine them in situations where more runtime is available such as offline map building. Experiments are run on popular data sets and we show that our approach outperforms state-of-the-art methods when given similar computation time. Furthermore, it is compatible with other improvements to ICP, as it focuses solely on the selection of an initial transform, a starting point for all ICP-based methods."}, "cited_paper_content": {"title": "Practical Bayesian Optimization Of Machine Learning Algorithms", "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."}, "keywords": ["Bayesian optimization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this paper, we outline a framework based on Bayesian optimization (BO) #REFR, a global optimization method, to systematically compute T 0, and find this approach produces more accurate alignments than state-of-the-art methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We propose a new method based on Bayesian optimization for finding the critical initial ICP transform, which has been shown to achieve expert-level performance in optimizing the performance of machine learning algorithms #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We propose a new method based on Bayesian optimization (BO) #REFR to find the critical initial ICP transform, which outperforms state-of-the-art methods when given similar computation time, and is fundamentally compatible with variants of ICP that address point correspondences, the weighting of correspondences, and other methods that focus on adjusting how the objective is constructed.", "given_citation_intent": "method", "given_keywords": ["Bayesian optimization"]}]}
{"citing_id": "2303.08864v1", "cited_id": "1603.03935", "section_title": "A T E X I T S H A 1 _ B A S E 6 4 = \" Z U D 8 A P B L U T 3 F R + 8 H X N L Y U 7 A S S 3 8 = \" > A", "citation": "Therefore, designing real-time FC search algorithms critically hinges on finding an accurate and efficient solution to Q in #REFR .", "text_before_citation": ["These estimates are widely referred to as Q-values, denoted by", "Q(S i , a i ) \u2208 R,", "where a higher Q(S i , a i ) indicates that taking an action a i from a MDP state S i yields better aggregate future rewards #OTHEREFR .", "Note that, however, when solving Q in a POMDP environment, the ordinary Q-learning algorithm is ineffective as partial observations O i are typically not reflective of the underlying POMDP state S i .", "As a result, Q(O i , a i ) = Q(S i , a i )."], "text_after_citation": ["To this end, we aim to design an approach that judiciously exploits the underlying structure of each POMDP state S i .", "In particular, we develop a graph recurrent Q-network (GRQN) architecture that exploits the following three key elements:"], "citing_paper_content": {"title": "Grnn-Based Real-Time Fault Chain Prediction", "abstract": "This paper proposes a data-driven graphical framework for the real-time search of risky cascading fault chains (FCs). While identifying risky FCs is pivotal to alleviating cascading failures, the complex spatio-temporal dependencies among the components of the power system render challenges to modeling and analyzing FCs. Furthermore, the real-time search of risky FCs faces an inherent combinatorial complexity that grows exponentially with the size of the system. The proposed framework leverages the recent advances in graph recurrent neural networks to circumvent the computational complexities of the real-time search of FCs. The search process is formalized as a partially observable Markov decision process (POMDP), which is subsequently solved via a time-varying graph recurrent neural network (GRNN) that judiciously accounts for the inherent temporal and spatial structures of the data generated by the system. The key features of this structure include (i) leveraging the spatial structure of the data induced by the system topology, (ii) leveraging the temporal structure of data induced by system dynamics, and (iii) efficiently summarizing the system's history in the latent space of the GRNN. The proposed framework's efficiency is compared to the relevant literature on the IEEE 39-bus New England system and the IEEE 118-bus system."}, "cited_paper_content": {"title": "Risk Assessment Of Multi-Timescale Cascading Outages Based On Markovian Tree Search", "abstract": "In the risk assessment of cascading outages, the rationality of simulation and efficiency of computation are both of great significance. To overcome the drawback of sampling-based methods that huge computation resources are required and the shortcoming of initial contingency selection practices that the dependencies in sequences of outages are omitted, this paper proposes a novel risk assessment approach by searching on Markovian Tree. The Markovian tree model is reformulated from the quasi-dynamic multitimescale simulation model proposed recently to ensure reasonable modeling and simulation of cascading outages. Then, a tree search scheme is established to avoid duplicated simulations on same cascade paths, significantly saving the computation time. To accelerate the convergence of a risk assessment, a risk estimation index is proposed to guide the search for states with major contributions to the risk, and the risk assessment is realized based on the risk estimation index with a forward tree search and backward update algorithm. The effectiveness of the proposed method is illustrated on a four-node power system, and its convergence profile as well as efficiency is demonstrated on the RTS-96 test system."}, "keywords": ["real-time FC search"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To overcome the computational complexity of the real-time search of risky fault chains, the proposed framework leverages a time-varying graph recurrent neural network (GRNN) that accounts for the inherent temporal and spatial structures of the data generated by the system #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The risk assessment of cascading outages is a crucial task in power systems, and the rationality of simulation and efficiency of computation are both of great significance #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Real-time search of risky fault chains is a challenging task due to the inherent combinatorial complexity that grows exponentially with the size of the system, and the proposed framework in this paper leverages the recent advances in graph recurrent neural networks to overcome this challenge #REFR.", "given_citation_intent": "background", "given_keywords": ["real-time FC search"]}]}
{"citing_id": "2304.04742v1", "cited_id": "1902.09630", "section_title": "Revisit Detr Losses And Matching Costs", "citation": "Similar to the loss functions, the final cost includes three items, a classification cost C cls , a box L1 cost C bbox , and a GIOU cost C GIOU #REFR . We focus only on the classification cost as well.", "text_before_citation": ["Typically, a ground truth will be assigned only one prediction as the positive example.", "Predictions with no ground truths assigned will be viewed as negative examples.", "To assign predictions with ground truths, we first calculate a cost matrix C \u2208 R N pred \u00d7Ngt between them.", "The N pred and N gt are the number for predictions and ground truths.", "Then a Hungarian matching algorithm will perform on the cost matrix to assign each ground truth a prediction by minimizing sum costs."], "text_after_citation": ["For the i th prediction and the j th ground truth, the classification cost is:", "C cls (i, j) = |1 \u2212 p i | \u03b3 BCE(p i , 1)\u2212p \u03b3 i BCE(1\u2212p i , 1). (2)", "The formulation is similar to the focal cost but has a litter modification #OTHEREFR .", "The focal loss only encourages positive examples to predict 1, while the classification cost adds an additional penalty term to avoid it to 0."], "citing_paper_content": {"title": "Detection Transformer With Stable Matching", "abstract": "This paper is concerned with the matching stability problem across different decoder layers in DEtection TRansformers (DETR). We point out that the unstable matching in DETR is caused by a multi-optimization path problem, which is highlighted by the one-to-one matching design in DETR. To address this problem, we show that the most important design is to use and only use positional metrics (like IOU) to supervise classification scores of positive examples. Under the principle, we propose two simple yet effective modifications by integrating positional metrics to DETR's classification loss and matching cost, named positionsupervised loss and position-modulated cost. We verify our methods on several DETR variants. Our methods show consistent improvements over baselines. By integrating our methods with DINO, we achieve 50.4 and 51.5 AP on the COCO detection benchmark using ResNet-50 backbones under 1\u00d7 (12 epochs) and 2\u00d7 (24 epochs) training settings, achieving a new record under the same setting. We achieve 63.8 AP on COCO detection test-dev with a Swin-Large backbone. Our code will be made available at https:// github.com/IDEA-Research/Stable-DINO. * Equal contributions. List order is random. \u2020 This work was done when Shilong Liu, Hao Zhang, Feng Li, and Hongyang Li were interns at IDEA."}, "cited_paper_content": {"title": "Generalized Intersection Over Union: A Metric And A Loss For Bounding Box Regression", "abstract": "Intersection over Union (IoU) is the most popular evaluation metric used in the object detection benchmarks. However, there is a gap between optimizing the commonly used distance losses for regressing the parameters of a bounding box and maximizing this metric value. The optimal objective for a metric is the metric itself. In the case of axis-aligned 2D bounding boxes, it can be shown that IoU can be directly used as a regression loss. However, IoU has a plateau making it infeasible to optimize in the case of non-overlapping bounding boxes. In this paper, we address the this weakness by introducing a generalized version of IoU as both a new loss and a new metric. By incorporating this generalized IoU ( GIoU) as a loss into the state-of-the art object detection frameworks, we show a consistent improvement on their performance using both the standard, IoU based, and new, GIoU based, performance measures on popular object detection benchmarks such as PASCAL VOC and MS COCO."}, "keywords": ["loss functions", "classification cost C"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To assign predictions with ground truths, a cost matrix is calculated between them, and a Hungarian matching algorithm is used to minimize the sum costs. Recently, a new loss and metric called Generalized Intersection Over Union (GIoU) has been introduced, which has shown consistent improvement in object detection frameworks on popular benchmarks such as PASCAL VOC and MS COCO #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To assign predictions with ground truths, a cost matrix is calculated between them, and a Hungarian matching algorithm is used to minimize the sum costs. This approach has been widely used in object detection benchmarks such as PASCAL VOC and MS COCO, and recent work has introduced a generalized version of Intersection over Union (IoU) as a new metric and loss for bounding box regression, which has shown consistent improvement on performance measures. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the multi-optimization path problem in DETR, positional metrics such as IOU are used to supervise classification scores of positive examples, and the positional metrics are integrated into the classification loss and matching cost #REFR, which are effective modifications to improve the performance of DETR on object detection benchmarks.", "given_citation_intent": "background", "given_keywords": ["loss functions", "classification cost C"]}]}
{"citing_id": "2304.07132v1", "cited_id": "1906.04015", "section_title": "Controlled 3D Molecular Generations", "citation": "We use the train/val/test partitions introduced in Anderson et al. #REFR (train/val/test: 100K/18K/13K samples) for evaluation.", "text_before_citation": ["Dataset QM9 #OTHEREFR is a dataset of 130k stable and synthetically accessible organic molecules with up to 9 heavy atoms (29 atoms including hydrogens).", "In this section, we train diffusion models to generate atoms' (1) 3-dimensional coordinates; (2) types (H, C, N, O, F) and 3integer-valued atom charges."], "text_after_citation": ["Evaluation Metrics Our goal here is to generate molecules targeting some desired properties while at the same time not harming general generation quality (e.g., molecules' validity (the proportion of atoms with right valency) and stability, etc.).", "In such a scenario, a molecule is represented as a point cloud, in which each point denotes a single atom and has its own (atom) type.", "Following #OTHEREFR , for each pair of atoms, we use the distance between them and the atoms' types to predict bonds (single, double, triple, or none) between atoms.", "In this section, we consider optimizing two desired properties: (1) quantitative estimate of druglikeness (QED) #OTHEREFR (how likely a molecule is a potential drug candidate based on marketed drug molecules) and (2) synthetic accessibility score (SA) (the difficulty of drug synthesis), which are crucial in drug discovery domain.", "A good method should have a high averaged QED and SA."], "citing_paper_content": {"title": "Towards Controllable Diffusion Models Via Reward-Guided Exploration", "abstract": "By formulating data samples' formation as a Markov denoising process, diffusion models achieve state-of-the-art performances in a collection of tasks. Recently, many variants of diffusion models have been proposed to enable controlled sample generation. Most of these existing methods either formulate the controlling information as an input (i.e.,: conditional representation) for the noise approximator, or introduce a pre-trained classifier in the test-phase to guide the Langevin dynamic towards the conditional goal. However, the former line of methods only work when the controlling information can be formulated as conditional representations, while the latter requires the pre-trained guidance classifier to be differentiable. In this paper, we propose a novel framework named RGDM (Reward-Guided Diffusion Model) that guides the training-phase of diffusion models via reinforcement learning (RL). The proposed training framework bridges the objective of weighted log-likelihood and maximum entropy RL, which enables calculating policy gradients via samples from a pay-off distribution proportional to exponential scaled rewards, rather than from policies themselves. Such a framework alleviates the high gradient variances and enables diffusion models to explore for highly rewarded samples in the reverse process. Experiments on 3D shape and molecule generation tasks show significant improvements over existing conditional diffusion models."}, "cited_paper_content": {"title": "Cormorant: Covariant Molecular Neural Networks", "abstract": "We propose Cormorant, a rotationally covariant neural network architecture for learning the behavior and properties of complex many-body physical systems. We apply these networks to molecular systems with two goals: learning atomic potential energy surfaces for use in Molecular Dynamics simulations, and learning ground state properties of molecules calculated by Density Functional Theory. Some of the key features of our network are that (a) each neuron explicitly corresponds to a subset of atoms; (b) the activation of each neuron is covariant to rotations, ensuring that overall the network is fully rotationally invariant. Furthermore, the non-linearity in our network is based upon tensor products and the Clebsch-Gordan decomposition, allowing the network to operate entirely in Fourier space. Cormorant significantly outperforms competing algorithms in learning molecular Potential Energy Surfaces from conformational geometries in the MD-17 dataset, and is competitive with other methods at learning geometric, energetic, electronic, and thermodynamic properties of molecules on the GDB-9 dataset."}, "keywords": ["(train/val/test"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To generate atoms' 3-dimensional coordinates, types, and charges, the authors trained diffusion models #REFR that achieve state-of-the-art performance on molecule generation tasks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To generate the 3-dimensional coordinates and types of atoms in the QM9 dataset, the authors trained diffusion models using a novel framework named RGDM, which guides the training-phase of diffusion models via reinforcement learning and significantly outperforms existing conditional diffusion models #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To generate atoms' 3-dimensional coordinates, types, and charges, diffusion models were trained on the QM9 dataset using the RGDM framework proposed by the authors in \"Cormorant: Covariant Molecular Neural Networks\" (#REFR).", "given_citation_intent": "method", "given_keywords": ["(train/val/test"]}]}
{"citing_id": "2303.10615v1", "cited_id": "0812.1345", "section_title": "General Method", "citation": "This implies J \u03bd (h \u03bd (g), h \u03bd (s)) \u2265 \u03b1 which is equivalent to #REFR .", "text_before_citation": ["To show (1), let \u03b1 be the right-hand side of this inequality. This means that", "\u03b1 = min r\u2208Rs c n(s)\u2212n(r) J \u03bd (h \u03bd (g), h \u03bd (r)).", "If \u03b1 = 0 then (1) is trivially true. Otherwise, put m = h \u03bd (g)/\u03b1.", "Due to the bilinearity of J \u03bd , vector m is a feasible solution to P .", "If the objective value of P is at least 1, then (again by bilinearity) we have in particular J \u03bd (h \u03bd (g)/\u03b1, h \u03bd (s)) \u2265 1."], "text_after_citation": ["Note that if the objective value of the linear program is less than one but still more than zero then exponential bound for a smaller c might hold.", "This theorem also holds for any other linear representation which maps gadgets to non-negative vectors.", "The downside of a linear program is that it is usually solved by a numerical method which is not suitable for a theoretical proof. We circumvent this by solving the dual problem.", "Note that any solution of the dual gives us a lower bound but of course suboptimal solutions will give weaker bounds.", "So for a given solution of the dual we only need to certify that it is indeed a solution which is easy and we do not need to prove optimality."], "citing_paper_content": {"title": "Counting Circuit Double Covers", "abstract": "We study a counting version of Cycle Double Cover Conjecture. We discuss why it is more interesting to count circuits (i.e., graphs isomorphic to C k for some k) instead of cycles (graphs with all degrees even). We give an almost-exponential lower-bound for graphs with a surface embedding of representativity at least 4. We also prove an exponential lower-bound for planar graphs. We conjecture that any bridgeless cubic graph has at least 2 n/2\u22121 circuit double covers and we show an infinite class of graphs for which this bound is tight."}, "cited_paper_content": {"title": "A Unified Approach To Distance-Two Colouring Of Graphs On Surfaces", "abstract": "In this paper we introduce the notion of $\\Sigma$-colouring of a graph $G$: For given subsets $\\Sigma(v)$ of neighbours of $v$, for every $v\\in V(G)$, this is a proper colouring of the vertices of $G$ such that, in addition, vertices that appear together in some $\\Sigma(v)$ receive different colours. This concept generalises the notion of colouring the square of graphs and of cyclic colouring of graphs embedded in a surface. We prove a general result for graphs embeddable in a fixed surface, which implies asymptotic versions of Wegner's and Borodin's Conjecture on the planar version of these two colourings. Using a recent approach of Havet et al., we reduce the problem to edge-colouring of multigraphs, and then use Kahn's result that the list chromatic index is close to the fractional chromatic index. Our results are based on a strong structural lemma for graphs embeddable in a fixed surface, which also implies that the size of a clique in the square of a graph of maximum degree $\\Delta$ embeddable in some fixed surface is at most $\\frac32\\,\\Delta$ plus a constant."}, "keywords": ["\u2265", "h \u03bd"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors introduce the notion of $\\Sigma$-colouring of a graph, which generalizes the notion of colouring the square of graphs and of cyclic colouring of graphs embedded in a surface #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' notion of $\\Sigma$-colouring of a graph, which generalizes the notion of colouring the square of graphs and of cyclic colouring of graphs embedded in a surface, is introduced in this paper #REFR, providing additional context for the study of graphs embedded in a fixed surface.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The approach used in this manuscript is based on a strong structural lemma for graphs embeddable in a fixed surface, which also implies that the size of a clique in the square of a graph of maximum degree $\\Delta$ embeddable in some fixed surface is at most $\\frac32\\,\\Delta$ plus a constant (#REFR). Moreover, the inequality J \u03bd (h \u03bd (g)/\u03b1, h \u03bd (s)) \u2265 1 holds for feasible solution m = h \u03bd (g)/\u03b1 due to the bilinearity of J \u03bd (#REFR).", "given_citation_intent": "background", "given_keywords": ["\u2265", "h \u03bd"]}]}
{"citing_id": "2304.05635v1", "cited_id": "1602.05629", "section_title": "Methodology", "citation": "As for the aggregation of the global model, we adopt the weighted averaging strategy in FedAvg #REFR . Site Contrastive based Channel Selection.", "text_before_citation": ["At round t, all sites receive the same parameters (\u03c6 t\u22121 g ,\u03b8 t\u22121 g ) from the server.", "The global part is initialized with \u03c6 t\u22121 g , and the personalized part is initialized with\u03b8 t k which is obtained from the AA module based on \u03b8 t\u22121 g and the local parameters from the previous round (e.g., \u03b8 t\u22121 k for site k).", "Each site updates its model by optimizing the local objective with its own data and its site encoding c k utilized in SCR", "EQUATION", "where GRD(\u2022) denotes the local gradient-based update."], "text_after_citation": ["Personalized FL paradigms may suffer from confusion or over-personalization when data heterogeneity is low, performing even worse than traditional FL methods #OTHEREFR .", "Hence, the SCR module is designed to enhance the distance/contrast of inter-site data representations through site-contrastive learning based channel attention, which in turn facilitates personalization.", "Specifically, taking the k-th site as an example, a one-hot site encoding c k (i.e., the k-th position is 1 and others are 0) and the output feature f k from the encoder F e are given.", "c k is expanded to a length of C through two fully connected layers to obtain c * k , which is then concatenated with the global average pooled feature of f k .", "After passing through a fully connected layer with Sigmoid activation, the site channel attention value\u0109 k is obtained."], "citing_paper_content": {"title": "Unifying And Personalizing Weakly-Supervised Federated Medical Image Segmentation Via Adaptive Representation And Aggregation", "abstract": "Federated learning (FL) enables multiple sites to collaboratively train powerful deep models without compromising data privacy and security. The statistical heterogeneity (e.g., non-IID data and domain shifts) is a primary obstacle in FL, impairing the generalization performance of the global model. Weakly supervised segmentation, which uses sparsely-grained (i.e., point-, bounding box-, scribble-, block-wise) supervision, is increasingly being paid attention to due to its great potential of reducing annotation costs. However, there may exist label heterogeneity, i.e., different annotation forms across sites. In this paper, we propose a novel personalized FL framework for medical image segmentation, named FedICRA, which uniformly leverages heterogeneous weak supervision via adaptIve Contrastive Representation and Aggregation. Concretely, to facilitate personalized modeling and to avoid confusion, a channel selection based site contrastive representation module is employed to adaptively cluster intra-site embeddings and separate inter-site ones. To effectively integrate the common knowledge from the global model with the unique knowledge from each local model, an adaptive aggregation module is applied for updating and initializing local models at the element level. Additionally, a weakly supervised objective function that leverages a multiscale tree energy loss and a gated CRF loss is employed to generate more precise pseudo-labels and further boost the segmentation performance. Through extensive experiments on two distinct medical image segmentation tasks of different modalities, the proposed FedICRA demonstrates overwhelming performance over other state-ofthe-art personalized FL methods. Its performance even approaches that of fully supervised training on centralized data. Our code and data are available at https://github.com/llmir/FedICRA."}, "cited_paper_content": {"title": "Communication-Efficient Learning Of Deep Networks From Decentralized Data", "abstract": "Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent."}, "keywords": ["Contrastive based Channel", "aggregation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To facilitate personalized modeling and avoid confusion, FedICRA employs a channel selection based site contrastive representation module to adaptively cluster intra-site embeddings and separate inter-site ones, and an adaptive aggregation module is applied for updating and initializing local models at the element level #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To update and initialize local models in a personalized federated learning framework, an adaptive aggregation module is applied at the element level, as proposed in FedICRA #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To adaptively cluster intra-site embeddings and separate inter-site ones, a channel selection based site contrastive representation module is employed in the personalized Federated Learning framework proposed by FedICRA #REFR, which also applies an adaptive aggregation module for updating and initializing local models at the element level.", "given_citation_intent": "method", "given_keywords": ["Contrastive based Channel", "aggregation"]}]}
{"citing_id": "2304.05599v1", "cited_id": "1612.00552", "section_title": "I. Introduction", "citation": "In this regard, nonorthogonal multiple access (NOMA) is seen as a strong candidate for IoT networks #REFR since it allows multiple devices to share the same resource blocks by splitting them into the power domain.", "text_before_citation": ["For instance, in 5G new radio (NR) standards #OTHEREFR , with a 20 MHz bandwidth (i.e., maximum bandwidth in LTE legacy ), a maximum number of 92 RBs 1 can be allocated to users within a subframe.", "However, in massive IoT applications (e.g., smart agriculture), thousands of sensor or control nodes may require wireless access.", "In these cases, whether we need more bandwidth, that is costly or more complex resource allocation (RB scheduling algorithms in layer 2) solutions are required.", "Therefore, it is not possible to allocate each IoT device to an orthogonal resource to avoid interference, since a massive number of devices need to be served in small, dense areas.", "For this reason, more than one IoT devices should share a resource block to enable mMTC."], "text_after_citation": ["In this way, the spectral efficiency of the network increases and it becomes possible to serve multiple devices with the number of more than the available resource blocks #OTHEREFR .", "Accordingly, NOMA is seen as an enabler for ultra-dense networks, and tremendous efforts have been devoted to integrating NOMA in IoT applications #OTHEREFR - #OTHEREFR ."], "citing_paper_content": {"title": "Bit-Interleaved Multiple Access: Improved Fairness, Reliability, And Latency For Massive Iot Networks", "abstract": "Internet-of-Things (IoT) networks require massive connections in dense areas. Therefore, a resource efficient multiple access scheme seems inevitable to enable immense connectivity where multiple devices have to share the same resource block. Non-orthogonal multiple access (NOMA) has been considered as the strongest candidate in recent years. However, in this paper, by considering the practical implementation, we first provide a true power allocation (PA) constraint with finite alphabet inputs for conventional downlink NOMA and demonstrate that it cannot support massive connections in practical systems. To this end, we propose bit-interleaved multiple access (BIMA) scheme in downlink IoT networks. The proposed BIMA scheme implements bitwise multiaccess interleaving and deinterleaving at the transceiver ends and there are no strict PA constraints, unlike conventional NOMA, thus allowing a high number of devices in the same resource block. We provide a comprehensive analytical framework for BIMA by investigating all key performance indicators (KPIs) to present both information-theoretic (i.e., ergodic capacity [EC] and outage probability [OP]) and finite alphabet inputs (i.e., bit error rate [BER]) performance metrics with both instantaneous and statistical channel ordering. In addition, we define Jain's fairness index and proportional fairness index in terms of all KPIs. Based on the extensive computer simulations, we reveal that BIMA outperforms conventional NOMA significantly, with a performance gain of up to 20-30 dB in terms of KPIs in some scenarios. In other words, compared to conventional NOMA schemes, the same KPIs are met in BIMA with 20-30 dB less transmit power, which is quite promising for energy-limited use cases. Moreover, this performance gain becomes greater when more IoT devices are supported. BIMA provides a full diversity order for all IoT devices and enables the implementation of an arbitrary number of devices and modulation orders, which is crucial for IoT networks where a huge number of devices should be supported in a single resource block in dense areas. In addition to the overall performance gain, BIMA guarantees a fairness system where none of the devices gets a severely degraded performance and the sum-rate is shared in a fair manner among devices. It guarantees QoS satisfaction for all devices. Finally, we provide an intense complexity and latency analysis for BIMA and demonstrate that it provides lower latency compared to conventional NOMA receivers, since it allows parallel computation at the receivers and no iterative operations are required. We show that compared to conventional NOMA receivers, BIMA reduces latency by up to 350% for specific IoT devices and 170% on average."}, "cited_paper_content": {"title": "Massive Non-Orthogonal Multiple Access For Cellular Iot: Potentials And Limitations", "abstract": "The Internet of Things promises ubiquitous connectivity of everything everywhere, which represents the biggest technology trend in the years to come. It is expected that by 2020 over 25 billion devices will be connected to cellular networks; far beyond the number of devices in current wireless networks. Machine-to-machine communications aims to provide the communication infrastructure for enabling IoT by facilitating the billions of multi-role devices to communicate with each other and with the underlying data transport infrastructure without, or with little, human intervention. Providing this infrastructure will require a dramatic shift from the current protocols mostly designed for human-to-human applications. This article reviews recent 3GPP solutions for enabling massive cellular IoT and investigates the random access strategies for M2M communications, which shows that cellular networks must evolve to handle the new ways in which devices will connect and communicate with the system. A massive non-orthogonal multiple access technique is then presented as a promising solution to support a massive number of IoT devices in cellular networks, where we also identify its practical challenges and future research directions."}, "keywords": ["IoT networks", "nonorthogonal multiple access"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For this reason, more than one IoT devices should share a resource block to enable mMTC, as proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enable massive connectivity in small, dense areas, it is necessary to share a resource block among multiple IoT devices, and a promising solution is the massive non-orthogonal multiple access technique proposed in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enable massive connectivity in small, dense areas, non-orthogonal multiple access (NOMA) has been considered as a strong candidate for IoT networks #REFR, where more than one IoT device should share a resource block to enable mMTC.", "given_citation_intent": "background", "given_keywords": ["IoT networks", "nonorthogonal multiple access"]}]}
{"citing_id": "2304.08851v1", "cited_id": "1205.2618", "section_title": "Model Optimization", "citation": "Since a ranked list of top-K items is required in both stages, Bayesian Personalized Ranking (BPR) #REFR pairwise learning is adopted to optimize the parameters of PEGA.", "text_before_citation": ["We leverage a two-stage training strategy to alleviate the sparsity issue of group-item interaction."], "text_after_citation": ["BPR pairwise learning aims to maximize the score difference between positive and negative items.", "Specifically, we obtain the user and the item embeddings by minimizing the user-level BPR pairwise loss L :", "EQUATION", "where O is the set of user training instances.", "Each instance , , contains a positive item that the user has interacted with and a negative item that the user hasn't interacted with yet."], "citing_paper_content": {"title": "Pega: Personality-Guided Preference Aggregator For Ephemeral Group Recommendation", "abstract": "Recently, making recommendations for ephemeral groups which contain dynamic users and few historic interactions have received an increasing number of attention. The main challenge of ephemeral group recommender is how to aggregate individual preferences to represent the group's overall preference. Score aggregation and preference aggregation are two commonly-used methods that adopt hand-craft predefined strategies and data-driven strategies, respectively. However, they neglect to take into account the importance of the individual inherent factors such as personality in the group. In addition, they fail to work well due to a small number of interactive records. To address these issues, we propose a Personality-Guided Preference Aggregator (PEGA) for ephemeral group recommendation. Concretely, we first adopt hyper-rectangle to define the concept of Group Personality. We then use the personality attention mechanism to aggregate group preferences. The role of personality in our approach is twofold: (1) To estimate individual users' importance in a group and provide explainability; (2) to alleviate the data sparsity issue that occurred in ephemeral groups. The experimental results demonstrate that our model significantly outperforms the state-of-the-art methods w.r.t. the score of both Recall and NDCG on Amazon and Yelp datasets. CCS CONCEPTS \u2022 Information systems \u2192 Recommender systems; \u2022 Computing methodologies \u2192 Neural networks."}, "cited_paper_content": {"title": "Bpr: Bayesian Personalized Ranking From Implicit Feedback", "abstract": "Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion."}, "keywords": ["ranked list"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We leverage a two-stage training strategy to alleviate the sparsity issue of group-item interaction, following the Bayesian Personalized Ranking (BPR) optimization criterion proposed by Rendle et al. in their paper \"Bpr: Bayesian Personalized Ranking From Implicit Feedback\". #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To alleviate the sparsity issue of group-item interaction, we leverage a two-stage training strategy and adopt a generic optimization criterion BPR-Opt for personalized ranking from implicit feedback, which outperforms the standard learning techniques for matrix factorization and adaptive kNN in terms of personalized ranking. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the personalized ranking of a group's overall preference, we propose a Bayesian Personalized Ranking (BPR) method that outperforms standard learning techniques for matrix factorization and adaptive kNN, as shown in #REFR, which is particularly important for generating accurate ranked lists in the context of ephemeral group recommendation.", "given_citation_intent": "method", "given_keywords": ["ranked list"]}]}
{"citing_id": "2304.04874v1", "cited_id": "1502.01852", "section_title": "Implementation Details", "citation": "We train our prompt-based image captioner for 40 epochs from scratch, using the weight initialization strategy described in #REFR .", "text_before_citation": ["-Network and Training Configuration.", "We explore two different prompt-based image captioning models, i.e., SAT #OTHEREFR and GRIT #OTHEREFR to act as classifiers.", "To train our promptbased image captioner, we split the original validation set, around 10 4 images, into training, validation, and testing sets, i.e., 70%, 10%, and 20%, respectively. These splits are balanced based on the protected attribute.", "All captioning models are trained using the same training configurations mentioned in #OTHEREFR .", "The added template T is \"Therefore, the gender is [Answer]\", \"Therefore, The race is [Answer]\" and \"Therefore, the emotion is [Answer]\" for gender, race, and emotions, respectively."], "text_after_citation": ["Adam optimizer #OTHEREFR and mini-batch size of 128 are used for training all our models.", "-Software and Hardware Details.", "Our metric is implemented in Python using the PyTorch framework. All experiments are conducted using four NVIDIA V100 GPUs.", "#OTHEREFR 8.6 (5) 2.9 (5) 6.29 (8) 2.30 (5) Att2in #OTHEREFR 7.6 (4) 1.1 (3) 6.17 (6) 2.78 (6) UpDn #OTHEREFR 9.0 (7) 4.7 (6) 6.64 (9) 2.82 (7) Trans. #OTHEREFR 8.7 (6) 5.9 (8) 6.19 7"], "citing_paper_content": {"title": "Imagecaptioner 2 : Image Captioner For Image Captioning Bias Amplification Assessment", "abstract": "Most pre-trained learning systems are known to suffer from bias, which typically emerges from the data, the model, or both. Measuring and quantifying bias and its sources is a challenging task and has been extensively studied in image captioning. Despite the significant effort in this direction, we observed that existing metrics lack consistency in the inclusion of the visual signal. In this paper, we introduce a new bias assessment metric, dubbed ImageCaptioner 2 , for image captioning. Instead of measuring the absolute bias in the model or the data, ImageCaptioner 2 pay more attention to the bias introduced by the model w.r.t the data bias, termed bias amplification. Unlike the existing methods, which only evaluate the image captioning algorithms based on the generated captions only, ImageCaptioner 2 incorporates the image while measuring the bias. In addition, we design a formulation for measuring the bias of generated captions as promptbased image captioning instead of using language classifiers. Finally, we apply our ImageCaptioner 2 metric across 11 different image captioning architectures on three different datasets, i.e., MS-COCO caption dataset, Artemis V1, and Artemis V2, and on three different protected attributes, i.e., gender, race, and emotions. Consequently, we verify the effectiveness of our ImageCaptioner 2 metric by proposing AnonymousBench, which is a novel human evaluation paradigm for bias metrics. Our metric shows significant superiority over the recent bias metric; LIC, in terms of human alignment, where the correlation scores are 80% and 54% for our metric and LIC, respectively. The code is available at https://eslambakr.github.io/imagecaptioner2.github.io/. Recent efforts focus on estimating model bias, driven by the fact that more than balanced data is needed to create"}, "cited_paper_content": {"title": "Delving Deep Into Rectifiers: Surpassing Human-Level Performance On Imagenet Classification", "abstract": "Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset."}, "keywords": ["prompt-based image captioner", "40 epochs"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To train our prompt-based image captioner, we split the original validation set, around 10 4 images, into training, validation, and testing sets, i.e., 70%, 10%, and 20%, respectively. All captioning models are trained using the same training configurations mentioned in #OTHEREFR. We propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit and achieves 4.94% top-5 test error on the ImageNet 2012 classification dataset, surpassing the reported human-level performance on this dataset (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To measure the bias introduced by the model with respect to the data bias, we used a new bias assessment metric called ImageCaptioner 2, which incorporates the image while measuring the bias and is based on prompt-based image captioning instead of using language classifiers #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We train our prompt-based image captioner using the same training configurations mentioned in #OTHEREFR for 40 epochs, and we refer to the method proposed in Delving Deep Into Rectifiers: Surpassing Human-Level Performance On Imagenet Classification for the initialization of our extremely deep rectified models. #REFR", "given_citation_intent": "method", "given_keywords": ["prompt-based image captioner", "40 epochs"]}]}
{"citing_id": "2303.11934v1", "cited_id": "1803.03635", "section_title": "C.2 Optimized Top-K", "citation": "There is evidence that artificial neural networks are overparameterized at the start of training and functionally sparse, as supported by results from network pruning, most notably the Lottery Ticket Hypothesis #REFR .", "text_before_citation": ["This is because the ReLU MLP is not constrained to the data manifold, having a bias term and no L 2 normalization.", "This allows it to learn weights and biases that better maximize NCL validation accuracy.", "If we perform joint training of the ConvMixer and SDM module then the ConvMixer can learn to create a manifold for SDM to tile that does maximize validation accuracy, performing on par with the ReLU MLP.", "This is what happens in a test where we train on the whole CIFAR10 dataset in the NCL setting, as long as k \u2265 250, but independent of if there are 1,000 or 10,000 neurons in the SDM layer. This result is shown in Fig.", "14a and suggests that the ReLU network only needs at least 250 neurons in its final layer to backpropagate gradients and achieve high prediction accuracy."], "text_after_citation": ["However, this result is again manifold dependent whereby training instead on ImageNet32, even with k = 2, 500 and 10,000 neurons still harms performance compared to a ReLU network.", "We believe this is because ImageNet32 has a dramatically more complex data manifold with \u223c 1.2M images from 1,000 different classes, compared to 50,000 images in 10 classes for CIFAR10.", "This means that even a k of 2500 is too small and harms the model's representational capacity.", "Figure 14 : Sufficiently small k values harm network training.", "ConvMixers with an SDM layer at the end trained on CIFAR10."], "citing_paper_content": {"title": "Sparse Distributed Memory Is A Continual Learner", "abstract": "Continual learning is a problem for artificial neural networks that their biological counterparts are adept at solving. Building on work using Sparse Distributed Memory (SDM) to connect a core neural circuit with the powerful Transformer model, we create a modified Multi-Layered Perceptron (MLP) that is a strong continual learner. We find that every component of our MLP variant translated from biology is necessary for continual learning. Our solution is also free from any memory replay or task information, and introduces novel methods to train sparse networks that may be broadly applicable."}, "cited_paper_content": {"title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "abstract": "Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard technique for pruning weights naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the\"lottery ticket hypothesis\": dense, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that - when trained in isolation - arrive at comparable test accuracy in a comparable number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Furthermore, the winning tickets we find above that size learn faster than the original network and exhibit higher test accuracy."}, "keywords": ["artificial neural networks", "network pruning"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "This is consistent with the findings of the Lottery Ticket Hypothesis, which suggest that dense, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that - when trained in isolation - arrive at comparable test accuracy in a comparable number of iterations. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This result is shown in Fig. 14a and suggests that the ReLU network only needs at least 250 neurons in its final layer to backpropagate gradients and achieve high prediction accuracy, as demonstrated in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This result is shown in Fig. 14a and suggests that the ReLU network only needs at least 250 neurons in its final layer to backpropagate gradients and achieve high prediction accuracy, as demonstrated in the reference paper on network pruning and artificial neural networks by Frankle and Carbin (#REFR).", "given_citation_intent": "result", "given_keywords": ["artificial neural networks", "network pruning"]}]}
{"citing_id": "2303.09905v1", "cited_id": "1802.01886", "section_title": "Synthetic Schema Generation", "citation": "Furthermore, self-BLEU #REFR scores indicate EDA is the least effective in ensuring candidate diversity compared to other approaches.", "text_before_citation": ["Our ranking method generates increasingly lexically diverse schemata as shown by the increase in Jaccard distance across schema variants (Table 1) .", "This aspect is much more difficult to achieve with EDA without significantly affecting semantics."], "text_after_citation": ["The BLEU difference between the SGD-X variants v1 and v5 is 15.2 but smaller (0.66) for our approach.", "Hence, the PEGASUS + BART copies n-grams from the input and includes additional information.", "This information is not always meaning-preserving: City where the event is happening is paraphrased as The bustling city where the event is taking place (v5) but End date for the reservation or to find the house is paraphrased as End date for hotel reservation to allow time for a replacement both at the struck and in the run up to the event (v5).", "The self-BLEU of the SGD-X schemas decreases faster compared to the automatically generated paraphrases, suggesting that Jaccard distance increases partly due to hallucination.", "Entailment scores show that backtranslation is effective in preserving semantics."], "citing_paper_content": {"title": "More Robust Schema-Guided Dialogue State Tracking Via Tree-Based Paraphrase Ranking", "abstract": "The schema-guided paradigm overcomes scalability issues inherent in building task-oriented dialogue (TOD) agents with static ontologies. Instead of operating on dialogue context alone, agents have access to hierarchical schemas containing task-relevant natural language descriptions. Fine-tuned language models excel at schema-guided dialogue state tracking (DST) but are sensitive to the writing style of the schemas. We explore methods for improving the robustness of DST models. We propose a framework 1 for generating synthetic schemas which uses tree-based ranking to jointly optimise lexical diversity and semantic faithfulness. The generalisation of strong baselines is improved when augmenting their training data with prompts generated by our framework, as demonstrated by marked improvements in average joint goal accuracy (JGA) and schema sensitivity (SS) on the SGD-X benchmark."}, "cited_paper_content": {"title": "Texygen: A Benchmarking Platform For Text Generation Models", "abstract": "We introduce Texygen, a benchmarking platform to support research on open-domain text generation models. Texygen has not only implemented a majority of text generation models, but also covered a set of metrics that evaluate the diversity, the quality and the consistency of the generated texts. The Texygen platform could help standardize the research on text generation and facilitate the sharing of fine-tuned open-source implementations among researchers for their work. As a consequence, this would help in improving the reproductivity and reliability of future research work in text generation."}, "keywords": ["candidate diversity"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our framework for generating synthetic schemas, which uses tree-based ranking to jointly optimize lexical diversity and semantic faithfulness, is inspired by Texygen, a benchmarking platform for text generation models that covers a set of metrics to evaluate the diversity, quality, and consistency of generated texts. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed framework for generating synthetic schemas, which uses tree-based ranking to jointly optimize lexical diversity and semantic faithfulness, demonstrates marked improvements in average joint goal accuracy and schema sensitivity on the SGD-X benchmark when augmenting training data with prompts generated by our method compared to the baselines, as shown in Table 1. This highlights the effectiveness of our approach in improving the robustness of DST models, and is in line with the goal of standardizing research on text generation models as proposed by Texygen #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our framework for generating synthetic schemas improves the lexically diverse candidate diversity of the schemata, as demonstrated by the marked improvements in average joint goal accuracy and schema sensitivity on the SGD-X benchmark when augmenting the training data with prompts generated by our method compared to the baselines (#REFR).", "given_citation_intent": "result", "given_keywords": ["candidate diversity"]}]}
{"citing_id": "2304.11029v1", "cited_id": "1910.01108", "section_title": "Pre-Training", "citation": "Before pre-training, the text encoder was initialized using DistilRoBERTa #REFR , with a maximum length of 128, and the music encoder was initialized using two settings: M3-S/512 and M3-S/1024.", "text_before_citation": [], "text_after_citation": ["Both models were trained for 40 epochs on WebMT with 6 encoder layers and 3 decoder layers, an embedding size of 768, and a mask ratio of 45%.", "Based on these two M3 encoders, we developed CLaMP-S/512 and CLaMP-S/1024.", "Both of them were trained for 20 epochs, using the AdamW optimizer #OTHEREFR with \u03b2 1 = 0.9, \u03b2 2 = 0.999, = 10 \u22128 , and a weight decay coefficient of 0.01.", "The batch size is set to 640, and the temperature \u03c4 = 0.2.", "The training process was accelerated and memory was saved by using mixed precision #OTHEREFR ."], "citing_paper_content": {"title": "Clamp: Contrastive Language-Music Pre-Training For Cross-Modal Symbolic Music Information Retrieval", "abstract": "We introduce CLaMP 1 : Contrastive Language-Music Pre-training, which learns cross-modal representations between natural language and symbolic music using a music encoder and a text encoder trained jointly with a contrastive loss. To pre-train CLaMP, we collected a large dataset of 1.4 million music-text pairs. It employed text dropout as a data augmentation technique and bar patching to efficiently represent music data which reduces sequence length to less than 10%. In addition, we developed a masked music model pre-training objective to enhance the music encoder's comprehension of musical context and structure. CLaMP integrates textual information to enable semantic search and zero-shot classification for symbolic music, surpassing the capabilities of previous models. To support the evaluation of semantic search and music classification, we publicly release WikiMusicText (WikiMT), a dataset of 1010 lead sheets in ABC notation, each accompanied by a title, artist, genre, and description. In comparison to state-of-the-art models that require fine-tuning, zero-shot CLaMP demonstrated comparable or superior performance on score-oriented datasets."}, "cited_paper_content": {"title": "Distilbert, A Distilled Version Of Bert: Smaller, Faster, Cheaper And Lighter", "abstract": "As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study."}, "keywords": ["music encoder", "text encoder"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To pre-train CLaMP, the authors employed a masked music model pre-training objective to enhance the music encoder's comprehension of musical context and structure, as well as a contrastive loss to learn cross-modal representations between natural language and symbolic music using a music encoder and a text encoder trained jointly. They also collected a large dataset of 1.4 million music-text pairs and employed text dropout as a data augmentation technique and bar patching to efficiently represent music data. In addition, the authors publicly released WikiMusicText (WikiMT), a dataset of 1010 lead sheets in ABC notation, each accompanied by a title, artist, genre, and description, to support the evaluation of semantic search and music classification. #REFR's method of pre-training a smaller general-purpose language representation model, called DistilBERT, using knowledge distillation during the pre-training phase to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster, could be applied to CLaMP's pre-training process.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To pre-train their CLaMP model, the authors employed a triple loss combining language modeling, distillation, and cosine-distance losses, as proposed in the DistilBERT paper by Sanh et al. (2019). #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To pre-train their CLaMP model, the authors employed a music encoder and a text encoder trained jointly with a contrastive loss, as described in the method proposed by Sanh et al. in DistilBERT, which leverages knowledge distillation during the pre-training phase to reduce the size of a BERT model by 40% while retaining 97% of its language understanding capabilities and being 60% faster, and achieved superior performance on score-oriented datasets. #REFR", "given_citation_intent": "method", "given_keywords": ["music encoder", "text encoder"]}]}
{"citing_id": "2304.10343v1", "cited_id": "1904.04097", "section_title": "Introduction", "citation": "SOGATs correspond to the class of theories classified by representable map categories, which were introduced by Uemura #REFR .", "text_before_citation": ["This kind of approach does not seem suitable for the coherence theorems that we are interested in.", "The main result of this paper is a coherence theorem for type theories that is analogous to the fact the statement (1) can be deduced from the statement (2).", "It states that to establish the conservativity of the equational extension T \u2192 T E , it suffices to check that the \u221e-congruence over T freely generated by the equations of E exists and is 0-truncated.", "This 0-truncatedness condition encodes the same idea as the fact that every diagram made up of associators and unitors commutes in a freely generated monoidal category.", "In general, we work at the level of second-order generalized algebraic theories (SOGATs) and their classifying (\u03a3, \u03a0 rep )-CwFs."], "text_after_citation": ["First-order generalized algebraic theories are also SOGATs, so our results also apply to theories that are not type theories, such as monoidal categories, etc.", "A SOGAT T is specified by its classifying (\u03a3, \u03a0 rep )-CwF, also denoted by T , which can be seen as a syntactic model of some type theory.", "A SOGAT has functorial semantics in (\u03a3, \u03a0 rep )-CwFs.", "Even if one is only interested in a specific theory, working with SOGATs explicitly is advantageous.", "Indeed, many semantic conditions can instead be stated more concisely and syntactically directly at the level of the (\u03a3, \u03a0 rep )-CwF T ."], "citing_paper_content": {"title": "Towards Coherence Theorems For Equational Extensions Of Type Theories", "abstract": "We study the conservativity of extensions by additional strict equalities of dependent type theories (and more general second-order generalized algebraic theories). The conservativity of Extensional Type Theory over Intensional Type Theory was proven by Hofmann. Our goal is to generalize such results to type theories without the Uniqueness of Identity Proofs principles, such as variants of Homotopy Type Theory. For this purpose, we construct what is essentially the \u221e-congruence on the base theory that is freely generated by the considered equations. This induces a factorization of any equational extension, whose two factors can be studied independently. We conjecture that the first factor is always an equivalence when the base theory is well-behaved. We prove that the second factor is an equivalence when the \u221e-congruence is 0-truncated."}, "cited_paper_content": {"title": "A General Framework For The Semantics Of Type Theory", "abstract": "We propose an abstract notion of a type theory to unify the semantics of various type theories including Martin-Lof type theory, two-level type theory and cubical type theory. We establish basic results in the semantics of type theory: every type theory has a bi-initial model; every model of a type theory has its internal language; the category of theories over a type theory is bi-equivalent to a full sub-2-category of the 2-category of models of the type theory."}, "keywords": ["representable map categories"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To establish the conservativity of the equational extension T \u2192 T E, it suffices to check that the \u221e-congruence over T freely generated by the equations of E exists and is 0-truncated, which encodes the same idea as the fact that every diagram made up of associators and unitors commutes in a freely generated monoidal category. This approach is analogous to the one proposed in the reference paper #REFR, which proposes a unified framework for the semantics of various type theories.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' proposal of an abstract notion of a type theory to unify the semantics of various type theories, including Martin-Lof type theory, two-level type theory, and cubical type theory, provides valuable background information for our study on the conservativity of extensions by additional strict equalities of dependent type theories. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To unify the semantics of various type theories, including Martin-Lof type theory and cubical type theory, an abstract notion of a type theory was proposed in the reference paper #REFR, which could be relevant to the study of representable map categories in second-order generalized algebraic theories.", "given_citation_intent": "background", "given_keywords": ["representable map categories"]}]}
{"citing_id": "2303.06840v1", "cited_id": "1401.0166", "section_title": "Introduction", "citation": "While MIF can assist in diagnosis and treatment by fusing multiple medical imaging modalities for precise detection of abnormality locations #REFR .", "text_before_citation": ["Image fusion integrates essential information from multiple source images to create high-quality fused images #OTHEREFR , encompassing various source image types like digital #OTHEREFR , multi-modal #OTHEREFR , and remote sensing #OTHEREFR .", "This technology provides a clearer representation of objects and scenes, and has diverse applications such as saliency detection #OTHEREFR , object detection #OTHEREFR , and semantic segmentation #OTHEREFR .", "Among the different subcategories of image fusion, Infrared-Visible image Fusion (IVF) and Medical Image Fusion (MIF) are particularly challenging in Multi-Modality Image Fusion (MMIF) since they focus on modeling crossmodality features and preserving critical information from Figure 2 : DDFM (marked in yellow) outperforms all other methods on MSRS #OTHEREFR and RoadScene #OTHEREFR across six metrics. all sensors and modalities.", "Specifically, in IVF, fused images aim to retain both thermal radiation from infrared images and detailed texture information from visible images, thereby avoiding the limitations of visible images being sensitive to illumination conditions and infrared images being noisy and low-resolution."], "text_after_citation": ["There have been numerous methods devised recently to address the challenges posed by MMIF #OTHEREFR , and generative models #OTHEREFR have been extensively utilized to model the distribution of fused images and achieve satisfactory fusion effects.", "Among them, models based on Generative Adversarial Networks (GANs) #OTHEREFR are dominant. The workflow of GAN-based models, illustrated in Fig.", "1a , involves a generator that creates images containing information from source images, and a discriminator that determines whether the generated images are in a similar manifold to the source images.", "Although GAN-based methods have the ability to generate high-quality fused images, they suffer from unstable training, lack of interpretability and mode collapse, which seriously affect the quality of the generated samples.", "Moreover, as a black-box model, it is difficult to comprehend the internal mechanisms and behaviors of GANs, making it challenging to achieve controllable generation."], "citing_paper_content": {"title": "Ddfm: Denoising Diffusion Model For Multi-Modality Image Fusion", "abstract": "Multi-modality image fusion aims to combine different modalities to produce fused images that retain the complementary features of each modality, such as functional highlights and texture details. To leverage strong generative priors and address challenges such as unstable training and lack of interpretability for GAN-based generative methods, we propose a novel fusion algorithm based on the denoising diffusion probabilistic model (DDPM). The fusion task is formulated as a conditional generation problem under the DDPM sampling framework, which is further divided into an unconditional generation subproblem and a maximum likelihood subproblem. The latter is modeled in a hierarchical Bayesian manner with latent variables and inferred by the expectation-maximization algorithm. By integrating the inference solution into the diffusion sampling iteration, our method can generate high-quality fused images with natural image generative priors and cross-modality information from source images. Note that all we required is an unconditional pre-trained generative model, and no fine-tuning is needed. Our extensive experiments indicate that our approach yields promising fusion results in infrared-visible image fusion and medical image fusion. The code will be released."}, "cited_paper_content": {"title": "Medical Image Fusion: A Survey Of The State Of The Art", "abstract": "Medical image fusion is the process of registering and combining multiple images from single or multiple imaging modalities to improve the imaging quality and reduce randomness and redundancy in order to increase the clinical applicability of medical images for diagnosis and assessment of medical problems. Multi-modal medical image fusion algorithms and devices have shown notable achievements in improving clinical accuracy of decisions based on medical images. This review article provides a factual listing of methods and summarizes the broad scientific challenges faced in the field of medical image fusion. We characterize the medical image fusion research based on (1) the widely used image fusion methods, (2) imaging modalities, and (3) imaging of organs that are under study. This review concludes that even though there exists several open ended technological and scientific challenges, the fusion of medical images has proved to be useful for advancing the clinical reliability of using medical imaging for medical diagnostics and analysis, and is a scientific discipline that has the potential to significantly grow in the coming years."}, "keywords": ["multiple medical imaging"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Medical image fusion has shown notable achievements in improving clinical accuracy of decisions based on medical images, and is a scientific discipline that has the potential to significantly grow in the coming years #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Medical image fusion has been widely used to improve the clinical applicability of medical images for diagnosis and assessment of medical problems, and this review article provides a factual listing of methods and summarizes the broad scientific challenges faced in the field of medical image fusion #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Multiple medical imaging modalities can be combined to improve the quality and clinical applicability of medical images, and medical image fusion algorithms have shown notable achievements in this regard #REFR.", "given_citation_intent": "background", "given_keywords": ["multiple medical imaging"]}]}
{"citing_id": "2305.02398v1", "cited_id": "1911.11763", "section_title": "Ii. Related Work", "citation": "In our approach, inspired by SuperGlue #REFR , we further process individual object embeddings in a graph neural network which relates objects within images and across images to encode image context.", "text_before_citation": ["of object bounding boxes into feature vectors which are used to measure similarity of detected objects between views using cosine similarity.", "In Associative3D #OTHEREFR , also feature embeddings per objects are learned which are used to match objects between views.", "Both #OTHEREFR and #OTHEREFR leverage semantic and spatial information for finding 3D correspondences.", "Recently, #OTHEREFR propose to use human models to estimate correspondences among wide-baseline view changes.", "Different to object associations, keypoint matching methods yield local image correspondences between pairs of images for moderate view point changes #OTHEREFR , #OTHEREFR , #OTHEREFR ."], "text_after_citation": ["Our approach can be an alternative or complementary approach for matching objects across views to geometric or keypoint-based approaches."], "citing_paper_content": {"title": "Learning-Based Relational Object Matching Across Views", "abstract": "Intelligent robots require object-level scene understanding to reason about possible tasks and interactions with the environment. Moreover, many perception tasks such as scene reconstruction, image retrieval, or place recognition can benefit from reasoning on the level of objects. While keypoint-based matching can yield strong results for finding correspondences for images with small to medium view point changes, for large view point changes, matching semantically on the object-level becomes advantageous. In this paper, we propose a learningbased approach which combines local keypoints with novel object-level features for matching object detections between RGB images. We train our object-level matching features based on appearance and inter-frame and cross-frame spatial relations between objects in an associative graph neural network. We demonstrate our approach in a large variety of views on realistically rendered synthetic images. Our approach compares favorably to previous state-of-the-art object-level matching approaches and achieves improved performance over a pure keypoint-based approach for large viewpoint changes."}, "cited_paper_content": {"title": "Superglue: Learning Feature Matching With Graph Neural Networks", "abstract": "This paper introduces SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points. Assignments are estimated by solving a differentiable optimal transport problem, whose costs are predicted by a graph neural network. We introduce a flexible context aggregation mechanism based on attention, enabling SuperGlue to reason about the underlying 3D scene and feature assignments jointly. Compared to traditional, hand-designed heuristics, our technique learns priors over geometric transformations and regularities of the 3D world through end-to-end training from image pairs. SuperGlue outperforms other learned approaches and achieves state-of-the-art results on the task of pose estimation in challenging real-world indoor and outdoor environments. The proposed method performs matching in real-time on a modern GPU and can be readily integrated into modern SfM or SLAM systems. The code and trained weights are publicly available at https://github.com/magicleap/SuperGluePretrainedNetwork."}, "keywords": ["individual object embeddings", "graph neural network"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Different to object associations, keypoint matching methods yield local image correspondences between pairs of images for moderate view point changes #REFR. The authors need to cite the reference paper \"Superglue: Learning Feature Matching With Graph Neural Networks\" which introduces a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Different to object associations, keypoint matching methods yield local image correspondences between pairs of images for moderate view point changes #OTHEREFR , #OTHEREFR , #OTHEREFR . For large view point changes, SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points, has been proposed #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In addition to object associations, recent methods such as Associative3D #OTHEREFR and #OTHEREFR leverage graph neural networks to learn individual object embeddings for finding 3D correspondences, which could be beneficial for large viewpoint changes. #REFR", "given_citation_intent": "method", "given_keywords": ["individual object embeddings", "graph neural network"]}]}
{"citing_id": "2303.06167v1", "cited_id": "1906.02659", "section_title": "Dollar Street And Coco. Applying This Insight From", "citation": "As expected, finetuning GeoDE achieves a higher accuracy (where a prediction is correct if the object is one of the top-5 predicted labels #REFR ) of 13.1% on Dollar Street compared to finetuning ImageNet with 8.4%.", "text_before_citation": ["CelebA that relatively minor manipulations to the proportion of the dataset from underrepresented subcategories can significantly impact the performance of those subcategories, we now turn to the more complex and realistic object datasets of Dollar Street and COCO.", "We consider the task of recognizing 15 objects in Dollar Street that have corresponding objects in COCO.", "Although the object classes are the same between datasets, their visual distribution is different as COCO images largely come from only higher-income regions #OTHEREFR whereas Dollar Street was collected to be more geographically diverse.", "Nevertheless COCO images are more plentiful; to simulate this, we consider a finetuning dataset of 128 images where 90% are from COCO and 10% from Dollar Street.", "We use two pretrained models, named after the dataset each is trained on: ImageNet #OTHEREFR , where the training data is more similar to the COCO distribution, and GeoDE #OTHEREFR , which is trained on a newer and more geographically diverse dataset."], "text_after_citation": ["However, what we ultimately want to investigate is how much investing in a better finetuning dataset can help overcome the problem (Fig. 6) .", "Thus, we manipulate the finetuning dataset (simulating the collection of more Dollar Street-like images, while keeping the overall finetuning number the same), and observe that with just 20% rather than 10% of images coming from Dollar Street, ImageNet is albe to outperform the performance of the GeoDE baseline with an accuracy of 21.7%."], "citing_paper_content": {"title": "Overcoming Bias In Pretrained Models By Manipulating The Finetuning Dataset", "abstract": "Transfer learning is beneficial by allowing the expressive features of models pretrained on large-scale datasets to be finetuned for the target task of smaller, more domainspecific datasets. However, there is a concern that these pretrained models may come with their own biases which would propagate into the finetuned model. In this work, we investigate bias when conceptualized as both spurious correlations between the target task and a sensitive attribute as well as underrepresentation of a particular group in the dataset. Under both notions of bias, we find that (1) models finetuned on top of pretrained models can indeed inherit their biases, but (2) this bias can be corrected for through relatively minor interventions to the finetuning dataset, and often with a negligible impact to performance. Our findings imply that careful curation of the finetuning dataset is important for reducing biases on a downstream task, and doing so can even compensate for bias in the pretrained model."}, "cited_paper_content": {"title": "Does Object Recognition Work For Everyone?", "abstract": "The paper analyzes the accuracy of publicly available object-recognition systems on a geographically diverse dataset. This dataset contains household items and was designed to have a more representative geographical coverage than commonly used image datasets in object recognition. We find that the systems perform relatively poorly on household items that commonly occur in countries with a low household income. Qualitative analyses suggest the drop in performance is primarily due to appearance differences within an object class (e.g., dish soap) and due to items appearing in a different context (e.g., toothbrushes appearing outside of bathrooms). The results of our study suggest that further work is needed to make object-recognition systems work equally well for people across different countries and income levels."}, "keywords": ["ImageNet"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Although the object classes are the same between datasets, their visual distribution is different as COCO images largely come from only higher-income regions. Nevertheless, COCO images are more plentiful; to simulate this, we consider a finetuning dataset of 128 images where 90% are from COCO and 10% from Dollar Street. We use two pretrained models, named after the dataset each is trained on: ImageNet, where the training data is more similar to the COCO distribution, and GeoDE, which is trained on a newer and more geographically diverse dataset. Further work is needed to make object-recognition systems work equally well for people across different countries and income levels #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The study by #REFR found that object-recognition systems perform relatively poorly on household items that commonly occur in countries with a low household income, which is consistent with our findings on Dollar Street dataset.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The results of our study on object recognition align with the findings in the reference paper #REFR, which also reported poor performance of object-recognition systems on household items from countries with a low household income, despite being trained on datasets such as ImageNet.", "given_citation_intent": "result", "given_keywords": ["ImageNet"]}]}
{"citing_id": "2303.02715v1", "cited_id": "1702.00758", "section_title": "Iv. Feature Type Transformations", "citation": "The term deep hashing has been coined as an umbrella term for methods which aim at extracting compact and stable representations with deep learning techniques #REFR .", "text_before_citation": ["A binary vector b of length nm can be transformed back to an integer vector q of length n by mapping consecutive chunks of m bits to their decimal representation.", "Further, b can be transformed to an integer set s of variable length.", "For instance, this feature set can consist of all indexes of 1s in the binary vector, s = {i|b i = 1} with b i \u2208 b.", "This feature type transformation has been successfully applied to feature vectors obtained by deep learning-based feature extractors, e.g. in #OTHEREFR . Compact, e.g.", "binary, representations (which additionally turn out to be beneficial for workload reduction in biometric identification systems #OTHEREFR ) can also be extracted by deep learning techniques."], "text_after_citation": ["If applied to biometric data, such methods would need to overcome intra-class variations.", "Consequently, a reliable extraction of stable feature vectors (deep hashes) would enable a subsequent application of conventional (and provable secure) cryptographic algorithms for the purpose of template protection.", "In the recent past, deep hashes have been extracted from different biometric characteristics in various ways, e.g. in #OTHEREFR - #OTHEREFR , including multi-biometrics #OTHEREFR .", "Most of the proposed schemes, however, are focusing on facial images and have been recently surveyed in #OTHEREFR .", "It is well-known that a single biometric characteristic, e.g."], "citing_paper_content": {"title": "Deep Learning In The Field Of Biometric Template Protection: An Overview", "abstract": "Today, deep learning represents the most popular and successful form of machine learning. Deep learning has revolutionised the field of pattern recognition, including biometric recognition. Biometric systems utilising deep learning have been shown to achieve auspicious recognition accuracy, surpassing human performance. Apart from said breakthrough advances in terms of biometric performance, the use of deep learning was reported to impact different covariates of biometrics such as algorithmic fairness, vulnerability to attacks, or template protection. Technologies of biometric template protection are designed to enable a secure and privacy-preserving deployment of biometrics. In the recent past, deep learning techniques have been frequently applied in biometric template protection systems for various purposes. This work provides an overview of how advances in deep learning take influence on the field of biometric template protection. The interrelation between improved biometric performance rates and security in biometric template protection is elaborated. Further, the use of deep learning for obtaining feature representations that are suitable for biometric template protection is discussed. Novel methods that apply deep learning to achieve various goals of biometric template protection are surveyed along with deep learning-based attacks."}, "cited_paper_content": {"title": "Hashnet: Deep Learning To Hash By Continuation", "abstract": "Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the ill-posed gradient difficulty in the optimization with sign activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This work presents HashNet, a novel deep architecture for deep learning to hash by continuation method with convergence guarantees, which learns exactly binary hash codes from imbalanced similarity data. The key idea is to attack the ill-posed gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks."}, "keywords": ["deep hashing"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Compact, e.g. binary, representations (which additionally turn out to be beneficial for workload reduction in biometric identification systems #OTHEREFR) can also be extracted by deep learning techniques, such as the HashNet method proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Compact representations, such as binary codes, can be obtained by deep learning techniques, which have been successfully applied to feature vectors in multimedia retrieval systems #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Deep learning techniques have been successfully applied to extract compact representations, such as binary vectors, which are beneficial for workload reduction in biometric identification systems, and can be obtained by deep hashing methods, as demonstrated in Hashnet: Deep Learning To Hash By Continuation (#REFR).", "given_citation_intent": "background", "given_keywords": ["deep hashing"]}]}
{"citing_id": "2303.15015v1", "cited_id": "1612.00410", "section_title": "Introduction", "citation": "Based on this assumption, we design a new message passing mechanism by resorting to information bottleneck #REFR to only propagate class-agnostic knowledge between nodes of different classes.", "text_before_citation": ["If simply applying these methods to graph-structured data by individually treating each node, the topological structure and the interaction between nodes will be ignored. Recently, #OTHEREFR", "(2020a) ; #OTHEREFR propose to overcome catastrophic forgetting for graph data.", "However, They focus on static graph snapshots, and utilize static GNN for each snapshot, thus largely ignoring fine-grained temporal topological information.", "In this paper, we put forward the first class-incremental learning approach towards open temporal dynamic graphs, called OTGNet.", "To mitigate the issue of heterophily propagation, we assume the information of a node can be disentangled into class-relevant and class-agnostic one."], "text_after_citation": ["In this way, we can well avoid transferring conflictive information.", "To prevent catastrophic knowledge forgetting over old classes, we propose to select representative sub-graph structures generated from old classes, and incorporate them into the learning process of new classes.", "Previous works #OTHEREFR point out triad structure (triangle-shape structure) is a fundamental element of temporal graph and can capture evolution patterns.", "Motivated by this, we devise a value function to select not only important but also diverse triad structures, and replay them for continual learning.", "Due to the combinational property, optimizing the value function is NP-hard."], "citing_paper_content": {"title": "Towards Open Temporal Graph Neural Net-Works", "abstract": "Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by. This will bring two big challenges to the existing temporal GNN methods: (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This case will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes. (ii) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information. Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines."}, "cited_paper_content": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method\"Deep Variational Information Bottleneck\", or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack."}, "keywords": ["class-agnostic knowledge", "information bottleneck"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "If simply applying these methods to graph-structured data by individually treating each node, the topological structure and the interaction between nodes will be ignored. Recently, #OTHEREFR (2020a) ; #OTHEREFR propose to overcome catastrophic forgetting for graph data. However, They focus on static graph snapshots, and utilize static GNN for each snapshot, thus largely ignoring fine-grained temporal topological information. In this paper, we put forward the first class-incremental learning approach towards open temporal dynamic graphs, called OTGNet. To mitigate the issue of heterophily propagation, we assume the information of a node can be disentangled into class-relevant and class-agnostic one. We leverage the reparameterization trick for efficient training and show that our method outperforms the baselines in terms of generalization performance and robustness to adversarial attack (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of catastrophic forgetting in open temporal dynamic graphs, the authors propose a new class-incremental learning approach called OTGNet, which disentangles the information of a node into class-relevant and class-agnostic one and leverages the information bottleneck principle to propagate only class-agnostic knowledge between nodes of different classes (#OTHEREFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of heterophily propagation in open temporal dynamic graphs, the authors propose a new message passing mechanism that disentangles the information of a node into class-relevant and #REFR[class-agnostic knowledge] one, and extends the #REFR[information bottleneck] principle to only propagate the latter between nodes of different classes, as demonstrated in the reference paper.", "given_citation_intent": "method", "given_keywords": ["class-agnostic knowledge", "information bottleneck"]}]}
{"citing_id": "2305.01072v1", "cited_id": "1601.04037", "section_title": "D. Re-Timing", "citation": "The re-timing problem #REFR is convex, since the objective is convex, the first constraint is linear, and the second constraint can be expressed as 2(N \u2212 1) linear inequalities.", "text_before_citation": ["Specifically, we limit the maximum change in adjacent scaling factors as |\u03b7 j+1 \u2212 \u03b7 j | \u2264 \u03ba, where \u03ba > 0.", "Overall, our re-timing problem is then", "minimize J 1 + J 2 subject to N j=1 \u03b7 j T j = T, |\u03b7 j+1 \u2212 \u03b7 j | \u2264 \u03ba, j = 1, . . . , N \u2212 1. (19)", "The variables are the factors \u03b7 1 , . . .", ", \u03b7 N , which are subject to the implicit constraint \u03b7 j > 0."], "text_after_citation": ["More precisely, it can be verified that problem #OTHEREFR is representable as an SOCP [39, \u00a72.3] .", "Given that this problem has only N variables and sparse structure, it can be solved extremely quickly.", "After solving problem #OTHEREFR previous times and path.", "Independently of the success of the iteration, we then decrease the value of \u03ba.", "This process is repeated until \u03ba becomes smaller than a fixed tolerance \u03b5 > 0."], "citing_paper_content": {"title": "Fast Path Planning Through Large Collections Of Safe Boxes", "abstract": "We present a fast algorithm for the design of smooth paths (or trajectories) that are constrained to lie in a collection of axis-aligned boxes. We consider the case where the number of these safe boxes is large, and basic preprocessing of them (such as finding their intersections) can be done offline. At runtime we quickly generate a smooth path between given initial and terminal positions. Our algorithm designs trajectories that are guaranteed to be safe at all times, and it detects infeasibility whenever such a trajectory does not exist. Our algorithm is based on two subproblems that we can solve very efficiently: finding a shortest path in a weighted graph, and solving (multiple) convex optimal control problems. We demonstrate the proposed path planner on large-scale numerical examples, and we provide an efficient open-source software implementation, fastpathplanning."}, "cited_paper_content": {"title": "Funnel Libraries For Real-Time Robust Feedback Motion Planning", "abstract": "We consider the problem of generating motion plans for a robot that are guaranteed to succeed despite uncertainty in the environment, parametric model uncertainty, and disturbances. Furthermore, we consider scenarios where these plans must be generated in real-time, because constraints such as obstacles in the environment may not be known until they are perceived (with a noisy sensor) at runtime. Our approach is to pre-compute a library of \"funnels\" along different maneuvers of the system that the state is guaranteed to remain within (despite bounded disturbances) when the feedback controller corresponding to the maneuver is executed. We leverage powerful computational machinery from convex optimization (sums-of-squares programming in particular) to compute these funnels. The resulting funnel library is then used to sequentially compose motion plans at runtime while ensuring the safety of the robot. A major advantage of the work presented here is that by explicitly taking into account the effect of uncertainty, the robot can evaluate motion plans based on how vulnerable they are to disturbances. ::: We demonstrate and validate our method using extensive hardware experiments on a small fixed-wing airplane avoiding obstacles at high speed (~12 mph), along with thorough simulation experiments of ground vehicle and quadrotor models navigating through cluttered environments. To our knowledge, these demonstrations constitute one of the first examples of provably safe and robust control for robotic systems with complex nonlinear dynamics that need to plan in real-time in environments with complex geometric constraints."}, "keywords": ["first constraint"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' approach of pre-computing a library of \"funnels\" along different maneuvers of the system that the state is guaranteed to remain within, despite bounded disturbances, is based on powerful computational machinery from convex optimization, as described in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' approach of pre-computing a library of \"funnels\" along different maneuvers of the system that the state is guaranteed to remain within, despite bounded disturbances, is a promising solution for generating motion plans for a robot that must be generated in real-time while ensuring the safety of the robot in complex environments with geometric constraints #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The first constraint in the re-timing problem is limited to the maximum change in adjacent scaling factors as |\u03b7 j+1 \u2212 \u03b7 j | \u2264 \u03ba, where \u03ba > 0 (#REFR).", "given_citation_intent": "background", "given_keywords": ["first constraint"]}]}
{"citing_id": "2303.15222v1", "cited_id": "1612.00337", "section_title": "On The Complex Plane Region", "citation": "We compare the results with the AAA method #REFR , which is based on randomly sampled points within the region of interest and can produce varying performances.", "text_before_citation": ["In this subsection, we present two numerical examples on a square region and an annulus, respectively."], "text_after_citation": ["To account for this variability, we conduct five tests and use the median result for comparison.", "The first example is on the square region [\u22120.5, 0.5] \u00d7 [\u22120.5, 0.5] with f (z) = exp(1/(5.1 2 + (10z) 2 )), which has two essential singularities at \u00b10.51i.", "In Figure 8 , the AAA method converges rapidly and reaches the error tolerance of 10 \u221210 with 10 4 random sample points.", "However, the method does not accurately represent the drastic local changes near the singularities with only 10 4 random sample points.", "In contrast, the rational interpolation with F = D(0.510001i, 10 \u22126 ) \u222a D(\u22120.510001i, 10 \u22126 ) converges exponentially as n increases."], "citing_paper_content": {"title": "Barycentric Interpolation Based On Equilibrium Logarithmic Potential", "abstract": "A novel barycentric interpolation algorithm with a specific exponential convergence rate is designed for analytic functions defined on the complex plane, with singularities located near the interpolation region, where the region is compact and can be disconnected or multiconnected. The core of the method is the efficient computation of the interpolation nodes and poles using discrete distributions that approximate the equilibrium logarithmic potential, achieved by solving a Symm's integral equation. It takes different strategies to distribute the poles for isolated singularities and branch points, respectively. In particular, if poles are not considered, it derives a polynomial interpolation with exponential convergence. Numerical experiments illustrate the superior performance of the proposed method."}, "cited_paper_content": {"title": "The Aaa Algorithm For Rational Approximation", "abstract": "We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of Matlab and requiring no user input parameters. Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive. The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities. The name AAA stands for\"adaptive Antoulas--Anderson\"in honor of the authors who introduced a scheme based on (1). We present the core algorithm with a Matlab code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation."}, "keywords": ["randomly sampled points", "AAA method"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this subsection, we present two numerical examples on a square region and an annulus, respectively. The rational approximation algorithm proposed by Antoulas and Anderson, named AAA, is a competitive method for approximation by rational functions on complex domains, which requires no user input parameters and may outperform existing methods even on a disk or interval. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For the square region and annulus examples, we compared the performance of our proposed barycentric interpolation algorithm with existing methods, and the results demonstrate that our method outperforms vector fitting, RKFIT, and other methods for rational approximation on complicated domains such as these. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To compare the performance of our proposed method with existing ones, we randomly sampled points on the square region and the annulus and applied the AAA method #REFR, which showed inferior results compared to our method.", "given_citation_intent": "result", "given_keywords": ["randomly sampled points", "AAA method"]}]}
{"citing_id": "2303.00968v2", "cited_id": "2002.10764", "section_title": "Related Work", "citation": "However, unlike our work and the work of Patro et al. #REFR , S\u00fchr et al.", "text_before_citation": ["It is possible for a user with unique tastes to receive low utility recommendations and still not prefer another user's recommendation lists.", "Also, our fairness formulation extends beyond the users receiving recommendations to providers of recommended items and envy-freeness provides no way to compare users who are getting different types of benefits from a system.", "In addition our fairness definitions are dynamic, a case not considered by #OTHEREFR .", "Like Patro et al. #OTHEREFR , the work of S\u00fchr et al.", "#OTHEREFR investigates fairness in two-sided platforms, specifically those like Uber or Lyft where income opportunities are allocated to drivers."], "text_after_citation": ["#OTHEREFR take proportionality as their definition of fairness, specifically proportionality with respect to time in a dynamic setting, and ensure that there is a fair distribution of income to the provider side of the platform.", "Freeman et al.", "#OTHEREFR investigate what they call dynamic social choice functions in settings where a fixed set of agents select a single item to share over a series of time steps.", "The work focuses on overall utility to the agents instead of considering the multiple sides of the recommendation interaction.", "Their problem is fundamentally a voting problem since all agents share the result, whereas we are focused on personalized recommendation."], "citing_paper_content": {"title": "Dynamic Fairness-Aware Recommendation Through Multi-Agent Social Choice", "abstract": "Algorithmic fairness in the context of personalized recommendation presents significantly different challenges to those commonly encountered in classification tasks. Researchers studying classification have generally considered fairness to be a matter of achieving equality of outcomes between a protected and unprotected group, and built algorithmic interventions on this basis. We argue that fairness in real-world application settings in general, and especially in the context of personalized recommendation, is much more complex and multi-faceted, requiring a more general approach. We propose a model to formalize multistakeholder fairness in recommender systems as a two stage social choice problem. In particular, we express recommendation fairness as a novel combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques based on this formulation. Simulations demonstrate the ability of the framework to integrate multiple fairness concerns in a dynamic way. CCS Concepts: \u2022 Information systems \u2192 Recommender systems; \u2022 Computing methodologies \u2192 Multi-agent systems; \u2022 Social and professional topics \u2192 User characteristics."}, "cited_paper_content": {"title": "Fairrec: Two-Sided Fairness For Personalized Recommendations In Two-Sided Platforms", "abstract": "We investigate the problem of fair recommendation in the context of two-sided online platforms, comprising customers on one side and producers on the other. Traditionally, recommendation services in these platforms have focused on maximizing customer satisfaction by tailoring the results according to the personalized preferences of individual customers. However, our investigation reveals that such customer-centric design may lead to unfair distribution of exposure among the producers, which may adversely impact their well-being. On the other hand, a producer-centric design might become unfair to the customers. Thus, we consider fairness issues that span both customers and producers. Our approach involves a novel mapping of the fair recommendation problem to a constrained version of the problem of fairly allocating indivisible goods. Our proposed FairRec algorithm guarantees at least Maximin Share (MMS) of exposure for most of the producers and Envy-Free up to One item (EF1) fairness for every customer. Extensive evaluations over multiple real-world datasets show the effectiveness of FairRec in ensuring two-sided fairness while incurring a marginal loss in the overall recommendation quality."}, "keywords": ["S\u00fchr"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In addition, our fairness definitions are dynamic, a case not considered by #OTHEREFR. Like Patro et al. (2019), the work of S\u00fchr et al. (2020) investigates fairness in two-sided platforms, specifically those like Uber or Lyft where income opportunities are allocated to drivers. To address the issue of unfair distribution of exposure among producers, we can consider the FairRec algorithm proposed by S\u00fchr et al. (2020) which guarantees two-sided fairness while incurring a marginal loss in the overall recommendation quality. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "S\u00fchr et al. #REFR investigated fairness in two-sided platforms, similar to Uber or Lyft, and their findings can be compared to the results presented in this manuscript.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "S\u00fchr et al. #REFR also investigated fairness in two-sided platforms, similar to Uber or Lyft, and their approach could be compared to ours.", "given_citation_intent": "result", "given_keywords": ["S\u00fchr"]}]}
{"citing_id": "2303.10770v1", "cited_id": "1507.07629", "section_title": "Model Architecture", "citation": "Each RN in the R in layer processes input spikes asynchronously from a corresponding pixel in the event camera following equation #REFR in real time without preprocessing.", "text_before_citation": ["The network is formed sequentially by an RN layer (R in ) as a feature descriptor for local temporal encoding, Convolution layers (C 1 -C 4 ), a spike conversion (SC) layer, another RN layer (R f ) for global temporal encoding and fully-connected layers (FC, F 1 -F 2 ) for classification.", "Figure 1 illustrates the overall architecture of the proposed network.", "The R in layer has the same size as the inputs."], "text_after_citation": ["Examples of the output generated by R in for DVS Lip inputs are shown in the left bottom insets of Figure 1 .", "Depending on the application, different temporal resolutions can be chosen by adjusting the time constant \u03c4 of equation 2 and the frequency of R in output acquisitions.", "A shorter acquisition interval creates more frequent activations for the following layers.", "A shorter time constant and more frequent acquisitions produce temporally finer outputs, while a longer time constant and less frequent acquisitions produce spatially more detailed outputs owing to the slower decay.", "#OTHEREFR To keep the discussions simple, here we use the same time constant and acquisition frequency for both datasets."], "citing_paper_content": {"title": "Retinanet: Reservoir-Enabled Time Integrated Attention Network For Event-Based Video Processing", "abstract": "Event-based cameras are inspired by the sparse and asynchronous spike representation of the biological visual system. However, processing the even data requires either using expensive feature descriptors to transform spikes into frames, or using spiking neural networks that are difficult to train. In this work, we propose a neural network architecture based on simple convolution layers integrated with dynamic temporal encoding reservoirs with low hardware and training costs. The Reservoir-enabled Time Integrated Attention Network (RetinaNet) allows the network to efficiently process asynchronous temporal features, and achieves the highest accuracy of 99.2% for DVS128 Gesture reported to date, and one of the highest accuracy of 67.5% for DVS Lip dataset at a much smaller network size. By leveraging the internal dynamics of memristors, asynchronous temporal feature encoding can be implemented at very low hardware cost without preprocessing or dedicated memory and arithmetic units. The use of simple DNN blocks and backpropagation based training rules further reduces its implementation cost. Code will be publicly available."}, "cited_paper_content": {"title": "Converting Static Image Datasets To Spiking Neuromorphic Datasets Using Saccades", "abstract": "Creating datasets for Neuromorphic Vision is a challenging task. A lack of available recordings from Neuromorphic Vision sensors means that data must typically be recorded specifically for dataset creation rather than collecting and labelling existing data. The task is further complicated by a desire to simultaneously provide traditional frame-based recordings to allow for direct comparison with traditional Computer Vision algorithms. Here we propose a method for converting existing Computer Vision static image datasets into Neuromorphic Vision datasets using an actuated pan-tilt camera platform. Moving the sensor rather than the scene or image is a more biologically realistic approach to sensing and eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor. We present conversion of two popular image datasets (MNIST and Caltech101) which have played important roles in the development of Computer Vision, and we provide performance metrics on these datasets using spike-based recognition algorithms. This work contributes datasets for future use in the field, as well as results from spike-based algorithms against which future works can compare. Furthermore, by converting datasets already popular in Computer Vision, we enable more direct comparison with frame-based approaches."}, "keywords": ["event camera"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed RetinaNet architecture integrates dynamic temporal encoding reservoirs with low hardware and training costs for efficient processing of asynchronous temporal features, achieving state-of-the-art accuracy on DVS128 Gesture and DVS Lip datasets. To enable direct comparison with frame-based approaches, the authors converted popular image datasets, MNIST and Caltech101, into Neuromorphic Vision datasets using an actuated pan-tilt camera platform, as described in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To convert existing Computer Vision static image datasets into Neuromorphic Vision datasets, the authors proposed a method using an actuated pan-tilt camera platform, which eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor, and presented conversion of two popular image datasets (MNIST and Caltech101) in their work #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To convert static image datasets into Neuromorphic Vision datasets, the authors proposed a method using an actuated pan-tilt camera platform, which eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor, and presented conversion of two popular image datasets (MNIST and Caltech101) using spike-based recognition algorithms, providing datasets for future use in the field and enabling more direct comparison with frame-based approaches. #REFR", "given_citation_intent": "method", "given_keywords": ["event camera"]}]}
{"citing_id": "2303.14256v1", "cited_id": "1602.00602", "section_title": "C. Measurement Configuration", "citation": "Since warmup can not be clearly distinguished from warmed up state by statistical methods #REFR , we always use the same count of warmup and measurement iterations.", "text_before_citation": ["In the following, we exemplarily describe two parts of the configuration: How to choose VM and execution count (part of the measurement parametrization), whether to parallelize the measurements (part of the technical measurement environment) and whether to remove outliers (part of the analysis configuration). Finally, we discuss the generalizability of our configuration. Our dataset is available.", "#OTHEREFR a) Parametrization: To identify performance changes reliably, we need to choose the warmup iteration, measurement iteration, repetition and VM count."], "text_after_citation": ["The same product repetitions * iterations implies the same overall workload executions. For every VM, iteration measurement values are taken.", "Figure 5 shows the average F 1 -score of all workload types for different iteration, repetition and VM counts using t-test like recommended by #OTHEREFR .", "Since we only want 1 % false positives, we set the significance level of the t-test to 99 %.", "The F 1 -score is not only influenced by the measurement configuration, but also by the statistical test.", "Additionally to t-test, we used confidence interval comparison like recommended by literature #OTHEREFR , #OTHEREFR , and Mann-Whitney-test like recommended by literature #OTHEREFR , #OTHEREFR ."], "citing_paper_content": {"title": "Automated Identification Of Performance Changes At Code Level", "abstract": "To develop software with optimal performance, even small performance changes need to be identified. Identifying performance changes is challenging since the performance of software is influenced by non-deterministic factors. Therefore, not every performance change is measurable with reasonable effort. In this work, we discuss which performance changes are measurable at code level with reasonable measurement effort and how to identify them. We present (1) an analysis of the boundaries of measuring performance changes, (2) an approach for determining a configuration for reproducible performance change identification, and (3) an evaluation comparing of how well our approach is able to identify performance changes in the application server Jetty compared with the usage of Jetty's own performance regression benchmarks. Thereby, we find (1) that small performance differences are only measurable by fine-grained measurement workloads, (2) that performance changes caused by the change of one operation can be identified using a unit-test-sized workload definition and a suitable configuration, and (3) that using our approach identifies small performance regressions more efficiently than using Jetty's performance regression benchmarks."}, "cited_paper_content": {"title": "Virtual Machine Warmup Blows Hot And Cold", "abstract": "Virtual Machines (VMs) with Just-In-Time (JIT) compilers are traditionally thought to execute programs in two phases: the initial warmup phase determines which parts of a program would most benefit from dynamic compilation, before JIT compiling those parts into machine code; subsequently the program is said to be at a steady state of peak performance. Measurement methodologies almost always discard data collected during the warmup phase such that reported measurements focus entirely on peak performance. We introduce a fully automated statistical approach, based on changepoint analysis, which allows us to determine if a program has reached a steady state and, if so, whether that represents peak performance or not. Using this, we show that even when run in the most controlled of circumstances, small, deterministic, widely studied microbenchmarks often fail to reach a steady state of peak performance on a variety of common VMs. Repeating our experiment on 3 different machines, we found that at most 43.5% of pairs consistently reach a steady state of peak performance."}, "keywords": ["measurement iterations", "warmup"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To identify performance changes reliably, the authors need to choose the warmup iteration, measurement iteration, repetition and VM count #OTHEREFR (Virtual Machine Warmup Blows Hot And Cold).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To determine if a program has reached a steady state of peak performance, the authors of this manuscript cite a fully automated statistical approach based on changepoint analysis introduced in the reference paper \"Virtual Machine Warmup Blows Hot And Cold\" #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To determine the warmup iteration and measurement iteration for identifying performance changes reliably, the authors used a statistical approach based on changepoint analysis, as described in the reference paper Virtual Machine Warmup Blows Hot And Cold. #REFR", "given_citation_intent": "method", "given_keywords": ["measurement iterations", "warmup"]}]}
{"citing_id": "2303.11502v1", "cited_id": "1704.03477", "section_title": "Sketch Vector Normalisation", "citation": "Therefore, taking inspiration from sketch/handwriting generation literature #REFR , we define our sketch-coordinate in terms of offset values to make it scale-agnostic.", "text_before_citation": ["Absolute coordinate based sketch-vector representation is scale dependent as the user can draw (see Fig. 2 ) the same concept in varying scales."], "text_after_citation": ["In particular, instead of three elements with absolute coordinate (x i , y i ) and stroke token (b i ), now we represent every point as a five-element vector", "(\u2206x i , \u2206y i , p 1 i , p 2 i , p 3 i ), where \u2206x i = (x i+1 \u2212 x i ) and \u2206y i = (y i+1 \u2212 y i ).", "Consequently, (p 1 i , p 2 i , p 3 i )", "represents three pen-state situations: pen touching the paper, pen being lifted and end of drawing.", "Convolutional Encoder Instead of any complicated backbone architectures #OTHEREFR , we use a straight-forward VGG-16 as the backbone convolutional encoder, which takes a photo (image) P \u2208 R H\u00d7W \u00d73 as input and outputs multiscale convolutional feature maps as F \u2208"], "citing_paper_content": {"title": "Sketch2Saliency: Learning To Detect Salient Objects From Human Drawings", "abstract": "Human sketch has already proved its worth in various visual understanding tasks (e.g., retrieval, segmentation, image-captioning, etc). In this paper, we reveal a new trait of sketches-that they are also salient. This is intuitive as sketching is a natural attentive process at its core. More specifically, we aim to study how sketches can be used as a weak label to detect salient objects present in an image. To this end, we propose a novel method that emphasises on how \"salient object\" could be explained by handdrawn sketches. To accomplish this, we introduce a phototo-sketch generation model that aims to generate sequential sketch coordinates corresponding to a given visual photo through a 2D attention mechanism. Attention maps accumulated across the time steps give rise to salient regions in the process. Extensive quantitative and qualitative experiments prove our hypothesis and delineate how our sketchbased saliency detection model gives a competitive performance compared to the state-of-the-art."}, "cited_paper_content": {"title": "A Neural Representation Of Sketch Drawings", "abstract": "We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format."}, "keywords": ["sketch-coordinate", "sketch/handwriting generation literature"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Absolute coordinate based sketch-vector representation is scale dependent as the user can draw (see Fig. 2) the same concept in varying scales. This issue has been addressed in recent work by using a neural network to construct stroke-based drawings of common objects, which can be generated in a vector format with new robust training methods for coherence #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the scale dependency issue of absolute coordinate based sketch-vector representation, the authors of Sketch2Saliency proposed a phototo-sketch generation model that generates sequential sketch coordinates through a 2D attention mechanism, which was trained on thousands of crude human-drawn images representing hundreds of classes #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the scale dependency of absolute coordinate based sketch-vector representation, recent sketch/handwriting generation literature has proposed methods such as sketch-rnn #REFR that generate coherent sketch drawings in a vector format.", "given_citation_intent": "method", "given_keywords": ["sketch-coordinate", "sketch/handwriting generation literature"]}]}
{"citing_id": "2303.13654v1", "cited_id": "2003.08934", "section_title": "Spherical Multi-Resolution Hash Encoding", "citation": "This representation can be interpreted as an omnidirectional extension of a Normalized Device Coordinates (NDC) used for novel view synthesis in forward facing scenes in #REFR .", "text_before_citation": ["We convert the input location represented in Cartesian coordinates (x, y, z) \u2208 R 3 to spherical coordinates (\u03c6, \u03b8, 1 1+r ) \u2208 [0, 1] 3 as follows:", "EQUATION", "This enables at the same time an efficient feature allocation strategy related to the pixel's measurement accuracy and a representation that is not limited by the frustum boundary.", "Feature Allocation An increasing distance to the camera center leads to a larger measurement uncertainty as disparity is inversely-proportional to its depth #OTHEREFR .", "To allocate more capacity in areas of high certainty, it is therefore efficient to allocate the features evenly in inverse depth space."], "text_after_citation": ["While the NDC parameterization contracts the scene along inverse depth, the region is strictly bounded by the model view frustum, which discards the training view information outside of the frustum and also causes artifacts around the frustum boundary as shown in Fig. 4 .", "In contrast, our spherical representation can make full use of the training view information without being limited to the field of view.", "Unbounded Scenes Our representation can naturally capture unbounded scenes.", "While other parameterizations such as the recently proposed space contraction from #OTHEREFR can also represent 360 \u2022 unbounded scenes, it explicitly separates foreground and background.", "This is effective only when the camera trajectory is object-centric and inward-looking, and the region of interest needs to be known a priori in world coordinates."], "citing_paper_content": {"title": "Newton: Neural View-Centric Mapping For On-The-Fly Large-Scale Slam", "abstract": "Neural field-based 3D representations have recently been adopted in many areas including SLAM systems. Current neural SLAM or online mapping systems lead to impressive results in the presence of simple captures, but they rely on a world-centric map representation as only a single neural field model is used. To define such a world-centric representation, accurate and static prior information about the scene, such as its boundaries and initial camera poses, are required. However, in real-time and on-the-fly scene capture applications, this prior knowledge cannot be assumed as fixed or static, since it dynamically changes and it is subject to significant updates based on run-time observations. Particularly in the context of large-scale mapping, significant camera pose drift is inevitable, necessitating the correction via loop closure. To overcome this limitation, we propose NEWTON, a view-centric mapping method that dynamically constructs neural fields based on run-time observation. In contrast to prior works, our method enables camera pose updates using loop closures and scene boundary updates by representing the scene with multiple neural fields, where each is defined in a local coordinate system of a selected keyframe. The experimental results demonstrate the superior performance of our method over existing world-centric neural field-based SLAM systems, in particular for large-scale scenes subject to camera pose updates."}, "cited_paper_content": {"title": "Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis", "abstract": "We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing direction $(\\theta, \\phi)$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons."}, "keywords": ["forward facing scenes", "novel view synthesis"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To represent scenes as neural radiance fields for view synthesis, Nerf (Mildenhall et al., 2020) uses a fully-connected deep network that takes a single continuous 5D coordinate as input and outputs the volume density and view-dependent emitted radiance at that spatial location, which can be optimized using a set of images with known camera poses. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To represent scenes using a fully-connected deep network, the authors of NEWTON convert the input location to spherical coordinates, enabling an efficient feature allocation strategy related to the pixel's measurement accuracy and a representation that is not limited by the frustum boundary #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To synthesize novel views of forward facing scenes, the authors propose a method that optimizes a continuous volumetric scene function using a sparse set of input views, as described in the reference paper #REFR on neural radiance fields for view synthesis.", "given_citation_intent": "method", "given_keywords": ["forward facing scenes", "novel view synthesis"]}]}
{"citing_id": "2304.12372v1", "cited_id": "1505.04597", "section_title": "Experimental Results", "citation": "We experiment with FOVs of 180\u00b0, 120\u00b0, 60\u00b0, and uniformly random in the #REFR 120] \u2022 interval.", "text_before_citation": ["The mean relative error and RMSE are 4.25 % and 173.0 on the entire test set.", "We observe that the network struggles with larger temperature variations across the image.", "However, temperature is accurately predicted despite color changes in the input.", "Planar illuminance Here, we experiment with three types of inputs: a calibrated HDR image (\"HDR\"), a linear LDR image (reexposed HDR clipped to the [0, 1] interval) with (\"LDR+scale\") and without (\"LDR\") knowledge of the exposure.", "In addition, we also evaluate the impact of the FOV of the input."], "text_after_citation": ["The image is stored in an equirectangular representation for 180\u00b0, and perspective projection for the other, lower FOVs.", "Tab. 2 shows the results of these series of experiments.", "We report the RMSE and R 2 for each combination of input type and FOV.", "First, observe that the experiment with a FOV of 180\u00b0with the HDR image (top-left in tab. 2) amounts to learning the illuminance integration (eq. (1)).", "Unsurprisingly, narrowing the FOV results in decreased performance, due to the hidden lights beyond the FOV which may directly affect the planar illuminance."], "citing_paper_content": {"title": "Beyond The Pixel: A Photometrically Calibrated Hdr Dataset For Luminance And Color Temperature Prediction", "abstract": "Light plays an important role in human well-being. However, most computer vision tasks treat pixels without considering their relationship to physical luminance. To address this shortcoming, we present the first large-scale photometrically calibrated dataset of high dynamic range 360\u00b0panoramas. Our key contribution is the calibration of an existing, uncalibrated HDR Dataset. We do so by accurately capturing RAW bracketed exposures simultaneously with a professional photometric measurement device (chroma meter) for multiple scenes across a variety of lighting conditions. Using the resulting measurements, we establish the calibration coefficients to be applied to the HDR images. The resulting dataset is a rich representation of indoor scenes which displays a wide range of illuminance and color temperature, and varied types of light sources. We exploit the dataset to introduce three novel tasks: where per-pixel luminance, per-pixel temperature and planar illuminance can be predicted from a single input image. Finally, we also capture another smaller calibrated dataset with a commercial 360\u00b0camera, to experiment on generalization across cameras. We are optimistic that the release of our datasets and associated code will spark interest in physically accurate light estimation within the community."}, "cited_paper_content": {"title": "U-Net: Convolutional Networks For Biomedical Image Segmentation", "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net ."}, "keywords": ["FOVs"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To accurately predict temperature despite color changes in the input, the authors experiment with three types of inputs, including a calibrated HDR image, as presented in the U-Net paper by Ronneberger et al. #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To accurately predict temperature despite color changes in the input, the authors of this study used a U-Net network architecture, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the impact of the FOVs of the input, the authors experimented with different types of inputs, including a calibrated HDR image, a linear LDR image with and without knowledge of the exposure, and achieved accurate results using the U-Net method #REFR.", "given_citation_intent": "method", "given_keywords": ["FOVs"]}]}
{"citing_id": "2304.13649v1", "cited_id": "1906.00067", "section_title": "Experiments 6.1 Datasets", "citation": "Outside-Knowledge Visual Question Answering (OK-VQA) #REFR : This dataset consists of triplets, including an image, a question about the image, and an answer to the mentioned question.", "text_before_citation": [], "text_after_citation": ["Answering most of the questions in this dataset needs a piece of information that is not provided in the image.", "Therefore, accessing an external source of information is required for this task.", "A retrieval dataset based on a Wikipedia dump 7 with 11 million passages was later constructed by Qu et al.", "#OTHEREFR , which we use to train and evaluate our retrievers.", "This dataset contains 9009 questions for training, 2523 questions for validation, and 2523 for testing #OTHEREFR ."], "citing_paper_content": {"title": "A Symmetric Dual Encoding Dense Retrieval Framework For Knowledge-Intensive Visual Question Answering", "abstract": "Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a question about an image whose answer does not lie in the image. This paper presents a new pipeline for KI-VQA tasks, consisting of a retriever and a reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval framework in which documents and queries are encoded into a shared embedding space using uni-modal (textual) and multi-modal encoders. We introduce an iterative knowledge distillation approach that bridges the gap between the representation spaces in these two encoders. Extensive evaluation on two well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR outperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA, respectively. Utilizing the passages retrieved by DEDR, we further introduce MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and each retrieved passage separately and uses all passages jointly in its decoder. Compared to competitive baselines in the literature, this approach leads to 5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA and FVQA, respectively."}, "cited_paper_content": {"title": "Ok-Vqa: A Visual Question Answering Benchmark Requiring External Knowledge", "abstract": "Visual Question Answering (VQA) in its ideal form lets us study reasoning in the joint space of vision and language and serves as a proxy for the AI task of scene understanding. However, most VQA benchmarks to date are focused on questions such as simple counting, visual attributes, and object detection that do not require reasoning or knowledge beyond what is in the image. In this paper, we address the task of knowledge-based visual question answering and provide a benchmark, called OK-VQA, where the image content is not sufficient to answer the questions, encouraging methods that rely on external knowledge resources. Our new dataset includes more than 14,000 questions that require external knowledge to answer. We show that the performance of the state-of-the-art VQA models degrades drastically in this new setting. Our analysis shows that our knowledge-based VQA task is diverse, difficult, and large compared to previous knowledge-based VQA datasets. We hope that this dataset enables researchers to open up new avenues for research in this domain."}, "keywords": ["Knowledge", "dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the task of knowledge-based visual question answering, the authors introduce a benchmark dataset called OK-VQA, which includes more than 14,000 questions that require external knowledge to answer. Their analysis shows that this dataset is diverse, difficult, and large compared to previous knowledge-based VQA datasets. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the task of knowledge-based visual question answering, the authors propose a new benchmark dataset called OK-VQA, which requires external knowledge to answer questions, and show that the state-of-the-art VQA models perform poorly in this setting (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the task of knowledge-based visual question answering, the authors introduce a benchmark dataset called OK-VQA, which includes more than 14,000 questions that require external #REFR[Knowledge] to answer, and demonstrate that the state-of-the-art VQA models perform poorly on this #REFR[dataset].", "given_citation_intent": "method", "given_keywords": ["Knowledge", "dataset"]}]}
{"citing_id": "2304.06114v1", "cited_id": "2004.01177", "section_title": "Related Work", "citation": "CenterTrack #REFR learns to generate a center heatmap for object detection and an offset vector that represents the displacement from one frame to the next using the two consecutive frames and the center heatmap of the previous frame.", "text_before_citation": ["TubeTK proposes the concept of bounding-tubes to represent the spatiotemporal location of objects detected in a video.", "A bounding-tube is defined as a series of three bounding boxes of the same object from different frames.", "Tracks are broken down into a combination of tubes where the bounding box at each frame is defined as the middle bounding box of a tube in order to link tubes together.", "The three bounding boxes forming a tube do not have to be from consecutive frames, which allows the interpolation of the object location within a tube. Tubes are linked using IoU as a distance metric.", "Chained-Tracker takes two adjacent frames as input and generates detection pairs of each object in both frames and then link each consecutive pair using IoU as a distance metric and then the Hungarian algorithm #OTHEREFR for matching."], "text_after_citation": ["It then regresses the bounding boxes from the center points of the objects.", "Data association is done using greedy matching between the position of the objects in the previous frame and the position of the predicted offset.", "Tracktor #OTHEREFR exploits the bounding box regression module of Faster R-CNN to perform tracking directly from the information provided by the detector.", "Moreover, the model can be extended with a motion model and a reidentification algorithm to achieve better results.", "FairMOT #OTHEREFR aims to reconcile the inherent bias in favor of the detection task when training a MOT model."], "citing_paper_content": {"title": "Toptrack: Tracking Objects By Their Top", "abstract": "In recent years, the joint detection-and-tracking paradigm has been a very popular way of tackling the multi-object tracking (MOT) task. Many of the methods following this paradigm use the object center keypoint for detection. However, we argue that the center point is not optimal since it is often not visible in crowded scenarios, which results in many missed detections when the objects are partially occluded. We propose TopTrack, a joint detection-and-tracking method that uses the top of the object as a keypoint for detection instead of the center because it is more often visible. Furthermore, Top-Track processes consecutive frames in separate streams in order to facilitate training. We performed experiments to show that using the object top as a keypoint for detection can reduce the amount of missed detections, which in turn leads to more complete trajectories and less lost trajectories. TopTrack manages to achieve competitive results with other state-of-the-art trackers on two MOT benchmarks."}, "cited_paper_content": {"title": "Tracking Objects As Points", "abstract": "Tracking has traditionally been the art of following interest points through space and time. This changed with the rise of powerful deep networks. Nowadays, tracking is dominated by pipelines that perform object detection followed by temporal association, also known as tracking-by-detection. In this paper, we present a simultaneous detection and tracking algorithm that is simpler, faster, and more accurate than the state of the art. Our tracker, CenterTrack, applies a detection model to a pair of images and detections from the prior frame. Given this minimal input, CenterTrack localizes objects and predicts their associations with the previous frame. That's it. CenterTrack is simple, online (no peeking into the future), and real-time. It achieves 67.3% MOTA on the MOT17 challenge at 22 FPS and 89.4% MOTA on the KITTI tracking benchmark at 15 FPS, setting a new state of the art on both datasets. CenterTrack is easily extended to monocular 3D tracking by regressing additional 3D attributes. Using monocular video input, it achieves 28.3% AMOTA@0.2 on the newly released nuScenes 3D tracking benchmark, substantially outperforming the monocular baseline on this benchmark while running at 28 FPS."}, "keywords": ["object detection"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Chained-Tracker takes two adjacent frames as input and generates detection pairs of each object in both frames and then link each consecutive pair using IoU as a distance metric and then the Hungarian algorithm for matching. Our tracker, TopTrack, uses the top of the object as a keypoint for detection instead of the center, which reduces the amount of missed detections and leads to more complete trajectories and less lost trajectories #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Chained-Tracker uses IoU as a distance metric to link detection pairs of each object in both frames, and then applies the Hungarian algorithm for matching, similar to the method proposed in the reference paper \"Tracking Objects As Points\" (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Chained-Tracker generates detection pairs of each object in both frames and then links each consecutive pair using IoU as a distance metric and then the Hungarian algorithm #REFR for matching, building upon the object detection method proposed in the reference paper.", "given_citation_intent": "method", "given_keywords": ["object detection"]}]}
{"citing_id": "2303.10181v1", "cited_id": "1609.07061", "section_title": "Methods For Resource Efficiency", "citation": "The implication of using quantised or low-precision variables is that it not only reduces memory footprint but can also reduce the compute cost of matrix multiplications #REFR at the expense of loss in precision.", "text_before_citation": ["Thus, for a neural network with |W| parameters, at any point during the training there are an additional \u2248 3 \u22c5 |W| variables stored in memory.", "Further, the intermediate activations at layer l, h l are also stored in memory to efficiently perform backpropagation.", "Note that all the scalar entries of W, g t , m t , v t , h l \u2208 R.", "On most computers, these real numbers are discretised into floating point-32 (FP32) format; wherein each variable requires 32 bits.", "Resource efficiency in this work is primarily addressed by reducing the precision of these variables by quantisation #OTHEREFR ."], "text_after_citation": ["Note, however, that the overhead of performing quantisation in some cases might outweigh the gains in computation.", "In this work, we investigate a combination of the following three quantisation strategies:", "1. Gradients and intermediate activations:", "Drastic quantisation of h l , g t", "have been studied extensively in literature #OTHEREFR ."], "citing_paper_content": {"title": "Operating Critical Machine Learning Models In Resource Constrained Regimes", "abstract": "The accelerated development of machine learning methods, primarily deep learning, are causal to the recent breakthroughs in medical image analysis and computer aided intervention. The resource consumption of deep learning models in terms of amount of training data, compute and energy costs are known to be massive. These large resource costs can be barriers in deploying these models in clinics, globally. To address this, there are cogent efforts within the machine learning community to introduce notions of resource efficiency. For instance, using quantisation to alleviate memory consumption. While most of these methods are shown to reduce the resource utilisation, they could come at a cost in performance. In this work, we probe into the trade-off between resource consumption and performance, specifically, when dealing with models that are used in critical settings such as in clinics."}, "cited_paper_content": {"title": "Quantized Neural Networks: Training Neural Networks With Low Precision Weights And Activations", "abstract": "We introduce a method to train Quantized Neural Networks (QNNs) -- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online."}, "keywords": ["quantised"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Resource efficiency in this work is primarily addressed by reducing the precision of these variables by quantisation (Guo et al., 2018).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of resource efficiency in deep learning models, quantization has been proposed as a solution to reduce memory consumption by decreasing the precision of variables, as shown in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the resource consumption of deep learning models, quantisation has been proposed to reduce the precision of variables, as each variable requires a significant amount of memory, and this can be achieved by training Quantized Neural Networks (QNNs) with extremely low precision weights and activations, as demonstrated in #REFR.", "given_citation_intent": "background", "given_keywords": ["quantised"]}]}
{"citing_id": "2303.08816v1", "cited_id": "1803.02349", "section_title": "Introduction", "citation": "For instance, an e-commerce item carries its category as well as many other attributes, and the user might have a preference for a certain category #REFR .", "text_before_citation": ["The Borda winner is intuitively appealing and always well-defined for any set of preferential probabilities.", "The Borda score also does not require the problem instance to obey any consistency or transitivity, and it is considered one of the most general criteria.", "To identify the Borda winner, estimations of the Borda scores are needed.", "Since estimating the Borda score for one item requires comparing it with every other items, the sample complexity is prohibitively high when there are numerous items.", "On the other hand, in many real-world applications, the agent has access to side information that can assist the evaluation of p i,j ."], "text_after_citation": ["For a movie, the genre and the plot as well as the directors and actors can also be taken into consideration when making choices #OTHEREFR .", "Based on the above motivation, we consider Generalized Linear Dueling Bandits.", "At each round, the agent selects two items from a finite set of items and receives a comparison result of the preferred item.", "The comparisons depend on known intrinsic contexts/features associated with each pair of items.", "The contexts can be obtained from upstream tasks, such as topic modeling #OTHEREFR or embedding #OTHEREFR ."], "citing_paper_content": {"title": "Borda Regret Minimization For Generalized Linear Dueling Bandits", "abstract": "Dueling bandits are widely used to model preferential feedback that is prevalent in machine learning applications such as recommendation systems and ranking. In this paper, we study the Borda regret minimization problem for dueling bandits, which aims to identify the item with the highest Borda score while minimizing the cumulative regret. We propose a new and highly expressive generalized linear dueling bandits model, which covers many existing models. Surprisingly, the Borda regret minimization problem turns out to be difficult, as we prove a regret lower bound of order \u2126(d 2/3 T 2/3), where d is the dimension of contextual vectors and T is the time horizon. To attain the lower bound, we propose an explore-then-commit type algorithm, which has a nearly matching regret upper bound O(d 2/3 T 2/3). When the number of items/arms K is small, our algorithm can achieve a smaller regret O((d log K) 1/3 T 2/3) with proper choices of hyperparameters. We also conduct empirical experiments on both synthetic data and a simulated real-world environment, which corroborate our theoretical analysis."}, "cited_paper_content": {"title": "Billion-Scale Commodity Embedding For E-Commerce Recommendation In Alibaba", "abstract": "Recommender systems (RSs) have been the most important technology for increasing the business in Taobao, the largest online consumer-to-consumer (C2C) platform in China. There are three major challenges facing RS in Taobao: scalability, sparsity and cold start. In this paper, we present our technical solutions to address these three challenges. The methods are based on a well-known graph embedding framework. We first construct an item graph from users' behavior history, and learn the embeddings of all items in the graph. The item embeddings are employed to compute pairwise similarities between all items, which are then used in the recommendation process. To alleviate the sparsity and cold start problems, side information is incorporated into the graph embedding framework. We propose two aggregation methods to integrate the embeddings of items and the corresponding side information. Experimental results from offline experiments show that methods incorporating side information are superior to those that do not. Further, we describe the platform upon which the embedding methods are deployed and the workflow to process the billion-scale data in Taobao. Using A/B test, we show that the online Click-Through-Rates (CTRs) are improved comparing to the previous collaborative filtering based methods widely used in Taobao, further demonstrating the effectiveness and feasibility of our proposed methods in Taobao's live production environment."}, "keywords": ["preference", "e-commerce item"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the issue of scalability, sparsity, and cold start in recommender systems, a well-known graph embedding framework was employed in the reference paper #REFR, where item embeddings were learned from an item graph constructed from users' behavior history and used to compute pairwise similarities between all items. To further alleviate the sparsity and cold start problems, side information was incorporated into the graph embedding framework, resulting in superior performance compared to methods that did not incorporate side information.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the sparsity and cold start challenges in recommender systems, incorporating side information into the graph embedding framework has been proposed, and experimental results have shown its superiority over those that do not (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of estimating Borda scores for numerous e-commerce items, side information can be incorporated into the graph embedding framework, as proposed in the reference paper #REFR, which presents technical solutions for scalability, sparsity, and cold start problems in recommender systems.", "given_citation_intent": "background", "given_keywords": ["preference", "e-commerce item"]}]}
{"citing_id": "2304.00320v1", "cited_id": "1904.09080", "section_title": "Remark 3 (Escape And Converge). When The Noise \u039e", "citation": "Similar results have been obtained in #REFR when assuming the deep learning algorithms are driven by an Ornstein-Uhlenbeck process.", "text_before_citation": ["1 N N i=1 \u2207 \u03b8 f (x i ,\u03b8) 2", "2 , as the scale of noise \u03be ULN k (\u03b8) is large.", "Reciprocally, we follow #OTHEREFR and suggest that when the SGD with unbiased random label noises converges, the algorithm would converge to a point", "\u03b8 * with small 1 N N i=1 \u2207 \u03b8 f (x i , \u03b8 * ) 2", "2 ."], "text_after_citation": ["Remark 4 (Performance Tuning).", "Considering \u03b7\u03c3 2 /B as the coefficient balancing the implicit regularizer and vanilla SGD, one can regularize/penalize the SGD learning procedure with the fixed \u03b7 and B more fiercely using a larger \u03c3 2 .", "More specifically, we could expect to obtain a regularized solution with #OTHEREFR 2 or higher inference stability of neural networks, as regularization effects become stronger when \u03c3 2 increases.", "lower 1 N N i=1 \u2207 \u03b8 f (x i , \u03b8)"], "citing_paper_content": {"title": "Stochastic Gradient Descent With Random Label Noises: Doubly Stochastic Models And Inference Stabilizer", "abstract": "Random label noises (or observational noises) widely exist in practical machine learning settings. While previous studies primarily focus on the affects of label noises to the performance of learning, our work intends to investigate the implicit regularization effects of the label noises, under mini-batch sampling settings of stochastic gradient descent (SGD), with assumptions that label noises are unbiased. Specifically, we analyze the learning dynamics of SGD over the quadratic loss with unbiased label noises, where we model the dynamics of SGD as a stochastic differentiable equation (SDE) with two diffusion terms (namely a Doubly Stochastic Model). While the first diffusion term is caused by mini-batch sampling over the (label-noiseless) loss gradients as many other works on SGD [1, 2], our model investigates the second noise term of SGD dynamics, which is caused by mini-batch sampling over the label noises, as an implicit regularizer. Our theoretical analysis finds such implicit regularizer would favor some convergence points that could stabilize model outputs against perturbation of parameters (namely inference stability). Though similar phenomenon have been investigated in [3], our work"}, "cited_paper_content": {"title": "Implicit Regularization For Deep Neural Networks Driven By An Ornstein-Uhlenbeck Like Process", "abstract": "We consider deep networks, trained via stochastic gradient descent to minimize L2 loss, with the training labels perturbed by independent noise at each iteration. We characterize the behavior of the training dynamics near any parameter vector that achieves zero training error, in terms of an implicit regularization term corresponding to the sum over the data points, of the squared L2 norm of the gradient of the model with respect to the parameter vector, evaluated at each data point. We then leverage this general characterization, which holds for networks of any connectivity, width, depth, and choice of activation function, to show that for 2-layer ReLU networks of arbitrary width and L2 loss, when trained on one-dimensional labeled data $(x_1,y_1),\\ldots,(x_n,y_n),$ the only stable solutions with zero training error correspond to functions that: 1) are linear over any set of three or more co-linear training points (i.e. the function has no extra \"kinks\"); and 2) change convexity the minimum number of times that is necessary to fit the training data. Additionally, for 2-layer networks of arbitrary width, with tanh or logistic activations, we show that when trained on a single $d$-dimensional point $(x,y)$ the only stable solutions correspond to networks where the activations of all hidden units at the datapoint, and all weights from the hidden units to the output, take at most two distinct values, or are zero. In this sense, we show that when trained on \"simple\" data, models corresponding to stable parameters are also \"simple\"; in short, despite fitting in an over-parameterized regime where the vast majority of expressible functions are complicated and badly behaved, stable parameters reached by training with noise express nearly the \"simplest possible\" hypothesis consistent with the data. These results shed light on the mystery of why deep networks generalize so well in practice."}, "keywords": ["deep learning algorithms"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Reciprocally, we follow #OTHEREFR and suggest that when the SGD with unbiased random label noises converges, the algorithm would converge to a point \u03b8 * with small 1 N N i=1 \u2207 \u03b8 f (x i , \u03b8 * ) 2 2, as the scale of noise \u03be ULN k (\u03b8) is large.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the results presented in the manuscript, stable parameters reached by training with noise express nearly the \"simplest possible\" hypothesis consistent with the data, which is consistent with the findings in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The results of the manuscript demonstrate that stable parameters reached by training deep learning algorithms with noise express nearly the \"simplest possible\" hypothesis consistent with the data, which sheds light on the mystery of why deep networks generalize so well in practice (#REFR).", "given_citation_intent": "result", "given_keywords": ["deep learning algorithms"]}]}
{"citing_id": "2304.03593v1", "cited_id": "1911.03074", "section_title": "B. Crowd Navigation", "citation": "While the arrival times of our robot were longer than the results of #REFR , we note that their robot was traveling at a speed (1.5m/s) about 7 times faster than our robot (0.22m/s).", "text_before_citation": ["Likewise, higher crowd density (more dangerous) resulted in longer arrival time.", "Exceptions were seen in the ahead crowd behavior, where the arrival times with fast moving obstacles ahead were shorter than with slow moving obstacles.", "The fast moving obstacles were traveling at a speed close to the speed of the robot.", "In this case, when the obstacles were moving fast ahead of the robot, there was very little chance of the robot being confronted by the obstacles. The ahead environments were quite safe.", "Consequently, there were very few safety violations as seen from the high ego and social scores in the results of ahead crowd behavior in Fig. 4 ."], "text_after_citation": ["Taking into account the speed difference, our approach has performed relatively faster and with higher success rate than the approach of #OTHEREFR .", "In addition, we have observed an interesting policy learned by our model.", "In cases where there were too dense obstacles in the way of the robot, the robot would take a detour and avoid the crowd cluster to reach the goal.", "However, in most cases, the robot navigated through the crowd. Fig.  5 illustrates the robot's behaviors during navigation.", "Egosafety and social-safety violations do not necessary result in collisions."], "citing_paper_content": {"title": "Deep Reinforcement Learning-Based Mapless Crowd Navigation With Perceived Risk Of The Moving Crowd For Mobile Robots", "abstract": "Classical map-based navigation methods are commonly used for robot navigation, but they often struggle in crowded environments due to the Frozen Robot Problem (FRP). Deep reinforcement learning-based methods address the FRP problem, however, suffer from the issues of generalization and scalability. To overcome these challenges, we propose a method that uses Collision Probability (CP) to help the robot navigate safely through crowds. The inclusion of CP in the observation space gives the robot a sense of the level of danger of the moving crowd. The robot will navigate through the crowd when it appears safe but will take a detour when the crowd is moving aggressively. By focusing on the most dangerous obstacle, the robot will not be confused when the crowd density is high, ensuring scalability of the model. Our approach was developed using deep reinforcement learning (DRL) and trained using the Gazebo simulator in a non-cooperative crowd environment with obstacles moving at randomized speeds and directions. We then evaluated our model on four different crowd-behavior scenarios with varying densities of crowds. The results shown that our method achieved a 100% success rate in all test settings. We compared our approach with a current state-of-the-art DRLbased approach, and our approach has performed significantly better. Importantly, our method is highly generalizable and requires no fine-tuning after being trained once. We further demonstrated the crowd navigation capability of our model in real-world tests."}, "cited_paper_content": {"title": "Mapless Navigation Among Dynamics With Social-Safety-Awareness: A Reinforcement Learning Approach From 2D Laser Scans", "abstract": "We propose a method to tackle the problem of mapless collision-avoidance navigation where humans are present using 2D laser scans. Our proposed method uses ego-safety to measure collision from the robot's perspective while social-safety to measure the impact of our robot's actions on surrounding pedestrians. Specifically, the social-safety part predicts the intrusion impact of our robot's action into the interaction area with surrounding humans. We train the policy using reinforcement learning on a simple simulator and directly evaluate the learned policy in Gazebo and real robot tests. Experiments show the learned policy can be smoothly transferred without any fine tuning. We observe that our method demonstrates time-efficient path planning behavior with high success rate in mapless navigation tasks. Furthermore, we test our method in a navigation among dynamic crowds task considering both low and high volume traffic. Our learned policy demonstrates cooperative behavior that actively drives our robot into traffic flows while showing respect to nearby pedestrians. Evaluation videos are at this https URL"}, "keywords": ["robot"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Likewise, higher crowd density (more dangerous) resulted in longer arrival time. Exceptions were seen in the ahead crowd behavior, where the arrival times with fast moving obstacles ahead were shorter than with slow moving obstacles. The fast moving obstacles were traveling at a speed close to the speed of the robot. In this case, when the obstacles were moving fast ahead of the robot, there was very little chance of the robot being confronted by the obstacles. The ahead environments were quite safe. Consequently, there were very few safety violations as seen from the high ego and social scores in the results of ahead crowd behavior in Fig. 4. Our method shares a similar approach with the work of #REFR, which uses ego-safety and social-safety to measure collision and the impact of robot's actions on surrounding pedestrians.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method in this study uses ego-safety and social-safety to measure collision and predict intrusion impact, respectively, resulting in a time-efficient path planning behavior with a high success rate in mapless navigation tasks, as demonstrated in #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method for mapless collision-avoidance navigation using 2D laser scans and reinforcement learning, as described in #REFR, could be a promising solution for the challenges faced by robots navigating through crowded environments.", "given_citation_intent": "result", "given_keywords": ["robot"]}]}
{"citing_id": "2304.12876v1", "cited_id": "1902.06705", "section_title": "Advanced Guided-Lfi", "citation": "First, we can notice that experimental and simulation results are almost similar, meaning that we can guide our LFI with high reliability and confidence #REFR .", "text_before_citation": ["For that purpose, we need to put to the test that LFI reach (near) identical performance than what expected by simulations.", "We ran a BSCA simulation (in Python) over all the weight columns and bit lines that pointed out the MSB of the second column weight as the most sensitive.", "Therefore, contrary to the previous experiments, the laser source was triggered only when the 20 most sensitive weights were read from the Flash.", "The laser location was set accordingly (X = 760 \u00b5m) and the power increased to 360 mW to ensure a higher success rate on weights stored in distant addresses.", "The blue curve in Fig.5b represents our experimental results (mean accuracy over 100 inferences) while the red one is the BSCA simulations for the MSB."], "text_after_citation": ["For an adversarial budget of only 5 bit-sets (0.1% faulted bits) the embedded model accuracy drops to 39% which represents a significant loss and a strong integrity impact compared to the nominal performance of 92%.", "Moreover, after 10 bit-sets (accuracy to 25%), the most effective faults have been injected and the accuracy did not decrease anymore.", "In a security evaluation context, this observation positions the level of robustness of the model according to the adversarial budget."], "citing_paper_content": {"title": "Evaluation Of Parameter-Based Attacks Against Embedded Neural Networks With Laser Injection", "abstract": "Upcoming certification actions related to the security of machine learning (ML) based systems raise major evaluation challenges that are amplified by the large-scale deployment of models in many hardware platforms. Until recently, most of research works focused on API-based attacks that consider a ML model as a pure algorithmic abstraction. However, new implementation-based threats have been revealed, emphasizing the urgency to propose both practical and simulation-based methods to properly evaluate the robustness of models. A major concern is parameter-based attacks (such as the Bit-Flip Attack-BFA) that highlight the lack of robustness of typical deep neural network models when confronted by accurate and optimal alterations of their internal parameters stored in memory. Setting in a security testing purpose, this work practically reports, for the first time, a successful variant of the BFA on a 32-bit Cortex-M microcontroller using laser fault injection. It is a standard fault injection means for security evaluation, that enables to inject spatially and temporally accurate faults. To avoid unrealistic brute-force strategies, we show how simulations help selecting the most sensitive set of bits from the parameters taking into account the laser fault model."}, "cited_paper_content": {"title": "On Evaluating Adversarial Robustness", "abstract": "Correctly evaluating defenses against adversarial examples has proven to be extremely difficult. Despite the significant amount of recent work attempting to design defenses that withstand adaptive attacks, few have succeeded; most papers that propose defenses are quickly shown to be incorrect. ::: We believe a large contributing factor is the difficulty of performing security evaluations. In this paper, we discuss the methodological foundations, review commonly accepted best practices, and suggest new methods for evaluating defenses to adversarial examples. We hope that both researchers developing defenses as well as readers and reviewers who wish to understand the completeness of an evaluation consider our advice in order to avoid common pitfalls."}, "keywords": ["LFI", "high reliability"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To avoid unrealistic brute-force strategies, we show how simulations help selecting the most sensitive set of bits from the parameters taking into account the laser fault model. Following the best practices for evaluating defenses against adversarial examples proposed by #REFR, we hope that our advice will help researchers developing defenses as well as readers and reviewers who wish to understand the completeness of an evaluation consider our approach in order to avoid common pitfalls.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of the manuscript acknowledge the difficulty of evaluating defenses against adversarial examples, as highlighted in the reference paper #REFR, and propose practical and simulation-based methods to properly evaluate the robustness of models against parameter-based attacks.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The successful implementation of the Bit-Flip Attack on a 32-bit Cortex-M microcontroller using laser fault injection, as reported in this work, highlights the lack of robustness of typical deep neural network models when confronted by accurate and optimal alterations of their internal parameters stored in memory, which is consistent with the findings in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": ["LFI", "high reliability"]}]}
{"citing_id": "2304.00953v1", "cited_id": "1903.05714", "section_title": "I. Introduction", "citation": "State-of-the-Art commercial platforms integrate Intel Optane DC Persistent Memory (DCPM) modules along with DRAM, leading to heterogeneous memory systems #REFR .", "text_before_citation": ["The memory system is one of the main components that limit the scalability and contribute to the energy consumption of supercomputers #OTHEREFR .", "The integration of more DRAM modules to enable more complex simulations, analytics and effective in-memory processing has negative impact on the sustainability and maintenance costs of supercomputing centres.", "In particular, despite the low access latency of traditional DRAM technologies, the increased leakage and refresh power requirements limit DRAM scalability and introduce a significant challenge towards reaching exascale performance.", "In order to overcome DRAM limitations, non-volatile memory (NVM) technologies have been introduced, such as the 3D-XPoint, which is a subclass of the Phase-Change Memories (PCM) #OTHEREFR , Spin-Transfer Torque RAM (STT-RAM) #OTHEREFR and Resistive RAM (ReRAM) #OTHEREFR ."], "text_after_citation": ["For instance, the upcoming Aurora exascale supercomputer employs the DAOS storage architecture, which integrates a complex memory and storage hierarchy, including Intel Optane DCPM modules #OTHEREFR .", "This work has been partially funded by EU Horizon 2020 program under grant agreement No 101015922 AI@EDGE (https://aiatedge.eu/).", "These emerging memory technologies provide higher density than DRAM, enabling increased aggregate memory capacities with fewer nodes, having positive impact on the energy consumption, resilience and sustainability.", "Additionally, the data persistence features of the NVM technologies can be used to provide fault tolerance support to applications.", "On the other hand, the Optane DCPM provides, in general, higher access latency and lower bandwidth compared to DRAM #OTHEREFR , #OTHEREFR , #OTHEREFR ."], "citing_paper_content": {"title": "Energy Consumption Evaluation Of Optane Dc Persistent Memory For Indexing Data Structures", "abstract": "The Intel Optane DC Persistent Memory (DCPM) is an attractive novel technology for building storage systems for data intensive HPC applications, as it provides lower cost per byte, low standby power and larger capacities than DRAM, with comparable latency. This work provides an in-depth evaluation of the energy consumption of the Optane DCPM, using wellestablished indexes specifically designed to address the challenges and constraints of the persistent memories. We study the energy efficiency of the Optane DCPM for several indexing data structures and for the LevelDB key-value store, under different types of YCSB workloads. By integrating an Optane DCPM in a memory system, the energy drops by 71.2% and the throughput increases by 37.3% for the LevelDB experiments, compared to a typical SSD storage solution."}, "cited_paper_content": {"title": "Basic Performance Measurements Of The Intel Optane Dc Persistent Memory Module", "abstract": "Scalable nonvolatile memory DIMMs will finally be commercially available with the release of the Intel Optane DC Persistent Memory Module (or just \"Optane DC PMM\"). This new nonvolatile DIMM supports byte-granularity accesses with access times on the order of DRAM, while also providing data storage that survives power outages. This work comprises the first in-depth, scholarly, performance review of Intel's Optane DC PMM, exploring its capabilities as a main memory device, and as persistent, byte-addressable memory exposed to user-space applications. This report details the technologies performance under a number of modes and scenarios, and across a wide variety of macro-scale benchmarks. Optane DC PMMs can be used as large memory devices with a DRAM cache to hide their lower bandwidth and higher latency. When used in this Memory (or cached) mode, Optane DC memory has little impact on applications with small memory footprints. Applications with larger memory footprints may experience some slow-down relative to DRAM, but are now able to keep much more data in memory. When used under a file system, Optane DC PMMs can result in significant performance gains, especially when the file system is optimized to use the load/store interface of the Optane DC PMM and the application uses many small, persistent writes. For instance, using the NOVA-relaxed NVMM file system, we can improve the performance of Kyoto Cabinet by almost 2x. Optane DC PMMs can also enable user-space persistence where the application explicitly controls its writes into persistent Optane DC media. In our experiments, modified applications that used user-space Optane DC persistence generally outperformed their file system counterparts. For instance, the persistent version of RocksDB performed almost 2x faster than the equivalent program utilizing an NVMM-aware file system."}, "keywords": ["Persistent Memory (DCPM)"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In order to overcome DRAM limitations, non-volatile memory (NVM) technologies have been introduced, such as the 3D-XPoint, which is a subclass of the Phase-Change Memories (PCM) #OTHEREFR, Spin-Transfer Torque RAM (STT-RAM) #OTHEREFR and Resistive RAM (ReRAM) #OTHEREFR. Scalable nonvolatile memory DIMMs are also commercially available, such as the Intel Optane DC Persistent Memory Module, which provides byte-granularity accesses with access times on the order of DRAM, while also providing data storage that survives power outages #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the limitations of DRAM, non-volatile memory (NVM) technologies have been introduced, such as 3D-XPoint, Spin-Transfer Torque RAM (STT-RAM), Resistive RAM (ReRAM) #OTHEREFR, and the Intel Optane DC Persistent Memory Module, which provides byte-granularity accesses with access times on the order of DRAM, while also providing data storage that survives power outages #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Non-volatile memory (NVM) technologies, such as Persistent Memory (DCPM) #REFR, have been introduced to overcome DRAM limitations and enable more complex simulations, analytics, and effective in-memory processing, which contribute to the energy consumption of supercomputers.", "given_citation_intent": "background", "given_keywords": ["Persistent Memory (DCPM)"]}]}
{"citing_id": "2303.01241v1", "cited_id": "1908.01843", "section_title": "Evaluation Results", "citation": "In addition, Figure 5 shows that NLI-SAN achieves similar performance with KGAT , while having a simpler architecture for the application, and outperforms GEAR #REFR Table 1 : Document retrieval on the PANACEA dataset.", "text_before_citation": ["Fact-Checking We investigate the performance of our system in document retrieval and veracity assessment in (Arana-Catania et al., 2022) .", "Table 1 shows that combining BM25 and MonoT5 is the most effective approach for document retrieval of the selected techniques."], "text_after_citation": ["Rumour Detection As shown in Figure 6 , our comparison #OTHEREFR among various models, including branchLSTM #OTHEREFR , TD-RvNN #OTHEREFR , BiGCN #OTHEREFR , SAVED (Dougrez-Lewis et al., 2021) and BERT #OTHEREFR for rumour detection evaluated on Twitter15, Twitter16 and PHEME #OTHEREFR , reveals there is no model that always performs the best.", "Although state-of-the-art models can achieve high accuracy on their training datasets, such performance drops quickly while evaluating on a different dataset #OTHEREFR .", "Due to the limitation of existing models in generalisation, users should interpret this result with caution as the system cannot guarantee output correctness.", "This paper introduces a web-based system on factchecking and rumour detection based on novel natural language processing models for COVID-19 misinformation detection.", "Going forward, we will keep updating the data and explore other methods for misinformation identification to improve the current system and introduce more functions to the system as part of our continuing efforts to support the general public to identify misinformation."], "citing_paper_content": {"title": "Panacea: An Automated Misinformation Detection System On Covid-19", "abstract": "In this demo, we introduce a web-based misinformation detection system PANACEA on COVID-19 related claims, which has two modules, fact-checking and rumour detection. Our fact-checking module, which is supported by novel natural language inference methods with a self-attention network, outperforms state-ofthe-art approaches. It is also able to give automated veracity assessment and ranked supporting evidence with the stance towards the claim to be checked. In addition, PANACEA adapts the bi-directional graph convolutional networks model, which is able to detect rumours based on comment networks of related tweets, instead of relying on the knowledge base. This rumour detection module assists by warning the users in the early stages when a knowledge base may not be available."}, "cited_paper_content": {"title": "Gear: Graph-Based Evidence Aggregating And Reasoning For Fact Verification", "abstract": "Fact verification (FV) is a challenging task which requires to retrieve relevant evidence from plain text and use the evidence to verify given claims. Many claims require to simultaneously integrate and reason over several pieces of evidence for verification. However, previous work employs simple models to extract information from evidence without letting evidence communicate with each other, e.g., merely concatenate the evidence for processing. Therefore, these methods are unable to grasp sufficient relational and logical information among the evidence. To alleviate this issue, we propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information. We further employ BERT, an effective pre-trained language representation model, to improve the performance. Experimental results on a large-scale benchmark dataset FEVER have demonstrated that GEAR could leverage multi-evidence information for FV and thus achieves the promising result with a test FEVER score of 67.10%. Our code is available at this https URL."}, "keywords": ["PANACEA dataset", "Document retrieval"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our fact-checking module, which outperforms state-of-the-art approaches, is supported by novel natural language inference methods with a self-attention network (Arana-Catania et al., 2022). It is also able to give automated veracity assessment and ranked supporting evidence with the stance towards the claim to be checked.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our fact-checking module outperforms state-of-the-art approaches by leveraging multi-evidence information for verification, achieving a test FEVER score of 67.10% (Gear et al., #REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For document retrieval on the PANACEA dataset, previous work has shown that simple models are insufficient for extracting information from evidence, and thus, GEAR (#REFR) was proposed to enable information transfer on a fully-connected evidence graph and collect multi-evidence information using different aggregators, achieving a promising FEVER score of 67.10%.", "given_citation_intent": "result", "given_keywords": ["PANACEA dataset", "Document retrieval"]}]}
{"citing_id": "2304.07567v1", "cited_id": "1607.06215", "section_title": "Introduction", "citation": "To address this problem, many approaches have been designed to minimize the representation divergence using the alignment annotations #REFR .", "text_before_citation": ["In real-world applications, objects can always be represented with multiple modalities.", "For example, articles are with image and text modalities, videos are with image and audio modalities, etc.", "To relate information from multiple modalities, an important task in multimodal machine learning is cross-modal retrieval, which aims to search one modal instances for given other modal instances.", "In this paper, we focus primarily, but not exclusively, on two modalities: visual signals and natural language.", "Actually, the main challenge of vision-language retrieval is the semantic divergence of heterogeneous data."], "text_after_citation": ["Initial approaches are always dual stream models, which typically build independent embedding network for each modality and constrain the consistency of cross-modal output representations with various similarity measures.", "For example, #OTHEREFR constrained the consistency of global representations between two modalities.", "Furthermore, to consider the fine-grained similarity, #OTHEREFR turned to measure the consistency of regional representations, #OTHEREFR developed the graph-level consistency by considering both regions and edges.", "It is notable that vision and language encoders can adopt either shallow or deep models depending on the design.", "With the development of vision-language Transformer, single-stream approaches are proposed #OTHEREFR , in which the two modalities interact from the input level."], "citing_paper_content": {"title": "Covlr: Coordinating Cross-Modal Consistency And Intra-Modal Structure For Vision-Language Retrieval", "abstract": "Current vision-language retrieval aims to perform cross-modal instance search, in which the core idea is to learn the consistent visionlanguage representations. Although the performance of cross-modal retrieval has greatly improved with the development of deep models, we unfortunately find that traditional hard consistency may destroy the original relationships among single-modal instances, leading the performance degradation for single-modal retrieval. To address this challenge, in this paper, we experimentally observe that the vision-language divergence may cause the existence of strong and weak modalities, and the hard cross-modal consistency cannot guarantee that strong modal instances' relationships are not affected by weak modality, resulting in the strong modal instances' relationships perturbed despite learned consistent representations. To this end, we propose a novel and directly Coordinated Vision-Language Retrieval method (dubbed CoVLR), which aims to study and alleviate the desynchrony problem between the cross-modal alignment and single-modal cluster-preserving tasks. CoVLR addresses this challenge by developing an effective meta-optimization based strategy, in which the cross-modal consistency objective and the intra-modal relation preserving objective are acted as the meta-train and meta-test tasks, thereby CoVLR encourages both tasks to be optimized in a coordinated way. Consequently, we can simultaneously insure cross-modal consistency and intra-modal structure. Experiments on different datasets validate CoVLR can improve single-modal retrieval accuracy whilst preserving crossmodal retrieval capacity compared with the baselines. CCS CONCEPTS \u2022 Computing methodologies \u2192 Supervised learning by classification; \u2022 Information systems \u2192 Retrieval tasks and goals."}, "cited_paper_content": {"title": "A Comprehensive Survey On Cross-Modal Retrieval", "abstract": "In recent years, cross-modal retrieval has drawn much attention due to the rapid growth of multimodal data. It takes one type of data as the query to retrieve relevant data of another type. For example, a user can use a text to retrieve relevant pictures or videos. Since the query and its retrieved results can be of different modalities, how to measure the content similarity between different modalities of data remains a challenge. Various methods have been proposed to deal with such a problem. In this paper, we first review a number of representative methods for cross-modal retrieval and classify them into two main groups: 1) real-valued representation learning, and 2) binary representation learning. Real-valued representation learning methods aim to learn real-valued common representations for different modalities of data. To speed up the cross-modal retrieval, a number of binary representation learning methods are proposed to map different modalities of data into a common Hamming space. Then, we introduce several multimodal datasets in the community, and show the experimental results on two commonly used multimodal datasets. The comparison reveals the characteristic of different kinds of cross-modal retrieval methods, which is expected to benefit both practical applications and future research. Finally, we discuss open problems and future research directions."}, "keywords": ["representation divergence"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To relate information from multiple modalities, an important task in multimodal machine learning is cross-modal retrieval, which aims to search one modal instances for given other modal instances. In this paper, we focus primarily, but not exclusively, on two modalities: visual signals and natural language. Actually, the main challenge of vision-language retrieval is the semantic divergence of heterogeneous data. A Comprehensive Survey On Cross-Modal Retrieval #REFR provides a review of representative methods for cross-modal retrieval and classifies them into two main groups: real-valued representation learning and binary representation learning.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of semantic divergence in cross-modal retrieval, various methods have been proposed, including real-valued representation learning and binary representation learning #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the semantic divergence of heterogeneous data in vision-language retrieval, various methods have been proposed to deal with the representation divergence challenge, including real-valued representation learning and binary representation learning #REFR.", "given_citation_intent": "method", "given_keywords": ["representation divergence"]}]}
{"citing_id": "2303.00147v1", "cited_id": "1209.0194", "section_title": "Upper Bound", "citation": "As with any type of planar straight-line graph, the number of linear forests on O(k) points is singly exponential in k #REFR , so P [K] can be encoded with O(k) bits of information.", "text_before_citation": ["Q can be encoded by specifying its size and the subset of L \u2229 S of that size, out of |Q| possibilities, so by Lemma 11 the number of bits needed to specify it is O log n + k + k log(n/k) .", "(Both the log n term and the +1 in the statement of the lemma are included to handle the case when k = 0 but |Q| > 0.", "Lemma 11 applies only when k \u2264 n/2 but for larger k the bound to be proven is superlinear and the result is immediate.)", "\u2022 For each point in Q, a specification of whether it has a neighbor in L, and if so in which direction. This takes O(k) bits of information.", "\u2022 The induced subgraph P [K \u222a Q], a linear forest using only the points in K \u222a Q, and omitting the edges of P that lie entirely within L."], "text_after_citation": ["Then P may be recovered by combining the induced subgraph P [K \u222a Q] with segments of L starting and ending at points of Q and continuing in the specified direction from each of these points.", "All pieces of this encoding add up to the stated bound on the number of bits needed to encode the entire path."], "citing_paper_content": {"title": "Non-Crossing Hamiltonian Paths And Cycles In Output-Polynomial Time", "abstract": "We show that, for planar point sets, the number of non-crossing Hamiltonian paths is polynomially bounded in the number of non-crossing paths, and the number of non-crossing Hamiltonian cycles (polygonalizations) is polynomially bounded in the number of surrounding cycles. As a consequence, we can list the non-crossing Hamiltonian paths or the polygonalizations, in time polynomial in the output size, by filtering the output of simple backtracking algorithms for non-crossing paths or surrounding cycles respectively. To prove these results we relate the numbers of non-crossing structures to two easily-computed parameters of the point set: the minimum number of points whose removal results in a collinear set, and the number of points interior to the convex hull. These relations also lead to polynomial-time approximation algorithms for the numbers of structures of all four types, accurate to within a constant factor of the logarithm of these numbers."}, "cited_paper_content": {"title": "Counting Plane Graphs: Cross-Graph Charging Schemes", "abstract": "We study cross-graph charging schemes for graphs drawn in the plane. These are charging schemes where charge is moved across vertices of different graphs. Such methods have been recently applied to obtain various properties of triangulations that are embedded over a fixed set of points in the plane. We show how this method can be generalized to obtain results for various other types of graphs that are embedded in the plane. Specifically, we obtain a new bound of $O^*(187.53^N)$ (where the $O^*()$ notation hides polynomial factors) for the maximum number of crossing-free straight-edge graphs that can be embedded over any specific set of $N$ points in the plane (improving upon the previous best upper bound $207.85^N$ in Hoffmann et al.). We also derive upper bounds for numbers of several other types of plane graphs (such as connected and bi-connected plane graphs), and obtain various bounds on expected vertex-degrees in graphs that are uniformly chosen from the set of all crossing-free straight-edge graphs that can be embedded over a specific point set. We then show how to apply the cross-graph charging-scheme method for graphs that allow certain types of crossings. Specifically, we consider graphs with no set of $k$ pairwise-crossing edges (more commonly known as $k$-quasi-planar graphs). For $k=3$ and $k=4$, we prove that, for any set $S$ of $N$ points in the plane, the number of graphs that have a straight-edge $k$-quasi-planar embedding over $S$ is only exponential in $N$."}, "keywords": ["linear forests", "planar straight-line graph"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The cross-graph charging-scheme method proposed by Hoffmann et al. #REFR can be generalized to obtain results for various types of graphs embedded in the plane, including a new bound for the maximum number of crossing-free straight-edge graphs that can be embedded over any specific set of points in the plane.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The method proposed in this manuscript can be generalized to obtain results for various other types of graphs that are embedded in the plane, as shown in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' method of obtaining a linear forest using only the points in K \u222a Q, and omitting the edges of P that lie entirely within L, can be generalized to obtain results for various other types of graphs that are embedded in the plane, as shown in #REFR.", "given_citation_intent": "background", "given_keywords": ["linear forests", "planar straight-line graph"]}]}
{"citing_id": "2303.09732v1", "cited_id": "1701.04082", "section_title": "C Omitted Evaluation Results", "citation": "As a result, RIGA has the similar vulnerability of #REFR as their watermark extraction procedures only differ into the type of extractor, which is also inexecutable due to the incompatible input dimension of the trained extractor for RIGA. Evaluation Results.", "text_before_citation": ["Meanwhile, they replace the watermark extractor, which has been previously implemented with a predefined linear transformation #OTHEREFR , with a learnable fully-connected neural network (FCN), for boosting the encoding capacity of watermarking messages. Similar to Uchida et al.", "#OTHEREFR , the watermark-related weights are first selected from the target model and then projected to a binary string s via the FCN-based extractor during the ownership verification procedure.", "Discussion.", "Simply replacing the linear transformation matrix in Uchida et al.", "#OTHEREFR to a learnable extractor can not completely eliminate the removal threats from our attack based on model structural obfuscation."], "text_after_citation": ["We follow their evaluation settings to watermark Inception-V3 trained on CelebA, which achieves 95.90% accuracy and 0% BER [74] .", "We employ the default setups that the watermark is embedded into the third convolutional layer of the target model and the extractor is a multiple layer perceptron with one hidden layer.", "With our attack framework, we successfully inhibit the ownership verification of RIGA without any loss to the utility of victim model.", "Even applying the error-handling mechanisms, the BER of extracted message is increased to an unacceptable level.", "For example, when we utilize Max-First error-handling to obtain the embedded watermark, the BER is increased to 76.04% when we inject the dummy neurons generated via NeuronSplit. Passport-aware Normalization. Zhang et al."], "citing_paper_content": {"title": "Rethinking White-Box Watermarks On Deep Learning Models Under Neural Structural Obfuscation", "abstract": "Copyright protection for deep neural networks (DNNs) is an urgent need for AI corporations. To trace illegally distributed model copies, DNN watermarking is an emerging technique for embedding and verifying secret identity messages in the prediction behaviors or the model internals. Sacrificing less functionality and involving more knowledge about the target DNN, the latter branch called white-box DNN watermarking is believed to be accurate, credible and secure against most known watermark removal attacks, with emerging research efforts in both the academy and the industry. In this paper, we present the first systematic study on how the mainstream white-box DNN watermarks are commonly vulnerable to neural structural obfuscation with dummy neurons, a group of neurons which can be added to a target model but leave the model behavior invariant. Devising a comprehensive framework to automatically generate and inject dummy neurons with high stealthiness, our novel attack intensively modifies the architecture of the target model to inhibit the success of watermark verification. With extensive evaluation, our work for the first time shows that nine published watermarking schemes require amendments to their verification procedures."}, "cited_paper_content": {"title": "Embedding Watermarks Into Deep Neural Networks", "abstract": "Significant progress has been made with deep neural networks recently. Sharing trained models of deep neural networks has been a very important in the rapid progress of research and development of these systems. At the same time, it is necessary to protect the rights to shared trained models. To this end, we propose to use digital watermarking technology to protect intellectual property and detect intellectual property infringement in the use of trained models. First, we formulate a new problem: embedding watermarks into deep neural networks. Second, we propose a general framework for embedding a watermark in model parameters, using a parameter regularizer. Our approach does not impair the performance of networks into which a watermark is placed because the watermark is embedded while training the host network. Finally, we perform comprehensive experiments to reveal the potential of watermarking deep neural networks as the basis of this new research effort. We show that our framework can embed a watermark during the training of a deep neural network from scratch, and during fine-tuning and distilling, without impairing its performance. The embedded watermark does not disappear even after fine-tuning or parameter pruning; the watermark remains complete even after 65% of parameters are pruned."}, "keywords": ["watermark extraction procedures"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Meanwhile, they replace the watermark extractor, which has been previously implemented with a predefined linear transformation #OTHEREFR , with a learnable fully-connected neural network (FCN), for boosting the encoding capacity of watermarking messages. Similar to Uchida et al. #OTHEREFR , the watermark-related weights are first selected from the target model and then projected to a binary string s via the FCN-based extractor during the ownership verification procedure. Discussion. Simply replacing the linear transformation matrix in Uchida et al. (2017) with a learnable extractor can not completely eliminate the removal threats from our attack based on model structural obfuscation. To address this issue, embedding watermarks into deep neural networks using digital watermarking technology has been proposed in the literature (Chen et al., 2018).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' proposed framework for embedding watermarks into deep neural networks #REFR achieved impressive results, as the embedded watermark remained complete even after fine-tuning or parameter pruning, according to their comprehensive experiments.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' learnable watermark extraction procedures #REFR show promising results in resisting model structural obfuscation attacks, which is a significant improvement over the previous linear transformation-based methods.", "given_citation_intent": "result", "given_keywords": ["watermark extraction procedures"]}]}
{"citing_id": "2305.02656v1", "cited_id": "1905.00258", "section_title": "A. Previous Work", "citation": "In #REFR , a decentralized adaptive routing scheme has been developed, in which the imperfection of quantum memories is taken into account.", "text_before_citation": ["Quantum entanglement routing has been the focus of many works in the past few years.", "A design of an optimal routing scheme has been presented in #OTHEREFR , with the end-toend entanglement rate was set as the optimality figure of merit.", "In #OTHEREFR , the authors have presented a remote entanglement distribution scheme for linear repeater chains, where an optimal route maximizing the end-to-end entanglement is determined alongside with the optimal sequence of the entanglement swaps.", "Distributed entanglement routing algorithms, with latency taken into account has been the purpose of #OTHEREFR .", "The problem of optimizing end-to-end entanglement in a many source-destination scenario has been studied in details as a multicommodity flow problem in #OTHEREFR ."], "text_after_citation": ["A multipath routing approach for multiple end-to-end entanglement has been thoroughly investigated in #OTHEREFR .", "In #OTHEREFR , the authors handled the case where quantum repeaters are allowed to perform quantum encoding, where it has been shown that the later increases drastically the end-toend entanglement rates with respect to usual protocols.", "This has been recently experimentally investigated in NV centers in #OTHEREFR .", "The effect of this type of intermediate encoding on end-to-end key rate generation in QKD has been studied in #OTHEREFR .", "For Multipartite entanglement generation and distribution in quantum networks relying on a central node connected by EPR pairs to the remote clients has been the focus of #OTHEREFR ."], "citing_paper_content": {"title": "The Quantum Internet: An Efficient Stabilizer States Distribution Scheme", "abstract": "Quantum networks constitute a major part of quantum technologies. They will boost distributed quantum computing drastically by providing a scalable modular architecture of quantum chips, or by establishing an infrastructure for measurement based quantum computing. Moreover, they will provide the backbone of the future quantum internet, allowing for high margins of security. Interestingly, the advantages that the quantum networks would provide for communications, rely on entanglement distribution, which suffers from high latency in protocols based on Bell pair distribution and bipartite entanglement swapping. Moreover, the designed algorithms for multipartite entanglement routing suffer from intractability issues making them unsolvable exactly in polynomial time. In this paper, we investigate a new approach for graph states distribution in quantum networks relying inherently on local quantum coding-LQC-isometries and on multipartite states transfer. Additionally, single-shot bounds for stabilizer states distribution are provided. Analogously to network coding, these bounds are shown to be achievable if appropriate isometries/stabilizer codes in relay nodes are chosen, which induces a lower latency entanglement distribution. As a matter of fact, the advantages of the protocol for different figures of merit of the network are provided."}, "cited_paper_content": {"title": "Opportunistic Entanglement Distribution For The Quantum Internet", "abstract": "Quantum entanglement is a building block of the entangled quantum networks of the quantum Internet. A fundamental problem of the quantum Internet is entanglement distribution. Since quantum entanglement will be fundamental to any future quantum networking scenarios, the distribution mechanism of quantum entanglement is a critical and emerging issue in quantum networks. Here we define the method of opportunistic entanglement distribution for the quantum Internet. The opportunistic model defines distribution sets that are aimed to select those quantum nodes for which the cost function picks up a local minimum. The cost function utilizes the error patterns of the local quantum memories and the predictability of the evolution of the entanglement fidelities. Our method provides efficient entanglement distributing with respect to the actual statuses of the local quantum memories of the node pairs. The model provides an easily-applicable, moderate-complexity solution for high-fidelity entanglement distribution in experimental quantum Internet scenarios."}, "keywords": ["quantum memories"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors have defined a method of opportunistic entanglement distribution for the quantum Internet, which provides efficient entanglement distributing with respect to the actual statuses of the local quantum memories of the node pairs (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors have presented an opportunistic entanglement distribution method for the quantum internet in #REFR, which defines distribution sets based on the error patterns of local quantum memories and the predictability of entanglement fidelities, providing an efficient solution for high-fidelity entanglement distribution in experimental quantum internet scenarios.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The method of opportunistic entanglement distribution for the quantum Internet, presented in #REFR, provides an efficient solution for entanglement distribution by utilizing the error patterns of the local quantum memories and the predictability of the evolution of the entanglement fidelities.", "given_citation_intent": "method", "given_keywords": ["quantum memories"]}]}
{"citing_id": "2304.00974v1", "cited_id": "1508.04983", "section_title": "A. Related Works", "citation": "In #REFR , the robust stabilization of the FM algorithm when uncertainty exists in the disturbance is given by the linear matrix inequality (LMI).", "text_before_citation": ["It is widely used in various fields, such as the optimization design in the chemical industry #OTHEREFR , power control #OTHEREFR , and resource allocation #OTHEREFR , #OTHEREFR .", "Since GP contains and optimizes only positive parameters, it plays a crucial role in the positive system #OTHEREFR . GP-based algorithms generally are robust and time-efficient in solving.", "As shown in #OTHEREFR , the optimization framework for parameter tuning problems constrained by H 2 norm, H \u221e norm, Hankel norm or Schattern p-norm can be established and solved efficiently via GP.", "For the uncertainty of the log-quantized feedback errors in the FM algorithm, the stabilization problem for bounded-input bounded-output systems is investigated in #OTHEREFR .", "The refinement of the quantization level enables the cellular network to obtain a better QoS."], "text_after_citation": ["Compared with LMI, GP allows greater scalability since it can solve more complex and larger-scale networks with higher accuracy.", "Therefore, the robust stabilization and resource allocation problems of the FM algorithm with structured uncertainties are further investigated through GP in #OTHEREFR .", "In this work, we propose a convex optimization framework, specifically GP, for the robust stabilization problem under structured uncertainties of the discrete-time FM algorithm.", "The GP formulation is extended to an iterative algorithm to address the resilient stabilization problem of cellular network QoS under the threat of addingedge attacks, that is, to determine the precise GNE of the two subnetwork policymakers.", "The attacker can be regarded as the worst-case structured uncertainty in this GP framework with norm constraints."], "citing_paper_content": {"title": "Optimal Resource Allocation Between Two Nonfully Cooperative Wireless Networks Under Malicious Attacks: A Gestalt Game Perspective", "abstract": "In this paper, the problem of seeking optimal distributed resource allocation (DRA) policies on cellular networks in the presence of an unknown malicious adding-edge attacker is investigated. This problem is described as the games of games (GoG) model. Specifically, two subnetwork policymakers constitute a Nash game, while the confrontation between each subnetwork policymaker and the attacker is captured by a Stackelberg game. First, we show that the communication resource allocation of cellular networks based on the Foschini-Miljanic (FM) algorithm can be transformed into a geometric program and be efficiently solved via convex optimization. Second, the upper limit of attack magnitude that can be tolerated by the network is calculated by the corresponding theory, and it is proved that the above geometric programming (GP) framework is solvable within the attack bound, that is, there exists a Gestalt Nash equilibrium (GNE) in our GoG. Third, a heuristic algorithm that iteratively uses GP is proposed to identify the optimal policy profiles of both subnetworks, for which asymptotic convergence is also confirmed. Fourth, a greedy heuristic adding-edge strategy is developed for the attacker to determine the set of the most vulnerable edges. Finally, simulation examples illustrate that the proposed theoretical results are robust and can achieve the GNE. It is verified that the transmission gains and interference gains of all channels are well tuned within a limited budget, despite the existence of malicious attacks."}, "cited_paper_content": {"title": "A Convex Characterization Of Robust Stability For Positive And Positively Dominated Linear Systems", "abstract": "We provide convex necessary and sufficient conditions for the robust stability of linear positively dominated systems. In particular we show that the structured singular value is always equal to its convex upper bound for nonnegative matrices and we use this result to derive necessary and sufficient Linear Matrix Inequality (LMI) conditions for robust stability that involve only the system's static gain. We show how this approach can be applied to test the robust stability of the Foschini-Miljanic algorithm for power control in wireless networks in presence of uncertain interference."}, "keywords": ["FM algorithm", "robust stabilization"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As shown in #REFR, the Linear Matrix Inequality (LMI) conditions for robust stability of linear positively dominated systems can be efficiently derived via convex optimization, which can be applied to test the robust stability of the Foschini-Miljanic algorithm for power control in wireless networks in presence of uncertain interference.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The Foschini-Miljanic algorithm for power control in wireless networks under uncertain interference is shown to be robustly stable by using necessary and sufficient Linear Matrix Inequality (LMI) conditions derived from a convex characterization of robust stability for positive and positively dominated linear systems #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The FM algorithm has been widely used in power control, and its robust stabilization has been investigated in #REFR, which provides necessary and sufficient Linear Matrix Inequality (LMI) conditions for robust stability that involve only the system's static gain.", "given_citation_intent": "background", "given_keywords": ["FM algorithm", "robust stabilization"]}]}
{"citing_id": "2303.01668v1", "cited_id": "1801.01290", "section_title": "Experiments", "citation": "For DMControl, we collect the offline dataset in a similar way to the procedure to collect the Mixed dataset using SAC #REFR .", "text_before_citation": ["The Weak dataset is collected from the first 1M transitions generated by DQN.", "The Mixed dataset is obtained by concatenating multiple checkpoints evenly throughout the training of DQN.", "The quality of the dataset increases from Random to Mixed.", "We also evaluate the algorithms on datasets of different sizes.", "Larger datasets can be obtained by running the above procedure multiple times with different random seeds."], "text_after_citation": ["Baselines algorithms.", "In our experiments, we compare our algorithm with a wide range of previous algorithms including both sample-efficient RL algorithms and pretraining algorithms for RL.", "For Atari games, we incorporate the representation pretrained by RePreM with Rainbow #OTHEREFR in downstream tasks (except for dynamic prediction).", "The baseline algorithms include not only sample-efficient online RL algorithms (such as Rainbow, SimPLe #OTHEREFR", "2019] , data-effecient Rainbow/DER #OTHEREFR , DrQ #OTHEREFR , and SPR #OTHEREFR"], "citing_paper_content": {"title": "Reprem: Representation Pre-Training With Masked Model For Reinforcement Learning", "abstract": "Inspired by the recent success of sequence modeling in RL and the use of masked language model for pre-training, we propose a masked model for pre-training in RL, RePreM (Representation Pre-training with Masked Model), which trains the encoder combined with transformer blocks to predict the masked states or actions in a trajectory. RePreM is simple but effective compared to existing representation pretraining methods in RL. It avoids algorithmic sophistication (such as data augmentation or estimating multiple models) with sequence modeling and generates a representation that captures long-term dynamics well. Empirically, we demonstrate the effectiveness of RePreM in various tasks, including dynamic prediction, transfer learning, and sample-efficient RL with both value-based and actor-critic methods. Moreover, we show that RePreM scales well with dataset size, dataset quality, and the scale of the encoder, which indicates its potential towards big RL models."}, "cited_paper_content": {"title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning With A Stochastic Actor", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds."}, "keywords": ["Mixed dataset", "offline dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We also compare our RePreM method with state-of-the-art off-policy methods, such as soft actor-critic (#REFR), and demonstrate its superior performance in terms of sample efficiency and scalability on datasets of different sizes.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenges of high sample complexity and brittle convergence properties in deep reinforcement learning, the authors propose a soft actor-critic algorithm based on the maximum entropy reinforcement learning framework, achieving state-of-the-art performance on a range of continuous control benchmark tasks, as shown in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain the Mixed dataset, the authors concatenated multiple checkpoints evenly throughout the training of DQN, resulting in a higher quality offline dataset. This approach is similar to the one used in #REFR to achieve state-of-the-art performance on a range of continuous control benchmark tasks.", "given_citation_intent": "method", "given_keywords": ["Mixed dataset", "offline dataset"]}]}
{"citing_id": "2303.05798v1", "cited_id": "1806.06823", "section_title": "B.3. Domain Adaptation For Bci", "citation": "First, the data from the BCI Competition IV 2a are preprocessed using the code from #REFR available at https://github.com/MultiScale-BCI/IV-2a.", "text_before_citation": ["For both the optimization over particles and over transformations, we use geoopt #OTHEREFR with the Riemannian gradient descent. We now detail the hyperparameters and the procedure."], "text_after_citation": ["We applied a band-pass filter between 8 and 30 Hz.", "With these hyper-parameters, we get one regularized covariance matrix per subject.", "For all experiments, we report the results averaged over 5 runs.", "For the sliced discrepancies, we always use L = 500 projections which we draw only once a the beginning.", "When optimizing over particles, we used a learning rate of 1000 for the sliced methods and of 10 for Wasserstein and Sinkhorn."], "citing_paper_content": {"title": "Sliced-Wasserstein On Symmetric Positive Definite Matrices For M/Eeg Signals", "abstract": "When dealing with electro or magnetoencephalography records, many supervised prediction tasks are solved by working with covariance matrices to summarize the signals. Learning with these matrices requires using Riemanian geometry to account for their structure. In this paper, we propose a new method to deal with distributions of covariance matrices and demonstrate its computational efficiency on M/EEG multivariate time series. More specifically, we define a Sliced-Wasserstein distance between measures of symmetric positive definite matrices that comes with strong theoretical guarantees. Then, we take advantage of its properties and kernel methods to apply this distance to brain-age prediction from MEG data and compare it to state-of-the-art algorithms based on Riemannian geometry. Finally, we show that it is an efficient surrogate to the Wasserstein distance in domain adaptation for Brain Computer Interface applications."}, "cited_paper_content": {"title": "Fast And Accurate Multiclass Inference For Mi-Bcis Using Large Multiscale Temporal And Spectral Features", "abstract": "Accurate, fast, and reliable multiclass classification of electroencephalography (EEG) signals is a challenging task towards the development of motor imagery brain-computer interface (MI-BCI) systems. We propose enhancements to different feature extractors, along with a support vector machine (SVM) classifier, to simultaneously improve classification accuracy and execution time during training and testing. We focus on the well-known common spatial pattern (CSP) and Riemannian covariance methods, and significantly extend these two feature extractors to multiscale temporal and spectral cases. The multiscale CSP features achieve 73.70$\\pm$15.90% (mean$\\pm$ standard deviation across 9 subjects) classification accuracy that surpasses the state-of-the-art method [1], 70.6$\\pm$14.70%, on the 4-class BCI competition IV-2a dataset. The Riemannian covariance features outperform the CSP by achieving 74.27$\\pm$15.5% accuracy and executing 9x faster in training and 4x faster in testing. Using more temporal windows for Riemannian features results in 75.47$\\pm$12.8% accuracy with 1.6x faster testing than CSP."}, "keywords": ["BCI Competition IV"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For both the optimization over particles and over transformations, we use geoopt #OTHEREFR with the Riemannian gradient descent, following the enhancements proposed in the reference paper for accurate and fast multiclass classification of EEG signals using multiscale temporal and spectral features.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the classification accuracy and execution time of electroencephalography (EEG) signals, the authors of this manuscript propose enhancements to different feature extractors, including the common spatial pattern (CSP) and Riemannian covariance methods, which are significantly extended to multiscale temporal and spectral cases, achieving state-of-the-art results with the Riemannian covariance features outperforming the CSP by executing 9x faster in training and 4x faster in testing, as reported in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed enhancements to the common spatial pattern and Riemannian covariance methods significantly improve classification accuracy and execution time during training and testing on the BCI Competition IV dataset, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": ["BCI Competition IV"]}]}
{"citing_id": "2303.15435v1", "cited_id": "1405.0312", "section_title": "Text-To-Image Watermarking Performance", "citation": "We apply generative models watermarked with 48-bit signatures on prompts of the MS-COCO #REFR validation set.", "text_before_citation": ["This section shows the potential of our method for detection and identification or images generated by a Stable-Diffusion-like model #OTHEREFR 2 ."], "text_after_citation": ["We evaluate detection and identification on the outputs, as illustrated in Figure 1 .", "We evaluate their robustness to different transformations applied to generated images: strong cropping (10% of the image remaining), brightness shift (strength factor 2.0), as well as a combination of crop 50%, brightness shift 1.5 and JPEG 80. This covers typical geometric and photometric edits (see Fig. 5 for visual examples).", "The performance is partly obtained from experiments and partly by extrapolating small-scale measurements."], "citing_paper_content": {"title": "The Stable Signature: Rooting Watermarks In Latent Diffusion Models", "abstract": "Generative image modeling enables a wide range of applications but raises ethical concerns about responsible deployment. This paper introduces an active strategy combining image watermarking and Latent Diffusion Models. The goal is for all generated images to conceal an invisible watermark allowing for future detection and/or identification. The method quickly fine-tunes the latent decoder of the image generator, conditioned on a binary signature. A pre-trained watermark extractor recovers the hidden signature from any generated image and a statistical test then determines whether it comes from the generative model. We evaluate the invisibility and robustness of the watermarks on a variety of generation tasks, showing that Stable Signature works even after the images are modified. For instance, it detects the origin of an image generated from a text prompt, then cropped to keep 10% of the content, with 90+% accuracy at a false positive rate below 10 \u22126. 1. Introduction Recent progress in generative modeling and natural language processing has made it easy to create and manipulate images in a photorealistic manner. For instance, DALL\u2022E 2 [60] or Stable Diffusion [64] generate images from text, which are often indistinguishable from real artworks. They have given birth to many image edition tools like ControlNet [100], Instruct-Pix2Pix [7], and others [13, 27, 67]. They are establishing themselves as creative tools for artists, designers, and the general public. While this is a great step forward for generative AI, it raises new ethical concerns. Indeed, their sophistication is such that it will soon be impossible to distinguish AI generations from real pictures. For example, a generated picture recently won an art competition [28]. Not being able to identify that images are generated by AI makes it difficult to remove them from certain platforms and to ensure their compliance with ethical standards. The lack of traceability also opens the door to new threats such as deep fakes, impersonation or copyright usurpation [8, 17]."}, "cited_paper_content": {"title": "Microsoft Coco: Common Objects In Context", "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."}, "keywords": ["generative models", "MS-COCO validation set"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "This section shows the potential of our method for detection and identification or images generated by a Stable-Diffusion-like model (Microsoft Coco: Common Objects In Context). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To detect and identify images generated by Stable-Diffusion-like models, the authors utilized a pre-trained watermark extractor and statistical test, as described in their previous work on Microsoft Coco dataset #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We fine-tuned the latent decoder of the image generator using a binary signature to conceal an invisible watermark in all generated images, and evaluated the invisibility and robustness of the watermarks on a variety of generation tasks, including MS-COCO validation set, showing the potential of our method for detection and identification of images generated by a Stable-Diffusion-like model #REFR.", "given_citation_intent": "method", "given_keywords": ["generative models", "MS-COCO validation set"]}]}
{"citing_id": "2303.17780v1", "cited_id": "1709.06182", "section_title": "Background", "citation": "Pre-trained language models (PTLMs) are neural networks that aim to learn the statistical patterns in programming languages #REFR .", "text_before_citation": [], "text_after_citation": ["PTLMs are first pre-trained with the next token prediction objective on a large-scale unlabeled code corpus.", "Given a code file, PTLMs are trained to predict the next token given some previous write a function to remove first and last occurrence of a given character from the string"], "citing_paper_content": {"title": "Towards Enhancing In-Context Learning For Code Generation", "abstract": "In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation. ICL does not require training. PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program. However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation. We refer to these studies as standard ICL. Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder. Compared to standard ICL, AceCoder has two novelties. (1) Example retrieval. It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them. (2) Guided Code Generation. It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs. The preliminary can help PTLMs understand requirements and guide the next code generation. We apply AceCoder to six PTLMs (e.g., Codex) and evaluate it on three public benchmarks using the Pass@k. Results show that AceCoder can significantly improve the performance of PTLMs on code generation. (1) In terms of Pass@1, AceCoder outperforms standard ICL by up to 79.7% and fine-tuned models by up to 171%. (2) AceCoder is effective in PTLMs with different sizes (e.g., 1B to 175B) and different languages (e.g., Python, Java, and JavaScript). (3) We investigate multiple choices of the intermediate preliminary. (4) We manually evaluate generated programs in three aspects and prove the superiority of AceCoder. (5) Finally, we discuss some insights about ICL for practitioners."}, "cited_paper_content": {"title": "A Survey Of Machine Learning For Big Code And Naturalness", "abstract": "Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities."}, "keywords": ["Pre-trained language models", "programming languages"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation, and researchers have proposed learnable probabilistic models of source code that exploit the abundance of patterns of code #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation, and recent research has proposed learnable probabilistic models of source code that exploit the abundance of patterns of code #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Research at the intersection of machine learning, programming languages, and software engineering has proposed learnable probabilistic models of source code that exploit the abundance of patterns of code, which can be used as a background for the study of pre-trained language models and programming languages in code generation. #REFR", "given_citation_intent": "background", "given_keywords": ["Pre-trained language models", "programming languages"]}]}
{"citing_id": "2303.12621v1", "cited_id": "1912.13192", "section_title": "Results On Wod", "citation": "In particular, for pedestrian, we outperform the baseline model PV-RCNN++ #REFR by 2.77%/2.56% in terms of both L1 and L2 mAP, which indicates the effectiveness of the proposed model in handling hard examples.", "text_before_citation": ["The results on the validation set are displayed in Tab.", "1, and it can be seen that we achieve new state-of-the-art performance on all the three classes."], "text_after_citation": ["In comparison with other Transformer-based models, we focus on vehicle since the counterparts only report the performance on it. As Tab.", "2 shows, our OcTr achieves the best mAP among all these convolution-and Transformer-based backbones.", "It also outperforms the Transformer-based detection head network CT3D #OTHEREFR by 2.52% and 1.46% in L1 and L2 mAP.", "Regarding the accuracies at different distances, OcTr ranks the first place in the range of 30m-50m and 50m-inf, which surpasses the previous best by 0.45%, 2.66% in L1 mAP and 1.18%, 2.26% in L2 mAP respectively.", "It clearly illustrates that OcTr has the advantage in capturing long-range fine-grained context, which facilitates dealing with objects far away."], "citing_paper_content": {"title": "Octr: Octree-Based Transformer For 3D Object Detection", "abstract": "A key challenge for LiDAR-based 3D object detection is to capture sufficient features from large scale 3D scenes especially for distant or/and occluded objects. Albeit recent efforts made by Transformers with the long sequence modeling capability, they fail to properly balance the accuracy and efficiency, suffering from inadequate receptive fields or coarse-grained holistic correlations. In this paper, we propose an Octree-based Transformer, named OcTr, to address this issue. It first constructs a dynamic octree on the hierarchical feature pyramid through conducting self-attention on the top level and then recursively propagates to the level below restricted by the octants, which captures rich global context in a coarse-to-fine manner while maintaining the computational complexity under control. Furthermore, for enhanced foreground perception, we propose a hybrid positional embedding, composed of the semantic-aware positional embedding and attention mask, to fully exploit semantic and geometry clues. Extensive experiments are conducted on the Waymo Open Dataset and KITTI Dataset, and OcTr reaches newly state-of-the-art results."}, "cited_paper_content": {"title": "Pv-Rcnn: Point-Voxel Feature Set Abstraction For 3D Object Detection", "abstract": "We present a novel and high-performance 3D object detection framework, named PointVoxel-RCNN (PV-RCNN), for accurate 3D object detection from point clouds. Our proposed method deeply integrates both 3D voxel Convolutional Neural Network (CNN) and PointNet-based set abstraction to learn more discriminative point cloud features. It takes advantages of efficient learning and high-quality proposals of the 3D voxel CNN and the flexible receptive fields of the PointNet-based networks. Specifically, the proposed framework summarizes the 3D scene with a 3D voxel CNN into a small set of keypoints via a novel voxel set abstraction module to save follow-up computations and also to encode representative scene features. Given the high-quality 3D proposals generated by the voxel CNN, the RoI-grid pooling is proposed to abstract proposal-specific features from the keypoints to the RoI-grid points via keypoint set abstraction with multiple receptive fields. Compared with conventional pooling operations, the RoI-grid feature points encode much richer context information for accurately estimating object confidences and locations. Extensive experiments on both the KITTI dataset and the Waymo Open dataset show that our proposed PV-RCNN surpasses state-of-the-art 3D detection methods with remarkable margins by using only point clouds."}, "keywords": ["L2 mAP", "baseline model"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The results on the validation set are displayed in Tab. 1, and it can be seen that we achieve new state-of-the-art performance on all the three classes. This is consistent with the findings in #REFR, where the authors proposed a novel 3D object detection framework, named PointVoxel-RCNN, that outperforms state-of-the-art methods on both the KITTI dataset and the Waymo Open dataset.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed method achieves new state-of-the-art performance on all three classes, surpassing the previous best results by a remarkable margin, as demonstrated in Tab. 1. This highlights the effectiveness of our approach compared to existing methods, including #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed method outperforms the baseline model with a remarkable margin of 4.2% in terms of L2 mAP on the KITTI dataset, as shown in Tab. 1, which demonstrates the effectiveness of our approach compared to previous state-of-the-art methods such as PV-RCNN #REFR.", "given_citation_intent": "result", "given_keywords": ["L2 mAP", "baseline model"]}]}
{"citing_id": "2303.02874v1", "cited_id": "1707.07397", "section_title": "C. Current Defense Strategy And Limitation", "citation": "High success had been achieved by successful defense of Randomization-based defense technique against both blackbox and gray-box based attacks, but it is still vulnerable whitebox based attack, for example, the EoT method #REFR can be easily attacked and compromised simply by considering the randomization process during attack.", "text_before_citation": ["The approach is similar to a typical antivirus software, which is constantly being updated on a regular basis.", "As effective as adversarial training may be in defense against adversarial attack, it still requires continuous maintenance or update in order to be effective in combating new threats and it is still suffering from the fundamental problem of the fact that it can only successfully defend against threats or attack that has already happened and is already trained against.", "2) Randomization: Several adversarial defense methods relied on randomization as a technique for mitigating the effects of adversarial Perturbations in the input and/or feature domain #OTHEREFR .", "The idea behind this defense technique is the robustness of deep neural network model to random perturbation.", "The aim of randomization-based defense is to randomize the adversarial effects of the adversarial sampling into several random effects which is a very ok and normal thing for varieties of deep neural network models."], "text_after_citation": [], "citing_paper_content": {"title": "Adversarial Sampling For Fairness Testing In Deep Neural Network", "abstract": "In this research, we focus on the usage of adversarial sampling to test for the fairness in the prediction of deep neural network model across different classes of image in a given dataset. While several framework had been proposed to ensure robustness of machine learning model against adversarial attack, some of which includes adversarial training algorithm. There is still the pitfall that adversarial training algorithm tends to cause disparity in accuracy and robustness among different group. Our research is aimed at using adversarial sampling to test for fairness in the prediction of deep neural network model across different classes or categories of image in a given dataset. We successfully demonstrated a new method of ensuring fairness across various group of input in deep neural network classifier. We trained our neural network model on the original image, and without training our model on the perturbed or attacked image. When we feed the adversarial samplings to our model, it was able to predict the original category/ class of the image the adversarial sample belongs to. We also introduced and used the separation of concern concept from software engineering whereby there is an additional standalone filter layer that filters perturbed image by heavily removing the noise or attack before automatically passing it to the network for classification, we were able to have accuracy of 93.3%. Cifar-10 dataset have ten categories of dataset, and so, in order to account for fairness, we applied our hypothesis across each categories of dataset and were able to get a consistent result and accuracy."}, "cited_paper_content": {"title": "Synthesizing Robust Adversarial Examples", "abstract": "Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world."}, "keywords": ["Randomization-based defense technique", "gray-box based attacks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Randomization-based defense is a technique that aims to randomize the adversarial effects of the adversarial sampling into several random effects, which is a very normal thing for varieties of deep neural network models #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To synthesize examples that are adversarial over a chosen distribution of transformations, the authors of this manuscript could use the algorithm presented in the reference paper \"Synthesizing Robust Adversarial Examples\" #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Randomization-based defense is a technique that has been used to mitigate the effects of adversarial perturbations in the input and/or feature domain, and it has been shown to be effective against gray-box based attacks #REFR.", "given_citation_intent": "method", "given_keywords": ["Randomization-based defense technique", "gray-box based attacks"]}]}
{"citing_id": "2303.10753v1", "cited_id": "0807.4462", "section_title": "Related Works:", "citation": "Bonnabel and Sepulchre #REFR proposed a metric for S + (p, n) that is invariant with respect to all transformations that preserve angles and derived the geometric mean.", "text_before_citation": ["In contrast to SPD matrices, symmetric positive semidefinite (SPSD) matrices are singular and do not have matrix logarithms.", "There are two main approaches to define metrics on SPSD matrices.", "The first approach #OTHEREFR , #OTHEREFR exploits S + (p, n), the manifold of rank-p SPSDs of size n, which can be identified with the quotient manifold R", "n\u00d7p * /O p , where R n\u00d7p *", "is the set of full-rank n \u00d7 p matrices and O p is the orthogonal group of order p."], "text_after_citation": ["The second approach involves adding a regularization term to transform the SPSD matrix to a PSD or truncating the spectrum. Dodero et al.", "#OTHEREFR regularized the graph Laplacian to become positive definite by adding a regularization term and used the Log-Euclidean metric for downstream classification tasks. Shnitzer et al.", "#OTHEREFR truncated the full spectrum of diffusion operators to a fixed length and proved that the spectrum truncation preserves the lower bound of the Log-Euclidean metric.", "(2) Fr\u00e9chet Analysis of Graph Laplacians.", "The Fr\u00e9chet mean #OTHEREFR is a concept in statistics that provides a representative center of a set of data objects in a metric space."], "citing_paper_content": {"title": "Fr\u00e9chet Statistics Based Change Point Detection In Dynamic Social Networks", "abstract": "This paper proposes a method to detect change points in dynamic social networks using Fr\u00e9chet statistics. We address two main questions: (1) what metric can quantify the distances between graph Laplacians in a dynamic network and enable efficient computation, and (2) how can the Fr\u00e9chet statistics be extended to detect multiple change points while maintaining the significance level of the hypothesis test? Our solution defines a metric space for graph Laplacians using the Log-Euclidean metric, enabling a closed-form formula for Fr\u00e9chet mean and variance. We present a framework for change point detection using Fr\u00e9chet statistics and extend it to multiple change points with binary segmentation. The proposed algorithm uses incremental computation for Fr\u00e9chet mean and variance to improve efficiency and is validated on simulated and two real-world datasets, namely the UCI message dataset and the Enron email dataset."}, "cited_paper_content": {"title": "Riemannian Metric And Geometric Mean For Positive Semidefinite Matrices Of Fixed Rank", "abstract": "This paper introduces a new metric and mean on the set of positive semidefinite matrices of fixed-rank. The proposed metric is derived from a well-chosen Riemannian quotient geometry that generalizes the reductive geometry of the positive cone and the associated natural metric. The resulting Riemannian space has strong geometrical properties: it is geodesically complete, and the metric is invariant with respect to all transformations that preserve angles (orthogonal transformations, scalings, and pseudoinversion). A meaningful approximation of the associated Riemannian distance is proposed, that can be efficiently numerically computed via a simple algorithm based on SVD. The induced mean preserves the rank, possesses the most desirable characteristics of a geometric mean, and is easy to compute."}, "keywords": ["metric"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In contrast to SPD matrices, symmetric positive semidefinite (SPSD) matrices are singular and do not have matrix logarithms. There are two main approaches to define metrics on SPSD matrices. The first approach exploits S + (p, n), the manifold of rank-p SPSDs of size n, which can be identified with the quotient manifold R n\u00d7p * /O p , where R n\u00d7p * is the set of full-rank n \u00d7 p matrices and O p is the orthogonal group of order p ( #REFR ).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One approach to defining metrics on SPSD matrices is to exploit the manifold of rank-p SPSDs of size n, which can be identified with the quotient manifold R n\u00d7p * /O p, as proposed in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One approach to defining metrics on SPSD matrices is to exploit the manifold of rank-p SPSDs of size n, which can be identified with the quotient manifold R n\u00d7p * /O p, as proposed by the authors in their work on Riemannian Metric And Geometric Mean For Positive Semidefinite Matrices Of Fixed Rank #REFR, where they introduce a new metric and mean on the set of positive semidefinite matrices of fixed-rank.", "given_citation_intent": "background", "given_keywords": ["metric"]}]}
{"citing_id": "2303.17958v1", "cited_id": "1801.05039", "section_title": "C. Global Convergence Of Deepo", "citation": "In contrast to the existing literature #REFR on PO for the LQR problem, the cost J(G) here is projected gradient dominated, meaning that G is optimal if the projected gradient \u03a0 X\u2212 \u2207J(G) is equal to zero.", "text_before_citation": ["V \u2208 N (X \u2212 ) with V F = 1 in the descent cone of S G (a) such that J (G)[V ] \u2264 \u2212c(\u03b1(a)(J(G) \u2212 J * ) 1/2 ), where J (G)[V ] denotes the derivative along the direction V .", "Let V = \u03a0 X\u2212 \u2207J(G)/ \u03a0 X\u2212 \u2207J(G) F be the normalized projected gradient.", "Then, we have J (G)[V ] \u2264 J (G)[V ] since both V and V are in N (X \u2212 )", ", and V is the direction of the projection of the gradient.", "The proof is completed by letting \u00b5(a) = 1/(c\u03b1(a)) #OTHEREFR ."], "text_after_citation": ["It is usually regarded as a weaker condition than strong convexity in nonconvex optimization theory.", "Under Lemma 4, one can show global convergence of projected gradient update #OTHEREFR .", "To further show a linear convergence rate, we require the smoothness of J(G).", "However, since J(K) tends extremely to infinity as G approaches the boundary \u2202S G , we can only show that J(G) is locally smooth over any sublevel set. Define the Hessian acting on the direction Z \u2208", "R T \u00d7n as \u2207 2 J(G)[Z, Z] := d 2 dt 2 J(G + tZ) t=0"], "citing_paper_content": {"title": "Data-Enabled Policy Optimization For The Linear Quadratic Regulator", "abstract": "Policy optimization (PO), an essential approach of reinforcement learning for a broad range of system classes, requires significantly more system data than indirect (identification-followed-by-control) methods or behavioralbased direct methods even in the simplest linear quadratic regulator (LQR) problem. In this paper, we take an initial step towards bridging this gap by proposing the data-enabled policy optimization (DeePO) method, which requires only a finite number of sufficiently exciting data to iteratively solve the LQR via PO. Based on a data-driven closed-loop parameterization, we are able to directly compute the policy gradient from a bath of persistently exciting data. Next, we show that the nonconvex PO problem satisfies a projected gradient dominance property by relating it to an equivalent convex program, leading to the global convergence of DeePO. Moreover, we apply regularization methods to enhance certainty-equivalence and robustness of the resulting controller and show an implicit regularization property. Finally, we perform simulations to validate our results."}, "cited_paper_content": {"title": "Global Convergence Of Policy Gradient Methods For The Linear Quadratic Regulator", "abstract": "Direct policy gradient methods for reinforcement learning and continuous control problems are a popular approach for a variety of reasons: 1) they are easy to implement without explicit knowledge of the underlying model 2) they are an \"end-to-end\" approach, directly optimizing the performance metric of interest 3) they inherently allow for richly parameterized policies. A notable drawback is that even in the most basic continuous control problem (that of linear quadratic regulators), these methods must solve a non-convex optimization problem, where little is understood about their efficiency from both computational and statistical perspectives. In contrast, system identification and model based planning in optimal control theory have a much more solid theoretical footing, where much is known with regards to their computational and statistical properties. This work bridges this gap showing that (model free) policy gradient methods globally converge to the optimal solution and are efficient (polynomially so in relevant problem dependent quantities) with regards to their sample and computational complexities."}, "keywords": ["projected gradient"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' proposed DeePO method for solving the nonconvex PO problem in the LQR satisfies a projected gradient dominance property, leading to global convergence #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors demonstrate in their work that policy gradient methods for the linear quadratic regulator (LQR) problem globally converge to the optimal solution and are efficient with regards to their sample and computational complexities, which supports the findings presented in this manuscript. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proof of global convergence of DeePO is completed by showing that the nonconvex PO problem satisfies a projected gradient dominance property, which is related to an equivalent convex program in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": ["projected gradient"]}]}
{"citing_id": "2303.08439v1", "cited_id": "1909.12962", "section_title": "Cross-Domain Performance Evaluation", "citation": "We train our model on the Faceforensics++ dataset and evaluate its performance on the test sets of Celeb-DF #REFR and DFDC [11] .", "text_before_citation": ["We ran the public code of methods marked with \"*\" to produce results under identical settings (HQ for training and single frames for testing). mum improvement of 10.25% (F2F \u2192FSW).", "Meanwhile, our model remains effective under the four intra-domain settings, which are shown in gray.", "The method tends to slightly underperform when trained on NeuralTextures, likely because its manipulation patterns only exist in certain small regions, and may be neglected during our block sampling.", "Nevertheless, compared to existing methods, our deepfake detector yields much better overall performances.", "Cross-dataset evaluations."], "text_after_citation": ["Specifically, following the previous practice in #OTHEREFR , we validate the model on Celeb-DF and use the selected model to test on DFDC.", "We adopt the HQ version of FF for training, and only use one frame every video for testing.", "Under the same setting, we ran the public code of RECCE #OTHEREFR , UIA-ViT #OTHEREFR and SBI #OTHEREFR to produce corresponding results.", "In Table 2 , we show a competitive performance with existing image-based methods, signaling satisfying adaptability of RFFR to different datasets, especially high quality datasets like Celeb-DF.", "SBI #OTHEREFR is a recent powerful deepfake detection method."], "citing_paper_content": {"title": "Real Face Foundation Representation Learning For Generalized Deepfake Detection", "abstract": "The emergence of deepfake technologies has become a matter of social concern as they pose threats to individual privacy and public security. It is now of great significance to develop reliable deepfake detectors. However, with numerous face manipulation algorithms present, it is almost impossible to collect sufficient representative fake faces, and it is hard for existing detectors to generalize to all types of manipulation. Therefore, we turn to learn the distribution of real faces, and indirectly identify fake images that deviate from the real face distribution. In this study, we propose Real Face Foundation Representation Learning (RFFR), which aims to learn a general representation from large-scale real face datasets and detect potential artifacts outside the distribution of RFFR. Specifically, we train a model on real face datasets by masked image modeling (MIM), which results in a discrepancy between input faces and the reconstructed ones when applying the model on fake samples. This discrepancy reveals the low-level artifacts not contained in RFFR, making it easier to build a deepfake detector sensitive to all kinds of potential artifacts outside the distribution of RFFR. Extensive experiments demonstrate that our method brings about better generalization performance, as it significantly outperforms the state-of-the-art methods in crossmanipulation evaluations, and has the potential to further improve by introducing extra real faces for training RFFR."}, "cited_paper_content": {"title": "Celeb-Df: A Large-Scale Challenging Dataset For Deepfake Forensics", "abstract": "AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for large-scale datasets. However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF."}, "keywords": ["Faceforensics++ dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We ran the public code of methods marked with \"*\" to produce results under identical settings (HQ for training and single frames for testing). mum improvement of 10.25% (F2F \u2192FSW). Meanwhile, our model remains effective under the four intra-domain settings, which are shown in gray. The method tends to slightly underperform when trained on NeuralTextures, likely because its manipulation patterns only exist in certain small regions, and may be neglected during our block sampling. Nevertheless, compared to existing methods, our deepfake detector yields much better overall performances. Cross-dataset evaluations. We used the large-scale challenging DeepFake video dataset, Celeb-DF, to evaluate our method's performance on real-world DeepFake videos #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of collecting representative fake faces for deepfake detection, the authors propose Real Face Foundation Representation Learning (RFFR) that learns a general representation from large-scale real face datasets and detects potential artifacts outside the distribution of RFFR, as demonstrated by their extensive experiments that outperform the state-of-the-art methods in cross-manipulation evaluations, and the authors credit the improved synthesis process of Celeb-DF dataset for providing high-quality deepfake videos of celebrities for their method. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train our deepfake detector, we utilized the Celeb-DF dataset, a large-scale challenging dataset for deepfake forensics that contains 5,639 high-quality DeepFake videos of celebrities generated using an improved synthesis process #REFR.", "given_citation_intent": "method", "given_keywords": ["Faceforensics++ dataset"]}]}
{"citing_id": "2303.12936v1", "cited_id": "1903.05987", "section_title": "Comparing Bert And Distilbert", "citation": "DistilBERT is on par with or exceeding ELMo on a binary text classification task #REFR .", "text_before_citation": ["And this would enable a fairer comparison.", "Recently, it was shown that ELMo and BERT make no significant difference in semantic analysis #OTHEREFR .", "Here it is observed that although they are close-by in the null context, DistilBERT is more robust than ELMo in the cross-context in text classification.", "The findings of this study are in line with prior work.", "The fairly comparable scores of ELMo and the traditional baselines in the null context supports the observation of #OTHEREFR that is, when it comes to contextual embeddings, there is only a small improvement in learning semantics over traditional ML methods."], "text_after_citation": ["DistilBERT, as a transformerbased model, is better in capturing long-term dependencies in an input sequence #OTHEREFR .", "DistilBERT is lighter than ELMo and has a shorter training time #OTHEREFR .", "Here it should be noted that the experimental settings of the previous work and In this study, ELMo and DistilBERT are compared on their fine-tuning performance on two binary text classification tasks.", "The main focus was to see how much can these models be benefited in a practical way without any modification to the pretraining outputs.", "But the models were actually pretrained on entirely different corpora (ELMo on One Billion Words Benchmark #OTHEREFR , DistilBERT on English Wikipedia and Toronto BookCorpus #OTHEREFR )."], "citing_paper_content": {"title": "", "abstract": "I am grateful to my family for their unconditional love and patience. I am grateful to Arzucan\u00d6zg\u00fcr, for being such an inspiring figure by her selfless devotion to research the most righteous way with the passion to contribute to the community. I am grateful to Ali H\u00fcrriyetoglu, for being such a role model, who could somehow always find a way to turn the mist of research questions into a structured path to create practical solutions by combining creativity and technique. I cannot thank enough my dear friends who put up with my whims throughout this journey. I thank fellows from TabiLAB for inspiring me with their brilliance, invaluable insights and recommendations. I thank Ko\u00e7 University EMW research team for their generosity in sharing the data which was created with blood, sweat and tears. I feel lucky that I got to meet fellows in EMW project engineering team who invested their precious time and energy to support me in this study from the very beginning. Lastly, I owe the deepest gratitude to our professors and staff members in our department who taught us how to form such a great community and made it feel like the dearest home from the day one."}, "cited_paper_content": {"title": "To Tune Or Not To Tune? Adapting Pretrained Representations To Diverse Tasks", "abstract": "While most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner."}, "keywords": ["binary text classification"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' empirical results demonstrate that the relative performance of fine-tuning versus feature extraction for adapting pretrained models to a given target task depends on the similarity of the pretraining and target tasks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' investigation of the relative performance of fine-tuning versus feature extraction for adapting pretrained models to target tasks #REFR aligns with prior work and provides valuable guidelines for NLP practitioners.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To adapt pretrained models to binary text classification tasks, it has been shown that the relative performance of fine-tuning versus feature extraction depends on the similarity of the pretraining and target tasks #REFR.", "given_citation_intent": "background", "given_keywords": ["binary text classification"]}]}
{"citing_id": "2303.04274v1", "cited_id": "1911.00222", "section_title": "C. Sensitivity And Privacy Analysis", "citation": "It is consistent with the amplitude of the DP noise in a Gaussian noise perturbation mechanism developed in #REFR .", "text_before_citation": ["given , \u03b4, and M , we adjust the DP noise variance to balance privacy preservation and the convergence of FL training.", "Remark 2.", "Given a privacy budget for M global aggregations, more clients involved in the model updates, i.e., a larger q in (8), lead to requirements of stronger perturbation noises being added to the local model of each involved client.", "This indicates less privacy leakage for each client, which is consistent with the conclusion drawn in #OTHEREFR .", "m = 1, \u2022 \u2022 \u2022 , M , since \u03d1\u2212\u03d1 1\u2212M \u03d1\u22121 \u03d1\u21921 \u2212 \u2212\u2212 \u2192 M ."], "text_after_citation": [], "citing_paper_content": {"title": "Amplitude-Varying Perturbation For Balancing Privacy And Utility In Federated Learning", "abstract": "While preserving the privacy of federated learning (FL), differential privacy (DP) inevitably degrades the utility (i.e., accuracy) of FL due to model perturbations caused by DP noise added to model updates. Existing studies have considered exclusively noise with persistent root-mean-square amplitude and overlooked an opportunity of adjusting the amplitudes to alleviate the adverse effects of the noise. This paper presents a new DP perturbation mechanism with a time-varying noise amplitude to protect the privacy of FL and retain the capability of adjusting the learning performance. Specifically, we propose a geometric series form for the noise amplitude and reveal analytically the dependence of the series on the number of global aggregations and the (, \u03b4)-DP requirement. We derive an online refinement of the series to prevent FL from premature convergence resulting from excessive perturbation noise. Another important aspect is an upper bound developed for the loss function of a multi-layer perceptron (MLP) trained by FL running the new DP mechanism. Accordingly, the optimal number of global aggregations is obtained, balancing the learning and privacy. Extensive experiments are conducted using MLP, supporting vector machine, and convolutional neural network models on four public datasets. The contribution of the new DP mechanism to the convergence and accuracy of privacy-preserving FL is corroborated, compared to the state-of-the-art Gaussian noise mechanism with a persistent noise amplitude."}, "cited_paper_content": {"title": "Federated Learning With Differential Privacy: Algorithms And Performance Analysis", "abstract": "In this paper, to effectively prevent information leakage, we propose a novel framework based on the concept of differential privacy (DP), in which artificial noises are added to the parameters at the clients side before aggregating, namely, noising before model aggregation FL (NbAFL). First, we prove that the NbAFL can satisfy DP under distinct protection levels by properly adapting different variances of artificial noises. Then we develop a theoretical convergence bound of the loss function of the trained FL model in the NbAFL. Specifically, the theoretical bound reveals the following three key properties: 1) There is a tradeoff between the convergence performance and privacy protection levels, i.e., a better convergence performance leads to a lower protection level; 2) Given a fixed privacy protection level, increasing the number $N$ of overall clients participating in FL can improve the convergence performance; 3) There is an optimal number of maximum aggregation times (communication rounds) in terms of convergence performance for a given protection level. Furthermore, we propose a $K$-random scheduling strategy, where $K$ ($1<K<N$) clients are randomly selected from the $N$ overall clients to participate in each aggregation. We also develop the corresponding convergence bound of the loss function in this case and the $K$-random scheduling strategy can also retain the above three properties. Moreover, we find that there is an optimal $K$ that achieves the best convergence performance at a fixed privacy level. Evaluations demonstrate that our theoretical results are consistent with simulations, thereby facilitating the designs on various privacy-preserving FL algorithms with different tradeoff requirements on convergence performance and privacy levels."}, "keywords": ["Gaussian noise perturbation", "DP noise"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Given a privacy budget for M global aggregations, more clients involved in the model updates, i.e., a larger q in (8), lead to requirements of stronger perturbation noises being added to the local model of each involved client. This indicates less privacy leakage for each client, which is consistent with the conclusion drawn in the reference paper on federated learning with differential privacy (NbAFL) that increasing the number N of overall clients participating in FL can improve the convergence performance #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors adjusted the DP noise variance to balance privacy preservation and the convergence of FL training, and their results are consistent with those in #REFR, which showed a tradeoff between convergence performance and privacy protection levels.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed geometric series form for the noise amplitude in this paper provides a promising approach to balance privacy preservation and the convergence of FL training, which outperforms the state-of-the-art Gaussian noise perturbation mechanism with a persistent noise amplitude, as demonstrated in #REFR.", "given_citation_intent": "result", "given_keywords": ["Gaussian noise perturbation", "DP noise"]}]}
{"citing_id": "2304.01639v1", "cited_id": "1801.09627", "section_title": "C. Chance-Constrained Mpc-Cbf", "citation": "The expectation and variance of CBC k+i|k are given in #REFR , and Var CBC k+i|k \u2265 2\u03c3 4 tr(W W).", "text_before_citation": ["Remark 2.", "The nice properties of deterministic MPC-CBF, such as avoiding obstacles at an early stage, are maintained in a stochastic scenario because the chance-constrained approach still considers the CBF constraints in the optimization problem.", "The chance constraint only adds an additional constraint on the probability of violating the CBF constraint.", ", then introducing more randomness to the system by increasing the standard deviation of the noise \u03c3 may lead to (18) becoming infeasible.", "Proof."], "text_after_citation": ["Meantime, we recall the trace inequality tr(W W) \u2264 tr(W) with W being a symmetric positive definite matrix.", "By substituting #OTHEREFR and the two inequality conditions into #OTHEREFR", "EQUATION", "where", "D = f (x k+i|k ) + g(x k+i|k )u k+i|k \u2212 \u03be(o k+i|k ) 2 W \u2212 (1 \u2212 \u03b3)h x k+i|k , o k+i|k \u2212 1 is deterministic if"], "citing_paper_content": {"title": "Moving Obstacle Collision Avoidance Via Chance-Constrained Mpc With Cbf", "abstract": "Model predictive control (MPC) with control barrier functions (CBF) is a promising solution to address the moving obstacle collision avoidance (MOCA) problem. Unlike MPC with distance constraints (MPC-DC), this approach facilitates early obstacle avoidance without the need to increase prediction horizons. However, the existing MPC-CBF method is deterministic and fails to account for perception uncertainties. This paper proposes a generalized MPC-CBF approach for stochastic scenarios, which maintains the advantages of the deterministic method for addressing the MOCA problem. Specifically, the chanceconstrained MPC-CBF (CC-MPC-CBF) technique is introduced to ensure that a user-defined collision avoidance probability is met by utilizing probabilistic CBFs. However, due to the potential empty intersection between the reachable set and the safe region confined by CBF constraints, the CC-MPC-CBF problem can pose challenges in achieving feasibility. To address this issue, we propose a sequential implementation approach that involves solving a standard MPC optimization problem followed by a predictive safety filter optimization, which leads to improved feasibility. Furthermore, we introduce an iterative convex optimization scheme to further expedite the resolution of the predictive safety filter, which results in an efficient approach to tackling the non-convex CC-MPC-CBF problem. We apply our proposed algorithm to a 2-D integrator system for MOCA, and we showcase its resilience to obstacle measurement uncertainties and favorable feasibility properties."}, "cited_paper_content": {"title": "Safety-Aware Adaptive Reinforcement Learning With Applications To Brushbot Navigation", "abstract": "This paper presents a safety-aware learning framework that employs an adaptive model learning method together with barrier certificates for systems with possibly nonstationary agent dynamics. To extract the dynamic structure of the model, we use a sparse optimization technique, and the resulting model will be used in combination with control barrier certificates which constrain feedback controllers only when safety is about to be violated. Under some mild assumptions, solutions to the constrained feedback-controller optimization are guaranteed to be globally optimal, and the monotonic improvement of a feedback controller is thus ensured. In addition, we reformulate the (action-)value function approximation to make any kernel-based nonlinear function estimation method applicable. We then employ a state-of-the-art kernel adaptive filtering technique for the (action-)value function approximation. The resulting framework is verified experimentally on a brushbot, whose dynamics is unknown and highly complex."}, "keywords": ["4 tr(W W", "variance"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The safety-aware learning framework proposed in #REFR can be combined with control barrier certificates to ensure global optimality and monotonic improvement of a feedback controller, which may be useful for addressing the moving obstacle collision avoidance problem.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The safety-aware learning framework proposed in #REFR employs an adaptive model learning method together with barrier certificates for systems with nonstationary agent dynamics, which can be used to address the moving obstacle collision avoidance problem in a stochastic scenario.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To extract the dynamic structure of the model, a sparse optimization technique is used in the safety-aware learning framework proposed by the authors in their previous work #REFR, which can be combined with control barrier certificates to constrain feedback controllers only when safety is about to be violated.", "given_citation_intent": "background", "given_keywords": ["4 tr(W W", "variance"]}]}
{"citing_id": "2303.08695v1", "cited_id": "1502.01852", "section_title": "Implementation", "citation": "We use Kaiming initialization #REFR for the NeRF model and initialize all cameras to the origin, looking in the \u2212z direction, with the focal length (f ) set to the image width.", "text_before_citation": ["Our implementation is based on the framework provided by Khalid et al.", "#OTHEREFR , with a few modifications for enhanced computation efficiency.", "Specifically, we do not include the effect of the dynamic component in our calculations, as the static representation is used in the analysis, ee keep the hidden layer dimension at 256, and we sample only 4096 pixels from each input image and 128 points along each ray."], "text_after_citation": ["To optimize the NeRF, camera poses, and focal lengths, we employ three separate Adam optimizers, all with an initial learning rate of 0.001.", "The learning rate of the NeRF model decays every 100 epochs by multiplying it by 0.997 (equivalent to stair-cased exponential decay), while the learning rates of the pose and focal length parameters decay every 10 epochs with a multiplier of 0.9.", "Unless otherwise specified, all models are trained for 10,000 epochs. Further technical details are provided in the supplementary material."], "citing_paper_content": {"title": "Refinerf: Modelling Dynamic Neural Radiance Fields With Inconsistent Or Missing Camera Parameters", "abstract": "Figure 1: Our proposed approach learns camera parameters using a simple photometric loss using a learning scheduler and is easy to incorporate in both static and dynamic frameworks."}, "cited_paper_content": {"title": "Delving Deep Into Rectifiers: Surpassing Human-Level Performance On Imagenet Classification", "abstract": "Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset."}, "keywords": ["cameras", "NeRF model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our implementation is based on the framework provided by Khalid et al. #OTHEREFR, with a few modifications for enhanced computation efficiency. Specifically, we do not include the effect of the dynamic component in our calculations, as the static representation is used in the analysis, we keep the hidden layer dimension at 256, and we sample only 4096 pixels from each input image and 128 points along each ray. To achieve state-of-the-art performance, we adopt the Parametric Rectified Linear Unit (PReLU) proposed by He et al. in #REFR, which improves model fitting with nearly zero extra computational cost and little overfitting risk.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enhance computation efficiency, we modified the framework provided by Khalid et al. #OTHEREFR by excluding the dynamic component, keeping the hidden layer dimension at 256, and sampling only 4096 pixels from each input image and 128 points along each ray. We also learned camera parameters using a simple photometric loss with a learning scheduler, a method proposed by He et al. in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn camera parameters, our proposed approach uses a simple photometric loss with a learning scheduler, which is easy to incorporate in both static and dynamic frameworks #REFR, demonstrating improved computation efficiency for cameras in the NeRF model.", "given_citation_intent": "method", "given_keywords": ["cameras", "NeRF model"]}]}
{"citing_id": "2304.09116v2", "cited_id": "1904.03446", "section_title": "Datasets", "citation": "The input text sequence is first converted into a phoneme sequence using grapheme-to-phoneme conversion #REFR and then aligned with speech using our internal alignment tool to obtain the phoneme-level duration.", "text_before_citation": ["Training Dataset To train the neural audio codec and the diffusion model, we use the English subset of Multilingual LibriSpeech (MLS) #OTHEREFR as the training data, which contains 44K hours of transcribed speech data derived from LibriVox audiobooks.", "The number of distinct speakers is 2742 for males and 2748 for females respectively. The sample rate is 16KHz for all speech data."], "text_after_citation": ["The frame-level pitch sequence is extracted from the speech using PyWorld 3 .", "Evaluation Dataset We employ two benchmark datasets for evaluation: 1) LibriSpeech #OTHEREFR test-clean, which contains 40 distinct speakers and 5.4 hours of annotated speech data.", "2) VCTK dataset #OTHEREFR , which contains 108 distinct speakers.", "For LibriSpeech test-clean, we randomly sample 15 utterances for each speaker and form a subset of 600 utterances for evaluation.", "For VCTK, we randomly sample 5 utterances for each speaker, resulting in a subset of 540 utterances for evaluation."], "citing_paper_content": {"title": "Naturalspeech 2: Latent Diffusion Models Are Natural And Zero-Shot Speech And Singing Synthesizers", "abstract": "Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://speechresearch.github.io/naturalspeech2."}, "cited_paper_content": {"title": "Token-Level Ensemble Distillation For Grapheme-To-Phoneme Conversion", "abstract": "Grapheme-to-phoneme (G2P) conversion is an important task in automatic speech recognition and text-to-speech systems. Recently, G2P conversion is viewed as a sequence to sequence task and modeled by RNN or CNN based encoder-decoder framework. However, previous works do not consider the practical issues when deploying G2P model in the production system, such as how to leverage additional unlabeled data to boost the accuracy, as well as reduce model size for online deployment. In this work, we propose token-level ensemble distillation for G2P conversion, which can (1) boost the accuracy by distilling the knowledge from additional unlabeled data, and (2) reduce the model size but maintain the high accuracy, both of which are very practical and helpful in the online production system. We use token-level knowledge distillation, which results in better accuracy than the sequence-level counterpart. What is more, we adopt the Transformer instead of RNN or CNN based models to further boost the accuracy of G2P conversion. Experiments on the publicly available CMUDict dataset and an internal English dataset demonstrate the effectiveness of our proposed method. Particularly, our method achieves 19.88% WER on CMUDict dataset, outperforming the previous works by more than 4.22% WER, and setting the new state-of-the-art results."}, "keywords": ["phoneme-level duration"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To train the neural audio codec and the diffusion model, the authors used the English subset of Multilingual LibriSpeech (MLS) #REFR as the training data, which contains 44K hours of transcribed speech data derived from LibriVox audiobooks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train the diffusion model, the authors leveraged additional unlabeled data and proposed token-level ensemble distillation for Grapheme-to-Phoneme conversion, achieving state-of-the-art results on the CMUDict dataset with a WER of 19.88%, outperforming previous works by more than 4.22% WER #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train the diffusion model, the authors used the English subset of Multilingual LibriSpeech dataset, and proposed a token-level ensemble distillation method for grapheme-to-phoneme conversion, achieving state-of-the-art results on the CMUDict dataset with 19.88% WER, which outperforms the previous works by more than 4.22% WER, and reduces the model size while maintaining high accuracy, making it practical for online deployment. #REFR", "given_citation_intent": "method", "given_keywords": ["phoneme-level duration"]}]}
{"citing_id": "2303.02948v1", "cited_id": "2003.05830", "section_title": "A. Related Work", "citation": "In #REFR , the authors proposed a joint sensing and transmission protocol to enable UAV-to-Device communication to improve UAV sensing services. Kurt et al.", "text_before_citation": ["#OTHEREFR proposed a differentially private AFL-based anomaly detection scheme for IoT infrastructure.", "However, in the literature on anomaly detection methods for IoT environments, there is a lack of discussion about the issue of continually moving sensing targets.", "Yet this is an issue that increases the difficulty of data sensing and collection.", "UAVs and HAPSs can provide wireless sensing support from the sky to track moving sensing targets #OTHEREFR , #OTHEREFR , #OTHEREFR .", "In #OTHEREFR , a cooperative internet of UAVs was established to execute integrated sensing and transmission tasks for ground sensing targets under energy and communication constraints."], "text_after_citation": ["#OTHEREFR leveraged caching, com-munication, computing, and sensing capabilities of a HAPS to serve autonomous devices for future aerial delivery networks.", "In addition to providing sensing capabilities, UAV-enabled and HAPS-enabled wireless technologies also play key roles in enhancing wireless connectivity and computation capability for ubiquitous IoT #OTHEREFR - #OTHEREFR .", "Considering the constrained energy capacity in UAVs, #OTHEREFR - #OTHEREFR studied the UAV-enabled energy-efficient computation offloading, data uploading, and coverage enhancement systems, respectively.", "Compared to UAVs, HAPSs can provide wider coverage and stronger computational capabilities in a sustainable manner. Ren et al.", "#OTHEREFR proposed a HAPS-assisted caching and computation offloading framework for intelligent transportation systems, where a HAPS played the dual role of a powerful computing server and a data library."], "citing_paper_content": {"title": "A Vhetnet-Enabled Asynchronous Federated Learning-Based Anomaly Detection Framework For Ubiquitous Iot", "abstract": "Anomaly detection for the Internet of Things (IoT) is a major intelligent service required by many fields, including intrusion detection, state monitoring, device-activity analysis, and security supervision. However, the heterogeneous distribution of data and resource-constrained end nodes in ubiquitous IoT systems present challenges for existing anomaly detection models. Due to the advantages of flexible deployment and multidimensional resources, high altitude platform stations (HAPSs) and unmanned aerial vehicles (UAVs), which are important components of vertical heterogeneous networks (VHetNets), have significant potential for sensing, computing, storage, and communication applications in ubiquitous IoT systems. In this paper, we propose a novel VHetNet-enabled asynchronous federated learning (AFL) framework to enable decentralized UAVs to collaboratively train a global anomaly detection model based on their local sensory data from ubiquitous IoT devices. In the VHetNet-enabled AFL framework, a HAPS operates as a central aerial server, and the local models trained in UAVs are uploaded to the HAPS for global aggregation due to its wide coverage and strong storage and computation capabilities. We also introduce a UAV selection strategy into the AFL framework to prevent UAVs with low local model quality and large energy consumption from affecting the learning efficiency and detection accuracy of the global model. To ensure the security of transmissions between UAVs and the HAPS via wireless links, we add designed noise to local model parameters in UAVs to achieve differential privacy during the information exchange process. Moreover, we propose a compound-action actor-critic (CA2C)-based joint device association, UAV selection, and UAV trajectory planning algorithm to further enhance the overall federated execution efficiency and detection model accuracy under the UAV energy constraints. Extensive experimental evaluation on a real-world dataset demonstrates that the proposed algorithm can achieve high detection accuracy with short federated execution time and low energy consumption. Index Terms-Anomaly detection, ubiquitous Internet of Things (IoT), vertical heterogeneous network (VHetNet), asynchronous federated learning (AFL), differential privacy."}, "cited_paper_content": {"title": "Uav-To-Device Underlay Communications: Age Of Information Minimization By Multi-Agent Deep Reinforcement Learning", "abstract": "In recent years, unmanned aerial vehicles (UAVs) have found numerous sensing applications, which are expected to add billions of dollars to the world economy in the next decade. To further improve the Quality-of-Service (QoS) in such applications, the 3rd Generation Partnership Project (3GPP) has considered the adoption of terrestrial cellular networks to support UAV sensing services, also known as the cellular Internet of UAVs. In this paper, we consider a cellular Internet of UAVs, where the sensory data can be transmitted either to base station (BS) via cellular links, or to mobile devices by underlay UAV-to-Device (U2D) communications. To evaluate the freshness of data, the age of information (AoI) is adopted, in which a lower AoI implies fresher data. Since UAVs' AoIs are determined by their trajectories during sensing and transmission, we investigate the AoI minimization problem for UAVs by designing their trajectories. This problem is a Markov decision problem (MDP) with an infinite state-action space, and thus we utilize multi-agent deep reinforcement learning (DRL) to approximate the state-action space. Then, we propose a multi-UAV trajectory design algorithm to solve this problem. Simulation results show that our algorithm achieves a lower AoI than greedy algorithm and policy gradient algorithm."}, "keywords": ["UAV sensing services"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this paper, the authors propose a multi-UAV trajectory design algorithm to minimize the age of information (AoI) for UAVs in a cellular Internet of UAVs. The problem is solved using multi-agent deep reinforcement learning (DRL) and simulation results show that their algorithm achieves a lower AoI than other algorithms. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of moving sensing targets in IoT environments, UAVs have been proposed to provide wireless sensing support from the sky #REFR, which can be further enhanced by designing their trajectories to minimize the age of information (AoI) #OTHEREFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "UAVs have been considered as a solution to the difficulty of data sensing and collection for moving sensing targets in IoT environments, and can provide wireless sensing support from the sky for UAV sensing services. #REFR", "given_citation_intent": "background", "given_keywords": ["UAV sensing services"]}]}
{"citing_id": "2304.04058v1", "cited_id": "1612.05024", "section_title": "Learning Mixed States.", "citation": "This observation is in line with what has been established in classical models as well #REFR .", "text_before_citation": ["5 , we see that an EBM can easily be learned for states that possess paramagnetic order.", "But as expected, the sample complexity of the learning procedure increases when the states come close to the ground state of the classical model.", "Therefore, the observed effect of g on learning is much more pronounced for ground states when compared to thermal states.", "The results of using NeurISE for an anti-ferromagnetic TIM on a 50 qubit 1D lattice with open boundaries at the critical point are given in Fig. 3d .", "We see that this method has no problems learning states that possess long-range order."], "text_after_citation": ["Similarly to learning representations of thermal states, our experiments with ground states also show that the error in the learning procedure scales favorably with the system size.", "In SI, section H, we give scaling results for learning ground states, and discuss learning EBM representations of ground states for the Heisenberg model in 2D.", "Learning states with symmetries.", "Another important aspect of quantum states that can greatly aid the learning process is the presence of symmetries.", "Symmetries can significantly reduce the size of the hypothesis space that a machine-learning method must optimize over."], "citing_paper_content": {"title": "Learning Energy Based Representations Of Quantum Many-Body States", "abstract": "Efficient representation of quantum many-body states on classical computers is a problem of enormous practical interest. An ideal representation of a quantum state combines a succinct characterization informed by the system's structure and symmetries, along with the ability to predict the physical observables of interest. A number of machine learning approaches have been recently used to construct such classical representations [1-6] which enable predictions of observables [7] and accounts for physical symmetries [8]. However, the structure of a quantum state gets typically lost unless a specialized ansatz is employed based on prior knowledge of the system [9-12]. Moreover, most such approaches give no information about what states are easier to learn in comparison to others. Here, we propose a new generative energy-based representation of quantum many-body states derived from Gibbs distributions used for modeling the thermal states of classical spin systems. Based on the prior information on a family of quantum states, the energy function can be specified by a small number of parameters using an explicit low-degree polynomial or a generic parametric family such as neural nets, and can naturally include the known symmetries of the system. Our results show that such a representation can be efficiently learned from data using exact algorithms in a form that enables the prediction of expectation values of physical observables. Importantly, the structure of the learned energy function provides a natural explanation for the hardness of learning for a given class of quantum states."}, "cited_paper_content": {"title": "Optimal Structure And Parameter Learning Of Ising Models", "abstract": "Reconstruction of structure and parameters of an Ising model from binary samples is a problem of practical importance in a variety of disciplines, ranging from statistical physics and computational biology to image processing and machine learning. The focus of the research community shifted towards developing universal reconstruction algorithms which are both computationally efficient and require the minimal amount of expensive data. We introduce a new method, Interaction Screening, which accurately estimates the model parameters using local optimization problems. The algorithm provably achieves perfect graph structure recovery with an information-theoretically optimal number of samples, notably in the low-temperature regime which is known to be the hardest for learning. The efficacy of Interaction Screening is assessed through extensive numerical tests on synthetic Ising models of various topologies with different types of interactions, as well as on a real data produced by a D-Wave quantum computer. This study shows that the Interaction Screening method is an exact, tractable and optimal technique universally solving the inverse Ising problem."}, "keywords": ["classical models"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors have shown that the sample complexity of learning an energy-based representation of quantum many-body states increases as the states come close to the ground state of the classical model. However, they have successfully learned states that possess long-range order using the NeurISE method [1]. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors demonstrated that their proposed Interaction Screening method achieves perfect graph structure recovery with an information-theoretically optimal number of samples, notably in the low-temperature regime which is known to be the hardest for learning, and extensively tested it on synthetic Ising models of various topologies with different types of interactions, as well as on a real data produced by a D-Wave quantum computer, making it a promising technique for solving the inverse Ising problem in practice. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The results of using NeurISE for an anti-ferromagnetic TIM on a 50 qubit 1D lattice with open boundaries at the critical point are given in Fig. 3d, where this method has no problems learning states that possess long-range order, in contrast to classical models #REFR.", "given_citation_intent": "result", "given_keywords": ["classical models"]}]}
{"citing_id": "2304.08354v1", "cited_id": "1911.00172", "section_title": "Tool-Augmented Learning", "citation": "For instance, kNN-LM #REFR combines a PLM and a k-nearest neighbors model by linearly interpolating both models' next word distributions, achieving lower perplexity in language modeling.", "text_before_citation": ["We categorize and compare representative works of tool-augmented learning in Table 1 .", "Retrieval-augmented Learning.", "The most representative tool used for augmentation is the text retriever tool, which develops from the early sparse retriever (Sparck #OTHEREFR to the recent dense retriever .", "Early endeavors resort to retrieving knowledge from local repositories to augment language generation.", "Some works propose retrieving knowledge using a frozen knowledge retriever."], "text_after_citation": ["RETRO #OTHEREFR demonstrates the benefits of extending the retrieval memory to a massive scale (i.e., trillions of tokens).", "Another line of work trains the retriever and the PLM in Figure 3 : Tool-augmented learning seeks to augment foundation models with the execution results from tools (i.e., tool for AI); while tool-oriented learning focuses on utilizing models to govern tools and make sequential decisions in place of humans (i.e., AI for tool). Our studied tool learning encompasses both of them.", "an end-to-end fashion, achieving superior performance in knowledge-intensive NLP tasks #OTHEREFR .", "Later works have gone beyond local repositories, for instance, some leverage the entire web as the knowledge source, which allows for improved temporal generalization and higher factual accuracy #OTHEREFR .", "Instead of treating the retriever as a passive agent, researchers further demonstrate that PLMs can actively interact with a search engine like humans."], "citing_paper_content": {"title": "Tool Learning With Foundation Models", "abstract": "Humans possess an extraordinary ability to create and utilize tools, allowing them to overcome physical limitations and explore new frontiers. With the advent of recent powerful foundation models, artificial intelligence systems have the potential to be equally adept in tool use as humans. This paradigm, which is dubbed as tool learning with foundation models, combines the strengths of specialized tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors in this field. To this end, we present a systematic investigation of tool learning in this paper. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research into tool-augmented and tool-oriented learning. We formulate a general tool learning framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate the generalization in tool learning. Considering the lack of a systematic tool learning evaluation in prior works, we experiment with 17 representative tools and show the potential of current foundation models in skillfully utilizing tools. Finally, we discuss several open problems that require further investigation for tool learning, such as ensuring safe and trustworthy tool use, enabling tool creation with foundation models, and addressing personalization challenges. Overall, we hope this paper could inspire future research in integrating tools with foundation models. The codes and datasets are publicly available for further research exploration 1 ."}, "cited_paper_content": {"title": "Generalization Through Memorization: Nearest Neighbor Language Models", "abstract": "We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this transformation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 -- a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail."}, "keywords": ["language modeling"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Some works propose retrieving knowledge using a frozen knowledge retriever, while others have explored the use of nearest neighbor language models (#REFR) to improve language generation.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The text retriever tool has been widely used for augmentation in tool learning, with early endeavors resorting to retrieving knowledge from local repositories to augment language generation #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The text retriever tool has been widely used for augmentation in tool learning, with early endeavors resorting to retrieving knowledge from local repositories to augment language generation #REFR.", "given_citation_intent": "background", "given_keywords": ["language modeling"]}]}
{"citing_id": "2304.03188v1", "cited_id": "1706.02413", "section_title": "3D Object Detection", "citation": "As shown in Figure 7 , the input to the system is a colorless point cloud of a scene, which is processed by PointNet++ #REFR , to produce features for every point.", "text_before_citation": ["[SZAB17] also address the limitation of Deep Sliding Shapes by adding orientation classification as an auxiliary task, and demonstrate that speed and accuracy of 3D detection using a sliding window increases when the 3D CNN is jointly trained on object labels, location and pose.", "Voting techniques.", "In recent years, voting concepts, specifically, Hough voting, have made a comeback in the space of 3D object detection.", "VoteNet #OTHEREFR and ImVoteNet #OTHEREFR are two such works that are built on voting strategies.", "VoteNet demonstrates two advantages of using the voting strategy for 3D object detection -first, it does not make use of any 2D object detectors which used to be the de-facto step in 3D object detection, and second, the Hough voting technique used in the work is now differentiably learned in an end-to-end supervised manner."], "text_after_citation": ["A voting net, which is nothing but a MLP on these point features, produces virtual points, called votes, for centers of 3D bounding boxes.", "The votes are clustered in the 3D space using farthest point sampling and L 2 distance, from where the extent of the 3D bounding boxes and their centroids are regressed using another MLP.", "All of this training is done in a su- Figure 7 : An end-to-end learning pipeline for 3D object detection using voting technique (VoteNet) #OTHEREFR that directly operates on 3D data without the need for any 2D image priors, such as 2D object detectors.", "#OTHEREFR that was originally proposed for the task of shape classification and segmentation at the object part level, as well as for indoor scenes.", "This work has been the basis for many 3D object detection works, especially for developing task-specific feature descriptors."], "citing_paper_content": {"title": "Advances In Data-Driven Analysis And Synthesis Of 3D Indoor Scenes", "abstract": "Figure 1: A sampler of representative results for different indoor scene modeling tasks surveyed in this report-(a) 3D object detection [YWY22] (Section 5.1), (b) 3D scene segmentation [ZJJ * 21] (Section 5.2), (c) scene reconstruction as image-CAD model alignment [GDN22] (Section 5.3), (d) 3D scene similarity [XMZ * 14] (Section 5.4), and (e) 3D scene synthesis [WSCR18, LPX * 19, YGZT21, PKS * 21] (Section 6). We survey advances in these indoor scene modeling tasks mainly in the realm of 3D geometry."}, "cited_paper_content": {"title": "Pointnet++: Deep Hierarchical Feature Learning On Point Sets In A Metric Space", "abstract": "Few prior works study deep learning on point sets. PointNet by Qi et al. is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds."}, "keywords": ["PointNet++"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In recent years, voting concepts, specifically, Hough voting, have made a comeback in the space of 3D object detection. VoteNet #REFR and ImVoteNet #OTHEREFR are two such works that are built on voting strategies.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed PointNet++ method #REFR is a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set, which enables the learning of local features with increasing contextual scales and has achieved significantly better results than state-of-the-art on challenging benchmarks of 3D point clouds.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed PointNet++ method #REFR is a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set, which is able to learn local features with increasing contextual scales and has achieved significantly better results than state-of-the-art on challenging benchmarks of 3D point clouds.", "given_citation_intent": "method", "given_keywords": ["PointNet++"]}]}
{"citing_id": "2304.07652v1", "cited_id": "1603.05346", "section_title": "Introduction", "citation": "More recently, Karnin, Lang, and Liberty (KLL) #REFR developed the randomized KLL sketch that succeeds at all points with probability 1 \u2212 \u03b4 and uses O((1/\u03b5) log log(1/\u03b4)) space and gave a matching lower bound.", "text_before_citation": [", x n and a query point q, the rank of q, denoted R(q), is the number of items in {x i } n i=1 such that x i \u2264 q.", "An \u03b5-approximate quantile sketch is a data structure that, given access to a single pass over the stream elements, can approximate the rank of all query points simultaneously with additive error at most \u03b5n.", "Given its central importance, the streaming quantiles problem has been studied extensively by both theoreticians and practitioners.", "Early work by Manku, Rajagopalan, and Lindsay #OTHEREFR gave a randomized solution that used O((1/\u03b5) log 2 (n\u03b5)) space; their technique can also be straightforwardly adapted to a deterministic solution that achieves the same bound #OTHEREFR .", "Later, Greenwald and Khanna #OTHEREFR developed a deterministic algo-rithm that requires only O((1/\u03b5) log(n\u03b5)) space."], "text_after_citation": ["Meanwhile, streaming quantile estimation is of significant interest to practitioners in databases, computer systems, and data science who have studied the problem as well.", "Most notably, Dunning #OTHEREFR introduced the celebrated t-digest, a heuristic quantile estimation technique based on 1-dimensional k-means clustering that has seen adoption in numerous systems, including Influx, Apache Arrow, and Apache Spark.", "Although tdigest achieves remarkable accuracy on many real-world data sets, it is known to have arbitrarily bad error in the worst case #OTHEREFR .", "To illustrate this core tradeoff, Figure 1 shows the rank function of the books dataset from the SOSD benchmark #OTHEREFR , along with KLL and t-digest approximations that use the same amount of space when the data set is randomly shuffled, and when the same data set is streamed in an adversarial order that we found to induce especially bad performance in t-digest.", "Recent advances in machine learning have led to the development of learning-augmented algorithms which seek to improve solutions to classical algorithms problems by exploiting empirical properties of the input distribution #OTHEREFR ."], "citing_paper_content": {"title": "Learned Interpolation For Better Streaming Quantile Approximation With Worst-Case Guarantees", "abstract": "An \u03b5-approximate quantile sketch over a stream of n inputs approximates the rank of any query point q-that is, the number of input points less than q-up to an additive error of \u03b5n, generally with some probability of at least 1\u22121/ poly(n), while consuming o(n) space. While the celebrated KLL sketch of Karnin, Lang, and Liberty achieves a provably optimal quantile approximation algorithm over worst-case streams, the approximations it achieves in practice are often far from optimal. Indeed, the most commonly used technique in practice is Dunning's t-digest, which often achieves much better approximations than KLL on realworld data but is known to have arbitrarily large errors in the worst case. We apply interpolation techniques to the streaming quantiles problem to attempt to achieve better approximations on real-world data sets than KLL while maintaining similar guarantees in the worst case. * Anthropic. Work done while at MIT."}, "cited_paper_content": {"title": "Optimal Quantile Approximation In Streams", "abstract": "This paper resolves one of the longest standing basic problems in the streaming computational model. Namely, optimal construction of quantile sketches. An $\\varepsilon$ approximate quantile sketch receives a stream of items $x_1,\\ldots,x_n$ and allows one to approximate the rank of any query up to additive error $\\varepsilon n$ with probability at least $1-\\delta$. The rank of a query $x$ is the number of stream items such that $x_i \\le x$. The minimal sketch size required for this task is trivially at least $1/\\varepsilon$. Felber and Ostrovsky obtain a $O((1/\\varepsilon)\\log(1/\\varepsilon))$ space sketch for a fixed $\\delta$. To date, no better upper or lower bounds were known even for randomly permuted streams or for approximating a specific quantile, e.g.,\\ the median. This paper obtains an $O((1/\\varepsilon)\\log \\log (1/\\delta))$ space sketch and a matching lower bound. This resolves the open problem and proves a qualitative gap between randomized and deterministic quantile sketching. One of our contributions is a novel representation and modification of the widely used merge-and-reduce construction. This subtle modification allows for an analysis which is both tight and extremely simple. Similar techniques should be useful for improving other sketching objectives and geometric coreset constructions."}, "keywords": ["randomized KLL sketch"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The streaming quantiles problem has been extensively studied, with early work by Manku, Rajagopalan, and Lindsay providing a randomized solution that used O((1/\u03b5) log 2 (n\u03b5)) space, and later work by Greenwald and Khanna developing a deterministic algorithm that requires only O((1/\u03b5) log(n\u03b5)) space. However, the optimal construction of quantile sketches has remained an open problem until Felber and Ostrovsky resolved it by obtaining an O((1/\u03b5)log log(1/\u03b4)) space sketch and a matching lower bound, which proves a qualitative gap between randomized and deterministic quantile sketching. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The streaming quantiles problem has been extensively studied, and several algorithms have been proposed to solve it, including randomized and deterministic solutions #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Early work by Manku, Rajagopalan, and Lindsay gave a randomized solution that used O((1/\u03b5) log 2 (n\u03b5)) space; their technique can also be straightforwardly adapted to a deterministic solution that achieves the same bound, which is relevant to the randomized KLL sketch used in the manuscript. #REFR", "given_citation_intent": "background", "given_keywords": ["randomized KLL sketch"]}]}
{"citing_id": "2305.01166v1", "cited_id": "1811.08839", "section_title": "C. Multi-Coil Mri Reconstruction", "citation": "We train score-based models with 128 hidden layers in the first block using 10000 multi-coil T2-weighted brain MRI scans from the FastMRI dataset #REFR .", "text_before_citation": ["The acquired kspace data from the i th coil is given by:", "EQUATION", "where n i is additive white Gaussian noise with variance \u03c3 2 w .", "Following convention, we define the acceleration factor 1/\u03b1 relative to a single fully sampled coil, such that the total number of acquired measurements is \u03b1 \u2022 N c \u2022 N .", "We can represent the MRI multi-coil forward model according to #OTHEREFR ."], "text_after_citation": ["The SURE-Score model was trained on a subset of the data (2000 samples) due to training time constraints.", "We first normalize all slices in the training set by performing a root sum-of-squares (RSS) reconstruction using k-space data from a central window of size 24 \u00d7 24.", "We divide the k-space of each slice by the 95 th magnitude percentile of this low-resolution reconstruction. We define the SNR as 1/\u03c3 2 w .", "1) Denoising Performance: We evaluate denoising performance using the Tweedie re-parameterization in (18) for score models trained (i) naively, (ii) with SURE-Score, and (iii) using noise-free data (supervised).", "Table I lists the NRMSE (mean and standard deviation) over 100 validation slices for SNR w levels of 0 dB and 10 dB."], "citing_paper_content": {"title": "Solving Inverse Problems With Score-Based Generative Priors Learned From Noisy Data", "abstract": "We present SURE-Score: an approach for learning score-based generative models using training samples corrupted by additive Gaussian noise. When a large training set of clean samples is available, solving inverse problems via score-based (diffusion) generative models trained on the underlying fullysampled data distribution has recently been shown to outperform end-to-end supervised deep learning. In practice, such a large collection of training data may be prohibitively expensive to acquire in the first place. In this work, we present an approach for approximately learning a score-based generative model of the clean distribution, from noisy training data. We formulate and justify a novel loss function that leverages Stein's unbiased risk estimate to jointly denoise the data and learn the score function via denoising score matching, while using only the noisy samples. We demonstrate the generality of SURE-Score by learning priors and applying posterior sampling to ill-posed inverse problems in two practical applications from different domains: compressive wireless multiple-input multiple-output channel estimation and accelerated 2D multi-coil magnetic resonance imaging reconstruction, where we demonstrate competitive reconstruction performance when learning at signal-to-noise ratio values of 0 and 10 dB, respectively."}, "cited_paper_content": {"title": "Fastmri: An Open Dataset And Benchmarks For Accelerated Mri", "abstract": "Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background."}, "keywords": ["brain MRI scans", "FastMRI dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To accelerate the 2D multi-coil magnetic resonance imaging reconstruction, the authors demonstrate competitive reconstruction performance by applying posterior sampling with learned priors using the fastMRI dataset #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To accelerate the 2D multi-coil MRI reconstruction, the authors utilized the fastMRI dataset #REFR as a benchmark for evaluating their proposed SURE-Score approach.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reconstruct brain MRI scans, the authors utilized the FastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, and demonstrated competitive reconstruction performance even at low signal-to-noise ratio values of 10 dB. #REFR", "given_citation_intent": "method", "given_keywords": ["brain MRI scans", "FastMRI dataset"]}]}
{"citing_id": "2304.01897v1", "cited_id": "1807.05560", "section_title": "Influencer Follower Size", "citation": "The results show that the proposed model has robust performance to discover effective influencers in the groups of all ranges of followers compared to the baseline methods. More specifically, DeepInf #REFR fails to discover effective micro-influencers.", "text_before_citation": ["Influencers who are followed by less than 20,000 followers are classified as the Micro influencers.", "The Mid-level influencers have followers between 20,000 and 100,000, and Macro influencers have more than 100,000 followers.", "In our dataset, around 30% of influencers are the micro-influencers, 45% of them are the mid-level influencers, and the remaining 25% influencers are the macroinfluencers.", "To evaluate the performance under the same conditions, we randomly select multiple sets of 1,000 influencers from each category and run the experiment 10 times.", "Figure 8 shows the average NDCG scores of Influencer-Rank and four baseline methods, including GCRN #OTHEREFR , DeepInf #OTHEREFR , CasCN #OTHEREFR , and EGCN #OTHEREFR over the micro, mid-level, and macro-influencers."], "text_after_citation": ["This is probably because DeepInf disregards the temporal information which is critical to find micro-influencers who have relatively large variance on their features and engagement rates over time compared to macro-influencers who are matured.", "On the other hand, our proposed model can accurately find highly effective micro-influencers since their unique features are captured by sequential learning of temporal information."], "citing_paper_content": {"title": "Influencerrank: Discovering Effective Influencers Via Graph Convolutional Attentive Recurrent Neural Networks", "abstract": "As influencers play considerable roles in social media marketing, companies increase the budget for influencer marketing. Hiring effective influencers is crucial in social influencer marketing, but it is challenging to find the right influencers among hundreds of millions of social media users. In this paper, we propose InfluencerRank that ranks influencers by their effectiveness based on their posting behaviors and social relations over time. To represent the posting behaviors and social relations, the graph convolutional neural networks are applied to model influencers with heterogeneous networks during different historical periods. By learning the network structure with the embedded node features, InfluencerRank can derive informative representations for influencers at each period. An attentive recurrent neural network finally distinguishes highly effective influencers from other influencers by capturing the knowledge of the dynamics of influencer representations over time. Extensive experiments have been conducted on an Instagram dataset that consists of 18,397 influencers with their 2,952,075 posts published within 12 months. The experimental results demonstrate that InfluencerRank outperforms existing baseline methods. An in-depth analysis further reveals that all of our proposed features and model components are beneficial to discover effective influencers."}, "cited_paper_content": {"title": "Deepinf: Social Influence Prediction With Deep Learning", "abstract": "Social and information networking activities such as on Facebook, Twitter, WeChat, and Weibo have become an indispensable part of our everyday life, where we can easily access friends' behaviors and are in turn influenced by them. Consequently, an effective social influence prediction for each user is critical for a variety of applications such as online recommendation and advertising. Conventional social influence prediction approaches typically design various hand-crafted rules to extract user- and network-specific features. However, their effectiveness heavily relies on the knowledge of domain experts. As a result, it is usually difficult to generalize them into different domains. Inspired by the recent success of deep neural networks in a wide range of computing applications, we design an end-to-end framework, DeepInf, to learn users' latent feature representation for predicting social influence. In general, DeepInf takes a user's local network as the input to a graph neural network for learning her latent social representation. We design strategies to incorporate both network structures and user-specific features into convolutional neural and attention networks. Extensive experiments on Open Academic Graph, Twitter, Weibo, and Digg, representing different types of social and information networks, demonstrate that the proposed end-to-end model, DeepInf, significantly outperforms traditional feature engineering-based approaches, suggesting the effectiveness of representation learning for social applications."}, "keywords": ["influencers", "effective influencers"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To evaluate the performance of InfluencerRank, we compared it with four baseline methods, including GCRN, CasCN, EGCN, and DeepInf #REFR, over the micro, mid-level, and macro-influencers, and the experimental results demonstrate that InfluencerRank outperforms existing baseline methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "InfluencerRank outperforms four baseline methods, including GCRN, CasCN, EGCN, and DeepInf #REFR, as demonstrated by the average NDCG scores over micro, mid-level, and macro-influencers in Figure 8.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "InfluencerRank outperforms four baseline methods, including GCRN, CasCN, EGCN, and DeepInf #REFR, in discovering effective influencers on Instagram.", "given_citation_intent": "result", "given_keywords": ["influencers", "effective influencers"]}]}
{"citing_id": "2304.05163v1", "cited_id": "1910.03910", "section_title": "Effect Of Number Of Labeled Training Samples: Full Data Sets", "citation": "For the ISIC data set, the ISIC 2019 methods paper of the challenge winners Gessert et al. #REFR was used as literature benchmark.", "text_before_citation": ["The first set of experiments aimed at a direct comparison with literature values and covered all classes available in the labeled data sets.", "For the BM and the Endo data set, balanced accuracy values as reported in the original data set publications #OTHEREFR were considered as literature benchmark and state-of-theart performance."], "text_after_citation": ["All benchmark values were obtained through supervised end-to-end trained DL, using the maximum available number of labeled data.", "With the SSL image representation as input features, three conventional classifiers with default parameters (see Sec.", "3) were trained (support vector common practice in SSL-based image classification #OTHEREFR , we also trained a linear layer (LL) on top of the frozen trained DINO feature extractor.", "To provide a DL baseline performance in addition to the literature benchmark data, we also trained the ImageNet-pretrained XCiT network that was used as the DINO backbone network with a linear layer on top in an endto-end supervised DL approach, i.e., using only labeled data instead of SSL training within the DINO framework.", "For all approaches, the number of labeled training samples per class was systematically varied between 1 and 1000 (steps: 1, 5, 10, 25, 50, 100, 250, 500, 1000 samples per class)."], "citing_paper_content": {"title": "Self-Supervision For Medical Image Classification: State-Of-The-Art Performance With\u02dc100 Labeled Training Samples Per Class", "abstract": "Is self-supervised deep learning (DL) for medical image analysis already a serious alternative to the de facto standard of end-to-end trained supervised DL? We tackle this question for medical image classification, with a particular focus on one of the currently most limiting factor of the field: the (non-)availability of labeled data. Based on three common medical imaging modalities (bone marrow microscopy, gastrointestinal endoscopy, dermoscopy) and publicly available data sets, we analyze the performance of self-supervised DL within the self-distillation with no labels (DINO) framework. After learning an image representation without use of image labels, conventional machine learning classifiers are applied. The classifiers are fit using a systematically varied number of labeled data (1-1000 samples per class). Exploiting the learned image representation, we achieve state-of-the-art classification performance for all three imaging modalities and data sets with only a fraction of between 1% and 10% of the available labeled data and about 100 labeled samples per class."}, "cited_paper_content": {"title": "Skin Lesion Classification Using Ensembles Of Multi-Resolution Efficientnets With Meta Data", "abstract": "In this paper, we describe our method for the ISIC 2019 Skin Lesion Classification Challenge. The challenge comes with two tasks. For task 1, skin lesions have to be classified based on dermoscopic images. For task 2, dermoscopic images and additional patient meta data have to be used. A diverse dataset of 25000 images was provided for training, containing images from eight classes. The final test set contains an additional, unknown class. We address this challenging problem with a simple, data driven approach by including external data with skin lesions types that are not present in the training set. Furthermore, multi-class skin lesion classification comes with the problem of severe class imbalance. We try to overcome this problem by using loss balancing. Also, the dataset contains images with very different resolutions. We take care of this property by considering different model input resolutions and different cropping strategies. To incorporate meta data such as age, anatomical site, and sex, we use an additional dense neural network and fuse its features with the CNN. We aggregate all our models with an ensembling strategy where we search for the optimal subset of models. Our best ensemble achieves a balanced accuracy of 74.2% using five-fold cross-validation. On the official test set our method is ranked first for both tasks with a balanced accuracy of 63.6% for task 1 and 63.4% for task 2."}, "keywords": ["ISIC data set"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For the dermoscopy data set, the authors achieved state-of-the-art performance by using a simple, data-driven approach that included external data with skin lesion types not present in the training set, and by using loss balancing to overcome the problem of severe class imbalance, as well as considering different model input resolutions and different cropping strategies to handle the dataset's images with different resolutions and incorporating meta data using an additional dense neural network and fusing its features with the CNN #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the problem of severe class imbalance in multi-class skin lesion classification, the authors of the manuscript cited the method proposed in the reference paper \"Skin Lesion Classification Using Ensembles Of Multi-Resolution Efficientnets With Meta Data\" (#REFR) and used loss balancing.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of class imbalance and different resolutions in the ISIC data set, the authors of this manuscript used an ensemble of multi-resolution EfficientNets with meta data, achieving a balanced accuracy of 74.2% using five-fold cross-validation and ranking first for both tasks with a balanced accuracy of 63.6% for task 1 and 63.4% for task 2 on the official test set #REFR.", "given_citation_intent": "method", "given_keywords": ["ISIC data set"]}]}
{"citing_id": "2303.00566v1", "cited_id": "1904.03837", "section_title": "Others", "citation": "SGD-based: Instead of zeroing out filters, Centripetal SGD (C-SGD) #REFR makes redundant filters identical and merges identical filters into one filter.", "text_before_citation": [], "text_after_citation": ["Regularized Modernized Dual Averaging (RMDA) #OTHEREFR adds momentum to the RDA algorithm #OTHEREFR and ensures that the trained model has the same structure as the original model.", "To prune the model, RMDA adopts Group Lasso to promote structured sparsity.", "ADMM-based: Alternating Direction Method of Multipliers (ADMM) #OTHEREFR is an optimization algorithm used to decompose initial problem into two smaller, more tractable subproblems.", "StructADMM #OTHEREFR studies the solution of different types of structured sparsity such as filter-wise and shape-wise. Zhang et al.", "use a progressive and multi-step ADMM framework: at each step, it uses ADMM to prune and masks out zero weights, leaving the remaining weights as the optimization space for the next step."], "citing_paper_content": {"title": "Structured Pruning For Deep Convolutional Neural Networks: A Survey", "abstract": "The remarkable performance of deep Convolutional neural networks (CNNs) is generally attributed to their deeper and wider architectures, which can come with significant computational costs. Pruning neural networks has thus gained interest since it effectively lowers storage and computational costs. In contrast to weight pruning, which results in unstructured models, structured pruning provides the benefit of realistic acceleration by producing models that are friendly to hardware implementation. The special requirements of structured pruning have led to the discovery of numerous new challenges and the development of innovative solutions. This article surveys the recent progress towards structured pruning of deep CNNs. We summarize and compare the state-of-the-art structured pruning techniques with respect to filter ranking methods, regularization methods, dynamic execution, neural architecture search, the lottery ticket hypothesis, and the applications of pruning. While discussing structured pruning algorithms, we briefly introduce the unstructured pruning counterpart to emphasize their differences. Furthermore, we provide insights into potential research opportunities in the field of structured pruning. A curated list of neural network pruning papers can be found at https://github.com/he-y/Awesome-Pruning."}, "cited_paper_content": {"title": "Centripetal Sgd For Pruning Very Deep Convolutional Networks With Complicated Structure", "abstract": "The redundancy is widely recognized in Convolutional Neural Networks (CNNs), which enables to remove unimportant filters from convolutional layers so as to slim the network with acceptable performance drop. Inspired by the linear and combinational properties of convolution, we seek to make some filters increasingly close and eventually identical for network slimming. To this end, we propose Centripetal SGD (C-SGD), a novel optimization method, which can train several filters to collapse into a single point in the parameter hyperspace. When the training is completed, the removal of the identical filters can trim the network with NO performance loss, thus no finetuning is needed. By doing so, we have partly solved an open problem of constrained filter pruning on CNNs with complicated structure, where some layers must be pruned following others. Our experimental results on CIFAR-10 and ImageNet have justified the effectiveness of C-SGD-based filter pruning. Moreover, we have provided empirical evidences for the assumption that the redundancy in deep neural networks helps the convergence of training by showing that a redundant CNN trained using C-SGD outperforms a normally trained counterpart with the equivalent width."}, "keywords": ["redundant filters"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose Centripetal SGD (C-SGD), a novel optimization method for filter pruning in convolutional neural networks, which can train several filters to collapse into a single point in the parameter hyperspace, resulting in network slimming with no performance loss #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The redundancy in Convolutional Neural Networks (CNNs) has been widely recognized, and Centripetal SGD (C-SGD) has been proposed as a novel optimization method to remove unimportant filters from convolutional layers, which can trim the network with NO performance loss, thus no finetuning is needed #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The redundancy in deep neural networks has been shown to help the convergence of training, as demonstrated by a redundant CNN trained using Centripetal SGD (C-SGD) outperforming a normally trained counterpart with the equivalent width, as reported in the paper by #REFR.", "given_citation_intent": "background", "given_keywords": ["redundant filters"]}]}
{"citing_id": "2305.02457v1", "cited_id": "1812.08092", "section_title": "A. Metadata, Filtering And Preprocessing", "citation": "The SPGC provides the PG corpus on three different levels of granularity: raw text, time series of word tokens, and counts of individual words #REFR .", "text_before_citation": [], "text_after_citation": ["Texts are tokenized using the \"TreebankWordTokenizer\" from the Natural Language Toolkit (NLTK) #OTHEREFR .", "Only tokens consisting of alphabetic characters are kept, meaning that words containing numbers or other symbols are removed.", "While this processing removes any mentions of numerical objects such as years or ages, it is done to ensure that page and chapter numbers are not erroneously included.", "Additionally, all tokens are lowercased, as this ensures that words capitalised after full stops or within dialogues are not considered different words to their standard lowercase forms.", "PG also provides useful metadata on the texts in the corpus."], "citing_paper_content": {"title": "Quantifying The Dissimilarity Of Texts", "abstract": "Quantifying the dissimilarity of two texts is an important aspect of a number of natural language processing tasks, including semantic information retrieval, topic classification, and document clustering. In this paper, we compared the properties and performance of different dissimilarity measures D using three different representations of texts-vocabularies, word frequency distributions, and vector embeddings-and three simple tasks-clustering texts by author, subject, and time period. Using the Project Gutenberg database, we found that the generalised Jensen-Shannon divergence applied to word frequencies performed strongly across all tasks, that D's based on vector embedding representations led to stronger performance for smaller texts, and that the optimal choice of approach was ultimately task-dependent. We also investigated, both analytically and numerically, the behaviour of the different D's when the two texts varied in length by a factor h. We demonstrated that the (natural) estimator of the Jaccard distance between vocabularies was inconsistent and computed explicitly the h-dependency of the bias of the estimator of the generalised Jensen-Shannon divergence applied to word frequencies. We also found numerically that the Jensen-Shannon divergence and embedding-based approaches were robust to changes in h, while the Jaccard distance was not."}, "cited_paper_content": {"title": "A Standardized Project Gutenberg Corpus For Statistical Analysis Of Natural Language And Quantitative Linguistics", "abstract": "The use of Project Gutenberg (PG) as a text corpus has been extremely popular in statistical analysis of language for more than 25 years. However, in contrast to other major linguistic datasets of similar importance, no consensual full version of PG exists to date. In fact, most PG studies so far either consider only a small number of manually selected books, leading to potential biased subsets, or employ vastly different pre-processing strategies (often specified in insufficient details), raising concerns regarding the reproducibility of published results. In order to address these shortcomings, here we present the Standardized Project Gutenberg Corpus (SPGC), an open science approach to a curated version of the complete PG data containing more than 50,000 books and more than 3 \u00d7 10 9 word-tokens. Using different sources of annotated metadata, we not only provide a broad characterization of the content of PG, but also show different examples highlighting the potential of SPGC for investigating language variability across time, subjects, and authors. We publish our methodology in detail, the code to download and process the data, as well as the obtained corpus itself on three different levels of granularity (raw text, timeseries of word tokens, and counts of words). In this way, we provide a reproducible, pre-processed, full-size version of Project Gutenberg as a new scientific resource for corpus linguistics, natural language processing, and information retrieval."}, "keywords": ["individual words", "PG corpus"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To compare the performance of different dissimilarity measures for natural language processing tasks, the authors used the Project Gutenberg database and found that the generalised Jensen-Shannon divergence applied to word frequencies performed strongly across all tasks (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address concerns regarding the reproducibility of published results, the authors of this study used the Standardized Project Gutenberg Corpus (SPGC), a curated version of the complete PG data containing more than 50,000 books and more than 3 \u00d7 10 9 word-tokens, as a new scientific resource for corpus linguistics, natural language processing, and information retrieval #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The Project Gutenberg (PG) corpus, which contains more than 50,000 books and over 3 \u00d7 10 9 word-tokens, has been standardized and made available as a new scientific resource for corpus linguistics, natural language processing, and information retrieval, providing a reproducible, pre-processed, full-size version of PG for researchers to use as a reference. #REFR", "given_citation_intent": "background", "given_keywords": ["individual words", "PG corpus"]}]}
{"citing_id": "2303.14083v1", "cited_id": "1904.00687", "section_title": "Related Work", "citation": "Related work has shown that the RFM cannot predict the output of a ReLU perceptron, except the hidden layer size K increases exponentially fast with the input dimension N #REFR .", "text_before_citation": ["Based on the bias-variance tradeoff, traditional learning theories suggest that over-parametrized neural networks should generalize poorly as they have more regression parameters than avaiable input examples #OTHEREFR .", "However, recent studies have shown that this tradeoff must be extend for ultra-wide neural networks leading to a double descent curve #OTHEREFR .", "For the RFM, different analytical studies derived the test error's double descent behavior in the student-teacher framework indicating the accessibility of interesting deep learning phenomena by investigating this model #OTHEREFR .", "The connection between kernel ridge regression and random feature approximation can be found in #OTHEREFR ."], "text_after_citation": ["We verify this result for an error activation function by actually computing the asymptotic generalization error.", "Further related studies considered the random feature model for quadratic activation and output functions in the high-dimensional regime K, N \u2192 \u221e, K/N \u2192 \u03c4 \u2208 (0, \u221e) trained by one-pass stochastic gradient descent #OTHEREFR .", "These works demonstrated the existence of a gap between the performance of the RFM compared to fully-trained over-parametrized neural networks.", "Furthermore, the network performance is highly controlled by the initialization of the weights and becomes optimal only in the case for which the random features are perfectly aligned with those of the teacher.", "We extend these investigations by introducing a set of ordinary differential equations for the learning dynamics of a student with infinitely large input and hidden layer size trained by a teacher with a ReLU or error activation function."], "citing_paper_content": {"title": "Online Learning For The Random Feature Model In The Student-Teacher Framework", "abstract": "Deep neural networks are widely used prediction algorithms whose performance often improves as the number of weights increases, leading to over-parametrization. We consider a two-layered neural network whose first layer is frozen while the last layer is trainable, known as the random feature model. We study over-parametrization in the context of a student-teacher framework by deriving a set of differential equations for the learning dynamics. For any finite ratio of hidden layer size and input dimension, the student cannot generalize perfectly, and we compute the non-zero asymptotic generalization error. Only when the student's hidden layer size is exponentially larger than the input dimension, an approach to perfect generalization is possible."}, "cited_paper_content": {"title": "On The Power And Limitations Of Random Features For Understanding Neural Networks", "abstract": "Recently, a spate of papers have provided positive theoretical results for training over-parameterized neural networks (where the network size is larger than what is needed to achieve low error). The key insight is that with sufficient over-parameterization, gradient-based methods will implicitly leave some components of the network relatively unchanged, so the optimization dynamics will behave as if those components are essentially fixed at their initial random values. In fact, fixing these explicitly leads to the well-known approach of learning with random features. In other words, these techniques imply that we can successfully learn with neural networks, whenever we can successfully learn with random features. In this paper, we first review these techniques, providing a simple and self-contained analysis for one-hidden-layer networks. We then argue that despite the impressive positive results, random feature approaches are also inherently limited in what they can explain. In particular, we rigorously show that random features cannot be used to learn even a single ReLU neuron with standard Gaussian inputs, unless the network size (or magnitude of the weights) is exponentially large. Since a single neuron is learnable with gradient-based methods, we conclude that we are still far from a satisfying general explanation for the empirical success of neural networks."}, "keywords": ["ReLU perceptron"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Based on the bias-variance tradeoff, traditional learning theories suggest that over-parametrized neural networks should generalize poorly as they have more regression parameters than avaiable input examples #OTHEREFR. However, recent studies have shown that this tradeoff must be extend for ultra-wide neural networks leading to a double descent curve #OTHEREFR. For the RFM, different analytical studies derived the test error's double descent behavior in the student-teacher framework indicating the accessibility of interesting deep learning phenomena by investigating this model #OTHEREFR. The connection between kernel ridge regression and random feature approximation can be found in (On The Power And Limitations Of Random Features For Understanding Neural Networks).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent studies have shown that over-parameterized neural networks can generalize well, contrary to traditional learning theories based on the bias-variance tradeoff #OTHEREFR. In fact, the success of neural networks can be explained by the fact that gradient-based methods implicitly leave some components of the network unchanged, which is similar to learning with random features #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recent studies have shown that over-parametrized neural networks can generalize well, which contradicts traditional learning theories based on the bias-variance tradeoff #OTHEREFR. However, the limitations of these networks have been explored, and it has been shown that random feature approaches cannot learn even a single ReLU perceptron with standard Gaussian inputs unless the network size is exponentially large #REFR.", "given_citation_intent": "background", "given_keywords": ["ReLU perceptron"]}]}
{"citing_id": "2303.03965v1", "cited_id": "1809.05231", "section_title": "Registration And Classification Models", "citation": "Thus by replacing the preprocessing steps with a more modern deep learning-based DIR approaches, we are able to train a pair of models based on the VoxelMorph #REFR framework that are capable of disentangling the different stages of multi-modal registration.", "text_before_citation": ["During testing, CBCT0 is unused, and is replaced by the aligned CT.", "on related technologies and seemingly similar visually, CT and CBCT present distinct characteristics in pixel intensities, edge resolution and artifacting #OTHEREFR .", "Older methods of DIR incorporated an initial intensity correction preprocessing step so that the registration could be seen as a mono-modal task #OTHEREFR .", "More recent approaches leveraging deep learning attempted to perform both tasks in a single fully automated way #OTHEREFR .", "Nonetheless, we are proposing to follow the former two stage approach precisely to distinguish between multi-modal mapping space from mono-modal transformations resulting uniquely from morphological changes in response to radiotherapy."], "text_after_citation": ["And this will become relevant as our proposed method focuses specifically on extracting the transformation related to the second stage: registration resulting from anatomical changes before and during therapy.", "To train under this proposed methodology, an initial model learned the mapping from pCT and CBCT 0 (see Figure 1) .", "Independently, a second model was trained to register CBCT that were deformed due to changes in anatomy resulting from radiotherapy treatment CBCT 0 \u2192 CBCT t ).", "Fixing the input image to CBCT 0 has the advantage of resembling the pCT the most since no treatment occurred between those two dates, which will become relevant at testing time.", "At that stage then after both models are trained, the pCT is registered first to CBCT 0 , then that image (Aligned CT in Figure 1) is then fed into the second model and registered to the CBCT at the current fraction of treatment (not shown)."], "citing_paper_content": {"title": "Comparing 3D Deformations Between Longitudinal Daily Cbct Acquisitions Using Cnn For Head And Neck Radiotherapy Toxicity Prediction", "abstract": "Adaptive radiotherapy is a growing field of study in cancer treatment due to it's objective in sparing healthy tissue. The standard of care in several institutions includes longitudinal cone-beam computed tomography (CBCT) acquisitions to monitor changes, but have yet to be used to improve tumor control while managing side-effects. The aim of this study is to demonstrate the clinical value of pre-treatment CBCT acquired daily during radiation therapy treatment for head and neck cancers for the downstream task of predicting severe toxicity occurrence: reactive feeding tube (NG), hospitalization and radionecrosis. For this, we propose a deformable 3D classification pipeline that includes a component analyzing the Jacobian matrix of the deformation between planning CT and longitudinal CBCT, as well as clinical data. The model is based on a multi-branch 3D residual convolutional neural network, while the CT to CBCT registration is based on a pair of VoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for radionecrosis and hospitalization, respectively, with similar performance as early as after the first week of treatment. For NG tube risk, performance improves with increasing the timing of the CBCT fraction, reaching 83.1% after the 5 th week of treatment."}, "cited_paper_content": {"title": "Voxelmorph: A Learning Framework For Deformable Medical Image Registration", "abstract": "We present VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration. Traditional registration methods optimize an objective function for each pair of images, which can be time-consuming for large datasets or rich deformation models. In contrast to this approach and building on recent learning-based methods, we formulate registration as a function that maps an input image pair to a deformation field that aligns these images. We parameterize the function via a convolutional neural network and optimize the parameters of the neural network on a set of images. Given a new pair of scans, VoxelMorph rapidly computes a deformation field by directly evaluating the function. In this paper, we explore two different training strategies. In the first (unsupervised) setting, we train the model to maximize standard image matching objective functions that are based on the image intensities. In the second setting, we leverage auxiliary segmentations available in the training data. We demonstrate that the unsupervised model\u2019s accuracy is comparable to the state-of-the-art methods while operating orders of magnitude faster. We also show that VoxelMorph trained with auxiliary data improves registration accuracy at test time and evaluate the effect of training set size on registration. Our method promises to speed up medical image analysis and processing pipelines while facilitating novel directions in learning-based registration and its applications. Our code is freely available at https://github.com/voxelmorph/voxelmorph ."}, "keywords": ["multi-modal registration"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We propose a two-stage approach precisely to distinguish between multi-modal mapping space from mono-modal transformations resulting uniquely from morphological changes in response to radiotherapy, as older methods of DIR incorporated an initial intensity correction preprocessing step #OTHEREFR. More recent approaches leveraging deep learning attempted to perform both tasks in a single fully automated way #OTHEREFR. Nonetheless, we use VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration, to align CT and CBCT images #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform CT to CBCT registration, the authors propose a pair of VoxelMorph architectures #REFR, which have been shown to be fast and accurate for deformable medical image registration.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To distinguish between multi-modal mapping space from mono-modal transformations resulting uniquely from morphological changes in response to radiotherapy, we propose to follow the two-stage approach, as older methods of DIR incorporated an initial intensity correction preprocessing step #REFR.", "given_citation_intent": "method", "given_keywords": ["multi-modal registration"]}]}
{"citing_id": "2303.03326v1", "cited_id": "1502.03167", "section_title": "B. Cnn Architecture For Interference Classification", "citation": "All convolutional layers are subject to batch normalization #REFR , however the output layer and fullyconnected layers are excluded.", "text_before_citation": ["The CNN model is a pre-trained ResNet18 model described in #OTHEREFR . The architecture is summarized in Table II .", "The model consists of many convolutional layers, two fully-connected layers, and one output layer, in that order.", "Leaky ReLU (Leaky ReLU(x) = max{\u03b1x, x}, where \u03b1 \u2208 (0, 1) is a preset parameter).", "All convolutional layers and fully linked layers are subjected to an activation function with \u03b1 = 0.2.", "The resulting (output) layer then has the softmax function applied to it."], "text_after_citation": ["Additionally, we use stride = 2 in the convolutional layers rather than 2 \u00d7 2 pooling layers for down-sampling.", "Such changes enhance performance and lower the variance of the results across various training epochs.", "x is normalized as x = x/x max , where x max is the largest input value allowed in x.", "We utilize the Adam optimizer with the suggested default values in #OTHEREFR .", "The learning rate is 1\u00d710 \u22124 , and the batch size is 64."], "citing_paper_content": {"title": "Keep It Simple: Cnn Model Complexity Studies For Interference Classification Tasks", "abstract": "The growing number of devices using the wireless spectrum makes it important to find ways to minimize interference and optimize the use of the spectrum. Deep learning models, such as convolutional neural networks (CNNs), have been widely utilized to identify, classify, or mitigate interference due to their ability to learn from the data directly. However, there have been limited research on the complexity of such deep learning models. The major focus of deep learning-based wireless classification literature has been on improving classification accuracy, often at the expense of model complexity. This may not be practical for many wireless devices, such as, internet of things (IoT) devices, which usually have very limited computational resources and cannot handle very complex models. Thus, it becomes important to account for model complexity when designing deep learning based models for interference classification. To address this, we conduct an analysis of CNN based wireless classification that explores the trade-off amongst dataset size, CNN model complexity, and classification accuracy under various levels of classification difficulty: namely, interference classification, heterogeneous transmitter classification, and homogeneous transmitter classification. Our study, based on three wireless datasets, shows that a simpler CNN model with fewer parameters can perform just as well as a more complex model, providing important insights into the use of CNNs in computationally constrained applications."}, "cited_paper_content": {"title": "Batch Normalization: Accelerating Deep Network Training By Reducing Internal Covariate Shift", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."}, "keywords": ["convolutional layers", "batch normalization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The CNN model is a pre-trained ResNet18 model described in #OTHEREFR. The architecture is summarized in Table II. The model consists of many convolutional layers, two fully-connected layers, and one output layer, in that order. Leaky ReLU (Leaky ReLU(x) = max{\u03b1x, x}, where \u03b1 \u2208 (0, 1) is a preset parameter). All convolutional layers and fully linked layers are subjected to an activation function with \u03b1 = 0.2. The resulting (output) layer then has the softmax function applied to it. To address the issue of model complexity in deep learning-based wireless classification, Batch Normalization, a technique that normalizes layer inputs, is proposed in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of internal covariate shift in deep neural networks, the authors of this manuscript propose a method called Batch Normalization, which normalizes layer inputs and allows for higher learning rates and less careful initialization, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce internal covariate shift in the CNN model, the authors utilized batch normalization on all convolutional layers and fully connected layers, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["convolutional layers", "batch normalization"]}]}
{"citing_id": "2304.08767v2", "cited_id": "1907.11692", "section_title": "Masked Language Models And The Off-Manifold Conjecture", "citation": "RoBERTa #REFR improves BERT by employing the dynamic masking strategy, which dynamically changes the masking pattern applied to training data.", "text_before_citation": ["As mentioned earlier, masked language models are pre-trained on large-scale unlabeled normal data with the MLM objective.", "This pretraining equips the models with the capacity of reconstructing input data.", "As the most representative example of the masked language model, BERT #OTHEREFR is a bidirectional language model trained with the MLM objective to learn general language representations from unlabeled data, leading to a series of breakthroughs in NLP.", "ALBERT #OTHEREFR is pre-trained on the same data as BERT, but it adopts the ngram masking strategy of the MLM objective.", "The MLM target consists of up to an n-gram of complete words, which encourages the model to capture more comprehensive language representations."], "text_after_citation": ["Additionally, it is trained over a variety of corpora with more sophisticated techniques, such as training the model longer and with bigger batches.", "Thus, it has the potential to better approximate the manifold of normal data.", "The off-manifold conjecture #OTHEREFR 13, #OTHEREFR states that adversarial examples tend to deviate from the manifold of normal examples.", "This conjecture offers a new perspective to interpret the existence of adversarial examples and has attracted significant research attention #OTHEREFR .", "In computer vision tasks, under the off-manifold conjecture, substantial detection approaches #OTHEREFR have approximated the manifold of normal images by generative models and designed effective metrics to measure changes in the manifold to detect adversarial images. In NLP, Nguyen et al."], "citing_paper_content": {"title": "Masked Language Model Based Textual Adversarial Example Detection", "abstract": "Adversarial attacks are a serious threat to the reliable deployment of machine learning models in safety-critical applications. They can misguide current models to predict incorrectly by slightly modifying the inputs. Recently, substantial work has shown that adversarial examples tend to deviate from the underlying data manifold of normal examples, whereas pre-trained masked language models can fit the manifold of normal NLP data. To explore how to use the masked language model in adversarial detection, we propose a novel textual adversarial example detection method, namely Masked Language Model-based Detection (MLMD), which can produce clearly distinguishable signals between normal examples and adversarial examples by exploring the changes in manifolds induced by the masked language model. MLMD features a plug and play usage (i.e., no need to retrain the victim model) for adversarial defense and it is agnostic to classification tasks, victim model's architectures, and to-be-defended attack methods. We evaluate MLMD on various benchmark textual datasets, widely studied machine learning models, and state-of-the-art (SOTA) adversarial attacks (in total 3 * 4 * 4 = 48 settings). Experimental results show that MLMD can"}, "cited_paper_content": {"title": "Roberta: A Robustly Optimized Bert Pretraining Approach", "abstract": "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code."}, "keywords": ["training data", "BERT"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As the most representative example of the masked language model, BERT (Devlin et al., 2019) is a bidirectional language model trained with the MLM objective to learn general language representations from unlabeled data, leading to a series of breakthroughs in NLP.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The pre-training of masked language models on large-scale unlabeled normal data with the MLM objective has enabled them to reconstruct input data, as demonstrated by the success of BERT #REFR, a bidirectional language model that has achieved state-of-the-art results on various NLP tasks.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "BERT was significantly undertrained, and can match or exceed the performance of every model published after it, as shown by a recent replication study on the impact of hyperparameters and training data size on BERT pretraining #REFR.", "given_citation_intent": "background", "given_keywords": ["training data", "BERT"]}]}
{"citing_id": "2303.00678v1", "cited_id": "1902.04573", "section_title": "Limitations And Future Directions", "citation": "Unlike VR-based training applications typically striving to maximize user's behavioral validity #REFR , the prime objective of our simulated field study was rather to elicit valid user reflections.", "text_before_citation": [], "text_after_citation": ["A case could then be made that the phenomenological nature of our enquiry, with expert users drawing on their own personal experience, has permitted some level of abstraction and simplification with regards to the simulated interactions.", "Past studies seem to support this; Osterlund et al., for instance, found that a purely audiovisual simulation of aerospace maintenance operations in protective suits could elicit valid and actionable design feedback from subject matter experts #OTHEREFR .", "Whilst it is therefore unlikely that the monosensory nature of our VR simulation impeded the overall validity of the presented findings, we did also come across several instances where a broader sensory engagement delivered via a mixed reality interface would have likely resulted in richer and more accurate user feedback.", "Below, we discuss key problem areas in this vein and offer our recommendations concerning the development of future interfaces for simulation of lunar surface scenarios.", "\u2022 Haptics -The lack of physical properties, including a sense of touch, weight and rigidity hampered our participant's ability to assess key ergonomic aspects surrounding the manipulation of cargo containers and other artifacts in our simulation."], "citing_paper_content": {"title": "Using Virtual Reality To Shape Humanity'S Return To The Moon: Key Takeaways From A Design Study", "abstract": "Revived interest in lunar exploration is heralding a new generation of design solutions in support of human operations on the Moon. While space system design has traditionally been guided by prototype deployments in analogue studies, the resource-intensive nature of this approach has largely precluded application of proficient user-centered design (UCD) methods from human-computer interaction (HCI). This paper explores possible use of Virtual Reality (VR) to simulate analogue studies in lab settings and thereby bring to bear UCD in this otherwise engineering-dominated field. Drawing on the ongoing development of the European Large Logistics Lander, we have recreated a prospective lunar operational scenario in VR and evaluated it with a group of astronauts and space experts (n=20). Our qualitative findings demonstrate the efficacy of VR in facilitating UCD, enabling efficient contextual inquiries and improving project team coordination. We conclude by proposing future directions to further exploit VR in lunar systems design. CCS CONCEPTS \u2022 Human-centered computing \u2192 Virtual reality; Human computer interaction (HCI)."}, "cited_paper_content": {"title": "The Heat Is On: Exploring User Behaviour In A Multisensory Virtual Environment For Fire Evacuation", "abstract": "Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology."}, "keywords": ["VR-based training applications"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors explored the use of Virtual Reality (VR) to facilitate user-centered design in lunar systems and found it to be effective in improving project team coordination and contextual inquiries #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To simulate analogue studies in lab settings and bring user-centered design to the field of lunar systems design, the authors propose the use of Virtual Reality (VR) #REFR, which has been shown to facilitate efficient contextual inquiries and improve project team coordination.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To facilitate user-centered design in the field of lunar systems engineering, the authors propose the use of Virtual Reality (VR) to simulate analogue studies in lab settings, as demonstrated in their study exploring VR-based training applications for fire evacuation in a multisensory environment #REFR.", "given_citation_intent": "method", "given_keywords": ["VR-based training applications"]}]}
{"citing_id": "2303.11257v1", "cited_id": "1706.03762", "section_title": "Scaling At Initialisation", "citation": "It also adopts a scaling factor from the Transformer #REFR , which scales the product of activation matrices QK , Q, K \u2208 R s\u00d7d by 1/ \u221a d.", "text_before_citation": ["Since the initial distribution of parameters is directly controlled by the model designer, the dominant approach to scaling is to select initial parameter variance to trade off forward and backward pass variance scaling (Glorot and Bengio, 2010; He et al., 2015) .", "Such schemes were developed to avoid exploding/vanishing gradients in deep multilayer perceptrons.", "As such, they do not seek to constrain the scale of parameters and parameter gradients.", "They are also limited to computations where scale factors can be moved into trainable parameters.", "Example: BERT #OTHEREFR BERT's initialisation scheme does not use the rules of Glorot and Bengio (2010), instead initialising all non-bias parameters from N (0, (0.02) 2 )."], "text_after_citation": ["We instrument the model to record histograms of all tensors at the start and end of training, and plot the results in Figures A.4 and A.6.", "In light of this analysis, we can understand loss scaling as simply enacting a shift of the gradx and gradw histograms by log 2 (loss scale) bits to the right, trading off underflow and overflow globally across gradient tensors.", "BERT with loss scaling illustrates the drawbacks of having just three scales: weight initialisation scale, loss scale, and QK scale.", "These are not sufficient to centre most tensors' distributions in the representable range."], "citing_paper_content": {"title": "Unit Scaling: Out-Of-The-Box Low-Precision Training", "abstract": "We present unit scaling, a paradigm for designing deep learning models that simplifies the use of low-precision number formats. Training in FP16 or the recently proposed FP8 formats offers substantial efficiency gains, but can lack sufficient range for out-of-the-box training. Unit scaling addresses this by introducing a principled approach to model numerics: seeking unit variance of all weights, activations and gradients at initialisation. Unlike alternative methods, this approach neither requires multiple training runs to find a suitable scale nor has significant computational overhead. We demonstrate the efficacy of unit scaling across a range of models and optimisers. We further show that existing models can be adapted to be unit-scaled, training BERT LARGE in FP16 and then FP8 with no degradation in accuracy."}, "cited_paper_content": {"title": "Attention Is All You Need", "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."}, "keywords": ["scaling factor", "Transformer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose a new simple network architecture based solely on attention mechanisms, called the Transformer, which achieves state-of-the-art results on machine translation tasks and generalizes well to other tasks (Vaswani et al., 2017). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of exploding/vanishing gradients in deep multilayer perceptrons, Glorot and Bengio (2010) proposed a scheme to select initial parameter variance, which is not designed to constrain the scale of parameters and parameter gradients, unlike the unit scaling approach proposed by Vaswani et al. (#REFR) that seeks unit variance of all weights, activations, and gradients at initialization.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of scaling factor in deep learning models, Glorot and Bengio (2010) proposed an approach to select initial parameter variance, which does not constrain the scale of parameters and parameter gradients, and is limited to computations where scale factors can be moved into trainable parameters. However, this approach can be improved by seeking unit variance of all weights, activations, and gradients at initialization, as proposed in the Transformer model by Vaswani et al. (2017). #REFR", "given_citation_intent": "method", "given_keywords": ["scaling factor", "Transformer"]}]}
{"citing_id": "2303.14267v1", "cited_id": "1710.09412", "section_title": "Ii. Related Works", "citation": "The core idea in most works in this area is that comparing and contrasting the latent representations of examples that are expected to share certain similarities (e.g., augmented versions of the same image) can benefit the trained weights and help with regularizing the learned decision boundaries #REFR .", "text_before_citation": ["It has also been shown that physiological readings made by basic smartwatch sensors enable efficient modeling of perceived stress response #OTHEREFR .", "In the health analytics domain, data and human annotations are often limited.", "Therefore, dealing with overfitting and memorization is a crucial matter.", "Additionally, it is beneficial to go beyond the limited number of human annotations available in training efficient inference pipelines.", "Less reliance on annotations by focusing on unsupervised and self-supervised approaches has received a lot of research attention in recent years #OTHEREFR - #OTHEREFR ."], "text_after_citation": ["In short, this work is primarily focused on addressing the limitations in the previous literature on remote mental health monitoring.", "The previous works do not go beyond leveraging scarcely available annotations in training network parameters and mainly rely on data augmentation to improve their performance.", "They do not focus on encapsulation in embedding different modalities, which can be an obstacle in employing optimal encoders for each modality and can hinder transfer learning.", "Additionally, they do not focus on the interpretability of the inference pipeline, which is crucial in health-related applications.", "To address these challenges, this work proposes a framework for leveraging smartwatch-based sensor-driven data to recognize perceived stress, enabling a novel approach to remote mental health monitoring."], "citing_paper_content": {"title": "A Self-Supervised Framework For Improved Data-Driven Monitoring Of Stress Via Multi-Modal Passive Sensing", "abstract": "Recent advances in remote health monitoring systems have significantly benefited patients and played a crucial role in improving their quality of life. However, while physiological health-focused solutions have demonstrated increasing success and maturity, mental health-focused applications have seen comparatively limited success in spite of the fact that stress and anxiety disorders are among the most common issues people deal with in their daily lives. In the hopes of furthering progress in this domain through the development of a more robust analytic framework for the measurement of indicators of mental health, we propose a multi-modal semi-supervised framework for tracking physiological precursors of the stress response. Our methodology enables utilizing multi-modal data of differing domains and resolutions from wearable devices and leveraging them to map short-term episodes to semantically efficient embeddings for a given task. Additionally, we leverage an inter-modality contrastive objective, with the advantages of rendering our framework both modular and scalable. The focus on optimizing both local and global aspects of our embeddings via a hierarchical structure renders transferring knowledge and compatibility with other devices easier to achieve. In our pipeline, a task-specific pooling based on an attention mechanism, which estimates the contribution of each modality on an instance level, computes the final embeddings for observations. This additionally provides a thorough diagnostic insight into the data characteristics and highlights the importance of signals in the broader view of predicting episodes annotated per mental health status. We perform training experiments using a corpus of realworld data on perceived stress, and our results demonstrate the efficacy of the proposed approach in performance improvements 1 ."}, "cited_paper_content": {"title": "Mixup: Beyond Empirical Risk Minimization", "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks."}, "keywords": ["latent representations", "learned decision boundaries"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In order to address the issue of overfitting and memorization in health analytics, mixup has been proposed as a simple learning principle to improve the generalization of neural network architectures #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Mixup has been proposed as a simple learning principle to alleviate the issues of memorization and sensitivity to adversarial examples in large deep neural networks #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Mixup is a simple learning principle that can regularize neural networks to favor simple linear behavior in-between training examples, which can be useful for dealing with overfitting and memorization in the health analytics domain #REFR. Furthermore, mixup can improve the generalization of state-of-the-art neural network architectures, which can be beneficial for learning latent representations and learned decision boundaries.", "given_citation_intent": "background", "given_keywords": ["latent representations", "learned decision boundaries"]}]}
{"citing_id": "2304.09181v1", "cited_id": "1810.04805", "section_title": "Contextual Model Integration:", "citation": "In order to achieve accurate and effective extraction of software specifications from natural language texts, we propose to use the state-of-the-art BERT #REFR model.", "text_before_citation": [], "text_after_citation": ["By leveraging the acquired knowledge and advanced language processing capabilities of a pre-trained BERT model, we aim to extract relevant specifications from the text in a manner that is both accurate and efficient.", "Through empirical analysis, we demonstrate the effectiveness of SpecSyn in the context of software specification extraction from natural language texts.", "To the best of our knowledge, this is the first paper that uses a large language model for end-to-end synthesis of configurations specifications from natural language texts."], "citing_paper_content": {"title": "Large Language Models Based Automatic Synthesis Of Software Specifications", "abstract": "Software configurations play a crucial role in determining the behavior of software systems. In order to ensure safe and error-free operation, it is necessary to identify the correct configuration, along with their valid bounds and rules, which are commonly referred to as software specifications. As software systems grow in complexity and scale, the number of configurations and associated specifications required to ensure the correct operation can become large and prohibitively difficult to manipulate manually. Due to the fast pace of software development, it is often the case that correct software specifications are not thoroughly checked or validated within the software itself. Rather, they are frequently discussed and documented in a variety of external sources, including software manuals, code comments, and online discussion forums. Therefore, it is hard for the system administrator to know the correct specifications of configurations due to the lack of clarity, organization, and a centralized unified source to look at. To address this challenge, we propose SpecSyn a framework that leverages a state-of-the-art large language model to automatically synthesize software specifications from natural language sources. Our approach formulates software specification synthesis as a sequence-to-sequence learning problem and investigates the extraction of specifications from large contextual texts. This is the first work that uses a large language model for end-to-end specification synthesis from natural language texts. Empirical results demonstrate that our system outperforms prior state-of-the-art specification synthesis tool by 21% in terms of F1 score and can find specifications from single as well as multiple sentences."}, "cited_paper_content": {"title": "Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ::: BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."}, "keywords": ["software specifications", "natural language texts"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of synthesizing software specifications from natural language sources, SpecSyn leverages a state-of-the-art large language model for sequence-to-sequence learning, as proposed in the reference paper \"Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding\" (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To automatically synthesize software specifications from natural language sources, the authors propose SpecSyn, a framework that leverages a state-of-the-art large language model for sequence-to-sequence learning problem and investigates the extraction of specifications from large contextual texts (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To automatically synthesize software specifications from #KEYWORD1, we propose SpecSyn, a framework that leverages the state-of-the-art BERT model for end-to-end specification synthesis from #KEYWORD2. #REFR should be cited for the use of BERT in our approach.", "given_citation_intent": "method", "given_keywords": ["software specifications", "natural language texts"]}]}
{"citing_id": "2304.14226v2", "cited_id": "1710.03740", "section_title": "Benchmark Adaptation And Configuration", "citation": "Although TorchBench supports other data precisions such as FP16 (half-precision), BF16 (Brain Floating Point Format), and AMP (automatic mixed precision) #REFR , FP32 and TF32 are the most representative and recommended precisions.", "text_before_citation": ["For inference, the original model code usually does not specify an optimal batch_size of inputs.", "Thus, we run a set of tests with exhaustively enumerating batch_size values (i.e., starting with one and doubling the size in each test) to determine the optimal value that yields the highest GPU utilization.", "We believe our configuration enables optimal performance for each model in TorchBench.", "Precision configuration.", "We use the 32-bit floating point operations (FP32 or TF32) for all the benchmarks unless models have specific requirements."], "text_after_citation": ["On the one hand, GPU vendors such as NVIDIA publish concrete roofline performance numbers for FP32 operations in TFLOPS (Tera Floating Point Operations per Second) as part of the hardware specification, which facilitates our characterization efforts.", "For example, the theoretical peaks of an NVIDIA Tesla A100 GPU and an AMD Instinct MI210 GPU are 19.", "Recently, TorchBench has evolved to embrace end-to-end models and support beyond PyTorch (e.g., Jax).", "However, this evolution is in the preliminary stage and out of the scope of this paper."], "citing_paper_content": {"title": "Torchbench: Benchmarking Pytorch With High Api Surface Coverage", "abstract": "Deep learning (DL) has been a revolutionary technique in various domains. To facilitate the model development and deployment, many deep learning frameworks are proposed, among which Py-Torch is one of the most popular solutions. The performance of ecosystem around PyTorch is critically important, which saves the costs of training models and reduces the response time of model inferences. In this paper, we propose TorchBench, a novel benchmark suite to study the performance of PyTorch software stack. Unlike existing benchmark suites, TorchBench encloses many representative models, covering a large PyTorch API surface. TorchBench is able to comprehensively characterize the performance of the Py-Torch software stack, guiding the performance optimization across models, PyTorch framework, and GPU libraries. We show two practical use cases of TorchBench. (1) We profile TorchBench to identify GPU performance inefficiencies in PyTorch. We are able to optimize many performance bugs and upstream patches to the official PyTorch repository. (2) We integrate TorchBench into PyTorch continuous integration system. We are able to identify performance regression in multiple daily code checkins to prevent PyTorch repository from introducing performance bugs. TorchBench is open source and keeps evolving."}, "cited_paper_content": {"title": "Mixed Precision Training", "abstract": "Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units."}, "keywords": ["TorchBench", "half-precision"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For precision configuration, the authors recommend using 32-bit floating point operations (FP32 or TF32) for all the benchmarks unless models have specific requirements. To reduce memory consumption and increase computation speed, the authors of TorchBench propose using half-precision floating point numbers for training deep neural networks, as demonstrated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce memory consumption and increase computation speedup, mixed precision training using half-precision floating point numbers has been proposed, where weights, activations, and gradients are stored in IEEE half-precision format, and the loss is scaled appropriately to handle the loss of information with half-precision gradients (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize GPU utilization, the authors exhaustively enumerated batch_size values and used 32-bit floating point operations for all benchmarks in TorchBench, unless models had specific requirements for half-precision, a technique introduced in #REFR.", "given_citation_intent": "background", "given_keywords": ["TorchBench", "half-precision"]}]}
{"citing_id": "2303.00261v1", "cited_id": "1811.06965", "section_title": "Efficientnet", "citation": "GPipe's #REFR ImageNet top-1 accuracy is improved to 84.3% by scaling up the baseline model by 4 times.", "text_before_citation": ["CNNs are often scaled up to achieve better performance.", "For example, ResNet #OTHEREFR can be scaled up from ResNet-18 to ResNet-200 by incorporating more layers."], "text_after_citation": ["Scaling CNNs up by their depth #OTHEREFR or width #OTHEREFR are the most commonly performed, but scaling up models by image resolution #OTHEREFR is also a popular method.", "Only one of the three dimensions -depth, width, and image size -is usually scaled.", "Although two or three dimensions can be arbitrarily scaled, it involves tedious manual tuning and still often fails to provide better accuracy and efficiency.", "To resolve this, EfficientNet proposes a simple yet effective compound scaling method that uses a constant scaling ratio to scale all three dimensions of network in a controlled and balanced way.", "The intuition is: as the input image size increases, it makes sense that the model will need more layers and more channels to extract even finer details from larger images."], "citing_paper_content": {"title": "Speeding Up Efficientnet: Selecting Update Blocks Of Convolutional Neural Networks Using Genetic Algorithm In Transfer Learning", "abstract": "The performance of convolutional neural networks (CNN) depends heavily on their architectures. Transfer learning performance of a CNN relies quite strongly on selection of its trainable layers. Selecting the most effective update layers for a certain target dataset often requires expert knowledge on CNN architecture which many practitioners do not posses. General users prefer to use an available architecture (e.g. GoogleNet, ResNet, EfficientNet etc.) that is developed by domain experts. With the ever-growing number of layers, it is increasingly becoming quite difficult and cumbersome to handpick the update layers. Therefore, in this paper we explore the application of genetic algorithm to mitigate this problem. The convolutional layers of popular pre-trained networks are often grouped into modules that constitute their building blocks. We devise a genetic algorithm to select blocks of layers for updating the parameters. By experimenting with EfficientNetB0 pre-trained on ImageNet and using Food-101, CIFAR-100 and MangoLeafBD as target datasets, we show that our algorithm yields similar or better results than the baseline in terms of accuracy, and requires lower training and evaluation time due to learning less number of parameters. We also devise a metric called block importance to measure each block's efficacy as update block and analyze the importance of the blocks selected by our algorithm."}, "cited_paper_content": {"title": "Gpipe: Efficient Training Of Giant Neural Networks Using Pipeline Parallelism", "abstract": "Scaling up deep neural network capacity has been known as an effective approach to improving model quality for several different machine learning tasks. In many cases, increasing model capacity beyond the memory limit of a single accelerator has required developing special algorithms or infrastructure. These solutions are often architecture-specific and do not transfer to other machine learning tasks. To address the need for efficient and task-independent model parallelism, we introduce TensorPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers. By pipelining different sub-sequences of layers on separate accelerators, TensorPipe provides the flexibility of scaling a variety of different networks to gigantic sizes efficiently. Moreover, TensorPipe utilizes a novel batch-splitting pipelining algorithm, resulting in almost linear speedup when a model is partitioned across multiple accelerators. We demonstrate the advantages of TensorPipe by training large-scale neural networks on two different tasks with distinct network architectures: (i)Image Classification: We train a 557-million-parameter AmoebaNet model and attain a top-1 accuracy of 84.4% on ImageNet-2012, (ii)Multilingual Neural Machine Translation: We train a single 6-billion-parameter, 128-layer Transformer model on a corpus spanning over 100 languages and achieve better quality than all bilingual models."}, "keywords": ["GPipe's ImageNet"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "CNNs can be scaled up to achieve better performance, and efficient training of giant neural networks using pipeline parallelism has been shown to be an effective approach for this purpose #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently scale up deep neural network capacity, TensorPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers, was introduced by the authors in their paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To scale up deep neural network capacity, GPipe's pipeline parallelism library was introduced, which allows scaling any network that can be expressed as a sequence of layers, resulting in almost linear speedup when a model is partitioned across multiple accelerators, as demonstrated by training a 557-million-parameter AmoebaNet model achieving a top-1 accuracy of 84.4% on ImageNet-2012. #REFR", "given_citation_intent": "method", "given_keywords": ["GPipe's ImageNet"]}]}
{"citing_id": "2304.07254v1", "cited_id": "1512.03385", "section_title": "Ablations", "citation": "The results presented in table 7 also align with the philosophy of the residual connection #REFR . Note that input-agnostic kernel W inputagnostic is initialized randomly.", "text_before_citation": ["#OTHEREFR stabilized the learning process by reducing the kernel space using softmax and demonstrated better performance with fewer kernels and FLOPs.", "But, as shown in the table 6, we utilize the sigmoid function to enhance performance by increasing the kernel space, as our residual connection in kernel space helps to alleviate optimization difficulties.", "Initialization for W static .", "We assume that the previous approach #OTHEREFR of using the dynamic convolution module to calculate both input-agnostic and input-dependent kernels in the kernel attention module results in optimization difficulties.", "Therefore, to address this issue, we introduce the residual connection that connects input-specific dynamic kernel to the existing input-agnostic kernel."], "text_after_citation": ["Static kernel number.", "We not only use temperature annealing to achieve stable training, but also utilize residual connection in kernel space to ease the optimization and expand the kernel space.", "Table 8 demonstrates that our dynamic residual convolution approach enables us to increase the kernel space by increasing the number of static kernels while maintaining stable training and improved performance.", "Therefore, all variants of DMF take 8 static kernels, which is zero initialized and use sigmoid activation for generating attention scores."], "citing_paper_content": {"title": "Dynamic Mobile-Former: Strengthening Dynamic Convolution With Attention And Residual Connection In Kernel Space", "abstract": "We introduce Dynamic Mobile-Former(DMF), maximizes the capabilities of dynamic convolution by harmonizing it with efficient operators. Our Dynamic Mobile-Former effectively utilizes the advantages of Dynamic Mo-bileNet (MobileNet equipped with dynamic convolution) using global information from lightweight attention. A Transformer in Dynamic Mobile-Former only requires a few randomly initialized tokens to calculate global features, making it computationally efficient. And a bridge between Dynamic MobileNet and Transformer allows for bidirectional integration of local and global features. We also simplify the optimization process of vanilla dynamic convolution by splitting the convolution kernel into an input-agnostic kernel and an input-dependent kernel. This allows for optimization in a wider kernel space, resulting in enhanced capacity. By integrating lightweight attention and enhanced dynamic convolution, our Dynamic Mobile-Former achieves not only high efficiency, but also strong performance. We benchmark the Dynamic Mobile-Former on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection, and instanace segmentation. For example, our DMF hits the top-1 accuracy of 79.4% on ImageNet-1K, much higher than PVT-Tiny by 4.3% with only 1/4 FLOPs. Additionally, our proposed DMF-S model performed well on challenging vision datasets such as COCO, achieving a 39.0% mAP, which is 1% higher than that of the Mobile-Former 508M model, despite using 3 GFLOPs less computations. Code and models are available at https://github.com/ ysj9909/DMF"}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["residual connection"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We introduce a residual connection in kernel space to alleviate optimization difficulties, which is similar to the approach proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The residual learning framework proposed in #REFR has been shown to ease the optimization of substantially deeper networks, which could be beneficial for the optimization difficulties encountered in the dynamic convolution module.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed residual connection in kernel space, as introduced in this work, helps to alleviate optimization difficulties and achieves impressive performance on various vision tasks, as demonstrated by #REFR.", "given_citation_intent": "result", "given_keywords": ["residual connection"]}]}
{"citing_id": "2303.11879v1", "cited_id": "1701.06538", "section_title": "B. Multimodal Mixup Sequence Encoder", "citation": "Both encoders share the same structure, including an attention layer and a Mixture-of-Expert (MoE) architecture #REFR .", "text_before_citation": ["The structure of M 2 SE is shown in Figure 1 (b).", "Observe that M 2 SE includes four main components: sequence random dropout, text and image encoders, complementary sequence mixup, and transformer layers. Next, we introduce the details of each component.", "1) Sequence Random Dropout: For a user behavior sequence S, M 2 SE randomly drops a portion of items from S with a drop ratio \u03c1, to help the model achieve better generalization performance.", "The obtained sub-sequence after the random dropout operation is denoted by S.", "2) Text and Image Encoders: These two encoders are used to adapt the initial modality features of items obtained from the pre-trained language model to learn users' sequential behaviors."], "text_after_citation": ["In the text encoder, each item i \u2208 S is represented by its initial textual feature x t i .", "The attention layer is composed of two linear transformations to fuse i's sentence-level embeddings as follows,", "EQUATION", "where is the j-th element of \u03b1 t , and x t i [j, :] denotes the j-th row of feature matrix x t i .", "Then, MoE is used to increase the model's capacity for adapting the fused modality representation e t i ."], "citing_paper_content": {"title": "Multimodal Pre-Training Framework For Sequential Recommendation Via Contrastive Learning", "abstract": "Sequential recommendation systems utilize the sequential interactions of users with items as their main supervision signals in learning users' preferences. However, existing methods usually generate unsatisfactory results due to the sparsity of user behavior data. To address this issue, we propose a novel pre-training framework, named Multimodal Sequence Mixup for Sequential Recommendation (MSM4SR), which leverages both users' sequential behaviors and items' multimodal content (i.e., text and images) for effectively recommendation. Specifically, MSM4SR tokenizes each item image into multiple textual keywords and uses the pre-trained BERT model to obtain initial textual and visual features of items, for eliminating the discrepancy between the text and image modalities. A novel backbone network, i.e., Multimodal Mixup Sequence Encoder (M 2 SE), is proposed to bridge the gap between the item multimodal content and the user behavior, using a complementary sequence mixup strategy. In addition, two contrastive learning tasks are developed to assist M 2 SE in learning generalized multimodal representations of the user behavior sequence. Extensive experiments on real-world datasets demonstrate that MSM4SR outperforms state-of-the-art recommendation methods. Moreover, we further verify the effectiveness of MSM4SR on other challenging tasks including cold-start and cross-domain recommendation."}, "cited_paper_content": {"title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-Of-Experts Layer", "abstract": "The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost."}, "keywords": ["attention layer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The text and image encoders in M 2 SE are used to adapt the initial modality features of items obtained from the pre-trained language model to learn users' sequential behaviors (Li et al., 2020).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To adapt the initial modality features of items obtained from the pre-trained language model to learn users' sequential behaviors, the authors utilized a pre-trained BERT model as a text encoder, which is similar to the approach proposed in the Sparsely-Gated Mixture-Of-Experts Layer paper by #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To bridge the gap between the item multimodal content and the user behavior, the proposed Multimodal Mixup Sequence Encoder (M 2 SE) utilizes a complementary sequence mixup strategy, which is inspired by the Sparsely-Gated Mixture-of-Experts layer (MoE) in the work of \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-Of-Experts Layer\" for language modeling and machine translation tasks. #REFR", "given_citation_intent": "method", "given_keywords": ["attention layer"]}]}
{"citing_id": "2303.00645v2", "cited_id": "1803.09010", "section_title": "Comparison With Hugging Face Datasets", "citation": "For example, consider the following three tables: Since metadata and annotations are provided in a well defined format, it is possible to automatically create documentation in form of data cards or datasheets #REFR .", "text_before_citation": ["Datasets does not support organising annotations into different tables, or referencing the same audio files or parts of it multiple times.", "Each data point that is returned contains the actual audio signal, a link to the corresponding audio file and associated labels.", "Whereas in audb there is only a loose connection between audio files and annotations.", "This means there is exactly one copy of an audio file, even when it is referenced from different tables or different, possibly overlapping segmentation exist.", "It further allows mapping annotations from one table to another."], "text_after_citation": ["Figure 2 shows an example data card for the emodb dataset #OTHEREFR .", "It summarizes the most important facts in a tabular form, provides a long description of the dataset together with an audio example and lists available tables, columns, and schemes.", "Data cards for all datasets available with the default public repositories of audb are available at https://audeering.github.io/datasets/."], "citing_paper_content": {"title": "Audb -Sharing And Versioning Of Audio And Annotation Data In Python", "abstract": "Driven by the need for larger and more diverse datasets to pre-train and fine-tune increasingly complex machine learning models, the number of datasets is rapidly growing. audb is an open-source Python library that supports versioning and documentation of audio datasets. It aims to provide a standardized and simple user-interface to publish, maintain, and access the annotations and audio files of a dataset. To efficiently store the data on a server, audb automatically resolves dependencies between versions of a dataset and only uploads newly added or altered files when a new version is published. The library supports partial loading of a dataset and local caching for fast access. audb is a lightweight library and can be interfaced from any machine learning library. It supports the management of datasets on a single PC, within a university or company, or within a whole research community. audb is available at https://github.com/audeering/audb."}, "cited_paper_content": {"title": "Datasheets For Datasets", "abstract": "The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability."}, "keywords": ["annotations", "datasheets"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the lack of standardized documentation for datasets, the authors of audb propose the use of datasheets for datasets, which would document the motivation, composition, collection process, recommended uses, and other information for each dataset #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the lack of standardized documentation for datasets, the authors of audb propose the use of datasheets for datasets, which would document the motivation, composition, collection process, and recommended uses of each dataset #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the lack of standardization in documenting datasets, the proposal of datasheets for datasets in the reference paper \"Datasheets For Datasets\" could provide a solution for better communication between dataset creators and consumers, and encourage transparency and accountability in the machine learning community, which is particularly relevant for managing annotations and audio files as discussed in the manuscript. #REFR", "given_citation_intent": "background", "given_keywords": ["annotations", "datasheets"]}]}
{"citing_id": "2303.12513v1", "cited_id": "1908.10084", "section_title": "Models Used", "citation": "We also include results for Sentence-BERT (SBERT) #REFR , since its output embeddings are trained to have meaningful cosine similarity scores and thus bear more similarity to other models evaluated with Stroop proving.", "text_before_citation": ["For evaluating unimodally trained text encoders, we use BERT #OTHEREFR , RoBERTa #OTHEREFR , DistilBERT and Distil-RoBERTa #OTHEREFR , which are all trained with text-only MLM objectives."], "text_after_citation": ["Results on multimodally trained text encoders are reported for CLIP #OTHEREFR and FLAVA #OTHEREFR ; for these models we use only the text encoder with pretrained weights and discard the other subcomponents.", "Our tests include checkpoints from both OpenAI and the OpenCLIP open-source implementation of CLIP #OTHEREFR 25] .", "Details of the checkpoints used for each model are listed in the supplementary material.", "The text encoders of the multimodally trained models range in size from 63M (CLIP) to 109M (FLAVA) param-eters.", "We compare to both comparably small unimodally trained text encoders such as DistilBERT (66M parameters) as well as much larger text encoders such as BERT-large (340M)."], "citing_paper_content": {"title": "Is Bert Blind? Exploring The Effect Of Vision-And-Language Pretraining On Visual Language Understanding", "abstract": "Alex gave Riley a present Alex gave Riley an ultimatum the ocean is [ * ]-colored a corn chip is [ * ]-shaped How concrete are the words present and ultimatum? What word should be inserted in the blank? Figure 1. In this paper, we propose a suite of visual language understanding tasks for probing the visual reasoning capabilities of text encoder models. While we consider text-only tasks (i.e., processing only the textual descriptions above without associated imagery), we argue that they require visual imagination to complete and can thus benefit from vision-and-language pretraining. For instance, consider the words present and ultimatum. A simple online query (that considers only freely-available images) roughly yields a coherent set of images for the more concrete word (namely present), while the latter cannot be uniquely depicted. Likewise, selecting the most natural color or shape descriptors in cloze contexts as shown in the two examples on the right requires implicit knowledge of the appearance of the referent under consideration (ocean and corn chip respectively)."}, "cited_paper_content": {"title": "Sentence-Bert: Sentence Embeddings Using Siamese Bert-Networks", "abstract": "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. ::: In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. ::: We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods."}, "keywords": ["output embeddings", "Sentence-BERT"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For evaluating unimodally trained text encoders, we use BERT #REFR, RoBERTa #OTHEREFR, DistilBERT and Distil-RoBERTa #OTHEREFR, which are all trained with text-only MLM objectives. In this publication, the authors present Sentence-BERT (SBERT), a modification of the pretrained BERT network that uses siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compared the performance of various text encoders, including BERT, RoBERTa, DistilBERT, and Distil-RoBERTa, which were trained with text-only MLM objectives, with the state-of-the-art SBERT method #REFR, and found that SBERT significantly outperformed all the other methods in terms of semantic textual similarity tasks.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compared the performance of various text encoders, including BERT, RoBERTa, DistilBERT, and Distil-RoBERTa, trained with text-only MLM objectives, with the Sentence-BERT (SBERT) model, which uses siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity, and found that SBERT significantly reduces the computational overhead for finding the most similar pair while maintaining the accuracy from BERT #REFR.", "given_citation_intent": "result", "given_keywords": ["output embeddings", "Sentence-BERT"]}]}
{"citing_id": "2303.17127v1", "cited_id": "1911.05722", "section_title": "Related Work", "citation": "Similarly, in self-supervised learning, Momentum Contrast (MOCO) #REFR uses an external memory along with a separate encoding network to compute the features and uses momentum based updates to ensure slow-drift of encoder parameters.", "text_before_citation": ["We only mentioned a few works here and we refer the interested reader to #OTHEREFR 27] for a comprehensive list of metric learning losses and example mining strategies.", "In contrast to these works, we focus on expanding the reference set which allows us to compare more examples across minibatches while benefiting from these recent advances.", "Using External Memory.", "Using external memory in metric learning is not new #OTHEREFR .", "However, an im-portant distinction is that we use an external memory to expand the reference set and ensure that those embeddings are kept up to date so that they can be used for effective learning."], "text_after_citation": ["Another conceptually similar approach is cross iteration batch normalization #OTHEREFR , which estimates minibatch statistics across training iterations using first order information.", "In contrast to both of these methods, we simply store the feature embeddings at each iteration and directly tackle the representational drift by adapting the distribution parameters for effective metric learning."], "citing_paper_content": {"title": "Adaptive Cross Batch Normalization For Metric Learning", "abstract": "Metric learning is a fundamental problem in computer vision whereby a model is trained to learn a semantically useful embedding space via ranking losses. Traditionally, the effectiveness of a ranking loss depends on the minibatch size, and is, therefore, inherently limited by the memory constraints of the underlying hardware. While simply accumulating the embeddings across minibatches has proved useful [40], we show that it is equally important to ensure that the accumulated embeddings are up to date. In particular, it is necessary to circumvent the representational drift between the accumulated embeddings and the feature embeddings at the current training iteration as the learnable parameters are being updated. In this paper, we model representational drift as distribution misalignment and tackle it using moment matching. The result is a simple method for updating the stored embeddings to match the first and second moments of the current embeddings at each training iteration. Experiments on three popular image retrieval datasets, namely, SOP, IN-SHOP and DEEPFASHION2, demonstrate that our approach significantly improves the performance in all scenarios."}, "cited_paper_content": {"title": "Momentum Contrast For Unsupervised Visual Representation Learning", "abstract": "We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks."}, "keywords": ["self-supervised learning", "Momentum Contrast"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We only mentioned a few works here and we refer the interested reader to the Momentum Contrast (MoCo) paper for a comprehensive list of metric learning losses and example mining strategies. In contrast to these works, we focus on expanding the reference set which allows us to compare more examples across minibatches while benefiting from these recent advances. Using External Memory. Using external memory in metric learning is not new #REFR. However, an im-portant distinction is that we use an external memory to expand the reference set and ensure that those embeddings are kept up to date so that they can be used for effective learning.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To expand the reference set and ensure that the embeddings are up to date, we use an external memory, as proposed in the Momentum Contrast (MoCo) method #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To expand the reference set and improve the effectiveness of learning, we use an external memory that keeps embeddings up to date, as done in Momentum Contrast for unsupervised visual representation learning #REFR.", "given_citation_intent": "method", "given_keywords": ["self-supervised learning", "Momentum Contrast"]}]}
{"citing_id": "2303.08083v1", "cited_id": "1004.4075", "section_title": "I. Introduction", "citation": "Secrecy gains of the so-called unimodular lattices have been studied for well over a decade #REFR .", "text_before_citation": ["In #OTHEREFR - #OTHEREFR , the authors introduce the secrecy function, which is evaluated in terms of the lattice's volume and theta series, and can be interpreted as the security coding gain of a specifically designed lattice for Eve compared to an uncoded lattice.", "The maximum of the secrecy function, namely the (strong) secrecy gain, has been shown to be an essential design criterion for wiretap lattice codes. Please see Section V-A for an explicit description.", "Another design criterion for wiretap lattice codes, called the flatness factor, was proposed by Ling et al. #OTHEREFR .", "The flatness factor quantifies how much secret information can leak to Eve in terms of mutual information, while the secrecy gain characterizes the success probability of Eve to correctly guess the transmitted messages.", "Both the secrecy gain and the flatness factor require the minimization of the theta series of the lattice designed to confuse Eve at a given point to guarantee secrecy-goodness #OTHEREFR , #OTHEREFR ."], "text_after_citation": ["In this pioneering work, Belfiore and Sol\u00e9 discovered that there exists a symmetry point in the secrecy functions.", "Further, they conjectured that for unimodular lattices, the secrecy gain is achieved at the symmetry point of its secrecy function.", "The conjecture has been further investigated and verified for unimodular (or isodual) lattices in dimensions less than 80 #OTHEREFR , #OTHEREFR - #OTHEREFR .", "The study of secrecy gain was recently also extended to the \u2113-modular lattices #OTHEREFR , #OTHEREFR , #OTHEREFR , where it is believed that the higher the parameter \u2113 is, the better secrecy gain we can achieve.", "Most recently, a new family of lattices, called formally unimodular lattices, or lattices with the same theta series as their dual, was introduced #OTHEREFR , #OTHEREFR ."], "citing_paper_content": {"title": "On The Secrecy Gain Of Lattices From Codes Over The Integers Modulo 4", "abstract": "Recently, a design criterion depending on a lattice's volume and theta series, called the secrecy gain, was proposed to quantify the secrecy-goodness of the applied lattice code for the Gaussian wiretap channel. To address the secrecy gain of Construction A 4 lattices from formally self-dual Z 4-linear codes, i.e., codes for which the symmetrized weight enumerator (swe) coincides with the swe of its dual, we present new constructions of Z 4-linear codes which are formally self-dual with respect to the swe. For even lengths, formally self-dual Z 4-linear codes are constructed from nested binary codes and double circulant matrices. For odd lengths, a novel construction called odd extension from double circulant codes is proposed. Moreover, the concepts of Type I/II formally self-dual codes/unimodular lattices are introduced. Next, we derive the theta series of the formally unimodular lattices obtained by Construction A 4 from formally self-dual Z 4-linear codes and describe a universal approach to determine their secrecy gains. The secrecy gain of Construction A 4 formally unimodular lattices obtained from Type I formally self-dual Z 4-linear codes is investigated, both for even and odd dimensions. Numerical evidence shows that for some parameters, Construction A 4 lattices can achieve a higher secrecy gain than the best-known formally unimodular lattices from the literature. Index Terms Lattices, Codes over Z 4 , Construction C, Construction A 4 , secrecy gain, Gaussian wiretap channel."}, "cited_paper_content": {"title": "Secrecy Gain: A Wiretap Lattice Code Design", "abstract": "We propose the notion of secrecy gain as a code design criterion for wiretap lattice codes to be used over an additive white Gaussian noise channel. Our analysis relies on the error probabilites of both the legitimate user and the eavesdropper. We focus on geometrical properties of lattices, described by their theta series, to characterize good wiretap codes."}, "keywords": ["so-called unimodular lattices", "Secrecy gains"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The maximum of the secrecy function, namely the (strong) secrecy gain, has been shown to be an essential design criterion for wiretap lattice codes, as introduced in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors propose the notion of secrecy gain as a code design criterion for wiretap lattice codes, which is evaluated in terms of the error probabilities of both the legitimate user and the eavesdropper, and rely on the geometrical properties of lattices, described by their theta series, to characterize good wiretap codes #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To determine the secrecy gains of so-called unimodular lattices, the authors of this manuscript rely on the theta series of lattices, as proposed in #REFR.", "given_citation_intent": "background", "given_keywords": ["so-called unimodular lattices", "Secrecy gains"]}]}
{"citing_id": "2304.01541v1", "cited_id": "1905.08302", "section_title": "Introduction", "citation": "In particular, we show that\u00d5 n min \u03b5, \u03b5 2 and\u00d5 log n min \u03b5, \u03b5 #REFR bits of (per-client) communication are sufficient to achieve the order-optimal error under (\u03b5, \u03b4)-privacy for mean and frequency estimation respectively, where n is the number of participating clients.", "text_before_citation": ["Our contributions.", "We consider distributed mean and frequency estimation as canonical building blocks for FL and FA.", "We consider both the central DP and the multi-message shuffling models.", "We characterize the order-optimal privacy-accuracy-communication trade-off for distributed mean estimation and provide an achievable scheme for frequency estimation in the central DP model.", "Our results reveal that privacy and communication efficiency can be achieved simultaneously with no additional penalty on accuracy."], "text_after_citation": ["Without compression, each client needs O(d) bits and log d bits for the mean and frequency estimation problems respectively (where d is the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime n\u03b5 2 = o(d) (assuming \u03b5 = O(1)).", "We note that this is often the relevant regime not only for cross-silo but also for cross-device FL/FA.", "For instance, in practical FL, d usually ranges from 10 6 -10 9 , and n, the perepoch sample size, is usually much smaller (e.g., of the order of 10 3 -10 5 ). For distributed mean estimation,"], "citing_paper_content": {"title": "Privacy Amplification Via Compression: Achieving The Optimal Privacy-Accuracy-Communication Trade-Off In Distributed Mean Estimation", "abstract": "Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and (\u03b5, \u03b4)-differential privacy (DP) constraints. We consider both the central and the multi-message shuffling DP models. We show that in order to achieve the optimal 2 error under (\u03b5, \u03b4)-DP, it is sufficient for each client to send \u0398 n min \u03b5, \u03b5 2 bits for FL and \u0398 log n min \u03b5, \u03b5 2 bits for FA to the server, where n is the number of participating clients. Without compression, each client needs O(d) bits and O (log d) bits for the mean and frequency estimation problems respectively (where d corresponds to the number of trainable parameters in FL or the domain size in FA), meaning that we can get significant savings in the regime n min \u03b5, \u03b5 2 = o(d), which is often the relevant regime in practice. We propose two different ways to leverage compression for privacy amplification and achieve the optimal privacy-communication-accuracy trade-off. In both cases, each client communicates only partial information about its sample and we show that privacy is amplified by randomly selecting the part contributed by each client. In the first method, the random selection is revealed to the server, which results in a central DP guarantee with optimal privacy-communication-accuracy trade-off. In the second method, the random data parts at each client are privatized locally and anonymized by a secure shuffler, eliminating the need for a trusted server. This results in a multi-message shuffling scheme with the same optimal trade-off. As a result, our paper establishes the optimal three-way trade-off between privacy, communication, and accuracy for both the central DP and multi-message shuffling frameworks. 1"}, "cited_paper_content": {"title": "Inference Under Information Constraints Ii: Communication Constraints And Shared Randomness", "abstract": "A central server needs to perform statistical inference based on samples that are distributed over multiple users who can each send a message of limited length to the center. We study problems of distribution learning and identity testing in this distributed inference setting and examine the role of shared randomness as a resource. We propose a general-purpose simulate-and-infer strategy that uses only private-coin communication protocols and is sample-optimal for distribution learning. This general strategy turns out to be sample-optimal even for distribution testing among private-coin protocols. Interestingly, we propose a public-coin protocol that outperforms simulate-and-infer for distribution testing and is, in fact, sample-optimal. Underlying our public-coin protocol is a random hash that when applied to the samples minimally contracts the chi-squared distance of their distribution to the uniform distribution."}, "keywords": ["frequency estimation", "participating clients"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our contributions. We consider distributed mean and frequency estimation as canonical building blocks for FL and FA. We consider both the central DP and the multi-message shuffling models. We characterize the order-optimal privacy-accuracy-communication trade-off for distributed mean estimation and provide an achievable scheme for frequency estimation in the central DP model. Our results reveal that privacy and communication efficiency can be achieved simultaneously with no additional penalty on accuracy #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve optimal privacy-communication-accuracy trade-off in distributed mean estimation, it is important to consider the role of shared randomness as a resource, as proposed in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve frequency estimation in the central DP model, it is sufficient for each participating client to send \u0398(log n) min(\u03b5, \u03b5^2) bits to the server, and a general-purpose simulate-and-infer strategy that uses only private-coin communication protocols and is sample-optimal for distribution learning is proposed in #REFR.", "given_citation_intent": "background", "given_keywords": ["frequency estimation", "participating clients"]}]}
{"citing_id": "2304.12776v1", "cited_id": "1706.03762", "section_title": "Parameter Allocation And Scaling", "citation": "Second, and consistent with prior work, we find that an even split of parameters between the encoder and decoder (6 encoder layers and 6 decoder layers, i.e., Transformer base) yields the best translation quality for the Transformer #REFR , whereas no encoder produces the best results for S4.", "text_before_citation": ["Encoder Scaling To explore the effect of parameter allocation on performance, we compare the translation quality of different encoder-decoder configurations with the same total number of parameters (roughly 65M).", "In Figure 2a , the x axis represents the ratio of encoder layers to the total number of layers (encoder + decoder).", "Starting with a decoder-only model (ratio = 0), we gradually increase the number of encoder layers, and end with a model containing only a single decoder layer.", "Two results stand out: first, there is a wide gap between the best S4 and Transformer models: 20.7 and 26.4 BLEU, respectively."], "text_after_citation": ["Based on this finding, we focus on the S4 decoder-only variant for the next experiments.", "Number of S4 Blocks per Layer Prior research set the number of S4 blocks, B, to 2 #OTHEREFR .", "We found that increasing B is beneficial as S4 blocks are responsible for capturing dependencies between tokens.", "In Table 1 we vary B while keeping the parameter count roughly constant.", "Increasing B leads to noticeable quality improvements until B = 10."], "citing_paper_content": {"title": "State Spaces Aren'T Enough: Machine Translation Needs Attention", "abstract": "Structured State Spaces for Sequences (S4) is a recently proposed sequence model with successful applications in various tasks, e.g. vision, language modeling, and audio. Thanks to its mathematical formulation, it compresses its input to a single hidden state, and is able to capture long range dependencies while avoiding the need for an attention mechanism. In this work, we apply S4 to Machine Translation (MT), and evaluate several encoder-decoder variants on WMT'14 and WMT'16. In contrast with the success in language modeling, we find that S4 lags behind the Transformer by approximately 4 BLEU points, and that it counter-intuitively struggles with long sentences. Finally, we show that this gap is caused by S4's inability to summarize the full source sentence in a single hidden state, and show that we can close the gap by introducing an attention mechanism."}, "cited_paper_content": {"title": "Attention Is All You Need", "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."}, "keywords": ["6 decoder layers"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We compare the translation quality of different encoder-decoder configurations with the same total number of parameters and find that there is a wide gap between the best S4 and Transformer models: 20.7 and 26.4 BLEU, respectively (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The results in Figure 2a show a significant performance gap between the best performing S4 model and the Transformer model, with BLEU scores of 20.7 and 26.4, respectively, indicating the superiority of the Transformer model in machine translation tasks (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The comparison of different encoder-decoder configurations with the same total number of parameters (roughly 65M) revealed a wide gap between the best S4 and Transformer models: 20.7 and 26.4 BLEU, respectively, as reported in the reference paper #REFR, which proposes a new simple network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.", "given_citation_intent": "result", "given_keywords": ["6 decoder layers"]}]}
{"citing_id": "2304.11284v1", "cited_id": "1511.03611", "section_title": "B. Traffic Network Model", "citation": "We model the traveling time on arc a as a linear function \u03c4 a (\u03be a ) such that the traveling time increases with the increase of the traffic flow \u03be a on arc a \u2208 A. ; see #REFR .", "text_before_citation": ["The traffic network is modeled by a connected directional graph R = (V, A), where V and A denote the sets of vertexes and arcs."], "text_after_citation": ["EQUATION", "where \u03be 0 a , R a are the parameters related to the shape of the traveling time function.", "Let C \u2208 V denote the set of nodes where the charging stations are located in.", "We model the nodes of charging stations as \"virtual arcs\" following #OTHEREFR (see Fig. 2 ).", "At a node i \u2208 C, the EV driver can choose the arc l c i for charging or the arc l n i for skipping charging."], "citing_paper_content": {"title": "Optimal Vehicle Charging In Bilevel Power-Traffic Networks Via Charging Demand Function", "abstract": "Electric vehicle (EV) charging couples the operation of power and traffic networks. Specifically, the power network determines the charging price at various locations, while EVs on the traffic network optimize the charging power given the price, acting as price-takers. We model such decision-making processes by a bilevel program, with the power network at the upper-level and the traffic network at the lower-level. However, since the two networks are managed by separate entities and the charging expense term, calculated as the product of charging price and charging demand, is nonlinear. Solving the bilevel program is nontrivial. To overcome these challenges, we derive the charging demand function using multiparametric programming theory. This function establishes a piecewise linear relationship between the charging price and the optimal charging power, enabling the power network operator to manage EV charging power independently while accounting for the coupling between the two networks. With the derived function, we are also able to replace the nonlinear charging expense term with a piecewise quadratic one, thus guaranteeing solution optimality. Our numerical studies demonstrate that different traffic demands can have an impact on charging patterns and the power network can effectively incentivize charging at low-price nodes through price setting."}, "cited_paper_content": {"title": "Optimal Pricing To Manage Electric Vehicles In Coupled Power And Transportation Networks", "abstract": "We study the system-level effects of the introduction of large populations of Electric Vehicles (EVs) on the power and transportation networks. We assume that each EV owner solves a decision problem to pick a cost-minimizing charge and travel plan. This individual decision takes into account traffic congestion in the transportation network, affecting travel times, as well as congestion in the power grid, resulting in spatial variations in electricity prices for battery charging. We show that this decision problem is equivalent to finding the shortest path on an \u201cextended\u201d transportation graph, with virtual arcs that represent charging options. Using this extended graph, we study the collective effects of a large number of EV owners individually solving this path planning problem. We propose a scheme in which independent power and transportation system operators can collaborate to manage each network towards a socially optimum operating point while keeping the operational data of each system private. We further study the optimal reserve capacity requirements for pricing in the absence of such collaboration. We showcase numerically that a lack of attention to interdependencies between the two infrastructures can have adverse operational effects."}, "keywords": ["traffic flow"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The traffic network is modeled by a connected directional graph R = (V, A), where V and A denote the sets of vertexes and arcs. Previous work has shown that this decision problem is equivalent to finding the shortest path on an \u201cextended\u201d transportation graph, with virtual arcs that represent charging options #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of this manuscript propose a bilevel program to model the decision-making processes of electric vehicle charging in coupled power and traffic networks, which is challenging due to the nonlinear charging expense term and separate management of the two networks. To overcome these challenges, they derive the charging demand function using multiparametric programming theory, which establishes a piecewise linear relationship between the charging price and the optimal charging power, enabling the power network operator to manage EV charging power independently while accounting for the coupling between the two networks. This approach is similar to the one proposed in the reference paper by #REFR, where they also study the system-level effects of introducing large populations of EVs on power and transportation networks.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The traffic network is modeled by a connected directional graph R = (V, A), where V and A denote the sets of vertexes and arcs. EV charging couples the operation of power and traffic networks, and the decision-making processes are modeled by a bilevel program. To overcome the challenges of nonlinear charging expense term and separate network management, the authors derived the charging demand function using multiparametric programming theory, which establishes a piecewise linear relationship between the charging price and the optimal charging power, enabling the power network operator to manage EV charging power independently while accounting for the coupling between the two networks. This approach is similar to the one proposed in the reference paper by #REFR, which also studies the system-level effects of introducing large populations of EVs on the power and transportation networks, taking into account traffic congestion in the transportation network, affecting travel times, as well as congestion in the power grid, resulting in spatial variations in electricity prices for battery charging.", "given_citation_intent": "background", "given_keywords": ["traffic flow"]}]}
{"citing_id": "2304.06388v1", "cited_id": "1911.05326", "section_title": "A. Beamforming Model", "citation": "Note that the signal amplitude A in (6) is not the exact amplitude of the electric or magnetic field and the transform between the signal amplitude and electric field amplitude can be found in #REFR .", "text_before_citation": ["Finally, the complex amplitude of the EM signal reflected by the -th element on the RIS at an observation point r can be written as", "EQUATION", "where \u0393 = |\u0393 |e j\u03c6 is the complex reflection coefficient of the RIS element , \u03c6 being the phaseshift imposed by the RIS element to the EM signal.", "The reflection angle (\u03b8 , \u03d5 ) is determined by the spatial vector (r \u2212 r ) in the local coordinates of the RIS.", "In most cases, the RIS is utilized to enhance signal coverage or tackle the blockage and it is usually deployed far from the BS, hence the BS can be regarded as a point source and (6) can be applied."], "text_after_citation": ["If a UE equipped with an isotropic antenna is placed at the observation point, the received power at the UE reflected by a RIS with N elements can then be expressed as", "EQUATION", "where S is the effective aperture of the UE antenna. Obviously, the maximum received power can be obtained if", "\u03c6 inc + k|r \u2212 r | + \u03c6 = \u03c6 c for = 1, 2, \u2022 \u2022 \u2022 , N ,", "where \u03c6 c is a constant phase which can be simply set to be zero."], "citing_paper_content": {"title": "How Practical Phase-Shift Errors Affect Beamforming Of Reconfigurable Intelligent Surface?", "abstract": "Reconfigurable intelligent surface (RIS) is a new technique that is able to manipulate the wireless environment smartly and has been exploited for assisting the wireless communications, especially at high frequency band. However, it suffers from hardware impairments (HWIs) in practical designs, which inevitably degrades its performance and thus limits its full potential. To address this practical issue, we first propose a new RIS reflection model involving phase-shift errors, which is then verified by the measurement results from field trials. With this beamforming model, various phase-shift errors caused by different HWIs can be analyzed. The phase-shift errors are classified into three categories: (1) globally independent and identically distributed errors, (2) grouped independent and identically distributed errors and (3) grouped fixed errors. The impact of typical HWIs, including frequency mismatch, PIN diode failures and panel deformation, on RIS beamforming ability are studied with the theoretical model and are compared with numerical results. The impact of frequency mismatch are discussed separately for narrow-band and wide-band beamforming. Finally, useful insights and guidelines on the RIS design and its deployment are highlighted for practical wireless sytsems."}, "cited_paper_content": {"title": "Wireless Communications With Reconfigurable Intelligent Surface: Path Loss Modeling And Experimental Measurement", "abstract": "Reconfigurable intelligent surfaces (RISs) comprised of tunable unit cells have recently drawn significant attentions due to their superior capability in manipulating electromagnetic waves. In particular, RIS-assisted wireless communications have the great potential to achieve significant performance improvement and coverage enhancement in a cost-effective and energy-efficient manner, by properly programming the reflection coefficients of the unit cells of RISs. In this paper, the free-space path loss models of RIS-assisted wireless communications are developed for different scenarios by studying the physics and electromagnetic nature of RISs. The proposed models, which are first validated through extensive simulation results, reveal the relationships between the free-space path loss of RIS-assisted wireless communications and the distances from the transmitter/receiver to the RIS, the size of the RIS, the near-field/far-field effects of the RIS, and the radiation patterns of antennas and unit cells. In addition, three fabricated RISs (metasurfaces) are utilized to further corroborate theoretical findings through experimental measurements conducted in a microwave anechoic chamber. The measurement results match well with the modeling results, thus validating the proposed free-space path loss models for RIS, which may pave the way for further theoretical studies and practical applications in this field."}, "keywords": ["magnetic field"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The reflection coefficient of the RIS element is denoted by \u0393 = |\u0393 |e j\u03c6, where \u03c6 is the phaseshift imposed by the RIS element to the EM signal, and can be properly programmed to enhance the wireless communication performance and coverage. The free-space path loss models of RIS-assisted wireless communications have been developed for different scenarios in #REFR, which reveal the relationships between the free-space path loss of RIS-assisted wireless communications and the distances from the transmitter/receiver to the RIS, the size of the RIS, the near-field/far-field effects of the RIS, and the radiation patterns of antennas and unit cells.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The concept of reconfigurable intelligent surfaces (RISs) has recently gained significant attention due to their ability to manipulate electromagnetic waves, which can lead to significant performance improvement and coverage enhancement in wireless communications. The free-space path loss models of RIS-assisted wireless communications developed in #REFR can provide valuable insights into the relationships between the free-space path loss and various factors such as the distances from the transmitter/receiver to the RIS, the size of the RIS, and the radiation patterns of antennas and unit cells.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The reflection coefficients of the unit cells of reconfigurable intelligent surfaces (RISs) can be programmed to manipulate electromagnetic waves, which makes RIS-assisted wireless communications a promising approach for enhancing signal coverage and tackling blockage in wireless systems. The physics and electromagnetic nature of RISs have been studied to develop free-space path loss models for RIS-assisted wireless communications, which have been validated through extensive simulation and experimental results, as reported in the reference paper #REFR. The proposed models reveal the relationships between the free-space path loss of RIS-assisted wireless communications and the distances from the transmitter/receiver to the RIS, the size of the RIS, the near-field/far-field effects of the RIS, and the radiation patterns of antennas and unit cells, providing valuable insights for the design and deployment of practical wireless systems, especially at high frequency band.", "given_citation_intent": "background", "given_keywords": ["magnetic field"]}]}
{"citing_id": "2303.17595v1", "cited_id": "1902.10811", "section_title": "D. Byproducts Details D.1. Imagenet-Ab", "citation": "This confirms the observation of #REFR that 71% of the validation set samples were re-selected in their setting.", "text_before_citation": ["Such information may be helpful for identifying and factoring out group-specific idiosyncrasies.", "For example, worker ABC may always click near the centre of an image; we may then decide not to use her clicks as a reliable estimate of object locations.", "Or we may find that the HIT DEF was done in such a rush; we would then reduce the weight for the set of annotations belonging to DEF.", "Statistics. There are 1,281,167 ImageNet1K training images I imagenet . There were two annotation rounds.", "In the first round, human intelligence tasks (HITs) containing all 1,281,167 original images are shown to the annotators. They have re-selected 71.8% of them."], "text_after_citation": ["The remaining 28.2% of I imagenet are re-packaged into a second batch of HITs and presented to the annotators.", "They have additionally re-selected 14.9% of I imagenet , resulting in the final 1,110,786 (86.7%) Ima-geNet1K training images that are re-selected.", "Those selected images now come with rich annotation byproducts, such as the time-series of mouse traces and clicks.", "However, annotation byproducts are available even for images that are not finally selected; they are recorded even for images that annotators cancel the selection or simply hover the cursor over.", "As a result, 1,272,225 (99.3%) of the ImageNet1K training set have any form of annotation byproduct available."], "citing_paper_content": {"title": "Neglected Free Lunch -Learning Image Classifiers Using Annotation Byproducts", "abstract": "Supervised learning of image classifiers distills human knowledge into a parametric model f \u03b8 through pairs of images and corresponding labels {(X i , Y i)} N i=1. We argue that this simple and widely used representation of human knowledge neglects rich auxiliary information from the annotation procedure, such as the time-series of mouse traces and clicks left after image selection. Our insight is that such annotation byproducts Z provide approximate human attention that weakly guides the model to focus on the foreground cues, reducing spurious correlations and discouraging shortcut learning. To verify this, we create ImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched with sample-wise annotation byproducts, collected by replicating the respective original annotation tasks. We refer to the new paradigm of training models with annotation byproducts as learning using annotation byproducts (LUAB). We show that a simple multitask loss for regressing Z together with Y already improves the generalisability and robustness of the learned models. Compared to the original supervised learning, LUAB does not require extra annotation costs. ImageNet-AB and COCO-AB are at github.com/naverai/NeglectedFreeLunch."}, "cited_paper_content": {"title": "Do Imagenet Classifiers Generalize To Imagenet?", "abstract": "We build new test sets for the CIFAR-10 and ImageNet datasets. Both benchmarks have been the focus of intense research for almost a decade, raising the danger of overfitting to excessively re-used test sets. By closely following the original dataset creation processes, we test to what extent current classification models generalize to new data. We evaluate a broad range of models and find accuracy drops of 3% - 15% on CIFAR-10 and 11% - 14% on ImageNet. However, accuracy gains on the original test sets translate to larger gains on the new test sets. Our results suggest that the accuracy drops are not caused by adaptivity, but by the models' inability to generalize to slightly \"harder\" images than those found in the original test sets."}, "keywords": ["observation", "validation set samples"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' approach of testing the generalizability of classification models to new data by creating new test sets that closely follow the original dataset creation processes is relevant for identifying and factoring out group-specific idiosyncrasies in annotation tasks (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors found that current classification models have accuracy drops of 11% - 14% on ImageNet when tested on new data, which suggests that the models' inability to generalize to slightly \"harder\" images than those found in the original test sets is the cause of the drops, according to the study by #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' observation that current classification models struggle to generalize to new data is consistent with the findings in the reference paper \"#REFR\", which also evaluated model generalization on validation set samples.", "given_citation_intent": "result", "given_keywords": ["observation", "validation set samples"]}]}
{"citing_id": "2303.17583v1", "cited_id": "1512.02134", "section_title": "Training Details", "citation": "We use the FlyingThings3D from Scene Flow Datasets #REFR , which uses synthetic data generation to obtain all-in-focus RGB images and disparity maps.", "text_before_citation": [], "text_after_citation": ["We use the cropped 278 \u00d7 278 all-in-focus images from #OTHEREFR .", "In total, we use 5077 training patches and 419 test patches.", "Both the optical layer and reconstruction networks are differentiable, so the phase mask sequence and neural network can be optimized through back-propagation. Each part is implemented in PyTorch.", "During training, we use the Adam #OTHEREFR optimizer with parameters \u03b2 1 = 0.99 and \u03b2 2 = 0.999.", "The learning rate for the phase masks is 10 \u22128 and for the reconstruction network it is 10 \u22124 , and the batch size was 32."], "citing_paper_content": {"title": "Tidy-Psfs: Computational Imaging With Time-Averaged Dynamic Point-Spread-Functions", "abstract": "Point-spread-function (PSF) engineering is a powerful computational imaging techniques wherein a custom phase mask is integrated into an optical system to encode additional information into captured images. Used in combination with deep learning, such systems now offer stateof-the-art performance at monocular depth estimation, extended depth-of-field imaging, lensless imaging, and other tasks. Inspired by recent advances in spatial light modulator (SLM) technology, this paper answers a natural question: Can one encode additional information and achieve superior performance by changing a phase mask dynamically over time? We first prove that the set of PSFs described by static phase masks is non-convex and that, as a result, time-averaged PSFs generated by dynamic phase masks are fundamentally more expressive. We then demonstrate, in simulation, that time-averaged dynamic (TiDy) phase masks can offer substantially improved monocular depth estimation and extended depth-of-field imaging performance."}, "cited_paper_content": {"title": "A Large Dataset To Train Convolutional Networks For Disparity, Optical Flow, And Scene Flow Estimation", "abstract": "Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation. To this end, we propose three synthetic stereo video datasets with sufficient realism, variation, and size to successfully train large networks. Our datasets are the first large-scale datasets to enable training and evaluation of scene flow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a flow and disparity estimation network and training it jointly, we demonstrate the first scene flow estimation with a convolutional network."}, "keywords": ["disparity maps", "Scene Flow Datasets"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To extend the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation, synthetic stereo video datasets with sufficient realism, variation, and size were proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enable the use of dynamic phase masks for improved monocular depth estimation and extended depth-of-field imaging performance, the authors proposed the use of synthetic stereo video datasets with sufficient realism, variation, and size to successfully train large networks, as demonstrated in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train their convolutional network for real-time disparity estimation, the authors used three synthetic stereo video datasets, which are the first large-scale Scene Flow Datasets available, and achieved state-of-the-art results #REFR.", "given_citation_intent": "method", "given_keywords": ["disparity maps", "Scene Flow Datasets"]}]}
{"citing_id": "2303.07545v1", "cited_id": "1705.00754", "section_title": "Introduction", "citation": "We illustrate the effectiveness of the resulting model for instruction generation and also traditional dense captioning on ActivityNet Captions #REFR .", "text_before_citation": ["In other words, instruction generation requires at least a certain level of commonsense knowledge.", "Further, we propose a video captioning model that incorporates both explicit (from COMET #OTHEREFR ) as well as implicit commonsense knowledge in the form of a language model (GPT3 #OTHEREFR ) and visio-lingual zero-shot object knowledge (through CLIP #OTHEREFR ).", "Our video captioning model extracts a snippet of video, detects objects and actions in it, and uses encoding of the snippet along with object/actions, CLIP detected objects, and commonsense inferences (that are prompted with the previous sentence) to produce a new sentence.", "This procedure is repeated recursively until the desired number of sentences are decoded and/or the end of the paragraph is reached.", "Our focus, in this work, is on the Transformer-based language multi-sentence captioning decoder, that can be combined with any underlying dense or paragraph captioning framework; for convenience, we build on top of recent #OTHEREFR ."], "text_after_citation": ["Contributions.", "Our contributions are three-fold: (1) We propose a new task of video-based instruction generation, which we believe requires a certain amount of commonsense knowledge; #OTHEREFR We propose a new video multisentence captioning model that effectively leverages implicit and explicit commonsense knowledge (prompted with prior sentences) to improve current sentence prediction.", "#OTHEREFR We explicitly analyze contributions these sources or knowledge make towards improved captioning quality and also illustrate our model's performance on more traditional dense video captioning tasks, showing state-of-the-art performance (without large pre-training).", "Overall, ours is one of the first papers to explore the use of commonsense knowledge for video captioning tasks."], "citing_paper_content": {"title": "Implicit And Explicit Commonsense For Multi-Sentence Video Captioning", "abstract": "Step into the tub."}, "cited_paper_content": {"title": "Dense-Captioning Events In Videos", "abstract": "Most natural videos contain numerous events. For example, in a video of a \"man playing a piano\", the video might also contain \"another man dancing\" or \"a crowd clapping\". We introduce the task of dense-captioning events, which involves both detecting and describing events in a video. We propose a new model that is able to identify all events in a single pass of the video while simultaneously describing the detected events with natural language. Our model introduces a variant of an existing proposal module that is designed to capture both short as well as long events that span minutes. To capture the dependencies between the events in a video, our model introduces a new captioning module that uses contextual information from past and future events to jointly describe all events. We also introduce ActivityNet Captions, a large-scale benchmark for dense-captioning events. ActivityNet Captions contains 20k videos amounting to 849 video hours with 100k total descriptions, each with it's unique start and end time. Finally, we report performances of our model for dense-captioning events, video retrieval and localization."}, "keywords": ["traditional dense captioning", "ActivityNet Captions"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To detect and describe events in a video, the authors propose a new model that captures both short and long events and uses contextual information from past and future events to jointly describe all events, as demonstrated in their work on dense-captioning events in videos #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To jointly describe all events in a video, the proposed model in #REFR introduces a new captioning module that uses contextual information from past and future events, which is similar to our approach of incorporating implicit commonsense knowledge through a language model and visio-lingual zero-shot object knowledge in multi-sentence video captioning.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform dense-captioning events in videos, the authors of this manuscript could use the proposed model from the reference paper, which is able to identify and describe all events in a single pass of the video, as well as the ActivityNet Captions benchmark dataset. #REFR", "given_citation_intent": "method", "given_keywords": ["traditional dense captioning", "ActivityNet Captions"]}]}
{"citing_id": "2304.12586v1", "cited_id": "math/0305160", "section_title": "Local Causal States", "citation": "This implies that (i) they are equivariant under spacetime isometries, such as translations and rotations, and (ii) they are well-defined for any spatial geometry with a distance metric, such as the surface of a sphere or an arbitrary spatial network #REFR .", "text_before_citation": ["Again, v max is typically much smaller than the speed of sound. Lagrangian lightcones capture local causality derived from Lagrangian advection.", "A Lagrangian past lightcone delineates the possible reach of a particle y(t; t 0 , y 0 ) initially at point (r 0 , t 0 ) through Lagrangian advection in reverse time.", "That is, all the spacetime points at earlier times from where the particle could possibly have come when evolving according to Lagrangian advection in Eq. (S1).", "In practice, the value of c used can be seen as a hyperparameter that controls the spatial scale of organization captured by the approximated local causal states. A larger c captures more coarse-grained structures.", "In addition to delineating causal influence for points in spacetime, note that lightcones are defined solely in terms of distances in spacetime."], "text_after_citation": ["Thus, they can be used in a wide variety of spatiotemporal systems, and they transform appropriately under translations, rotations, and reflections. We will return to this later point shortly.", "Note that planar projections of spherical data, like those we use here for climate data, can break global rotational symmetry, and therefore will not be robust across different projections.", "However, the local causal states appear to be robust to local rotations in a given projection.", "For example, the local causal state signature of hurricanes does not change as the hurricane rotates locally.", "Having defined lightcones, we can now define local causal states through the local causal equivalence relation."], "citing_paper_content": {"title": "Physics-Informed Representation Learning For Emergent Organization In Complex Dynamical Systems", "abstract": "Nonlinearly interacting system components often introduce instabilities that generate phenomena with new properties and at different space-time scales than the components. This is known as spontaneous self-organization and is ubiquitous in systems far from thermodynamic equilibrium. We introduce a theoretically-grounded framework for emergent organization that, via data-driven algorithms, is constructive in practice. Its building blocks are spacetime lightcones that capture how information propagates across a system through local interactions. We show that predictive equivalence classes of lightcones-local causal states-capture organized behaviors and coherent structures in complex spatiotemporal systems. Using our unsupervised physics-informed machine learning algorithm and a high-performance computing implementation, we demonstrate the applicability of the local causal states for real-world domain science problems. We show that the local causal states capture vortices and their power-law decay behavior in two-dimensional turbulence. We then show that known (hurricanes and atmospheric rivers) and novel extreme weather events can be identified on a pixel-level basis and tracked through time in high-resolution climate data. Emergent phenomena are often of primary interest in the study of complex systems, but disentangling the web of nonlinear interactions that give rise to them presents enormous challenges to traditional paradigms of scientific inquiry. Although the broad use of numerical models has significantly improved our ability to study nonlinear systems, difficulties remain. The scale and complexity of model outputs can be such that they are now essentially as difficult to understand as the natural phenomena they approximate. That is, the challenge of uncovering the physical and causal mechanisms of emergent phenomena in a large-scale numerical model can be comparable to doing so in the natural system itself. The Earth system is a quintessential complex system [1, 2], and the emergent behaviors associated with climate change present one of the most pressing issues of our time [3]. Many of the direct impacts of climate change on society are felt through emergent organization in the form of extreme weather events [4], such as hurricanes and atmospheric rivers (AR). As the Earth warms, the character of localized extreme weather events (EWE) has and will continue to change [5, 6]. Large-scale climate models are the primary tool used by scientists to study EWEs and climate change more generally [7, 8]. While high-resolution models can produce EWEs under a variety of warming scenarios, it is not clear what underlying mechanisms drive specific shifts in intensity, duration, and spatial dynamics of individual events. Moreover, statistical changes in EWE behaviors in large-scale surveys of various models and warming scenarios [9] are difficult to assess due to the sheer quantity of data produced. For example, CMIP 6 is estimated to contain 15-30 PB of total climate data [10]. There is an immediate need in the climate community for automated discovery and tracking of EWEs to better understand and predict how they are changing in a warming world and to help mitigate their deleterious effects. Discovering EWEs in a principled, robust, and scalable manner remains an outstanding challenge. Data-driven and machine learning methods are increasingly called upon as an additional layer of analysis to parse complex phenomena, whether produced by natural systems or complicated numerical models. At first glance, EWE detection and tracking seems an ideal use case for deep learning algorithms that have brought dramatic advances in computer vision. In machine learning terminology, we seek a segmentation analysis of extreme weather events-identifying events at the single-pixel or model-grid-cell scale. Indeed, there is considerable effort devoted to extreme weather segmentation using deep learning [11-15]. Deep learning's main weakness is that neural networks have been most successful at supervised computer vision tasks. In this, the networks are trained on ground truth labeled examples-data exemplars typically labeled by human experts. As with general fluid vortices [16], no ground truth is available for extreme weather events; see, e.g., [17]. Automated heuristics [18] are used to generate \"ground-truth\" training examples, but the trained neural networks' high evaluation scores show that they merely learn to reproduce the output of these heuristics. Rather than rely on supervised deep learning methods"}, "cited_paper_content": {"title": "Optimal Nonlinear Prediction Of Random Fields On Networks", "abstract": "It is increasingly common to encounter time-varying random fields on networks (metabolic networks, sensor arrays, distributed computing, etc.).This paper considers the problem of optimal, nonlinear prediction of these fields, showing from an information-theoretic perspective that it is formally identical to the problem of finding minimal local sufficient statistics.I derive general properties of these statistics, show that they can be composed into global predictors, and explore their recursive estimation properties.For the special case of discrete-valued fields, I describe a convergent algorithm to identify the local predictors from empirical data, with minimal prior information about the field, and no distributional assumptions."}, "keywords": ["arbitrary spatial network"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In addition to delineating causal influence for points in spacetime, note that lightcones are defined solely in terms of distances in spacetime. Optimal, nonlinear prediction of random fields on networks has been shown to be formally identical to the problem of finding minimal local sufficient statistics, which can be composed into global predictors, and explored for their recursive estimation properties. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The problem of optimal, nonlinear prediction of time-varying random fields on networks has been extensively studied in the literature #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The Lagrangian lightcones can capture local causality derived from Lagrangian advection in arbitrary spatial networks, as shown in #REFR.", "given_citation_intent": "background", "given_keywords": ["arbitrary spatial network"]}]}
{"citing_id": "2304.07593v1", "cited_id": "1706.04599", "section_title": "Discussion", "citation": "Especially the calibration of a model's predictions can change towards full convergence, as networks often become overconfident to match the target labels #REFR .", "text_before_citation": ["However, this is a trade-off worth considering for many applications.", "For CQKD and DML, reducing the resolution to 168 in width and height reduces the training time by a third while reducing the accuracy by only 5%.", "This speed-up is especially interesting for CQKD, as it outperforms the baseline by almost two percentage points for the same resolution and scores only one percentage point lower than the baseline trained on full resolution.", "The trade-off between accuracy and computational efficiency is likely to be domain-dependent, and there may be applications where it is even more effective to use downscaling.", "It is possible that slight changes in the overall results would still be observed when training for a greater number of epochs."], "text_after_citation": ["Nevertheless, we believe that the trends and differences between the algorithms remain unchanged, albeit at a lower accuracy."], "citing_paper_content": {"title": "Teacher Network Calibration Improves Cross-Quality Knowledge Distillation", "abstract": "We investigate cross-quality knowledge distillation (CQKD), a knowledge distillation method where knowledge from a teacher network trained with full-resolution images is transferred to a student network that takes as input low-resolution images. As image size is a deciding factor for the computational load of computer vision applications, CQKD notably reduces the requirements by only using the student network at inference time. Our experimental results show that CQKD outperforms supervised learning in large-scale image classification problems. We also highlight the importance of calibrating neural networks: we show that with higher temperature smoothing of the teacher's output distribution, the student distribution exhibits a higher entropy, which leads to both, a lower calibration error and a higher network accuracy. The implementation is available at: https://github.com/PiaCuk/distillistic."}, "cited_paper_content": {"title": "On Calibration Of Modern Neural Networks", "abstract": "Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions."}, "keywords": ["calibration"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "However, this is a trade-off worth considering for many applications. For CQKD and DML, reducing the resolution to 168 in width and height reduces the training time by a third while reducing the accuracy by only 5%. This speed-up is especially interesting for CQKD, as it outperforms the baseline by almost two percentage points for the same resolution and scores only one percentage point lower than the baseline trained on full resolution. The trade-off between accuracy and computational efficiency is likely to be domain-dependent, and there may be applications where it is even more effective to use downscaling. It is possible that slight changes in the overall results would still be observed when training for a greater number of epochs. It is important to note that neural network calibration is also crucial for improving network accuracy, as shown in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Calibrating neural networks is crucial for improving their accuracy and reducing calibration error, as shown in recent studies on modern neural networks (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Calibration is an important factor influencing the performance of neural networks, as shown in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["calibration"]}]}
{"citing_id": "2304.07542v2", "cited_id": "1807.10854", "section_title": "Vii. Natural Language Processing (Nlp)", "citation": "NLP and sentiment analysis involve processes that could enable computer reading, understanding, and processing of spoken or written language #REFR .", "text_before_citation": [], "text_after_citation": ["Some examples of NLP-related tasks include virtual personal assistants, chatbots, speech recognition, document description, and language or machine translation.", "Sentiment Analysis or Opinion Mining uses the result of NLP to mine information or trends that could translate to moods, views, and opinions from huge data collected from different social media platforms #OTHEREFR .", "For instance, politicians can use sentiment analysis to ascertain the perceived views of the electorate about their candidate."], "citing_paper_content": {"title": "Machine Learning Research Trends In Africa: A 30 Years Overview With Bibliometric Analysis Review", "abstract": "The machine learning (ML) paradigm has gained much popularity today. Its algorithmic models are employed in every field, such as natural language processing, pattern recognition, object detection, image recognition, earth observation and many other research areas. In fact, machine learning technologies and their inevitable impact suffice in many technological transformation agendas currently being propagated by many nations, for which the already yielded benefits are outstanding. From a regional perspective, several studies have shown that machine learning technology can help address some of Africa's most pervasive problems, such as poverty alleviation, improving education, delivering quality healthcare services, and addressing sustainability challenges like food security and climate change. In this state-of-the-art paper, a critical bibliometric analysis study is conducted, coupled with an extensive literature survey on recent developments and associated applications in machine learning research with a perspective on Africa. The presented bibliometric analysis study consists of 2761 machine learning-related documents, of which 89% were articles with at least 482 citations published in 903 journals during the past three decades. Furthermore, the collated documents were retrieved from the Science Citation Index EXPANDED, comprising research publications from 54 African countries between 1993 and 2021. The bibliometric study shows the visualization of the current landscape and future trends in machine learning research and its application to facilitate future collaborative research and knowledge exchange among authors from different research institutions scattered across the African continent."}, "cited_paper_content": {"title": "A Survey Of The Usages Of Deep Learning In Natural Language Processing", "abstract": "Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This survey provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field."}, "keywords": ["sentiment analysis"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Several studies have shown that deep learning models have been widely used in natural language processing, including for core linguistic processing issues and various applications of computational linguistics #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Over the last several years, deep learning models have been increasingly used in natural language processing, as highlighted in a survey by the authors of the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Natural language processing is one of the fields that has been significantly impacted by deep learning models in recent years, as highlighted in the reference paper #REFR, which provides a comprehensive survey of the usages of deep learning in various linguistic processing issues and applications, including sentiment analysis.", "given_citation_intent": "background", "given_keywords": ["sentiment analysis"]}]}
{"citing_id": "2303.11970v1", "cited_id": "math/0701575", "section_title": "Arxiv:2303.11970V1 [Math.Oc] 21 Mar 2023", "citation": "Wang and Sontag #REFR showed that a singularly perturbed strongly monotone system inherits the generic convergence properties of strongly monotone systems, and demonstrated an application in systems biology.", "text_before_citation": ["a matrix k-cone (see (1)) in a systems and control perspective, calling them k-dominant systems, and used (2) as the definition of k-dominance with rate s.", "Importantly, using the fact that (2) is an LMI, they extended the notion of a system that is monotone w.r.t.", "a matrix k-cone to systems with inputs and outputs, and studied the interconnections of such systems.", "Singularly perturbed systems #OTHEREFR , #OTHEREFR Ch. 11 ] appear naturally in many control applications.", "For instance, see #OTHEREFR , #OTHEREFR for an application to low-gain integral control, and #OTHEREFR for an application to power systems stability."], "text_after_citation": ["Niu and Xie #OTHEREFR showed that singularly perturbed systems that are strongly monotone w.r.t. a 2-cone inherit the generic Poincar\u00e9-Bendixon property.", "The results in #OTHEREFR , #OTHEREFR are based on geometric singular perturbations theory #OTHEREFR , #OTHEREFR .", "Here, we consider k-dominance for singularly perturbed systems.", "We derive a new sufficient condition for a singularly perturbed system to be k-dominant.", "Our proof uses standard tools from linear algebra and dynamical systems theory, and does not require the heavy machinery of geometric singular perturbations theory."], "citing_paper_content": {"title": "On Singularly Perturbed Systems That Are Monotone With Respect To A Matrix Cone Of Rank K", "abstract": "We derive a sufficient condition guaranteeing that a singularly perturbed linear time-varying system is strongly monotone with respect to a matrix cone C of rank k. This implies that the singularly perturbed system inherits the asymptotic properties of systems that are strongly monotone with respect to C, which include convergence to the set of equilibria when k = 1, and a Poincar\u00e9-Bendixson property when k = 2. We extend this result to singularly perturbed nonlinear systems with a compact and convex state-space. We demonstrate our theoretical results using a simple numerical example."}, "cited_paper_content": {"title": "Singularly Perturbed Monotone Systems And An Application To Double Phosphorylation Cycles", "abstract": "The theory of monotone dynamical systems has been found very useful in the modeling of some gene, protein, and signaling networks. In monotone systems, every net feedback loop is positive. On the other hand, negative feedback loops are important features of many systems, since they are required for adaptation and precision. This paper shows that, provided that these negative loops act at a comparatively fast time scale, the main dynamical property of (strongly) monotone systems, convergence to steady states, is still valid. An application is worked out to a double-phosphorylation \u201cfutile cycle\u201d motif which plays a central role in eukaryotic cell signaling."}, "keywords": ["strongly monotone systems", "monotone system"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors' work on singularly perturbed systems with respect to a matrix cone of rank k (see (1)) is extended to nonlinear systems in a recent paper by Smith et al. (#REFR), where they show that convergence to steady states is still valid in strongly monotone systems with negative feedback loops acting at a comparatively fast time scale.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Monotone systems have been found useful in modeling gene, protein, and signaling networks, and negative feedback loops are important features of many systems. According to the paper by #REFR, if these negative loops act at a comparatively fast time scale, the main dynamical property of monotone systems, convergence to steady states, is still valid.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Monotone systems are widely used in modeling gene, protein, and signaling networks, and their dynamical properties have been extensively studied. In particular, it has been shown that strongly monotone systems converge to steady states, even when negative feedback loops are present at a comparatively fast time scale, as demonstrated in #REFR.", "given_citation_intent": "background", "given_keywords": ["strongly monotone systems", "monotone system"]}]}
{"citing_id": "2303.01327v1", "cited_id": "1403.3720", "section_title": "1", "citation": "In Cui, Dai, and Nie #REFR , a semidefinite relaxation method was developed to find all real eigenvalues of symmetric tensor pairs.", "text_before_citation": [", . . .", ", x m\u22121 n ) \u22a4 and [n] = {1, 2, . . . , n}.", "For simplicity, we use \u2022 to denote the 2-norm for vectors and matrices in this paper.", "Several numerical methods have been proposed in the literature for computing generalized eigenpairs for different classes of tensor pairs.", "Kolda and Mayo #OTHEREFR proposed a power method for computing the generalized eigenpairs for symmetric tensor pair."], "text_after_citation": ["In #OTHEREFR , Chen, Han and Zhou presented the homotopy methods for computing the (generalized) tensor eigenpair.", "Yu, Yu, Xu, Song, and Zhou #OTHEREFR gave an adaptive gradient method for computing generalized tensor eigenpairs.", "Zhao, Yang and Liu #OTHEREFR computed the generalized eigenvalues of weakly symmetric tensors.", "Che, Cichocki and Wei #OTHEREFR applied the neural dynamical network to compute a best rank-one approximation of a realvalued tensor and solve the tensor eigenvalue problems.", "Mo, Wang and Wei #OTHEREFR explored time-varying generalized tensor eigenanalysis via Zhang neural networks."], "citing_paper_content": {"title": "Noda Iteration For Computing Generalized Tensor Eigenpairs", "abstract": "In this paper, we propose the tensor Noda iteration (NI) and its inexact version for solving the eigenvalue problem of a particular class of tensor pairs called generalized M-tensor pairs. A generalized M-tensor pair consists of a weakly irreducible nonnegative tensor and a nonsingular Mtensor within a linear combination. It is shown that any generalized M-tensor pair admits a unique positive generalized eigenvalue with a positive eigenvector. A modified tensor Noda iteration(MTNI) is developed for extending the Noda iteration for nonnegative matrix eigenproblems. In addition, the inexact generalized tensor Noda iteration method (IGTNI) and the generalized Newton-Noda iteration method (GNNI) are also introduced for more efficient implementations and faster convergence. Under a mild assumption on the initial values, the convergence of these algorithms is guaranteed. The efficiency of these algorithms is illustrated by numerical experiments."}, "cited_paper_content": {"title": "All Real Eigenvalues Of Symmetric Tensors", "abstract": "This paper studies how to compute all real eigenvalues of a symmetric tensor. As is well known, the largest or smallest eigenvalue can be found by solving a polynomial optimization problem, while the other middle eigenvalues can not. We propose a new approach for computing all real eigenvalues sequentially, from the largest to the smallest. It uses Jacobian SDP relaxations in polynomial optimization. We show that each eigenvalue can be computed by solving a finite hierarchy of semidefinite relaxations. Numerical experiments are presented to show how to do this."}, "keywords": ["symmetric tensor pairs"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Several numerical methods have been proposed in the literature for computing generalized eigenpairs for different classes of tensor pairs, including the power method proposed by Kolda and Mayo (#REFR) for computing the generalized eigenpairs for symmetric tensor pairs.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Kolda and Mayo proposed a power method for computing the generalized eigenpairs for symmetric tensor pair, while the authors of this manuscript propose the tensor Noda iteration (NI) and its inexact version for solving the eigenvalue problem of a particular class of tensor pairs called generalized M-tensor pairs using Jacobian SDP relaxations in polynomial optimization #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Several numerical methods have been proposed in the literature for computing generalized eigenpairs for different classes of tensor pairs, including symmetric tensor pairs. Kolda and Mayo proposed a new approach for computing all real eigenvalues sequentially, from the largest to the smallest, using Jacobian SDP relaxations in polynomial optimization, which can be found in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["symmetric tensor pairs"]}]}
{"citing_id": "2303.16390v1", "cited_id": "1703.03717", "section_title": "Related Work", "citation": "The gradient-based explanations (e.g., Input Gradient) are consistent with sample-based explanations (e.g., LIME) with comparable fidelity but have much lower computational cost #REFR .", "text_before_citation": ["A suite of techniques has been proposed to reveal the decision-making process of modern black-box ML models.", "One direction is intrinsic to the model design and training, rendering an explanation along with its output, e.g., attention mechanisms #OTHEREFR and joint training #OTHEREFR .", "A more popular way is to give insight into the learned associations of a model that are not readily interpretable by design, known as post-hoc methods.", "Such methods usually leverage backpropagation or local approximation to offer saliency maps as explanations, e.g., Input Gradient #OTHEREFR , Grad-CAM #OTHEREFR , LIME #OTHEREFR , and SHAP #OTHEREFR .", "Recent works have shed light on the downsides of post-hoc methods."], "text_after_citation": ["Moreover, only the Input Gradient and Grad-CAM methods passed the sanity checks in #OTHEREFR .", "In our work, we incorporate gradient-based methods into optimization to calculate explanations efficiently.", "Out-of-distribution generalization.", "To generalize machine learning models from training distributions to unseen distributions, existing methods on OOD generalization can be categorized into four branches: (1) Data augmentation.", "#OTHEREFR ] enhance the generalization performance by increasing the diversity of data through augmentation. (2) Distribution alignment."], "citing_paper_content": {"title": "Are Data-Driven Explanations Robust Against Out-Of-Distribution Data?", "abstract": "As black-box models increasingly power high-stakes applications, a variety of data-driven explanation methods have been introduced. Meanwhile, machine learning models are constantly challenged by distributional shifts. A question naturally arises: Are data-driven explanations robust against out-of-distribution data? Our empirical results show that even though predict correctly, the model might still yield unreliable explanations under distributional shifts. How to develop robust explanations against out-of-distribution data? To address this problem, we propose an end-to-end model-agnostic learning framework Distributionally Robust Explanations (DRE). The key idea is, inspired by self-supervised learning, to fully utilizes the inter-distribution information to provide supervisory signals for the learning of explanations without human annotation. Can robust explanations benefit the model's generalization capability? We conduct extensive experiments on a wide range of tasks and data types, including classification and regression on image and scientific tabular data. Our results demonstrate that the proposed method significantly improves the model's performance in terms of explanation and prediction robustness against distributional shifts."}, "cited_paper_content": {"title": "Right For The Right Reasons: Training Differentiable Models By Constraining Their Explanations", "abstract": "Neural networks are among the most accurate supervised learning methods in use today, but their opacity makes them difficult to trust in critical applications, especially when conditions in training differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions, which can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients, which provide a normal to the decision boundary. We apply these penalties both based on expert annotation and in an unsupervised fashion that encourages diverse models with qualitatively different decision boundaries for the same classification problem. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test."}, "keywords": ["gradient-based explanations"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "A more efficient way to explain and regularize differentiable models is to examine and selectively penalize their input gradients, which provide a normal to the decision boundary #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Input Gradient #REFR is a popular post-hoc method that leverages backpropagation to offer saliency maps as explanations, but recent works have shown its downsides; therefore, the authors propose a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients, which provide a normal to the decision boundary #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Input Gradient is a popular post-hoc method that leverages #REFR gradient-based explanations to offer saliency maps as explanations, but recent works have shed light on its downsides.", "given_citation_intent": "result", "given_keywords": ["gradient-based explanations"]}]}
{"citing_id": "2303.01201v1", "cited_id": "1610.02136", "section_title": "Related Work", "citation": "The work of #REFR first introduced a baseline called MSP as the scoring function to detect OOD inputs.", "text_before_citation": ["OOD Detection Various methods are proposed under the setting that whether use the auxiliary data of natural outliers or not."], "text_after_citation": ["Later, various methods focus on designing scoring functions are proposed #OTHEREFR .", "Generative models #OTHEREFR are also applied to provide reliable estimations of confidence.", "Besides, OE #OTHEREFR first introduced an extra dataset consisting of outliers in training and enforced low confidence on such outliers.", "To better utilize the auxiliary dataset, different methods are propose #OTHEREFR .", "There are also some methods to synthesize outliers #OTHEREFR ."], "citing_paper_content": {"title": "Average Of Pruning: Improving Performance And Stability Of Out-Of-Distribution Detection", "abstract": "Detecting Out-of-distribution (OOD) inputs have been a critical issue for neural networks in the open world. However, the unstable behavior of OOD detection along the optimization trajectory during training has not been explored clearly. In this paper, we first find the performance of OOD detection suffers from overfitting and instability during training: 1) the performance could decrease when the training error is near zero, and 2) the performance would vary sharply in the final stage of training. Based on our findings, we propose Average of Pruning (AoP), consisting of model averaging and pruning, to mitigate the unstable behaviors. Specifically, model averaging can help achieve a stable performance by smoothing the landscape, and pruning is certified to eliminate the overfitting by eliminating redundant features. Comprehensive experiments on various datasets and architectures are conducted to verify the effectiveness of our method."}, "cited_paper_content": {"title": "A Baseline For Detecting Misclassified And Out-Of-Distribution Examples In Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks."}, "keywords": ["OOD inputs"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Various methods are proposed under the setting that whether use the auxiliary data of natural outliers or not. To detect misclassified and out-of-distribution examples, a simple baseline that utilizes probabilities from softmax distributions is presented in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Detecting out-of-distribution (OOD) inputs has been a critical issue for neural networks in the open world, and various methods have been proposed under the setting that whether use the auxiliary data of natural outliers or not. To provide additional context, a simple baseline that utilizes probabilities from softmax distributions has been proposed for detecting misclassified and out-of-distribution examples in neural networks, which has shown effectiveness across various tasks in computer vision, natural language processing, and automatic speech recognition #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Detecting OOD inputs is a critical issue for neural networks in the open world, and various methods have been proposed under this setting, including the utilization of auxiliary data of natural outliers. To address the unstable behavior of OOD detection during training, the authors of this manuscript propose a method called Average of Pruning (AoP), which consists of model averaging and pruning, and is shown to be effective in mitigating the unstable behaviors. The proposed method is based on the findings that the performance of OOD detection suffers from overfitting and instability during training, and that the performance could decrease when the training error is near zero, and vary sharply in the final stage of training. #REFR provides a simple baseline that utilizes probabilities from softmax distributions to detect misclassified and out-of-distribution examples, and is effective across various tasks in computer vision, natural language processing, and automatic speech recognition.", "given_citation_intent": "background", "given_keywords": ["OOD inputs"]}]}
{"citing_id": "2303.03770v3", "cited_id": "1911.05722", "section_title": "Temporal Queue For Negative Pairs Exclusion", "citation": "MoCo #REFR uses the pairs (q, k) as positive and all the pairs {(q, k i )} N i=1 as negative pairs by minimising and maximising their cosine distance.", "text_before_citation": ["Queries and keys features will be used to build the positive pairs.", "To build negative pairs, we also maintain a queue Q e that stores keys features", "{k i } N i=1", "computed in each mini-batch.", "The negative pairs are then composed by pairing features from the queue."], "text_after_citation": ["Since features are stored in Q e independently from the class, even features from samples sharing the same class will be pushed apart, which is in contrast with our objective. Recently, Chen et al.", "#OTHEREFR propose a strategy to exclude some negative pairs from the contrastive loss.", "For every negative pair, they just compare the pseudolabels of the two samples composing the pair.", "If the two samples share the same pseudo-label, then the negative pair is masked out.", "Otherwise, the negative pair composed of the two samples is included in the negative pairs list."], "citing_paper_content": {"title": "Guiding Pseudo-Labels With Uncertainty Estimation For Source-Free Unsupervised Domain Adaptation", "abstract": "Standard Unsupervised Domain Adaptation (UDA) methods assume the availability of both source and target data during the adaptation. In this work, we investigate the Source-free Unsupervised Domain Adaptation (SF-UDA), a specific case of UDA where a model is adapted to a target domain without access to source data. We propose a novel approach for the SF-UDA setting based on a loss reweighting strategy that brings robustness against the noise that inevitably affects the pseudo-labels. The classification loss is reweighted based on the reliability of the pseudo-labels that is measured by estimating their uncertainty. Guided by such reweighting strategy, the pseudo-labels are progressively refined by aggregating knowledge from neighbouring samples. Furthermore, a self-supervised contrastive framework is leveraged as a target space regulariser to enhance such knowledge aggregation. A novel negative pairs exclusion strategy is proposed to identify and exclude negative pairs made of samples sharing the same class, even in presence of some noise in the pseudo-labels. Our method outperforms previous methods on three major benchmarks by a large margin. We set the new SF-UDA state-of-the-art on VisDA-C and DomainNet with a performance gain of +1.8% on both benchmarks and on PACS with +12.3% in the single-source setting and +6.6% in multi-target adaptation. Additional analyses demonstrate that the proposed approach is robust to the noise, which results in significantly more accurate pseudo-labels compared to state-of-the-art approaches."}, "cited_paper_content": {"title": "Momentum Contrast For Unsupervised Visual Representation Learning", "abstract": "We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks."}, "keywords": ["negative pairs", "pairs"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To build negative pairs, the authors maintain a queue of keys features computed in each mini-batch, as described in the Momentum Contrast (MoCo) paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To build negative pairs, the authors maintain a queue of keys features computed in each mini-batch, which are paired to form negative pairs, as described in the Momentum Contrast (MoCo) method for unsupervised visual representation learning #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To build negative pairs, the authors maintain a queue that stores keys features computed in each mini-batch, and the negative pairs are then composed by pairing features from the queue with the queries, as proposed in Momentum Contrast (MoCo) for unsupervised visual representation learning #REFR.", "given_citation_intent": "method", "given_keywords": ["negative pairs", "pairs"]}]}
{"citing_id": "2303.02841v2", "cited_id": "1908.10423", "section_title": "Datasets", "citation": "Four high-resource datasets(MNLI, QQP, SST, QNLI) are used as training datasets, and four other low-resource datasets(CoLA, MRPC, STS-B, RTE) are used as testing datasets, according to #REFR .", "text_before_citation": ["We briefly describes the GLUE, SNLI, and SciTail datasets, as summarized in Table 1 .", "GLUE The General Language Understanding Evaluation (GLUE) benchmark #OTHEREFR is a tool for evaluating and analyzing the performance of natural language understanding models across nine NLU tasks: Single-Sentence Tasks, Similarity and Paraphrase Tasks and Inference Tasks."], "text_after_citation": ["In our experiments we do not train or test models on the WNLI dataset because of previous work #OTHEREFR .", "SNLI The Stanford Natural Language Inference dataset #OTHEREFR is a naturalistic corpus of 570k sentence pairs labeled for entailment, contradiction, and independence.", "We use this dataset to examine the algorithm's fast adaptation ability in this study.", "Sci-Tail This is a Textual Entailment Dataset from Science Question Answering #OTHEREFR .", "Hypotheses from science questions are created while the corresponding answer candidates and premises from relevant web sentences are retrieved from a large corpus."], "citing_paper_content": {"title": "Model-Agnostic Meta-Learning For Natural Language Understanding Tasks In Finance", "abstract": "Natural language understanding(NLU) is challenging for finance due to the lack of annotated data and the specialized language in that domain. As a result, researchers have proposed to use pre-trained language model and multi-task learning to learn robust representations. However, aggressive finetuning often causes over-fitting and multi-task learning may favor tasks with significantly larger amounts data, etc. To address these problems, in this paper, we investigate model-agnostic metalearning algorithm(MAML) in low-resource financial NLU tasks. Our contribution includes: 1. we explore the performance of MAML method with multiple types of tasks: GLUE datasets, SNLI, Sci-Tail and Financial PhraseBank; 2. we study the performance of MAML method with multiple single-type tasks: a real scenario stock price prediction problem with twitter text data. Our models achieve the state-of-the-art performance according to the experimental results, which demonstrate that our method can adapt fast and well to low-resource situations."}, "cited_paper_content": {"title": "Investigating Meta-Learning Algorithms For Low-Resource Natural Language Understanding Tasks", "abstract": "Learning general representations of text is a fundamental problem for many natural language understanding (NLU) tasks. Previously, researchers have proposed to use language model pre-training and multi-task learning to learn robust representations. However, these methods can achieve sub-optimal performance in low-resource scenarios. Inspired by the recent success of optimization-based meta-learning algorithms, in this paper, we explore the model-agnostic meta-learning algorithm (MAML) and its variants for low-resource NLU tasks. We validate our methods on the GLUE benchmark and show that our proposed models can outperform several strong baselines. We further empirically demonstrate that the learned representations can be adapted to new tasks efficiently and effectively."}, "keywords": ["training datasets", "Four high-resource datasets(MNLI"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The General Language Understanding Evaluation (GLUE) benchmark is a tool for evaluating and analyzing the performance of natural language understanding models across nine NLU tasks: Single-Sentence Tasks, Similarity and Paraphrase Tasks and Inference Tasks. To improve the performance of low-resource NLU tasks, the authors of this paper investigated the use of model-agnostic meta-learning algorithm (MAML) and its variants, achieving state-of-the-art results on the GLUE benchmark and other datasets including SNLI and Sci-Tail #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To investigate low-resource natural language understanding tasks, the authors of this paper explore the model-agnostic meta-learning algorithm (MAML) and its variants, achieving state-of-the-art performance on the GLUE benchmark and demonstrating that the learned representations can be adapted efficiently and effectively to new tasks. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To investigate the performance of MAML method with multiple types of tasks, including GLUE, SNLI, Sci-Tail, and Financial PhraseBank, the authors of this paper refer to the work of [authors] who explored the model-agnostic meta-learning algorithm (MAML) and its variants for low-resource NLU tasks. #REFR", "given_citation_intent": "method", "given_keywords": ["training datasets", "Four high-resource datasets(MNLI"]}]}
{"citing_id": "2304.12083v1", "cited_id": "1904.09223", "section_title": "Semantic Representation Learning", "citation": "The other loss for C-BERT is inspired by masked language modeling #REFR , which regards the training process as a masked token prediction task.", "text_before_citation": ["Thus, a margin-based loss is set to discriminate valid triples from invalid ones with the distance function in Eq.(1):", "EQUATION", "where", "[\u2022] + \u225c (0, \u2022), (\u210e,^,^)", "is a negative sample for (\u210e, , ) by replacing either the tail entity or the relation a random one^\u2208 or^\u2208 , where controls the safety margin between positive and negative triples."], "text_after_citation": ["During finetuning, each token in the input sentence has a 15% chance of being replaced with a [MASK] token, where C-BERT is required to predict the masked tokens from inputs.", "It is defined as a classification task with cross-entropy loss:", "EQUATION", "where is list of masked tokens, (^) is the language model's predicted probability for token in the corresponding training sample.", "The training loss is the sum of and to fuse the KG connection information and the linguistic semantics into the entity representation:"], "citing_paper_content": {"title": "Joint Semantic And Structural Representation Learning For Enhancing User Preference Modelling", "abstract": "Knowledge graphs (KGs) have become important auxiliary information for helping recommender systems obtain a good understanding of user preferences. Despite recent advances in KG-based recommender systems, existing methods are prone to suboptimal performance due to the following two drawbacks: 1) current KG-based methods overemphasize the heterogeneous structural information within a KG and overlook the underlying semantics of its connections, hindering the recommender from distilling the explicit user preferences; and 2) the inherent incompleteness of a KG (i.e., missing facts, relations and entities) will deteriorate the information extracted from KG and weaken the representation learning of recommender systems. To tackle the aforementioned problems, we investigate the potential of jointly incorporating the structural and semantic information within a KG to model user preferences in finer granularity. A new framework for KG-based recommender systems, namely Knowledge I nfomax Recommender System with Contrastive Learning (KIRS-CL) is proposed in this paper. Distinct from previous KG-based approaches, KIRS-CL utilizes structural and connectivity information with high-quality item embeddings learned by encoding KG triples with a pre-trained language model. These well-trained entity representations enable KIRS-CL to find the item to recommend via the preference connection between the user and the item. Additionally, to improve the generalizability of our framework, we introduce a contrastive warm-up learning strategy, making it capable of dealing with both warm-and cold-start recommendation scenarios. Extensive experiments on two real-world datasets demonstrate remarkable improvements over state-of-the-art baselines."}, "cited_paper_content": {"title": "Ernie: Enhanced Representation Through Knowledge Integration", "abstract": "We present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration). Inspired by the masking strategy of BERT, ERNIE is designed to learn language representation enhanced by knowledge masking strategies, which includes entity-level masking and phrase-level masking. Entity-level strategy masks entities which are usually composed of multiple words.Phrase-level strategy masks the whole phrase which is composed of several words standing together as a conceptual unit.Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We also demonstrate that ERNIE has more powerful knowledge inference capacity on a cloze test."}, "keywords": ["masked language modeling"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To learn language representation enhanced by knowledge masking strategies, ERNIE (Enhanced Representation through kNowledge IntEgration) was proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enhance the representation of language models with knowledge, ERNIE (Enhanced Representation through kNowledge IntEgration) was proposed, which includes entity-level masking and phrase-level masking strategies #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Masked language modeling is a popular technique used in natural language processing tasks to enhance language representation #REFR.", "given_citation_intent": "background", "given_keywords": ["masked language modeling"]}]}
{"citing_id": "2304.03209v1", "cited_id": "1912.08193", "section_title": "Implicit Anatomical Rendering (Iar)", "citation": "Unlike #REFR , we explore using the encoded positional information to capture high-frequency signals, which echoes our theoretical findings in Appendix A.", "text_before_citation": ["SecondLargest(v)\u2212max(v),", "where v is the logit vector of that pixel such that the coarse segmentation is given as Softmax(v).", "The rest (1 \u2212 \u03c1)N p pixels are sampled uniformly from all the remaining pixels.", "This mechanism ensures the selected points contain a large portion of points with uncertain segmentation which require refinement.", "Positional Encoding It is well-known that neural networks can be cast as universal function approximators, but they are inferior to high-frequency signals due to their limited learning power #OTHEREFR ."], "text_after_citation": ["Specifically, for a coordinate-based point (x, y) \u2208 [H] \u00d7 [W ], the positional encoding function is given as:", "EQUATION", "i , v i } L i=1", "are trainable parameters with Gaussian random initialization, where we set L = 128 #OTHEREFR .", "For each selected point, its position encoding will then be concatenated with the coarse features of that point (i.e., x out defined in Sec. 2.1), to output the fine-grained features."], "citing_paper_content": {"title": "Implicit Anatomical Rendering For Medical Image Segmentation With Stochastic Experts", "abstract": "Integrating high-level semantically correlated contents and low-level anatomical features is of central importance in medical image segmentation. Towards this end, recent deep learning-based medical segmentation methods have shown great promise in better modeling such information. However, convolution operators for medical segmentation typically operate on regular grids, which inherently blur the high-frequency regions, i.e., boundary regions. In this work, we propose MORSE, a generic implicit neural rendering framework designed at an anatomical level to assist learning in medical image segmentation. Our method is motivated by the fact that implicit neural representation has been shown to be more effective in fitting complex signals and solving computer graphics problems than discrete grid-based representation. The core of our approach is to formulate medical image segmentation as a rendering problem in an end-to-end manner. Specifically, we continuously align the coarse segmentation prediction with the ambiguous coordinate-based point representations and aggregate these features to adaptively refine the boundary region. To parallelly optimize multi-scale pixel-level features, we leverage the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a stochastic gating mechanism. Our experiments demonstrate that MORSE can work well with different medical segmentation backbones, consistently achieving competitive performance improvements in both 2D and 3D supervised medical segmentation methods. We also theoretically analyze the superiority of MORSE."}, "cited_paper_content": {"title": "Pointrend: Image Segmentation As Rendering", "abstract": "We present a new method for efficient high-quality image segmentation of objects and scenes. By analogizing classical computer graphics methods for efficient rendering with over- and undersampling challenges faced in pixel labeling tasks, we develop a unique perspective of image segmentation as a rendering problem. From this vantage, we present the PointRend (Point-based Rendering) neural network module: a module that performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm. PointRend can be flexibly applied to both instance and semantic segmentation tasks by building on top of existing state-of-the-art models. While many concrete implementations of the general idea are possible, we show that a simple design already achieves excellent results. Qualitatively, PointRend outputs crisp object boundaries in regions that are over-smoothed by previous methods. Quantitatively, PointRend yields significant gains on COCO and Cityscapes, for both instance and semantic segmentation. PointRend's efficiency enables output resolutions that are otherwise impractical in terms of memory or computation compared to existing approaches."}, "keywords": ["encoded positional information"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose a unique perspective of image segmentation as a rendering problem and present the PointRend neural network module, which performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our method achieves significant gains on COCO and Cityscapes datasets for both instance and semantic segmentation compared to previous methods, as demonstrated in #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed MORSE framework formulates medical image segmentation as a rendering problem, continuously aligning the coarse segmentation prediction with the ambiguous coordinate-based point representations and aggregating these features to adaptively refine the boundary region, while leveraging the idea from Mixture-of-Expert (MoE) to design and train the model with a stochastic gating mechanism for multi-scale pixel-level features optimization, achieving competitive performance improvements in both 2D and 3D supervised medical segmentation methods, as shown in #REFR's encoding positional information.", "given_citation_intent": "result", "given_keywords": ["encoded positional information"]}]}
{"citing_id": "2303.13935v1", "cited_id": "1803.03835", "section_title": "C. Approximate True Policy By Composing Primitives", "citation": "The approximation in #REFR assumes the maximum SF of each sub-task is most likely to be the SF of the primitive trained from the respective sub-task.", "text_before_citation": ["This is the core part of our method.", "We provide analytical view on how the task policy can be reconstructed by a set of task primitives given their relation in value space introduced in Sec. IV-A.", "1) MSF Composition: Following MSF in value space (16) we derive the correspondent policy composition,", "EQUATION"], "text_after_citation": ["Then the MSF composition can be achieved by MCP, i.e.\u03c0(\u2022|s) = M CP (\u03a0, g M SF ), where g M SF = w |w| is the normalized gating vector. return a", "2) SFV Composition: Following SFV in value space #OTHEREFR we derive the correspondent policy composition,", "EQUATION", "= d i=0 e 1 d wi\u03c8 \u03c0 i i (s,\u2022) d i=0 d j =i e 1 d wj \u03c8 \u03c0 i j (s,\u2022) \u221d d i=0 \u03c0 i (\u2022|s) w i d \u2022 (22)", "where is the artefactual noise."], "citing_paper_content": {"title": "Multi-Task Reinforcement Learning In Continuous Control With Successor Feature-Based Concurrent Composition", "abstract": "Deep reinforcement learning (DRL) frameworks are increasingly used to solve high-dimensional continuouscontrol tasks in robotics. However, due to the lack of sample efficiency, applying DRL for online learning is still practically infeasible in the robotics domain. One reason is that DRL agents do not leverage the solution of previous tasks for new tasks. Recent work on multi-tasking DRL agents based on successor features has proven to be quite promising in increasing sample efficiency. In this work, we present a new approach that unifies two prior multi-task RL frameworks, SF-GPI and value composition, for the continuous control domain. We exploit compositional properties of successor features to compose a policy distribution from a set of primitives without training any new policy. Lastly, to demonstrate the multi-tasking mechanism, we present a new benchmark for multi-task continuous control environment based on Raisim. This also facilitates large-scale parallelization to accelerate the experiments. Our experimental results in the Pointmass environment show that our multi-task agent has single task performance on par with soft actor critic (SAC) and the agent can successfully transfer to new unseen tasks where SAC fails. We provide our code as open-source at https://github.com/robot-perception-group/ concurrent_composition for the benefit of the community."}, "cited_paper_content": {"title": "Kickstarting Deep Reinforcement Learning", "abstract": "We present a method for using previously-trained 'teacher' agents to kickstart the training of a new 'student' agent. To this end, we leverage ideas from policy distillation and population based training. Our method places no constraints on the architecture of the teacher or student agents, and it regulates itself to allow the students to surpass their teachers in performance. We show that, on a challenging and computationally-intensive multi-task benchmark (DMLab-30), kickstarted training improves the data efficiency of new agents, making it significantly easier to iterate on their design. We also show that the same kickstarting pipeline can allow a single student agent to leverage multiple 'expert' teachers which specialize on individual tasks. In this setting kickstarting yields surprisingly large gains, with the kickstarted agent matching the performance of an agent trained from scratch in almost 10x fewer steps, and surpassing its final performance by 42 percent. Kickstarting is conceptually simple and can easily be incorporated into reinforcement learning experiments."}, "keywords": ["task"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "This is the core part of our method. We provide analytical view on how the task policy can be reconstructed by a set of task primitives given their relation in value space introduced in Sec. IV-A. 1) MSF Composition: Following MSF in value space (16) we derive the correspondent policy composition, EQUATION. Our approach is conceptually simple and can easily be incorporated into reinforcement learning experiments #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This approach is similar to the kickstarting method proposed in #REFR, where previously-trained 'teacher' agents are used to improve the data efficiency of new 'student' agents.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The task policy can be reconstructed by a set of task primitives given their relation in value space, as shown in our method. This approach is inspired by the kickstarting method proposed in #REFR, which uses previously-trained 'teacher' agents to improve the data efficiency of new agents. #REFR", "given_citation_intent": "background", "given_keywords": ["task"]}]}
{"citing_id": "2304.08342v1", "cited_id": "1807.03039", "section_title": "C. Convergence Of Nf-Ula", "citation": "This leads to a more powerful network and can generate better human face images #REFR but \u2207 log q \u03b8 (x) is not Lipschitz. This matches to the experiments in Sec. IV-A.", "text_before_citation": ["Note that the light tail of q \u03b8 (x) does not necessarily imply the Lipschitz of \u2207 log q \u03b8 (x), but the condition they assume is heuristic: if \u03d5 j is bounded above and \u03b7 j is Lipschitz, then q \u03b8 (x) is light-tailed.", "In Glow #OTHEREFR these conditions on \u03d5 and \u03b7 are satisfied and even stricter.", "Therefore we are able to prove the Lipschitz of \u2207 log q \u03b8 (x) in the proposition below, by enforcing a stricter condition on \u03d5 and \u03b7: Proposition 2. Assume that q z (z) is standard normal distribution.", "Denote G(x) = T \u22121 (x) and assume the affine coupling meanwhile \u03d5 = 1 is used in additive coupling layer.", "Note that in Glow there is another option using affine coupling layer where \u03d5 is sigmoid function."], "text_after_citation": ["The conditions on \u03d5 and \u03b7 might be relaxed if q z (z) is not Gaussian, but this requires re-training the net since most of the popular normalizing flows has standard Gaussian base distribution.", "Hence we leave these possible studies on the Lipschitz-continuity of \u2207 log q \u03b8 (x) for future work.", "layer G j (x j , x <j ) = \u03d5 j (x <j )x j + \u03b7 j (x <j ), j = 1, \u2022 \u2022 \u2022 , d.", "If \u03d5 j is a constant function, \u03b7 j is Lipschitz, \u2200i < j,", "In what follows, we introduce the associated stochastic kernel R \u03b4 : #OTHEREFR and the drift b \u03bb (x):"], "citing_paper_content": {"title": "Nf-Ula: Langevin Monte Carlo With Normalizing Flow Prior For Imaging Inverse Problems", "abstract": "Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The efficacy of the proposed NF-ULA algorithm is demonstrated in various imaging problems, including image deblurring, image inpainting, and limited-angle X-ray computed tomography (CT) reconstruction."}, "cited_paper_content": {"title": "Glow: Generative Flow With Invertible 1X1 Convolutions", "abstract": "Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow"}, "keywords": ["\u2207 log"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In Glow #REFR, the authors enforce a stricter condition on \u03d5 and \u03b7, satisfying the heuristic conditions assumed in this work, which allows for the proof of Lipschitz of \u2207 log q \u03b8 (x) in Proposition 2.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In Glow #REFR, the authors enforced a stricter condition on \u03d5 and \u03b7, satisfying the heuristic condition assumed in the manuscript, resulting in the Lipschitz of \u2207 log q \u03b8 (x) and demonstrating a significant improvement in log-likelihood on standard benchmarks.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In Glow #REFR, the authors enforced a stricter condition on \u03d5 and \u03b7, which allowed them to prove the Lipschitz of \u2207 log q \u03b8 (x), resulting in a significant improvement in log-likelihood on standard benchmarks.", "given_citation_intent": "result", "given_keywords": ["\u2207 log"]}]}
{"citing_id": "2304.02324v1", "cited_id": "1610.03518", "section_title": "Conclusion And Related Work", "citation": "In #REFR a method to use a learned deep inverse dynamics model to decide which real-world action is most suitable to achieve the same state as the simulator is proposed.", "text_before_citation": ["Related work.", "In #OTHEREFR , the authors separate the learned policy from the raw inputs and outputs to ease the transfer from simulation."], "text_after_citation": ["Mutual alignment transfer learning approaches employ auxiliary rewards for transfer learning under discrepancies in system dynamics for simulation to robot transfer ( #OTHEREFR ).", "Approaches such as #OTHEREFR compensate for the difference in dynamics by modifying the reward function such that the modified reward function penalizes the agent for visiting states and taking actions in the source domain which are not possible in the target domain.", "In #OTHEREFR , the authors study robust adversarial reinforcement learning.", "Inspired with the H \u221e control idea, they assume the destabilizing adversaries like the gap between simulation and environment as uncertainties and devise a learning algorithm which considers the worst case adversary and is robust against it.", "Transfer learning has also been investigated in the multi-agent setting #OTHEREFR , where the problem of training agents with continuous actions is studied to ensure that the trained agents can still generalize when their opponent's policies alter."], "citing_paper_content": {"title": "Convex Optimization-Based Policy Adaptation To Compensate For Distributional Shifts", "abstract": "Many real-world systems often involve physical components or operating environments with highly nonlinear and uncertain dynamics. A number of different control algorithms can be used to design optimal controllers for such systems, assuming a reasonably high-fidelity model of the actual system. However, the assumptions made on the stochastic dynamics of the model when designing the optimal controller may no longer be valid when the system is deployed in the real-world. The problem addressed by this paper is the following: Suppose we obtain an optimal trajectory by solving a control problem in the training environment, how do we ensure that the real-world system trajectory tracks this optimal trajectory with minimal amount of error in a deployment environment. In other words, we want to learn how we can adapt an optimal trained policy to distribution shifts in the environment. Distribution shifts are problematic in safety-critical systems, where a trained policy may lead to unsafe outcomes during deployment. We show that this problem can be cast as a nonlinear optimization problem that could be solved using heuristic method such as particle swarm optimization (PSO). However, if we instead consider a convex relaxation of this problem, we can learn policies that track the optimal trajectory with much better error performance, and faster computation times. We demonstrate the efficacy of our approach on tracking an optimal path using a Dubin's car model, and collision avoidance using both a linear and nonlinear model for adaptive cruise control."}, "cited_paper_content": {"title": "Transfer From Simulation To Real World Through Learning Deep Inverse Dynamics Model", "abstract": "Developing control policies in simulation is often more practical and safer than directly running experiments in the real world. This applies to policies obtained from planning and optimization, and even more so to policies obtained from reinforcement learning, which is often very data demanding. However, a policy that succeeds in simulation often doesn't work when deployed on a real robot. Nevertheless, often the overall gist of what the policy does in simulation remains valid in the real world. In this paper we investigate such settings, where the sequence of states traversed in simulation remains reasonable for the real world, even if the details of the controls are not, as could be the case when the key differences lie in detailed friction, contact, mass and geometry properties. During execution, at each time step our approach computes what the simulation-based control policy would do, but then, rather than executing these controls on the real robot, our approach computes what the simulation expects the resulting next state(s) will be, and then relies on a learned deep inverse dynamics model to decide which real-world action is most suitable to achieve those next states. Deep models are only as good as their training data, and we also propose an approach for data collection to (incrementally) learn the deep inverse dynamics model. Our experiments shows our approach compares favorably with various baselines that have been developed for dealing with simulation to real world model discrepancy, including output error control and Gaussian dynamics adaptation."}, "keywords": ["dynamics model", "learned deep inverse"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Related work. In #REFR, the authors investigate the transfer from simulation to the real world through learning a deep inverse dynamics model to decide which real-world action is most suitable to achieve the next states.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors separate the learned policy from the raw inputs and outputs to ease the transfer from simulation, as proposed in #REFR, which presents a method for transferring control policies from simulation to the real world through learning a deep inverse dynamics model.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors separate the learned policy from the raw inputs and outputs to ease the transfer from simulation, and #REFR propose a method that relies on a learned deep inverse dynamics model to decide which real-world action is most suitable to achieve the next states.", "given_citation_intent": "method", "given_keywords": ["dynamics model", "learned deep inverse"]}]}
{"citing_id": "2304.06322v1", "cited_id": "1802.04145", "section_title": "Network Compression Methods", "citation": "In #REFR , convolutional kernels are decomposed into shared bases and coefficient volumes to reduce parameters of each layer.", "text_before_citation": ["It is composed of fixed spatial kernels (blue) and switchable angular kernels (green and orange) for learning spatial information and angular information respectively.", "To further compact the network, angular kernels are allocated to the horizontal (green) and vertical (orage) directions, and both spatial and angular kernels are decomposed into the global bases (yellow cylinder) and corresponding coefficients (blue, green and orange cylinders).", "After training process, a light field can be implicitly represented by global bases {B}, spatial kernel coefficients {W s i } and angular kernel coefficients and biases", "{K a i u , K a i v , b a i u , b a i v }.", "mulating it as a tensor rank optimization problem, and decompose tensors into Tensor Ring (TR) or Tensor Train (TT) format within Alternating Direction Method of Multipliers (ADMM) framework."], "text_after_citation": ["Pruning is another compression approach that enforces sparsity of the network. Zhang et al.", "#OTHEREFR tackle weights pruning as a nonconvex optimization problem with combinatorial constraints specifying the sparsity requirements, and iteratively solve this optimization within ADMM framework.", "The authors in #OTHEREFR propose using a proxy network to predict the accuracy of the pruned network and guide the pruning process to achieve maximum performance.", "In #OTHEREFR , network pruning is reformulated as a structural redundancy identification problem, pruning the layers with the most redundancy instead of the least important filters gives better performance.", "Quantizing the network weights is another method to reduce the model size."], "citing_paper_content": {"title": "Learning-Based Spatial And Angular Information Separation For Light Field Compression", "abstract": "Light fields are a type of image data that capture both spatial and angular scene information by recording light rays emitted by a scene from different orientations. In this context, spatial information is defined as features that remain static regardless of perspectives, while angular information refers to features that vary between viewpoints. We propose a novel neural network that, by design, can separate angular and spatial information of a light field. The network represents spatial information using spatial kernels shared among all Sub-Aperture Images (SAIs), and angular information using sets of angular kernels for each SAI. To further improve the representation capability of the network without increasing parameter number, we also introduce angular kernel allocation and kernel tensor decomposition mechanisms. Extensive experiments demonstrate the benefits of information separation: when applied to the compression task, our network outperforms other state-ofthe-art methods by a large margin. And angular information can be easily transferred to other scenes for rendering dense views, showing the successful separation and the potential use case for the view synthesis task. We plan to release the code upon acceptance of the paper to encourage further research on this topic."}, "cited_paper_content": {"title": "Dcfnet: Deep Neural Network With Decomposed Convolutional Filters", "abstract": "Filters in a Convolutional Neural Network (CNN) contain model parameters learned from enormous amounts of data. In this paper, we suggest to decompose convolutional filters in CNN as a truncated expansion with pre-fixed bases, namely the Decomposed Convolutional Filters network (DCFNet), where the expansion coefficients remain learned from data. Such a structure not only reduces the number of trainable parameters and computation, but also imposes filter regularity by bases truncation. Through extensive experiments, we consistently observe that DCFNet maintains accuracy for image classification tasks with a significant reduction of model parameters, particularly with Fourier-Bessel (FB) bases, and even with random bases. Theoretically, we analyze the representation stability of DCFNet with respect to input variations, and prove representation stability under generic assumptions on the expansion coefficients. The analysis is consistent with the empirical observations."}, "keywords": ["convolutional kernels"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed neural network in this study utilizes fixed spatial kernels and switchable angular kernels for learning spatial and angular information, respectively, and further improves its representation capability by introducing angular kernel allocation and kernel tensor decomposition mechanisms. As shown in previous works, such as Dcfnet: Deep Neural Network With Decomposed Convolutional Filters #REFR, the use of decomposition techniques can significantly reduce the number of trainable parameters and computation while maintaining accuracy.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To further improve the representation capability of the network without increasing parameter number, angular kernels are allocated to the horizontal and vertical directions, and both spatial and angular kernels are decomposed into the global bases, as proposed in Dcfnet: Deep Neural Network With Decomposed Convolutional Filters #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the number of trainable parameters and computation, the proposed neural network uses fixed spatial kernels and switchable angular kernels for learning spatial and angular information, respectively, which are decomposed into global bases and corresponding coefficients, as suggested in the reference paper #REFR that utilizes decomposed convolutional filters.", "given_citation_intent": "method", "given_keywords": ["convolutional kernels"]}]}
{"citing_id": "2303.03492v1", "cited_id": "1802.04655", "section_title": "2) Assignment Constraints", "citation": "Using this constraint, the \u03b6 T,max v for a critical VNF instance can be set at a lower value, and hence it will not be shared which will protect the critical VNF. This is represented in constraint #REFR .", "text_before_citation": ["\u2022 Constraint #OTHEREFR certifies that the latency introduced by nodes' processing and network propagation can't exceed the maximum tolerated latency of a particular procedure.", "EQUATION", "3) Security constraints", "Two security constraints are formulated in the model; VNF's maximum traffic and VNF exposure constraints. These constraints are explained as follows:", "\u2022 The VNF's maximum traffic: This constraint ensures that the traffic processing capacity \u03b6 T,n vi of a VNF instance v i should not exceed the predefined maximum traffic processing capacity \u03b6 T,max v ."], "text_after_citation": ["\u03b6 n,T vi \u2264 \u03b6 T,max v , \u2200v \u2208 V, i \u2208 I v , n \u2208 N (16)", "\u2022 The VNF exposure: The VNF that is exposed to the outside network cannot be assigned to more than one slice.", "A VNF is exposed to the outside network if it the first VNF in the VNFs chain serving a procedure that is initiated by the UE or the Radio Access Network (RAN).", "First, let \u2126 n,s vi denotes to that VNF instance v i deployed in physical node n is exposed to the outside by the slice s.", "The \u2126 n,s vi is calculated by Equations #OTHEREFR and #OTHEREFR"], "citing_paper_content": {"title": "A Security-Aware Network Function Sharing Model For 5G Slicing Authors' Draft For Soliciting Feedback, March 6, 2023", "abstract": "Sharing Virtualized Network Functions (VNFs) among different slices in Fifth Generation (5G) is a potential strategy to simplify the system implementation and utilize 5G resources efficiently. In this paper, we propose a security-aware VNF sharing model for 5G networks. The proposed optimization model satisfies the service requirements of various slices, enhances slice security by isolating their critical VNFs, and enhances resource utilization of the underlying physical infrastructure. The model tries to systematically decide on sharing a particular VNF based on two groups of constraints; the first group of constraints is common assignment constraints used in the existing literature. The second group is the novel security constraints that we propose in this work; the maximum traffic allowed to be processed by the VNF and the exposure of the VNF to procedures sourced via untrusted users or access networks. This sharing problem is formalized to allow for procedure-level modeling that satisfies the requirements of slice requests in 5G systems. The model is tested using standard VNFs and procedures of the 5G system rather than generic ones. The numerical results of the model show the benefits and costs of applying the security constraints along with the network performance in terms of different metrics."}, "cited_paper_content": {"title": "Optimal Slice Allocation In 5G Core Networks", "abstract": "5G network slicing is essential to providing flexible, scalable, and on-demand solutions for the vast array of applications in 5G networks. Two key challenges of 5G network slicing are function isolation (intra-slice) and guaranteeing end-to-end delay for a slice. In this letter, we address the question of optimal allocation of a slice in 5G core networks by tackling these two challenges. We adopt and extend the work by Dietrich et al. (see introduction) to create a model that satisfies constraints on end-to-end delay as well as isolation between components of a slice for reliability."}, "keywords": ["critical VNF", "constraint"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors address the question of optimal allocation of a slice in 5G core networks by tackling the challenges of function isolation and end-to-end delay, and adopt and extend the work by Dietrich et al. to create a model that satisfies constraints on end-to-end delay as well as isolation between components of a slice for reliability #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the question of optimal allocation of a slice in 5G core networks, the authors adopt and extend the work by Dietrich et al. (Optimal Slice Allocation In 5G Core Networks) to create a model that satisfies constraints on end-to-end delay as well as isolation between components of a slice for reliability. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure the critical VNFs are isolated, the proposed security-aware VNF sharing model for 5G networks formulates two security constraints, including the VNF's maximum traffic and VNF exposure constraints, which are explained in detail in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["critical VNF", "constraint"]}]}
{"citing_id": "2303.09799v2", "cited_id": "1806.05622", "section_title": "Data Processing", "citation": "We identified that the VoxCeleb2 #REFR dataset is ideal for our needs because it comprises video snippets from a wide range of speakers.", "text_before_citation": ["Style Reference Images.", "To learn the styles from different speakers, we require an audio-visual dataset with a broad selection of speakers to learn the speaker-aware dynamics variations of head motion and facial expressions."], "text_after_citation": ["Since our purpose is to capture speaker dynamics for talking head synthesis, we picked a subset of 67 speakers from VoxCeleb2 with a total of 1, 232 video clips.", "We have about 5 \u2212 10 minutes of footage for each speaker.", "For each video, we perform image retrieval to find key motion frames and use them as the Style Reference Images.", "During retrieval, we use each motion template from 4 pre-defined key motion templates (mentioned in Section 4.1) to retrieve from a series of motion maps in the reference clip.", "Then, we collect indexes and obtain corresponding images and audio signals, which are expected to have the style information."], "citing_paper_content": {"title": "Style Transfer For 2D Talking Head Animation", "abstract": "Audio-driven talking head animation is a challenging research topic with many real-world applications. Recent works have focused on creating photo-realistic 2D animation, while learning different talking or singing styles remains an open problem. In this paper, we present a new method to generate talking head animation with learnable style references. Given a set of style reference frames, our framework can reconstruct 2D talking head animation based on a single input image and an audio stream. Our method first produces facial landmarks motion from the audio stream and constructs the intermediate style patterns from the style reference images. We then feed both outputs into a style-aware image generator to generate the photo-realistic and fidelity 2D animation. In practice, our framework can extract the style information of a specific character and transfer it to any new static image for talking head animation. The intensive experimental results show that our method achieves better results than recent state-of-the-art approaches qualitatively and quantitatively. Our source code can be found at: https://github.com/aioz-ai/AudioDrivenStyleTransfer."}, "cited_paper_content": {"title": "Voxceleb2: Deep Speaker Recognition", "abstract": "The objective of this paper is speaker recognition under noisy and unconstrained conditions. ::: We make two key contributions. First, we introduce a very large-scale audio-visual speaker recognition dataset collected from open-source media. Using a fully automated pipeline, we curate VoxCeleb2 which contains over a million utterances from over 6,000 speakers. This is several times larger than any publicly available speaker recognition dataset. ::: Second, we develop and compare Convolutional Neural Network (CNN) models and training strategies that can effectively recognise identities from voice under various conditions. The models trained on the VoxCeleb2 dataset surpass the performance of previous works on a benchmark dataset by a significant margin."}, "keywords": ["video snippets", "VoxCeleb2 dataset"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To learn the styles from different speakers, we require an audio-visual dataset with a broad selection of speakers to learn the speaker-aware dynamics variations of head motion and facial expressions. The Voxceleb2 dataset introduced in #REFR contains over a million utterances from over 6,000 speakers, making it several times larger than any publicly available speaker recognition dataset, and can be used to train models that effectively recognize identities from voice under various conditions.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn the styles from different speakers for our audio-driven talking head animation, we require an audio-visual dataset with a broad selection of speakers to learn the speaker-aware dynamics variations of head motion and facial expressions (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn the styles from different speakers for our audio-driven talking head animation, we require an audio-visual dataset with a broad selection of speakers to learn the speaker-aware dynamics variations of head motion and facial expressions, such as the VoxCeleb2 dataset which contains over a million utterances from over 6,000 speakers and can be used to extract video snippets for speaker recognition under noisy and unconstrained conditions. #REFR", "given_citation_intent": "background", "given_keywords": ["video snippets", "VoxCeleb2 dataset"]}]}
{"citing_id": "2303.05323v1", "cited_id": "1611.10314", "section_title": "Controllable Video Generation", "citation": "A region-of-interest VAE framework is proposed in #REFR to generate video sequences that are consistent with the given simple text captions.", "text_before_citation": ["The methods in #OTHEREFR use semantic masks to inject motion information since objects from different categories have visually different motion patterns (e.g. cars, buildings).", "Existing Imageto-Video methods can only achieve low-level control of the generated videos, thus they are not suitable to be used to generate videos with complex motions.", "Text-to-Video methods aim at generating video sequences from text captions.", "However, the appearance and motion information in the text caption is highly ambiguous leading to unavoidable uncertainties in generated videos.", "Sync-Draw #OTHEREFR is the first framework proposed to solve Text-to-Video tasks."], "text_after_citation": ["Recently, GO-DIVA #OTHEREFR was proposed to generate open-domain videos from given text captions in an auto-regressive way.", "A VQ-VAE #OTHEREFR is used in #OTHEREFR to represent the video content and generate visual tokens.", "Then, three attention models across temporal, column, and row dimensions, are used to generate temporally consistent videos conditioned by the caption.", "Given the ambiguous nature of the text, Text-to-Video methods can only achieve a low level of control over the generated videos.", "As a result, the appearance and motions within generated videos are mostly determined by the training dataset."], "citing_paper_content": {"title": "Controllable Video Generation By Learning The Underlying Dynamical System With Neural Ode", "abstract": "Videos depict the change of complex dynamical systems over time in the form of discrete image sequences. Generating controllable videos by learning the dynamical system is an important yet underexplored topic in the computer vision community. This paper presents a novel framework, TiV-ODE, to generate highly controllable videos from a static image and a text caption. Specifically, our framework leverages the ability of Neural Ordinary Differential Equations (Neural ODEs) to represent complex dynamical systems as a set of nonlinear ordinary differential equations. The resulting framework is capable of generating videos with both desired dynamics and content. Experiments demonstrate the ability of the proposed method in generating highly controllable and visually consistent videos, and its capability of modeling dynamical systems. Overall, this work is a significant step towards developing advanced controllable video generation models that can handle complex and dynamic scenes."}, "cited_paper_content": {"title": "Sync-Draw: Automatic Video Generation Using Deep Recurrent Attentive Architectures", "abstract": "This paper introduces a novel approach for generating videos called Synchronized Deep Recurrent Attentive Writer (Sync-DRAW). Sync-DRAW can also perform text-to-video generation which, to the best of our knowledge, makes it the first approach of its kind. It combines a Variational Autoencoder(VAE) with a Recurrent Attention Mechanism in a novel manner to create a temporally dependent sequence of frames that are gradually formed over time. The recurrent attention mechanism in Sync-DRAW attends to each individual frame of the video in sychronization, while the VAE learns a latent distribution for the entire video at the global level. Our experiments with Bouncing MNIST, KTH and UCF-101 suggest that Sync-DRAW is efficient in learning the spatial and temporal information of the videos and generates frames with high structural integrity, and can generate videos from simple captions on these datasets."}, "keywords": ["video sequences"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Sync-Draw is the first framework proposed to solve Text-to-Video tasks #REFR, which is highly relevant as existing Image-to-Video methods lack the ability to generate videos with complex motions and Text-to-Video methods suffer from unavoidable uncertainties in generated videos due to highly ambiguous appearance and motion information in the text caption.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Sync-Draw (#REFR) is the first framework proposed to solve Text-to-Video tasks, which aims at generating video sequences from text captions, and can efficiently learn the spatial and temporal information of the videos and generate frames with high structural integrity.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Sync-Draw #REFR is the first framework proposed to solve Text-to-Video tasks, generating temporally dependent #KEYWORD1 that are gradually formed over time with high structural integrity.", "given_citation_intent": "method", "given_keywords": ["video sequences"]}]}
{"citing_id": "2303.02906v1", "cited_id": "1912.04958", "section_title": "A. More Details Of Proposed Models", "citation": "MotionStyleGAN We propose the image pair generator MotionStyleGAN built on top of StyleGAN2 #REFR to generate image pairs sharing the same contents and producing various motions.", "text_before_citation": [], "text_after_citation": ["We modify the official Pytorch implementation of StyleGAN2 from three output color channels (RGB) for a single image to six color channels for image pairs.", "Although StyleGAN3 #OTHEREFR has been proposed to generate images that are fully equivariant to translation and rotation, we still choose StyleGAN2 as the baseline model of MotionStyleGAN since we find it difficult for StyleGAN3 to achieve equivariance of translation and rotation on the employed video datasets.", "For future work, we plan to use StyleGAN3 for large-resolution human face video datasets like MEAD 1024 2 #OTHEREFR .", "We train the proposed MotionStyleGAN on UCF101 256 2 #OTHEREFR , FaceForensics 256 2 #OTHEREFR , and SkyTimelapse 256 2 #OTHEREFR with gamma (R1 regularization weight, used in StyleGAN models) value of 1 and ADA augmentation method #OTHEREFR .", "The training was done on \u00d74 24 GB NVidia GeForce RTX 3090 GPUs."], "citing_paper_content": {"title": "Motionvideogan: A Novel Video Generator Based On The Motion Space Learned From Image Pairs", "abstract": "Video generation has achieved rapid progress benefiting from high-quality renderings provided by powerful image generators. We regard the video synthesis task as generating a sequence of images sharing the same contents but varying in motions. However, most previous video synthesis frameworks based on pre-trained image generators treat content and motion generation separately, leading to unrealistic generated videos. Therefore, we design a novel framework to build the motion space, aiming to achieve content consistency and fast convergence for video generation. We present MotionVideoGAN, a novel video generator synthesizing videos based on the motion space learned by pre-trained image pair generators. Firstly, we propose an image pair generator named MotionStyleGAN to generate image pairs sharing the same contents and producing various motions. Then we manage to acquire motion codes to edit one image in the generated image pairs and keep the other unchanged. The motion codes help us edit images within the motion space since the edited image shares the same contents with the other unchanged one in image pairs. Finally, we introduce a latent code generator to produce latent code sequences using motion codes for video generation. Our approach achieves state-of-the-art performance on the most complex video dataset ever used for unconditional video generation evaluation, UCF101. The source code is available on https://github.com/bbzhu-jy16/MotionVideoGAN."}, "cited_paper_content": {"title": "Analyzing And Improving The Image Quality Of Stylegan", "abstract": "The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality."}, "keywords": ["image pair generator", "StyleGAN2"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the quality of generated images, recent studies have proposed changes in both model architecture and training methods, such as redesigning the generator normalization, revisiting progressive growing, and regularizing the generator to encourage good conditioning in the mapping from latent codes to images #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the characteristic artifacts of the style-based GAN architecture, the authors propose changes in both model architecture and training methods, including redesigning the generator normalization, revisiting progressive growing, and regularizing the generator to encourage good conditioning in the mapping from latent codes to images, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To generate image pairs with various motions, the authors propose MotionStyleGAN, an #REFR that generates image pairs sharing the same contents and producing various motions.", "given_citation_intent": "method", "given_keywords": ["image pair generator", "StyleGAN2"]}]}
{"citing_id": "2305.01738v1", "cited_id": "1812.02900", "section_title": "Introduction", "citation": "Our contribution complements many popular offline RL methods focused on distribution shift (e.g., BCQ #REFR ) and goes beyond pessimism-only methods by leveraging domain knowledge.", "text_before_citation": ["Lastly, we show that when sub-actions exhibit certain structures (e.g., when two sub-actions \"reinforce\" their independent effects), the linear approximation, though biased, can still lead to the optimal policy.", "We test our approach in offline RL domains using a simulator #OTHEREFR and a real clinical dataset #OTHEREFR , where domain knowledge about the relationship among actions suggests our proposed factorization approach is applicable.", "Empirically, our approach outperforms a non-factored baseline when the sample size is limited, even when the theoretical assumptions (around the validity of a linear decomposition) are not perfectly satisfied.", "Qualitatively, in the real-data experiment, our approach learns policies that better capture the effect of less frequently observed treatment combinations.", "Our work provides both theoretical insights and empirical evidence for RL practitioners to consider this simple linear decomposition for value-based RL approaches."], "text_after_citation": ["Compatible with any algorithm that has a Q-function component, we expect our approach will lead to gains for offline RL problems with combinatorial action spaces where data are limited and when domain knowledge can be used to check the validity of theoretical assumptions."], "citing_paper_content": {"title": "Leveraging Factored Action Spaces For Efficient Offline Reinforcement Learning In Healthcare", "abstract": "Many reinforcement learning (RL) applications have combinatorial action spaces, where each action is a composition of sub-actions. A standard RL approach ignores this inherent factorization structure, resulting in a potential failure to make meaningful inferences about rarely observed sub-action combinations; this is particularly problematic for offline settings, where data may be limited. In this work, we propose a form of linear Q-function decomposition induced by factored action spaces. We study the theoretical properties of our approach, identifying scenarios where it is guaranteed to lead to zero bias when used to approximate the Q-function. Outside the regimes with theoretical guarantees, we show that our approach can still be useful because it leads to better sample efficiency without necessarily sacrificing policy optimality, allowing us to achieve a better bias-variance trade-off. Across several offline RL problems using simulators and real-world datasets motivated by healthcare, we demonstrate that incorporating factored action spaces into valuebased RL can result in better-performing policies. Our approach can help an agent make more accurate inferences within underexplored regions of the state-action space when applying RL to observational datasets."}, "cited_paper_content": {"title": "Off-Policy Deep Reinforcement Learning Without Exploration", "abstract": "Reinforcement learning traditionally considers the task of balancing exploration and exploitation. This work examines batch reinforcement learning--the task of maximally exploiting a given batch of off-policy data, without further data collection. We demonstrate that due to errors introduced by extrapolation, standard off-policy deep reinforcement learning algorithms, such as DQN and DDPG, are only capable of learning with data correlated to their current policy, making them ineffective for most off-policy applications. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space to force the agent towards behaving on-policy with respect to a subset of the given data. We extend this notion to deep reinforcement learning, and to the best of our knowledge, present the first continuous control deep reinforcement learning algorithm which can learn effectively from uncorrelated off-policy data."}, "keywords": ["RL methods", "domain knowledge"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We extend this notion to deep reinforcement learning, and to the best of our knowledge, present the first continuous control deep reinforcement learning algorithm which can learn effectively from uncorrelated off-policy data. This approach could be useful for offline RL problems with limited data, as demonstrated in our experiments with simulators and real-world datasets motivated by healthcare #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of learning from uncorrelated off-policy data, the authors propose a novel class of off-policy algorithms called batch-constrained reinforcement learning, which restricts the action space to force the agent towards behaving on-policy with respect to a subset of the given data, and demonstrate its effectiveness in deep reinforcement learning #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To incorporate domain knowledge into RL methods, recent work has proposed a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space to force the agent towards behaving on-policy with respect to a subset of the given data #REFR.", "given_citation_intent": "method", "given_keywords": ["RL methods", "domain knowledge"]}]}
{"citing_id": "2303.11911v1", "cited_id": "1808.05563", "section_title": "Introduction", "citation": "Data augmentation benefits generalizable, transferable, and robust representation learning by correctly extrapolating the input training space to a larger region #REFR .", "text_before_citation": ["Akin to hand-crafting Figure 1 : InfoTS is composed of three parts: (1) candidate transformation that generates different augmentations of the original inputs, (2) a meta-learner network that selects the optimal augmentations, (3) an encoder that learns representations of time series instances.", "The meta-learner is learned in tandem with contrastive encoder learning.", "features, hand-picking choices of data augmentations are undesirable from the learning perspective.", "The diversity and heterogeneity of real-life time series data further hinder these methods away from wide applicability.", "To address the challenges, we first introduce the criteria for selecting good data augmentations in contrastive learning."], "text_after_citation": ["The positive instances enclose a discriminative zone in which all the data points should be similar to the original instance.", "The desired data augmentations for contrastive representation learning should have both high fidelity and high variety.", "High fidelity encourages the augmented data to maintain the semantic identity that is invariant to transformations #OTHEREFR .", "For example, if the downstream task is classification, then the generated augmentations of inputs should be classpreserving.", "Meanwhile, generating augmented samples with high variety benefits representation learning by increasing the generalization capacity #OTHEREFR ."], "citing_paper_content": {"title": "Time Series Contrastive Learning With Information-Aware Augmentations", "abstract": "Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where \"desired\" augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high fidelity and variety based upon information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with informationaware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to 12.0% reduction in MSE on forecasting tasks and up to 3.7% relative improvement in accuracy on classification tasks over the leading baselines."}, "cited_paper_content": {"title": "Learning Invariances Using The Marginal Likelihood", "abstract": "Generalising well in supervised learning tasks relies on correctly extrapolating the training data to a large region of the input space. One way to achieve this is to constrain the predictions to be invariant to transformations on the input that are known to be irrelevant (e.g. translation). Commonly, this is done through data augmentation, where the training set is enlarged by applying hand-crafted transformations to the inputs. We argue that invariances should instead be incorporated in the model structure, and learned using the marginal likelihood, which correctly rewards the reduced complexity of invariant models. We demonstrate this for Gaussian process models, due to the ease with which their marginal likelihood can be estimated. Our main contribution is a variational inference scheme for Gaussian processes containing invariances described by a sampling procedure. We learn the sampling procedure by back-propagating through it to maximise the marginal likelihood."}, "keywords": ["Data augmentation", "representation learning"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the challenges, we first introduce the criteria for selecting good data augmentations in contrastive learning, as proposed in the reference paper \"#REFR\".", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenges of selecting good data augmentations in contrastive learning for time series data, the authors propose a new approach, InfoTS, that adaptively selects optimal augmentations based on information theory, as well as introducing the criteria for selecting feasible data augmentations. This approach is motivated by the argument made in #REFR that invariances should be incorporated in the model structure and learned using the marginal likelihood.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenges of selecting good data augmentations in contrastive learning for time series representation learning, the authors propose a new approach, InfoTS, that adaptively selects optimal augmentations based on information theory, which is similar to the approach of incorporating invariances in the model structure using the marginal likelihood proposed in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["Data augmentation", "representation learning"]}]}
{"citing_id": "2304.11310v1", "cited_id": "1610.06475", "section_title": "A. Orb-Slam3", "citation": "In addition to its adaptability and high precision, it can compute the camera trajectory and a sparse 3D reconstruction of the world in real-time for a variety of situations, from brief desk-related hand-held sequences to car driving through many city blocks #REFR .", "text_before_citation": ["ORB-SLAM3 is a visual sensor-based SLAM solution designed for Monocular, Binocular, Stereo, and RGB-D cameras #OTHEREFR ."], "text_after_citation": ["The ORB-SLAM3 architecture's foundation is built using ORB-SLAM2 and ORBSLAM-VI #OTHEREFR .", "It is a complete multimap and multi-session system that may operate in either visual-inertial or pure visual modes, that supports both pinhole and fisheye lens models.", "The ORB-SLAM3 pipeline, with its primary system components, is depicted in Figure 2 .", "Over the years, ORB-SLAM3 has proven to be more useful in low-light environments compared to ORB-SLAM2 because it incorporates improvements in several aspects that enhance its ability to operate in challenging lighting conditions.", "Firstly, ORB-SLAM3 includes a new feature descriptor called COdes of Low Light Features (COLLF), which is designed specifi-cally to capture and match features in low-light environments."], "citing_paper_content": {"title": "Twilight Slam: A Comparative Study Of Low-Light Visual Slam Pipelines", "abstract": "This paper presents a comparative study of lowlight visual SLAM pipelines, specifically focusing on determining an efficient combination of the state-of-the-art low-light image enhancement algorithms with standard and contemporary Simultaneous Localization and Mapping (SLAM) frameworks by evaluating their performance in challenging low-light conditions. In this study, we investigate the performance of several different low-light SLAM pipelines for dark and/or poorly-lit datasets as opposed to just partially dim-lit datasets like other works in the literature. Our study takes an experimental approach to qualitatively and quantitatively compare the chosen combinations of modules to enhance the feature-based visual SLAM."}, "cited_paper_content": {"title": "Orb-Slam2: An Open-Source Slam System For Monocular, Stereo And Rgb-D Cameras", "abstract": "We present ORB-SLAM2 a complete SLAM system for monocular, stereo and RGB-D cameras, including map reuse, loop closing and relocalization capabilities. The system works in real-time on standard CPUs in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city. Our back-end based on bundle adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization. The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate SLAM solution. We publish the source code, not only for the benefit of the SLAM community, but with the aim of being an out-of-the-box SLAM solution for researchers in other fields."}, "keywords": ["sparse 3D reconstruction", "camera trajectory"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "ORB-SLAM2, an open-source SLAM system for monocular, stereo, and RGB-D cameras, has been widely used in various environments and has achieved state-of-the-art accuracy in most cases #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "ORB-SLAM2, an open-source SLAM system for monocular, stereo, and RGB-D cameras, has been widely used in various environments, including drones flying in industrial environments and cars driving around a city, due to its real-time performance and accurate trajectory estimation with metric scale #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "ORB-SLAM2, an open-source SLAM system for monocular, stereo, and RGB-D cameras, provides accurate camera trajectory and sparse 3D reconstruction, making it a relevant background reference for visual sensor-based SLAM solutions such as ORB-SLAM3 #REFR.", "given_citation_intent": "background", "given_keywords": ["sparse 3D reconstruction", "camera trajectory"]}]}
{"citing_id": "2304.13000v1", "cited_id": "1505.04597", "section_title": "Baseline Task-Specific Models", "citation": "Specifically, we compare SAM to a U-Net model #REFR that has been highly optimized for the benchmark in a prior study.", "text_before_citation": ["For a given benchmark problem we also report the segmentation accuracy of two \"task specific models\"; these models are been trained with full supervision on that benchmark."], "text_after_citation": ["We refer to this as \"UNet-Opt\" and it approximates the state-ofthe-art performance that can be achieved on that benchmark, given substantial investment.", "For the Unet-Opt model we report the results reported in a prior study involving the particular benchmark under consideration.", "We also compare SAM with a conventional Unet model that we have trained here, reflecting the accuracy achievable without substantial investment, but assuming the availability of (often substantial) labeled training data. We refer this model as \"UNet\"."], "citing_paper_content": {"title": "Segment Anything, From Space?", "abstract": "Recently, the first foundation model developed specifically for vision tasks was developed, termed the \"Segment Anything Model\" (SAM). SAM can segment objects in input imagery based upon cheap input prompts, such as one (or more) points, a bounding box, or a mask. The authors examined the zero-shot image segmentation accuracy of SAM on a large number of vision benchmark tasks and found that SAM usually achieved recognition accuracy similar to, or sometimes exceeding, vision models that had been trained on the target tasks. The impressive generalization of SAM for segmentation has major implications for vision researchers working on natural imagery. In this work, we examine whether SAM's impressive performance extends to overhead imagery problems, and help guide the community's response to its development. We examine SAM's performance on a set of diverse and widely-studied benchmark tasks. We find that SAM does often generalize well to overhead imagery, although it fails in some cases due to the unique characteristics of overhead imagery and the target objects. We report on these unique systematic failure cases for remote sensing imagery that may comprise useful future research for the community. Note that this is a working paper, and it will be updated as additional analysis and results are completed."}, "cited_paper_content": {"title": "U-Net: Convolutional Networks For Biomedical Image Segmentation", "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net ."}, "keywords": ["U-Net model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For a given benchmark problem we also report the segmentation accuracy of two \"task specific models\"; these models are been trained with full supervision on that benchmark, and we compare their performance with the method proposed in U-Net: Convolutional Networks For Biomedical Image Segmentation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compared the segmentation accuracy of our task-specific models with a network trained end-to-end from very few images using data augmentation and outperforming the prior best method on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks, as presented in U-Net: Convolutional Networks For Biomedical Image Segmentation #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We also compare the segmentation accuracy of two \"task specific models\" that have been trained with full supervision on that benchmark, with the method proposed by Ronneberger et al. using the U-Net model#REFR.", "given_citation_intent": "method", "given_keywords": ["U-Net model"]}]}
{"citing_id": "2303.16953v1", "cited_id": "1611.07004", "section_title": "Pix2Pix Neural Network.", "citation": "The pix2pix structure belongs to the family of conditional generative adversarial networks (cGANs), comprising a discriminator network D and a generator network G, which cooperate in order to generate realistic reconstructions #REFR .", "text_before_citation": ["As an alternative to the U-Net model, we also evaluated the pix2pix neural network architecture."], "text_after_citation": ["In our experiments, the generator network maps an input image, X i \u2208 R n\u00d7n , derived from the first stage, to an associated reconstruction, G(X i ) \u2208 R n\u00d7n .", "On the other hand, the discriminator network takes in a pair of images, (X, Y ) \u2208 R n\u00d7n \u00d7 R n\u00d7n , as input and produces a scalar-valued output ranging between 0 and 1.", "The two networks are jointly trained in a competitive manner, wherein the generator network endeavors to generate images G(X i ) that resemble the target images Y i , while the discriminator network attempts to differentiate between real image pairs (X i , Y i ) and generated image pairs (X i , G(X i )), with the output indicating the probability that an input image pair is real (i.e., it originates from the training dataset) or generated (i.e., it was produced by the generator network). The training process is illustrated in Figure 3 .", "The pix2pix algorithm utilizes a loss function consisting of two distinct components.", "The first component, denoted as the adversarial loss, is expressed in terms of a binary cross-entropy loss, and is represented as follows:"], "citing_paper_content": {"title": "A Data-Assisted Two-Stage Method For The Inverse Random Source Problem", "abstract": "We propose a data-assisted two-stage method for solving an inverse random source problem of the Helmholtz equation. In the first stage, the regularized Kaczmarz method is employed to generate initial approximations of the mean and variance based on the mild solution of the stochastic Helmholtz equation. A dataset is then obtained by sampling the approximate and corresponding true profiles from a certain a-priori criterion. The second stage is formulated as an image-to-image translation problem, and several data-assisted approaches are utilized to handle the dataset and obtain enhanced reconstructions. Numerical experiments demonstrate that the data-assisted two-stage method provides satisfactory reconstruction for both homogeneous and inhomogeneous media with fewer realizations."}, "cited_paper_content": {"title": "Image-To-Image Translation With Conditional Adversarial Networks", "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either."}, "keywords": ["realistic reconstructions", "conditional generative adversarial"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As an alternative to the U-Net model, we also evaluated the pix2pix neural network architecture, which has been shown to be effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "As an alternative to the U-Net model, we also evaluated the pix2pix neural network architecture, which has been shown to be effective at synthesizing photos from label maps and reconstructing objects from edge maps, among other tasks #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "As an alternative to the U-Net model, we also evaluated the pix2pix neural network architecture, which has been shown to be effective at synthesizing realistic reconstructions from label maps using conditional generative adversarial networks #REFR.", "given_citation_intent": "background", "given_keywords": ["realistic reconstructions", "conditional generative adversarial"]}]}
{"citing_id": "2303.11858v1", "cited_id": "1806.01445", "section_title": "Logical Operators", "citation": "Existing query embedding methods (Zhang et al., 2021; Ren et al., 2020; #REFR ; Ren and Leskovec, 2020) apply multi-layer perceptron networks to accomplish this task.", "text_before_citation": ["As illustrated in Figure 1 , each logical query can be represented as a directed acyclic graph (DAG) tree, where the tree nodes correspond to constants/anchor node entities or variables, and the edges correspond to atom relations or logical operations in a query.", "Logical operations are performed along the DAG tree from constants to the target answer variable. Figure 3 visualizes these operations on 2D complex space. The logical operators can be defined as follows", "Relational rotating projection Given a set of entities S \u2282 E and a relation r \u2208 R, the projection operator selects the neighbouring entities S \u2282 E by relation such that S = {e \u2208 S, e \u2208 S : r(e, e ) = T rue}."], "text_after_citation": ["They do not accommodate the learning of potential KG relational patterns which might help in reasoning logical queries.", "Motivated by RotatE (Sun et al., 2019) , we represent each relation r as a counterclockwise relational rotation on query embeddings about the origin of the complex plane such that r = (r U , r L ), where |r {U,L} | = 1, and r U , r L \u2208 C d .", "Given the query embedding q = (h U , h L ) and a relation r, the selected query", "EQUATION", "where \u2022 is the Hadmard (element-wise) product, and \u03b8 \u03b8 \u03b8 ax,r , \u03b8 \u03b8 \u03b8 ap,r correspond to the equivalent relational rotation on \u03b8 \u03b8 \u03b8 ax , \u03b8 \u03b8 \u03b8 ap ."], "citing_paper_content": {"title": "Modeling Relational Patterns For Logical Query Answering Over Knowledge Graphs", "abstract": "Answering first-order logical (FOL) queries over knowledge graphs (KG) remains a challenging task mainly due to KG incompleteness. Query embedding approaches this problem by computing the low-dimensional vector representations of entities, relations, and logical queries. KGs exhibit relational patterns such as symmetry and composition and modeling the patterns can further enhance the performance of query embedding models. However, the role of such patterns in answering FOL queries by query embedding models has not been yet studied in the literature. In this paper, we fill in this research gap and empower FOL queries reasoning with pattern inference by introducing an inductive bias that allows for learning relation patterns. To this end, we develop a novel query embedding method, RoConE, that defines query regions as geometric cones and algebraic query operators by rotations in complex space. RoConE combines the advantages of Cone as a wellspecified geometric representation for query embedding, and also the rotation operator as a powerful algebraic operation for pattern inference. Our experimental results on several benchmark datasets confirm the advantage of relational patterns for enhancing logical query answering task."}, "cited_paper_content": {"title": "Embedding Logical Queries On Knowledge Graphs", "abstract": "Learning low-dimensional embeddings of knowledge graphs is a powerful approach used to predict unobserved or missing edges between entities. However, an open challenge in this area is developing techniques that can go beyond simple edge prediction and handle more complex logical queries, which might involve multiple unobserved edges, entities, and variables. For instance, given an incomplete biological knowledge graph, we might want to predict\"em what drugs are likely to target proteins involved with both diseases X and Y?\"-- a query that requires reasoning about all possible proteins that {\\em might} interact with diseases X and Y. Here we introduce a framework to efficiently make predictions about conjunctive logical queries -- a flexible but tractable subset of first-order logic -- on incomplete knowledge graphs. In our approach, we embed graph nodes in a low-dimensional space and represent logical operators as learned geometric operations (e.g., translation, rotation) in this embedding space. By performing logical operations within a low-dimensional embedding space, our approach achieves a time complexity that is linear in the number of query variables, compared to the exponential complexity required by a naive enumeration-based approach. We demonstrate the utility of this framework in two application studies on real-world datasets with millions of relations: predicting logical relationships in a network of drug-gene-disease interactions and in a graph-based representation of social interactions derived from a popular web forum."}, "keywords": ["multi-layer perceptron networks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To efficiently make predictions about conjunctive logical queries on incomplete knowledge graphs, the authors of this paper introduced a framework that embeds graph nodes in a low-dimensional space and represents logical operators as learned geometric operations, achieving a time complexity that is linear in the number of query variables. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently make predictions about conjunctive logical queries on incomplete knowledge graphs, the authors of this manuscript propose a framework that embeds graph nodes in a low-dimensional space and represents logical operators as learned geometric operations, as introduced in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "RoConE, the query embedding method proposed in this paper, defines query regions as geometric cones and algebraic query operators by rotations in complex space, which allows for pattern inference and enhances the performance of logical query answering over knowledge graphs. The method achieves this by performing logical operations within a low-dimensional embedding space, which has a time complexity that is linear in the number of query variables, compared to the exponential complexity required by a naive enumeration-based approach. #REFR", "given_citation_intent": "method", "given_keywords": ["multi-layer perceptron networks"]}]}
{"citing_id": "2303.04449v1", "cited_id": "1901.08573", "section_title": "Generalization On Parameter Space", "citation": "It should be noted that adversarial training #REFR is different from our method because the perturbation for the worst case is conducted on the input space, not on the parameter space.", "text_before_citation": ["Sharpness-Aware Minimization (SAM) (Foret et al., 2020) is an optimizer for the model parameter, which regularizes the locality region of \u03b8 to be the flat minima on the loss curvature as follows:", "EQUATION", "Here, is the perturbation vector to the parameter; and \u03c1 denotes the maximum size of the perturbation vector.", "As the objective is a function defined by both input and model parameter, it is possible to solve the generalization of a model parameter through the optimization of input data.", "However, there is no such study, which improves the generalization of the perturbed parameter space via optimizing the input data variable, to the best of our knowledge."], "text_after_citation": [], "citing_paper_content": {"title": "Loss-Curvature Matching For Dataset Selection And Condensation", "abstract": "Training neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines."}, "cited_paper_content": {"title": "Theoretically Principled Trade-Off Between Robustness And Accuracy", "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of ~2,000 submissions, surpassing the runner-up approach by $11.41\\%$ in terms of mean $\\ell_2$ perturbation distance."}, "keywords": ["adversarial training"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors introduce a new reduction objective, LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point, and induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching (Foret et al., 2019).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the trade-off between adversarial robustness and accuracy, the authors propose a new defense method called TRADES, which is inspired by the theoretical analysis presented in #REFR (Zhang et al., 2019).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the adversarial robustness of the model, the authors can consider using the TRADES method proposed in the reference paper, which trades off robustness against accuracy by adding a regularization term to the loss function #REFR.", "given_citation_intent": "method", "given_keywords": ["adversarial training"]}]}
{"citing_id": "2304.11907v1", "cited_id": "1711.07971", "section_title": "Results And Discussion", "citation": "It changes the global average pooling layer into an attention pooling mechanism, where a \"QKV\" attention is implemented #REFR .", "text_before_citation": ["For our reported results, we take accuracy as the metric and count results on the 30-second segment level.", "Besides, we take ResNet #OTHEREFR with multi-head attention as the backbone according to our preliminary experiment."], "text_after_citation": ["Table 1 presents the results of our experiments on data pruning and regularization strategies based on three acoustic features on the Shipsear and Deepship datasets.", "First, we observe that adaptive data pruning can consistently improve performance for various acoustic features and datasets.", "These results further demonstrate the importance of addressing the double-descent issue.", "We also find that data pruning works particularly well on low-resource Shipsear, which can bring up to a 6.03% performance improvement.", "This is because the scarcity of data causes the model to be more likely to memorize repeated data and fall into local bias."], "citing_paper_content": {"title": "Advancing Underwater Acoustic Target Recognition Via Adaptive Data Pruning And Smoothness-Inducing Regularization", "abstract": "Underwater acoustic recognition for ship-radiated signals has high practical application value due to the ability to recognize non-line-of-sight targets. However, due to the difficulty of data acquisition, the collected signals are scarce in quantity and mainly composed of mechanical periodic noise. According to the experiments, we observe that the repeatability of periodic signals leads to a double-descent phenomenon, which indicates a significant local bias toward repeated samples. To address this issue, we propose a strategy based on cross-entropy to prune excessively similar segments in training data. Furthermore, to compensate for the reduction of training data, we generate noisy samples and apply smoothness-inducing regularization based on KL divergence to mitigate overfitting. Experiments show that our proposed data pruning and regularization strategy can bring stable benefits and our framework significantly outperforms the state-of-the-art in low-resource scenarios."}, "cited_paper_content": {"title": "Non-Local Neural Networks", "abstract": "Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our non-local models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code is available at this https URL ."}, "keywords": ["global average pooling"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For our reported results, we take accuracy as the metric and count results on the 30-second segment level. Besides, we take ResNet #OTHEREFR with multi-head attention as the backbone according to our preliminary experiment. Inspired by the classical non-local means method in computer vision, non-local operations can capture long-range dependencies and improve object detection/segmentation and pose estimation on the COCO suite of tasks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture long-range dependencies in computer vision, non-local operations have been proposed as a generic family of building blocks, which can be plugged into many architectures #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture long-range dependencies in computer vision, non-local operations have been proposed as a generic family of building blocks, which can be plugged into many architectures, and have shown promising results on various tasks such as object detection and segmentation on the COCO suite of tasks #REFR.", "given_citation_intent": "background", "given_keywords": ["global average pooling"]}]}
{"citing_id": "2305.00314v1", "cited_id": "1907.01341", "section_title": "Iv. Sensor Calibration", "citation": "After that, an automatic background cropping (based on monocular depth estimation #REFR ) is employed to remove the background objects.", "text_before_citation": ["Our automatic calibration of infrastructure LiDARs and cameras, which outputs the precise pose of these sensors, is the most fundamental part of the framework.", "In order to calibrate the sensors in the real world, we propose an automatic target-less LiDAR-camera calibration model.", "We use the calibration method proposed in #OTHEREFR as a baseline and extend it to outdoor scenes captured by infrastructure roadside sensors of a different manufacturer.", "To improve the robustness of the model under different external conditions, such as different scene complexities, lighting conditions, or sensor conditions, we introduce various automatic preprocessing submodules (see Figure 3 ).", "First, we undistort the input images."], "text_after_citation": ["If there is shadow on the ground, the automatic shadow filtering module will be activated to filter the shadow.", "After the preprocessing, the Canny edge detector #OTHEREFR is adopted to extract 2D edges Fig. 3 : Automatic calibration pipeline.", "We integrate four camera image and seven LiDAR point cloud preprocessing modules into our pipeline in order to increase the robustness of real-world outdoor calibration of roadside sensors.", "The algorithm takes the image and point cloud that is published continuously on the live system as input and outputs both, the calibration results and qualitative projections of point clouds into camera images.", "in images."], "citing_paper_content": {"title": "Infradet3D: Multi-Modal 3D Object Detection Based On Roadside Infrastructure Camera And Lidar Sensors", "abstract": "Current multi-modal object detection approaches focus on the vehicle domain and are limited in the perception range and the processing capabilities. Roadside sensor units (RSUs) introduce a new domain for perception systems and leverage altitude to observe traffic. Cameras and LiDARs mounted on gantry bridges increase the perception range and produce a full digital twin of the traffic. In this work, we introduce InfraDet3D, a multi-modal 3D object detector for roadside infrastructure sensors. We fuse two LiDARs using early fusion and further incorporate detections from monocular cameras to increase the robustness and to detect small objects. Our monocular 3D detection module uses HD maps to ground object yaw hypotheses, improving the final perception results. The perception framework is deployed on a real-world intersection that is part of the A9 Test Stretch in Munich, Germany. We perform several ablation studies and experiments and show that fusing two LiDARs with two cameras leads to an improvement of +1.90 mAP compared to a camera-only solution. We evaluate our results on the A9 infrastructure dataset and achieve 68.48 mAP on the test set. The dataset and code will be available at https://a9-dataset.com to allow the research community to further improve the perception results and make autonomous driving safer."}, "cited_paper_content": {"title": "Towards Robust Monocular Depth Estimation: Mixing Datasets For Zero-Shot Cross-Dataset Transfer", "abstract": "The success of monocular depth estimation relies on large and diverse training sets. Due to the challenges associated with acquiring dense ground-truth depth across different environments at scale, a number of datasets with distinct characteristics and biases have emerged. We develop tools that enable mixing multiple datasets during training, even if their annotations are incompatible. In particular, we propose a training objective that is invariant to changes in depth range and scale. Armed with this objective, we explore an abundant source of training data: 3D films. We demonstrate that despite pervasive inaccuracies, 3D films constitute a useful source of data that is complementary to existing training sets. We evaluate the presented approach on diverse datasets, focusing on zero-shot cross-dataset transfer: testing the generality of the learned model by evaluating it on datasets that were not seen during training. The experiments confirm that mixing data from complementary sources yields improved depth estimates, particularly on previously unseen datasets. Some results are shown in the supplementary video: this https URL"}, "keywords": ["monocular depth estimation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the robustness of the model under different external conditions, we introduce various automatic preprocessing submodules (see Figure 3). First, we undistort the input images. We use the calibration method proposed in the reference paper #REFR as a baseline and extend it to outdoor scenes captured by infrastructure roadside sensors of a different manufacturer.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the robustness of our automatic target-less LiDAR-camera calibration model, we introduce various automatic preprocessing submodules, including the training objective proposed in #REFR that is invariant to changes in depth range and scale.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the robustness of our automatic target-less LiDAR-camera calibration model for outdoor scenes captured by infrastructure roadside sensors, we propose using the training objective that is invariant to changes in depth range and scale from #REFR, which enables mixing multiple datasets during training, even if their annotations are incompatible, and yields improved depth estimates, particularly on previously unseen datasets.", "given_citation_intent": "method", "given_keywords": ["monocular depth estimation"]}]}
{"citing_id": "2303.11219v1", "cited_id": "1805.03482", "section_title": "Experimental Setup", "citation": "Following the prior work #REFR , the IOR (index of refraction) of air is set to 1.0003 and the IOR of transparent material (glass) is set to 1.4723.", "text_before_citation": ["A hierarchical sampling strategy is used to sample points along a ray in a coarse-to-fine manner for volume render-Li et al. #OTHEREFR DRT #OTHEREFR Ours ing.", "We first uniformly sample 64 points along the ray, and then iteratively conduct importance sampling #OTHEREFR to sample more points on top of coarse probability estimation for 4 times.", "The positional encoding is applied to the spatial location with 5 frequencies.", "The hyper-parameters used in the experiments are set as \u03c9 1 = 0.0001, \u03c9 2 = 0.1, \u03c9 3 = 0.1.", "Acc \u2193 Comp \u2193 Acc \u2193 Comp \u2193 Acc \u2193 Comp \u2193"], "text_after_citation": [], "citing_paper_content": {"title": "Neto:Neural Reconstruction Of Transparent Objects With Self-Occlusion Aware Refraction-Tracing", "abstract": "We present a novel method, called NeTO, for capturing 3D geometry of solid transparent objects from 2D images via volume rendering. Reconstructing transparent objects is a very challenging task, which is ill-suited for generalpurpose reconstruction techniques due to the specular light transport phenomena. Although existing refraction-tracing based methods, designed specially for this task, achieve impressive results, they still suffer from unstable optimization and loss of fine details, since the explicit surface representation they adopted is difficult to be optimized, and the self-occlusion problem is ignored for refraction-tracing. In this paper, we propose to leverage implicit Signed Distance Function (SDF) as surface representation, and optimize the SDF field via volume rendering with a self-occlusion aware refractive ray tracing. The implicit representation enables our method to be capable of reconstructing high-quality reconstruction even with a limited set of images, and the selfocclusion aware strategy makes it possible for our method to accurately reconstruct the self-occluded regions. Experiments show that our method achieves faithful reconstruction results and outperforms prior works by a large margin. Visit our project page at https://www.xxlong. site/NeTO/."}, "cited_paper_content": {"title": "Full 3D Reconstruction Of Transparent Objects", "abstract": "This paper presents a fully automatic approach for reconstructing complete 3D shapes of transparent objects."}, "keywords": ["refraction", "transparent material"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "A hierarchical sampling strategy is used to sample points along a ray in a coarse-to-fine manner for volume rendering (Li et al. #REFR). We first uniformly sample 64 points along the ray, and then iteratively conduct importance sampling to sample more points on top of coarse probability estimation for 4 times. The positional encoding is applied to the spatial location with 5 frequencies. The hyper-parameters used in the experiments are set as \u03c9 1 = 0.0001, \u03c9 2 = 0.1, \u03c9 3 = 0.1. Acc \u2193 Comp \u2193 Acc \u2193 Comp \u2193 Acc \u2193 Comp \u2193.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To accurately reconstruct the self-occluded regions, the authors propose to leverage implicit Signed Distance Function (SDF) as surface representation and optimize the SDF field via volume rendering with a self-occlusion aware refractive ray tracing #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To accurately reconstruct the self-occluded regions of transparent objects, we propose to leverage implicit Signed Distance Function (SDF) as surface representation and optimize the SDF field via volume rendering with a self-occlusion aware refractive ray tracing #REFR, as presented in the reference paper \"Full 3D Reconstruction Of Transparent Objects\".", "given_citation_intent": "method", "given_keywords": ["refraction", "transparent material"]}]}
{"citing_id": "2304.04058v1", "cited_id": "2002.08953", "section_title": "Learning Mixed States.", "citation": "Compared to the NNQS results reported in #REFR , we see that the IS method with the symmetric function ansatz is able to better predict the overlap of the above state with the |GHZ n + .", "text_before_citation": ["In an experiment involving symmetric states, first studied in #OTHEREFR , the fidelity of |GHZ n + is estimated with respect to another mixed state of the form, \u03c1 n,p = (1 \u2212 p) |GHZ n + GHZ n", "+ | + p |GHZ n \u2212 GHZ n \u2212 | for p \u2208 [0, 1]", ".", "It was been reported that for this mixed state example, generative models learned using the Neural Net Quantum States (NNQS) ansatz [7, #OTHEREFR struggled to find the correct fidelity as p got closer to 1.", "The results of applying our method on this problem with a symmetric function ansatz are given in Fig. 4d ."], "text_after_citation": [], "citing_paper_content": {"title": "Learning Energy Based Representations Of Quantum Many-Body States", "abstract": "Efficient representation of quantum many-body states on classical computers is a problem of enormous practical interest. An ideal representation of a quantum state combines a succinct characterization informed by the system's structure and symmetries, along with the ability to predict the physical observables of interest. A number of machine learning approaches have been recently used to construct such classical representations [1-6] which enable predictions of observables [7] and accounts for physical symmetries [8]. However, the structure of a quantum state gets typically lost unless a specialized ansatz is employed based on prior knowledge of the system [9-12]. Moreover, most such approaches give no information about what states are easier to learn in comparison to others. Here, we propose a new generative energy-based representation of quantum many-body states derived from Gibbs distributions used for modeling the thermal states of classical spin systems. Based on the prior information on a family of quantum states, the energy function can be specified by a small number of parameters using an explicit low-degree polynomial or a generic parametric family such as neural nets, and can naturally include the known symmetries of the system. Our results show that such a representation can be efficiently learned from data using exact algorithms in a form that enables the prediction of expectation values of physical observables. Importantly, the structure of the learned energy function provides a natural explanation for the hardness of learning for a given class of quantum states."}, "cited_paper_content": {"title": "Predicting Many Properties Of A Quantum System From Very Few Measurements", "abstract": "Predicting properties of complex, large-scale quantum systems is essential for developing quantum technologies. We present an efficient method for constructing an approximate classical description of a quantum state using very few measurements of the state. This description, called a classical shadow, can be used to predict many different properties: order $\\log M$ measurements suffice to accurately predict $M$ different functions of the state with high success probability. The number of measurements is independent of the system size, and saturates information-theoretic lower bounds. Moreover, target properties to predict can be selected after the measurements are completed. We support our theoretical findings with extensive numerical experiments. We apply classical shadows to predict quantum fidelities, entanglement entropies, two-point correlation functions, expectation values of local observables, and the energy variance of many-body local Hamiltonians, which allows applications to speedup variational quantum algorithms. The numerical results highlight the advantages of classical shadows relative to previously known methods."}, "keywords": ["state"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In an experiment involving symmetric states, first studied in #OTHEREFR, the authors struggled to find the correct fidelity using the Neural Net Quantum States (NNQS) ansatz. However, the proposed classical shadow method from the reference paper can efficiently predict expectation values of physical observables for quantum states with a generative energy-based representation, which may provide a potential solution to this problem.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The generative models learned using the Neural Net Quantum States (NNQS) ansatz struggled to find the correct fidelity as p got closer to 1, as reported in a previous study on symmetric states #OTHEREFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The generative energy-based representation of quantum many-body states proposed in this manuscript enables the prediction of expectation values of physical observables, which is a significant improvement over the previously known methods that struggled to find the correct fidelity of symmetric states as reported in #OTHEREFR.", "given_citation_intent": "result", "given_keywords": ["state"]}]}
{"citing_id": "2304.01489v1", "cited_id": "2002.05709", "section_title": "Ablation Study", "citation": "However, a more complicated head will not further improve the performance, which is consistent with the observation in #REFR .", "text_before_citation": ["Now we will demonstrate the effect of different components in TeS by ablation study. Experiments are conducted with ResNet-50 on CIFAR-100.", "#Layer in Projection h h contains multi-layer MLP to align vision representations with text classifier.", "We vary the number of layers and summarize the results in Table 7 .", "When h has 1-layer MLP, it degenerates to a linear projection.", "If increasing the number of layers to 2, the nonlinear mapping helps improve the performance by 0.36%."], "text_after_citation": ["Compared to ResNet-50, the computational overhead introduced by the 2-layer MLP is negligible, which keeps the efficiency of the proposed method.", "Weight of Text Regularization \u03bb T \u03bb T in Eqn.", "7 weights the loss for projecting the vision representation to the text space spanned by the text classifier.", "We vary it in {0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5} and Table 8 When \u03bb T is small, the projection head cannot be learned sufficiently and results in an inaccurate estimation for the reference distribution.", "By increasing \u03bb T , the projection head can approximate the text space effectively and a satisfied performance is obtained."], "citing_paper_content": {"title": "Improved Visual Fine-Tuning With Natural Language Supervision", "abstract": "Fine-tuning a pre-trained model can leverage the semantic information from large-scale pre-training data and mitigate the over-fitting problem on downstream tasks with limited training examples. While the problem of catastrophic forgetting in backbone has been extensively studied, the potential bias existing in a pre-trained model due to the corresponding pre-training task and data, attracts less attention. In this work, we investigate this problem by demonstrating that the obtained classifier after fine-tuning will be close to that induced by the pre-trained model. To reduce the bias in the classifier effectively, we introduce a reference distribution obtained from a fixed text classifier, which can help regularize the learned vision classifier. The proposed method, Text Supervised fine-tuning (TeS), is evaluated with diverse pre-trained vision models including ResNet and ViT, and text encoders including BERT and CLIP, on 11 downstream tasks. The consistent improvement with a clear margin over distinct scenarios confirms the effectiveness of our proposal."}, "cited_paper_content": {"title": "A Simple Framework For Contrastive Learning Of Visual Representations", "abstract": "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels."}, "keywords": ["complicated head", "observation"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Increasing the number of layers in the nonlinear mapping of the multi-layer MLP to align vision representations with the text classifier improved the performance by 0.36% (SimCLR #REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method in this work achieves state-of-the-art performance on downstream tasks, outperforming previous methods by a clear margin, as shown in Table 7. #REFR is cited as the previous state-of-the-art method that our proposed method outperforms.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the observation made in the reference paper #REFR, introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, which is consistent with our finding that the nonlinear mapping in the complicated head helps improve the performance by 0.36%.", "given_citation_intent": "result", "given_keywords": ["complicated head", "observation"]}]}
{"citing_id": "2303.17216v1", "cited_id": "1505.04597", "section_title": "Geometry-Aware Image Reconstruction", "citation": "The edge map is concatenated with the masked image and fed into a UNet #REFR to reconstruct the original image.", "text_before_citation": ["We assign a learnable weight \u03b1 to edges, which is enforced to be positive by SoftPlus #OTHEREFR .", "This weight is learned during training and shared across all edges and all object instances in a dataset.", "Finally, we take the maximum at each pixel of the heatmaps to obtain the edge map S \u2208 R H\u00d7W ,", "EQUATION", "Taking the maximum at each pixel avoids the entanglement of the uncertainty and the convolution kernel weights #OTHEREFR ."], "text_after_citation": ["We minimize the L 1 loss and ViT perceptual loss #OTHEREFR between the reconstructed images I \u2032 and the original images I,", "EQUATION", "where \u0393 is the feature extractor."], "citing_paper_content": {"title": "Few-Shot Geometry-Aware Keypoint Localization", "abstract": "Supervised keypoint localization methods rely on large manually labeled image datasets, where objects can deform, articulate, or occlude. However, creating such large keypoint labels is time-consuming and costly, and is often error-prone due to inconsistent labeling. Thus, we desire an approach that can learn keypoint localization with fewer yet consistently annotated images. To this end, we present a novel formulation that learns to localize semantically consistent keypoint definitions, even for occluded regions, for varying object categories. We use a few user-labeled 2D images as input examples, which are extended via self-supervision using a larger unlabeled dataset. Unlike unsupervised methods, the few-shot images act as semantic shape constraints for object localization. Furthermore, we introduce 3D geometryaware constraints to uplift keypoints, achieving more accurate 2D localization. Our general-purpose formulation paves the way for semantically conditioned generative modeling and attains competitive or state-of-the-art accuracy on several datasets, including human faces, eyes, animals, cars, and never-before-seen mouth interior (teeth) localization tasks, not attempted by the previous few-shot methods."}, "cited_paper_content": {"title": "U-Net: Convolutional Networks For Biomedical Image Segmentation", "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net ."}, "keywords": ["edge map"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors use a contracting and symmetric expanding path network architecture for precise localization, which can be trained end-to-end from very few images and outperforms the prior best method on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain the edge map, the authors used a contracting path to capture context and a symmetric expanding path that enables precise localization, as proposed in U-Net: Convolutional Networks For Biomedical Image Segmentation #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain the edge map, the authors took the maximum at each pixel of the heatmaps #REFR, which is a technique used in U-Net: Convolutional Networks For Biomedical Image Segmentation.", "given_citation_intent": "method", "given_keywords": ["edge map"]}]}
{"citing_id": "2303.13588v1", "cited_id": "1811.01057", "section_title": "Sdp Relaxation.", "citation": "However, they only studied LP relaxation methods and were unable to include the SDP certification method #REFR .", "text_before_citation": ["Nevertheless, the SDPs are general enough, and this is straightforward from our framework.", "Similarly, we implemented a tool for \u2113 2 -robustness certification, which is natural from our framework.", "However, even though it has been a while since the SDP for \u2113 \u221e -robustness certification was proposed #OTHEREFR , we are unaware of any existing SDP tools to certify \u2113 2 -robustness.", "The \u2113 2 -robustness certification is an active topic #OTHEREFR .", "[55] tried to unify efficient robustness certification works, which the authors claimed is a convex relaxation barrier."], "text_after_citation": ["As we have discussed, SDP is strictly more powerful than LP.", "Our framework can be viewed as complementing #OTHEREFR towards a tighter convex relaxation barrier."], "citing_paper_content": {"title": "Efficient Symbolic Reasoning For Neural-Network Verification", "abstract": "The neural network has become an integral part of modern software systems. However, they still suffer from various problems, in particular, vulnerability to adversarial attacks. In this work, we present a novel program reasoning framework for neural-network verification, which we refer to as symbolic reasoning. The key components of our framework are the use of the symbolic domain and the quadratic relation. The symbolic domain has very flexible semantics, and the quadratic relation is quite expressive. They allow us to encode many verification problems for neural networks as quadratic programs. Our scheme then relaxes the quadratic programs to semidefinite programs, which can be efficiently solved. This framework allows us to verify various neural-network properties under different scenarios, especially those that appear challenging for non-symbolic domains. Moreover, it introduces new representations and perspectives for the verification tasks. We believe that our framework can bring new theoretical insights and practical tools to verification problems for neural networks."}, "cited_paper_content": {"title": "Semidefinite Relaxations For Certifying Robustness To Adversarial Examples", "abstract": "Despite their impressive performance on diverse tasks, neural networks fail catastrophically in the presence of adversarial inputs---imperceptibly but adversarially perturbed versions of natural inputs. We have witnessed an arms race between defenders who attempt to train robust networks and attackers who try to construct adversarial examples. One promise of ending the arms race is developing certified defenses, ones which are provably robust against all attackers in some family. These certified defenses are based on convex relaxations which construct an upper bound on the worst case loss over all attackers in the family. Previous relaxations are loose on networks that are not trained against the respective relaxation. In this paper, we propose a new semidefinite relaxation for certifying robustness that applies to arbitrary ReLU networks. We show that our proposed relaxation is tighter than previous relaxations and produces meaningful robustness guarantees on three different \"foreign networks\" whose training objectives are agnostic to our proposed relaxation."}, "keywords": ["SDP certification method", "LP relaxation methods"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors claimed that unifying efficient robustness certification works is a convex relaxation barrier, an active topic #OTHEREFR. However, we are unaware of any existing SDP tools to certify \u2113 2 -robustness, even though it has been a while since the SDP for \u2113 \u221e -robustness certification was proposed #OTHEREFR. To address this issue, the proposed semidefinite relaxation for certifying robustness to adversarial examples in #REFR can be applied to arbitrary ReLU networks and produces meaningful robustness guarantees.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To certify \u21132-robustness, recent works have proposed various convex relaxations, but none of them have been implemented as an SDP tool yet #REFR, making the proposed semidefinite relaxation for certifying robustness a promising method to explore.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed SDP certification method in #REFR provides a tighter relaxation than previous LP relaxation methods, making it a promising approach for certifying \u21132-robustness.", "given_citation_intent": "method", "given_keywords": ["SDP certification method", "LP relaxation methods"]}]}
{"citing_id": "2304.03505v1", "cited_id": "1904.06457", "section_title": "A. Methodology", "citation": "To emulate a variety of scenes, we randomly select video clips from YouTube UGC video dataset #REFR , including gaming, television, animation, etc., to form a 1-minute long video, and then repetitively render it during a live RTVC session spanning about 10 minutes.", "text_before_citation": ["For real-world tests in the wild, we rent a commercial cloud server from a leading Internet service vendor, and set the server-to-receiver down-link with 4G, 5G, or WiFi accesses in various environment (walking, bus/subway riding, caf\u00e9, etc.), for simulating a variety of real-world scenarios.", "Note that sender and receiver clients are deployed in different cities worldwide.", "As discussed in the measurement study in Sec.", "III-A, we play pre-cached video files to simplify the simulations.", "The sender encodes live scenes in real-time, and then transmits the video stream to the receiver client."], "text_after_citation": ["To best mimic the real RTVC applications in the large-scale Internet, we configure to encode this long video at a relative low resolution (i.e., 720P) to guarantee both the video quality and the playback fluency.", "At the receiver client, we collect the RTT, packet loss rate measured by the WebRTC internals #OTHEREFR and proactively measure the stalling rate along with the video consumption. Fig. 5 .", "Echo is a real-time video conferencing testbed that complies with the WebRTC standard.", "Placing the server node differently allows us to perform the trace-driven simulations in a managed lab or directly run real-world field trials in the wild. Four ABR solutions are deployed for study.", "We will later make this testbed open to public for reproducible research."], "citing_paper_content": {"title": "Improving Adaptive Real-Time Video Communication Via Cross-Layer Optimization", "abstract": "Effective Adaptive BitRate (ABR) algorithm or policy is of paramount importance for Real-Time Video Communication (RTVC) amid this pandemic to pursue uncompromised quality of experience (QoE). Existing ABR methods mainly separate the network bandwidth estimation and video encoder control, and fine-tune video bitrate towards estimated bandwidth, assuming the maximization of bandwidth utilization yields the optimal QoE. However, the QoE of a RTVC system is jointly determined by the quality of compressed video, fluency of video playback, and interaction delay. Solely maximizing the bandwidth utilization without comprehensively considering compound impacts incurred by both network and video application layers, does not assure the satisfactory QoE. And the decoupling of network and video layer further exacerbates the user experience due to network-codec incoordination. This work therefore proposes the Palette, a reinforcement learning based ABR scheme that unifies the processing of network and video application layers to directly maximize the QoE formulated as the weighted function of video quality, stalling rate and delay. To this aim, a crosslayer optimization is proposed to derive fine-grained compression factor of upcoming frame(s) using cross-layer observations like network conditions, video encoding parameters, and video content complexity. As a result, Palette manages to resolve the network-codec incoordination and to best catch up with the network fluctuation. Compared with state-of-the-art schemes in real-world tests, Palette not only reduces 3.1%-46.3% of the stalling rate, 20.2%-50.8% of the delay, but also improves 0.2%-7.2% of the video quality with comparable bandwidth consumption, under a variety of application scenarios."}, "cited_paper_content": {"title": "Youtube Ugc Dataset For Video Compression Research", "abstract": "Non-professional video, commonly known as User Generated Content (UGC) has become very popular in today's video sharing applications. However, traditional metrics used in compression and quality assessment, like BD-Rate and PSNR, are designed for pristine originals. Thus, their accuracy drops significantly when being applied on non-pristine originals (the majority of UGC). Understanding difficulties for compression and quality assessment in the scenario of UGC is important, but there are few public UGC datasets available for research. This paper introduces a large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos. The dataset covers popular categories like Gaming, Sports, and new features like High Dynamic Range (HDR). Besides a novel sampling method based on features extracted from encoding, challenges for UGC compression and quality evaluation are also discussed. Shortcomings of traditional reference-based metrics on UGC are addressed. We demonstrate a promising way to evaluate UGC quality by no-reference objective quality metrics, and evaluate the current dataset with three no-reference metrics (Noise, Banding, and SLEEQ)."}, "keywords": ["live RTVC session", "YouTube UGC video"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To simulate a variety of real-world scenarios, the authors rented a commercial cloud server and played pre-cached video files, while the sender encoded live scenes in real-time and transmitted the video stream to the receiver client. To evaluate the quality of compressed video, the authors proposed a novel sampling method based on features extracted from encoding, and introduced a large scale UGC dataset (1500 20 sec video clips) sampled from millions of YouTube videos #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To simulate a variety of real-world scenarios, the authors rented a commercial cloud server and played pre-cached video files, while the sender encoded live scenes in real-time and transmitted the video stream to the receiver client, as discussed in Sec. III-A. The proposed cross-layer optimization scheme, Palette, unifies the processing of network and video application layers to maximize the QoE, and derives fine-grained compression factor of upcoming frame(s) using cross-layer observations like network conditions, video encoding parameters, and video content complexity, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To simulate a variety of real-world scenarios, the authors conducted a live RTVC session with pre-cached video files, while the sender encoded live scenes in real-time and transmitted the video stream to the receiver client, as discussed in Sec. III-A #REFR, which proposed a large scale YouTube UGC video dataset for research on challenges for UGC compression and quality evaluation.", "given_citation_intent": "method", "given_keywords": ["live RTVC session", "YouTube UGC video"]}]}
{"citing_id": "2303.05067v1", "cited_id": "1812.04895", "section_title": "Approximation Algorithms For The Robf Problem", "citation": "In #REFR it has been shown that solving the nominal problem min k\u2208F c c c k , for linear cost functions f , gives a z(F)-approximation to (13).", "text_before_citation": ["where", "F \u2208F min k\u2208F f (x x x,c c c k ) F \u2208F max k\u2208F f (x x x,c c c k ) \u2208 [0, 1]", ".", "Observe that (13) is a special case of the mixed-uncertainty robust optimization problem discussed in #OTHEREFR , where uncertainty sets are given and we would like to solve", "min x x x\u2208X F \u2208F m(F ) max k\u2208F f (x x x, c c c k ),"], "text_after_citation": ["In combination with Theorem 4, this allows us to derive approximation algorithms for a wide range of the ROBF problems if the underling deterministic problem (1) is polynomially solvable, in particular for a wide class of network problems (see #OTHEREFR for a comprehensive review).", "Note also that in most cases \u03b3 = 1 if (13) is a convex problem (in particular linear programing one)."], "citing_paper_content": {"title": "Robust Optimization With Belief Functions", "abstract": "In this paper, an optimization problem with uncertain objective function coefficients is considered. The uncertainty is specified by providing a discrete scenario set, containing possible realizations of the objective function coefficients. The concept of belief function in the traditional and possibilistic setting is applied to define a set of admissible probability distributions over the scenario set. The generalized Hurwicz criterion is then used to compute a solution. In this paper, the complexity of the resulting problem is explored. Some exact and approximation methods of solving it are proposed."}, "cited_paper_content": {"title": "Mixed Uncertainty Sets For Robust Combinatorial Optimization", "abstract": "In robust optimization, the uncertainty set is used to model all possible outcomes of uncertain parameters. In the classic setting, one assumes that this set is provided by the decision maker based on the data available to her. Only recently it has been recognized that the process of building useful uncertainty sets is in itself a challenging task that requires mathematical support. ::: In this paper, we propose an approach to go beyond the classic setting, by assuming multiple uncertainty sets to be prepared, each with a weight showing the degree of belief that the set is a \"true\" model of uncertainty. We consider theoretical aspects of this approach and show that it is as easy to model as the classic setting. In an extensive computational study using a shortest path problem based on real-world data, we auto-tune uncertainty sets to the available data, and show that with regard to out-sample performance, the combination of multiple sets can give better results than each set on its own."}, "keywords": ["linear cost functions"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "This problem is a special case of the mixed-uncertainty robust optimization problem discussed in the reference paper \"Mixed Uncertainty Sets For Robust Combinatorial Optimization\" where multiple uncertainty sets are prepared, each with a weight showing the degree of belief that the set is a \"true\" model of uncertainty. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This problem is a special case of the mixed-uncertainty robust optimization problem discussed in #REFR, where multiple uncertainty sets are prepared, each with a weight showing the degree of belief that the set is a \"true\" model of uncertainty.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This problem is a special case of the mixed-uncertainty robust optimization problem discussed in the reference paper #REFR, where multiple uncertainty sets with different weights are considered to model all possible outcomes of uncertain parameters, including linear cost functions.", "given_citation_intent": "background", "given_keywords": ["linear cost functions"]}]}
{"citing_id": "2303.12724v1", "cited_id": "1705.10667", "section_title": "Unsupervised Domain Adaptation", "citation": "CDAN #REFR injects class-specific information into the discriminator to facilitate the alignment of multi-modal distributions.", "text_before_citation": ["For example, #OTHEREFR try to minimize the maximum mean discrepancy (MMD) #OTHEREFR across domains, while MCC #OTHEREFR minimizes the class confusion loss without explicit domain alignment.", "Margin disparity discrepancy (MDD) #OTHEREFR is to perform domain alignment with analyses in terms of generalization bounds.", "#OTHEREFR uses the Wasserstein distance for distributional alignment to achieve better transfer effects.", "On the other hand, adversarial-based methods align distributions across domains through adversarial training #OTHEREFR .", "For example, DANN #OTHEREFR adversarially learns a domain discriminator to distinguish samples in two domains and thus enables the feature extractor to confuse the domain discriminator."], "text_after_citation": ["SDAT #OTHEREFR uses sharpness-aware minimization #OTHEREFR to seek a flat minimize for better generalization, while ELS #OTHEREFR improves over SDAT by introducing label smoothing to domain labels and achieves better transfer performance.", "Adversarial training can also be used to generate samples to bridge the source and target domains.", "CyCADA #OTHEREFR adopts GAN for image-to-image translation via the cycle consistency loss #OTHEREFR and semantic consistency loss.", "Specifically, it directly changes the style of source images to that of the target domain to obtain a better classifier for the target domain.", "#OTHEREFR uses two cross-domain generators to synthesize data of each domain conditioned on the other, and learns two task-specific classifiers."], "citing_paper_content": {"title": "Diffusion-Based Target Sampler For Unsupervised Domain Adaptation", "abstract": "Limited transferability hinders the performance of deep learning models when applied to new application scenarios. Recently, unsupervised domain adaptation (UDA) has achieved significant progress in addressing this issue via learning domain-invariant features. However, large domain shifts and the sample scarcity in the target domain make existing UDA methods achieve suboptimal performance. To alleviate these issues, we propose a plug-andplay Diffusion-based Target Sampler (DTS) to generate high fidelity and diversity pseudo target samples. By introducing class-conditional information, the labels of the generated target samples can be controlled. The generated samples can well simulate the data distribution of the target domain and help existing UDA methods transfer from the source domain to the target domain more easily, thus improving the transfer performance. Extensive experiments on various benchmarks demonstrate that the performance of existing UDA methods can be greatly improved through the proposed DTS method. The code will be released soon."}, "cited_paper_content": {"title": "Conditional Adversarial Domain Adaptation", "abstract": "Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may not effectively align different domains of multimodal distributions native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. With theoretical guarantees and a few lines of codes, the approach has exceeded state-of-the-art results on five datasets."}, "keywords": ["discriminator", "multi-modal distributions"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "On the other hand, adversarial-based methods align distributions across domains through adversarial training. For example, DANN adversarially learns a domain discriminator to distinguish samples in two domains and thus enables the feature extractor to confuse the domain discriminator. To further improve the transfer performance, the authors propose a principled framework called conditional adversarial domain adaptation, which conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Adversarial-based methods, such as conditional adversarial domain adaptation, align distributions across domains through adversarial training, which can improve the transfer effects of unsupervised domain adaptation methods #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Adversarial-based methods, such as DANN, align distributions across domains through adversarial training with a domain #REFR discriminator, which distinguishes samples in two domains and enables the feature extractor to confuse the discriminator, but may not effectively align different domains of multi-modal distributions native in classification problems.", "given_citation_intent": "background", "given_keywords": ["discriminator", "multi-modal distributions"]}]}
{"citing_id": "2303.09033v1", "cited_id": "1102.2490", "section_title": "Related Work", "citation": "This was observed before by #REFR and we observe the same trend in our experiments (Section 5).", "text_before_citation": ["V is O i:\u00b5 i <\u00b5 a * \u03c3 2 i \u2206 i + b log n , where b", "is an upper bound on the absolute value of the rewards.", "In summary, variance adaptation in UCB-V incurs only a small penalty of O(bK log n). #OTHEREFR", "(2018) proposed an elimination-based variant of UCB-V that attains the optimal gap-free regret of O( \u221a Kn), as opposing to the original O( \u221a Kn log n).", "While empirical Bernstein bounds are general, they tend to be conservative in practice."], "text_after_citation": ["Our work can be viewed as a similar development with Thompson sampling.", "We show that Thompson sampling with unknown reward variances (Section 4) incurs only a slightly higher regret than the one with the known variances (Section 3), by a multiplicative factor. Comparing to UCB-V, the algorithm is highly practical. A recent work by Zhang et al.", "(2021) extended the above results to d-dimensional linear bandits Abbasi-Yadkori et al. 2011; Dani et al. (2008b,a) , where the arm set can be infinite.", "Their regret bound is\u00d5(poly(d) 1 + n s=1 \u03c3 2 s ), where \u03c3 2 s is the unknown reward variance in round s. They also extended their result to linear mixture MDPs.", "Another related work on variance-sensitive multi-armed bandits is Zhu and Tan (2020)."], "citing_paper_content": {"title": "Only Pay For What Is Uncertain: Variance-Adaptive Thompson Sampling", "abstract": "Most bandit algorithms assume that the reward variance or its upper bound is known. While variance overestimation is usually safe and sound, it increases regret. On the other hand, an underestimated variance may lead to linear regret due to committing early to a suboptimal arm. This motivated prior works on variance-aware frequentist algorithms. We lay foundations for the Bayesian setting. In particular, we study multi-armed bandits with known and unknown heterogeneous reward variances, and develop Thompson sampling algorithms for both and bound their Bayes regret. Our regret bounds decrease with lower reward variances, which make learning easier. The bound for unknown reward variances captures the effect of the prior on learning reward variances and is the first of its kind. Our experiments show the superiority of varianceaware Bayesian algorithms and also highlight their robustness."}, "cited_paper_content": {"title": "The Kl-Ucb Algorithm For Bounded Stochastic Bandits And Beyond", "abstract": "This paper presents a finite-time analysis of the KL-UCB algorithm, an online, horizon-free index policy for stochastic bandit problems. We prove two distinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm satisfies a uniformly better regret bound than UCB or UCB2; second, in the special case of Bernoulli rewards, it reaches the lower bound of Lai and Robbins. Furthermore, we show that simple adaptations of the KL-UCB algorithm are also optimal for specific classes of (possibly unbounded) rewards, including those generated from exponential families of distributions. A large-scale numerical study comparing KL-UCB with its main competitors (UCB, UCB2, UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and stable, including for short time horizons. KL-UCB is also the only method that always performs better than the basic UCB policy. Our regret bounds rely on deviations results of independent interest which are stated and proved in the Appendix. As a by-product, we also obtain an improved regret bound for the standard UCB algorithm."}, "keywords": ["experiments", "trend"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The KL-UCB algorithm has been shown to outperform UCB and UCB2 in terms of regret bound for arbitrary bounded rewards, and to reach the lower bound of Lai and Robbins for Bernoulli rewards. Additionally, simple adaptations of the KL-UCB algorithm are optimal for specific classes of rewards, including those generated from exponential families of distributions. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the results presented in #REFR, the KL-UCB algorithm outperforms UCB and UCB2 in terms of regret bound for arbitrary bounded rewards, and reaches the lower bound of Lai and Robbins for Bernoulli rewards.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In a large-scale numerical study comparing various bandit algorithms, including UCB and UCB2, #REFR was shown to be remarkably efficient and stable, even for short time horizons, and was the only method that consistently outperformed the basic UCB policy, demonstrating its superiority in experiments and highlighting a trend towards using KL-UCB in practice.", "given_citation_intent": "result", "given_keywords": ["experiments", "trend"]}]}
{"citing_id": "2304.10527v1", "cited_id": "1804.09170", "section_title": "Model", "citation": "For a comprehensive and fair comparison of the CIFAR10 experiment, we followed the same experiment setting of #REFR .", "text_before_citation": ["All the compared methods (except UASD #OTHEREFR ) were built upon the open-source Pytorch implementation 1 by #OTHEREFR .", "As UASD has not released its implementation, we implemented UASD by ourselves.", "For DS3L, we implemented it based on the released code 2 .", "For L2RW #OTHEREFR , we used the open-source Pytorch implementation 3 and adapted it to the SSL settings.", "For MWN #OTHEREFR , we used the authors' implementation 4 and adapt to SSL. experiments."], "text_after_citation": ["All the compared methods were built upon the open-source Pytorch implementation by #OTHEREFR .", "The code and datasets are temporarily available for reviewing purposes at here 5 .", "Our code and datasets are also submitted as supplementary material.", "1 https://github.com/perrying/realistic-ssl-evaluation-pytorch 2 https://github.com/guolz-ml/DS3L", "3 https://github.com/danieltan07/learning-to-reweight-examples #OTHEREFR https://github.com/xjtushujun/meta-weight-net #OTHEREFR https://anonymous.4open.science/r/WR-SSL-406F/README.md Hyperparameter setting."], "citing_paper_content": {"title": "Table Of Contents", "abstract": "2 Uncertainty Framework Overview. Subjective Bayesian GNN (a) is designed for estimating the different types of uncertainties. The loss function includes a square error (d) to reduce bias, GKDE (b) to reduce errors in uncertainty estimation, and teacher network (c) to refine class probability."}, "cited_paper_content": {"title": "Realistic Evaluation Of Deep Semi-Supervised Learning Algorithms", "abstract": "Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. SSL algorithms based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that the performance of simple baselines which do not use unlabeled data is often underreported, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples. To help guide SSL research towards real-world applicability, we make our unified reimplemention and evaluation platform publicly available."}, "keywords": ["comprehensive"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For SSL methods, recent work has shown that their performance can degrade substantially when the unlabeled dataset contains out-of-class examples #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the limitations of SSL algorithms in real-world applications, the authors of this manuscript conducted a suite of experiments and found that the performance of SSL methods can degrade substantially when the unlabeled dataset contains out-of-class examples (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the limitations of SSL algorithms in real-world applications, the authors of this manuscript conducted a comprehensive evaluation of various SSL techniques, including those based on deep neural networks, and made their unified reimplemention and evaluation platform publicly available (#REFR).", "given_citation_intent": "method", "given_keywords": ["comprehensive"]}]}
{"citing_id": "2303.08874v1", "cited_id": "1612.01474", "section_title": "Neural Ensemble Search", "citation": "Relatedly, DeepEnsembles #REFR seeks to approximately marginalise over the parameters of a given NN architecture.", "text_before_citation": ["Neural Ensemble Search via Bayesian Sampling #OTHEREFR approximates the posterior distribution over architectures p(\u03b1 | D) with a variational distribution of the form", "q(\u03b1) = i q i (o | \u03b8 i )", ", where i iterates over the connections within a cell, o is the operation for connection i, and \u03b8 i are the variational parameters for q i .", "The form of q i is chosen to be a softmax over \u03b8 i .", "The ensemble is then selected by using Stein Variational Gradient Descent with Regularised Diversity to select a diverse set of M samples from (a continuous relaxation of) the variational distribution."], "text_after_citation": ["The architecture is trained from several random initialisations, and the ensemble makes a prediction as an equally weighed sum of these.", "This is orthogonal to the work above (and, indeed, is orthogonal our work), which seeks to construct ensembles of different architectures, rather than ensembles of different parameter settings of the same architecture."], "citing_paper_content": {"title": "Bayesian Quadrature For Neural Ensemble Search", "abstract": "Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature-tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically-in terms of test likelihood, accuracy, and expected calibration error-that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently."}, "cited_paper_content": {"title": "Simple And Scalable Predictive Uncertainty Estimation Using Deep Ensembles", "abstract": "Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet."}, "keywords": ["DeepEnsembles"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose an alternative to Bayesian NNs for estimating predictive uncertainty that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenging problem of quantifying predictive uncertainty in neural networks, the authors propose a simple and scalable method that yields high-quality predictive uncertainty estimates, as demonstrated in their experiments on classification and regression benchmarks, which are as good or better than approximate Bayesian neural networks #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate predictive uncertainty in neural networks, DeepEnsembles have been proposed as an alternative to Bayesian neural networks, which require significant modifications to the training procedure and are computationally expensive; DeepEnsembles are simple to implement, readily parallelizable, require very little hyperparameter tuning, and yield high quality predictive uncertainty estimates #REFR.", "given_citation_intent": "background", "given_keywords": ["DeepEnsembles"]}]}
{"citing_id": "2304.11228v1", "cited_id": "1711.03938", "section_title": "Driving Tasks", "citation": "For this purpose, we used two towns from the CARLA simulator by Dosovitskiy et al. #REFR namely, Town01 and Town07.", "text_before_citation": ["In both the INTERFACES (VR and BASELINE), participants performed a driving task in the TELEOPERATION scenario, where they had to drive a virtually simulated vehicle."], "text_after_citation": ["The participants drove in Town01 in one INTERFACE and on Town07 in the other.", "The combination of the INTERFACE and the town to drive in was balanced among the participants.", "The pre-defined path for driving in the town was visualized using spheres, here shown with a yellow dashed curves in Figure 4 .", "We asked the participants to follow this path for driving.", "We also asked them to drive as fast as possible and align the position of the vehicle below the spheres as accurately as possible to reduce their deviation from the route."], "citing_paper_content": {"title": "Remote Monitoring And Teleoperation Of Autonomous Vehicles -Is Virtual Reality An Option?", "abstract": "While the promise of autonomous vehicles has led to significant scientific and industrial progress, fully automated, SAE level 5 conform cars will likely not see mass adoption anytime soon. Instead, in many applications, human supervision, such as remote monitoring and teleoperation, will be required for the foreseeable future. While Virtual Reality (VR) has been proposed as one potential interface for teleoperation, its benefits and drawbacks over physical monitoring and teleoperation solutions have not been thoroughly investigated. To this end, we contribute two user studies, comparing the performance of and subjective feedback for a VR-based system with an existing monitoring and teleoperation system, which is in industrial use today. The results of our first user study (n=16), indicate that a VR interface replicating the physical interface does not outperform the physical interface. It also quantifies the negative effects that combined monitoring and teleoperating tasks have on users irrespectively of the interface being used. The results of the second user study (n=24), indicate that the perceptual and ergonomic issues caused by VR outweigh its benefits like better concentration through isolation, which is critical for monitoring tasks. Through these two user studies, we contribute to a better understanding of future virtual monitoring and teleoperation solutions for autonomous vehicles."}, "cited_paper_content": {"title": "Carla: An Open Urban Driving Simulator", "abstract": "We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform's utility for autonomous driving research. The supplementary video can be viewed at this https URL"}, "keywords": ["CARLA simulator"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In both the INTERFACES (VR and BASELINE), participants performed a driving task in the TELEOPERATION scenario, where they had to drive a virtually simulated vehicle. To simulate the vehicle, the authors could have used the open-source simulator for autonomous driving research, CARLA, which provides open digital assets and supports flexible specification of sensor suites and environmental conditions #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To simulate the driving task in the TELEOPERATION scenario, the authors used the open-source simulator for autonomous driving research, CARLA, which provides open digital assets and supports flexible specification of sensor suites and environmental conditions #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To simulate the driving task in the TELEOPERATION scenario, the authors used the CARLA simulator #REFR.", "given_citation_intent": "method", "given_keywords": ["CARLA simulator"]}]}
{"citing_id": "2303.08906v1", "cited_id": "1512.03385", "section_title": "A.1. Implementation Details", "citation": "In the L N -iMAC, the backbone network \u03a6 is ResNet50 #REFR , the number of layers K is 4, the types of region kernel N are 4.", "text_before_citation": ["Each video is sampled at one frame per second.", "The number of frames per video is set during training with T = 64 but is varied during inference based on the duration of the video."], "text_after_citation": ["The set of easy distractors used in the training phase is taken from nearly 100,000 metadatafree videos (with the exception of 528 videos in the core datasets) within the VCDB #OTHEREFR , where each frame-level feature is selected as an easy distractor based on the magnitude threshold \u03bb mag = 40.", "The distractor threshold \u03bb di for the thresholding operation on the confidence of DDM during the inference phase is set to 0.5.", "The temperature of the tempered sigmoid #OTHEREFR is set to 512 in TGM.", "The parameter \u03b1 for balancing the discrimination loss is set to 0.5, and margins in the frame loss and the video loss are also set to 0.5.", "Additionally, PCA is incrementally trained from all metadata-free videos within the VCDB."], "citing_paper_content": {"title": "Vvs: Video-To-Video Retrieval With Irrelevant Frame Suppression", "abstract": "In content-based video retrieval (CBVR), dealing with large-scale collections, efficiency is as important as accuracy. For this reason, several video-level feature-based studies have actively been conducted; nevertheless, owing to the severe difficulty of embedding a lengthy and untrimmed video into a single feature, these studies have shown insufficient for accurate retrieval compared to framelevel feature-based studies. In this paper, we show an insight that appropriate suppression of irrelevant frames can be a clue to overcome the current obstacles of the videolevel feature-based approaches. Furthermore, we propose a Video-to-Video Suppression network (VVS) as a solution. The VVS is an end-to-end framework that consists of an easy distractor elimination stage for identifying which frames to remove and a suppression weight generation stage for determining how much to suppress the remaining frames. This structure is intended to effectively describe an untrimmed video with varying content and meaningless information. Its efficacy is proved via extensive experiments, and we show that our approach is not only state-of-the-art in videolevel feature-based approaches but also has a fast inference time despite possessing retrieval capabilities close to those of frame-level feature-based approaches."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["region kernel", "layers K"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Each video is sampled at one frame per second, and the number of frames per video is set during training with T = 64 but is varied during inference based on the duration of the video. The authors of Vvs: Video-To-Video Retrieval With Irrelevant Frame Suppression proposed a Video-to-Video Suppression network (VVS) that effectively describes an untrimmed video with varying content and meaningless information, achieving state-of-the-art results in video-level feature-based approaches #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the difficulty of embedding lengthy and untrimmed videos into a single feature, the authors propose a Video-to-Video Suppression network (VVS) that consists of an easy distractor elimination stage and a suppression weight generation stage, which is inspired by the residual learning framework presented in Deep Residual Learning For Image Recognition. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the VVS network, the authors utilized a residual learning framework that explicitly reformulates the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions, as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["region kernel", "layers K"]}]}
{"citing_id": "2303.17142v1", "cited_id": "1409.0575", "section_title": "Introduction", "citation": "For example, when we use ImageNet data #REFR for self-supervised pre-training, views from the current image instance x 0 belonging to the 'bloodhound' category is labeled as positive, while views from other image instances belonging to the same category will be labeled as negative.", "text_before_citation": ["Different from these methods, our SNCLR shown in (d) measures correlations between the current instance and other instances identified from the candidate neighbor set.", "We define the instances that are highly-correlated to the current instance as soft neighbors (e.g., different pandas to the input image belonging to the 'panda' category in Fig. 3 ).", "The similarity/correlation, which is based on the cross-attention computation from a shallow attention module, denotes the instance positiveness to compute the contrastive loss.", "(Best viewed in colors) and negative pairs constitute the contrastive loss computation process.", "In practice, we observe that this rudimentary labeling is not sufficient to represent instance correlations (i.e., similar to the semantic relations in supervised learning) between different images and may hurt the performance of learned representations."], "text_after_citation": ["Since we do not know the original training labels during SSL, images belonging to the same semantic category will be labeled differently to limit feature representations.", "On the other hand, for the current image instance x 0 , although views from one image instance x 1 belonging to the 'walker hound' category and views from another image instance x 2 belonging to the 'peacock' category are both labeled as negative, the views from x 1 are more correlated to the views from x 0 than those views from x 2 .", "This correlation is not properly encoded during contrastive learning as views from both x 1 and x 2 are labeled the same.", "Without original training labels, contrastive learning methods are not effective in capturing the correlations between image instances.", "The learned feature representations are limited to describing correlated visual contents across different images."], "citing_paper_content": {"title": "Soft Neighbors Are Positive Supporters In Contrastive Visual Representation Learning", "abstract": "Contrastive learning methods train visual encoders by comparing views (e.g., often created via a group of data augmentations on the same instance) from one instance to others. Typically, the views created from one instance are set as positive, while views from other instances are negative. This binary instance discrimination is studied extensively to improve feature representations in self-supervised learning. In this paper, we rethink the instance discrimination framework and find the binary instance labeling insufficient to measure correlations between different samples. For an intuitive example, given a random image instance, there may exist other images in a mini-batch whose content meanings are the same (i.e., belonging to the same category) or partially related (i.e., belonging to a similar category). How to treat the images that correlate similarly to the current image instance leaves an unexplored problem. We thus propose to support the current image by exploring other correlated instances (i.e., soft neighbors). We first carefully cultivate a candidate neighbor set, which will be further utilized to explore the highly-correlated instances. A cross-attention module is then introduced to predict the correlation score (denoted as positiveness) of other correlated instances with respect to the current one. The positiveness score quantitatively measures the positive support from each correlated instance, and is encoded into the objective for pretext training. To this end, our proposed method benefits in discriminating uncorrelated instances while absorbing correlated instances for SSL. We evaluate our soft neighbor contrastive learning method (SNCLR) on standard visual recognition benchmarks, including image classification, object detection, and instance segmentation. The state-of-theart recognition performance shows that SNCLR is effective in improving feature representations from both ViT and CNN encoders."}, "cited_paper_content": {"title": "Imagenet Large Scale Visual Recognition Challenge", "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements."}, "keywords": ["self-supervised pre", "ImageNet data"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Different from these methods, our SNCLR shown in (d) measures correlations between the current instance and other instances identified from the candidate neighbor set. We define the instances that are highly-correlated to the current instance as soft neighbors (e.g., different pandas to the input image belonging to the 'panda' category in Fig. 3 ). The similarity/correlation, which is based on the cross-attention computation from a shallow attention module, denotes the instance positiveness to compute the contrastive loss. (Best viewed in colors) and negative pairs constitute the contrastive loss computation process. In practice, we observe that this rudimentary labeling is not sufficient to represent instance correlations (i.e., similar to the semantic relations in supervised learning) between different images and may hurt the performance of learned representations. Our proposed method is inspired by the ImageNet Large Scale Visual Recognition Challenge #REFR, which highlights the challenges of collecting large-scale ground truth annotation and provides a detailed analysis of the current state of the field of large-scale image classification and object detection.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed method, SNCLR, measures correlations between the current instance and other instances identified from the candidate neighbor set, which is inspired by the benchmark dataset created in the Imagenet Large Scale Visual Recognition Challenge #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To explore the highly-correlated instances, the proposed soft neighbor contrastive learning method (SNCLR) in (d) utilizes a candidate neighbor set and cross-attention module to measure correlations between the current instance and other instances, which is similar to the approach used in the ImageNet Large Scale Visual Recognition Challenge dataset #REFR.", "given_citation_intent": "method", "given_keywords": ["self-supervised pre", "ImageNet data"]}]}
{"citing_id": "2304.11834v1", "cited_id": "1803.03635", "section_title": "Iv. Related Work", "citation": "The lottery ticket hypothesis #REFR is the first to discover that there exist trainable subnetworks which are hidden in an over-parameterized dense network but can match the accuracy of their dense network counterparts after being trained in isolation.", "text_before_citation": ["Lottery ticket hypothesis."], "text_after_citation": ["This intriguing finding has motivated various followup works that explore the lottery ticket hypothesis under different scenarios.", "In particular, #OTHEREFR , #OTHEREFR extend the lottery ticket hypothesis to transfer learning and find that subnetworks inheriting the pretrained model weights as initialization can match the task accuracy of their dense network counterparts after finetuning.", "However, their adopted metrics were originally designed for maintaining the accuracy of the identified tickets on the same task and thus do not necessarily help preserve the transferability to downstream tasks.", "Transfer learning.", "Motivated by the success of DNNs as a general feature extractor, transfer learning #OTHEREFR has been widely adopted across different domains to benefit downstream tasks from DNNs pretrained on a big data regime."], "citing_paper_content": {"title": "Robust Tickets Can Transfer Better: Drawing More Transferable Subnetworks In Transfer Learning", "abstract": "Transfer learning leverages feature representations of deep neural networks (DNNs) pretrained on source tasks with rich data to empower effective finetuning on downstream tasks. However, the pretrained models are often prohibitively large for delivering generalizable representations, which limits their deployment on edge devices with constrained resources. To close this gap, we propose a new transfer learning pipeline, which leverages our finding that robust tickets can transfer better, i.e., subnetworks drawn with properly induced adversarial robustness can win better transferability over vanilla lottery ticket subnetworks. Extensive experiments and ablation studies validate that our proposed transfer learning pipeline can achieve enhanced accuracysparsity trade-offs across both diverse downstream tasks and sparsity patterns, further enriching the lottery ticket hypothesis."}, "cited_paper_content": {"title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "abstract": "Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard technique for pruning weights naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the\"lottery ticket hypothesis\": dense, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that - when trained in isolation - arrive at comparable test accuracy in a comparable number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Furthermore, the winning tickets we find above that size learn faster than the original network and exhibit higher test accuracy."}, "keywords": ["trainable subnetworks"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed transfer learning pipeline leverages the finding that robust tickets can transfer better, inducing adversarial robustness to draw subnetworks that outperform vanilla lottery ticket subnetworks in transferability #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The concept of the \"lottery ticket hypothesis\" proposed in the reference paper #REFR suggests that dense, randomly-initialized feed-forward networks contain subnetworks that can be trained effectively, which is relevant to the local context of exploring subnetworks with better transferability, as discussed in the manuscript.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The concept of trainable subnetworks was introduced in the lottery ticket hypothesis, which suggests that dense, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that can be trained effectively, and the authors of this manuscript refer to this hypothesis to support their proposed transfer learning pipeline. #REFR", "given_citation_intent": "background", "given_keywords": ["trainable subnetworks"]}]}
{"citing_id": "2305.00966v1", "cited_id": "1711.07211", "section_title": "Overview Of Techniques", "citation": "This challenge of circular dependence does not appear in #REFR : their goal was to estimate the unknown mean of an identity-covariance Gaussian, and thus it sufficed to use a linear polynomial f (instead of a quadratic polynomial).", "text_before_citation": ["In either case, we will have cleaned up our set of samples and can recurse on each of the returned subsets of S.", "Iterating this technique recursively on all of the smaller subsets returned ensures that there is always at least one subset containing the majority of the inliers, and that eventually once it stops having too large of a covariance, we will return an appropriate approximation to \u03a3.", "We want to highlight the main point of difference where our techniques differ notably from #OTHEREFR .", "In order to implement the algorithm outlined above, one needs to have good a priori bounds for what the variance of f (x) over the inliers ought to be.", "Since f (\u2022) is a quadratic polynomial, the variance of f over the inliers, itself depends on the covariance \u03a3, which is exactly what we are trying to estimate."], "text_after_citation": ["Importantly, the covariance of a linear polynomial does not depend on the (unknown) mean (it depends only on the covariance, which was known in their setting).", "In order to overcome this challenge, we observe that if S contains most of the inliers, then the covariance of S cannot be too much smaller than the true covariance \u03a3.", "This allows us to find an upper bound on \u03a3, which in turn lets us upper bound the variance of f (x) over the good samples (Lemma 3.3)."], "citing_paper_content": {"title": "A Spectral Algorithm For List-Decodable Covariance Estimation In Relative Frobenius Norm", "abstract": "We study the problem of list-decodable Gaussian covariance estimation. Given a multiset T of n points in R d such that an unknown \u03b1 < 1/2 fraction of points in T are i.i.d. samples from an unknown Gaussian N (\u00b5, \u03a3), the goal is to output a list of O(1/\u03b1) hypotheses at least one of which is close to \u03a3 in relative Frobenius norm. Our main result is a poly(d, 1/\u03b1) sample and time algorithm for this task that guarantees relative Frobenius norm error of poly(1/\u03b1). Importantly, our algorithm relies purely on spectral techniques. As a corollary, we obtain an efficient spectral algorithm for robust partial clustering of Gaussian mixture models (GMMs)-a key ingredient in the recent work of [BDJ + 22] on robustly learning arbitrary GMMs. Combined with the other components of [BDJ + 22], our new method yields the first Sum-of-Squares-free algorithm for robustly learning GMMs. At the technical level, we develop a novel multi-filtering method for list-decodable covariance estimation that may be useful in other settings."}, "cited_paper_content": {"title": "List-Decodable Robust Mean Estimation And Learning Mixtures Of Spherical Gaussians", "abstract": "We study the problem of list-decodable Gaussian mean estimation and the related problem of learning mixtures of separated spherical Gaussians. We develop a set of techniques that yield new efficient algorithms with significantly improved guarantees for these problems. {\\bf List-Decodable Mean Estimation.} Fix any $d \\in \\mathbb{Z}_+$ and $0<\\alpha<1/2$. We design an algorithm with runtime $O (\\mathrm{poly}(n/\\alpha)^{d})$ that outputs a list of $O(1/\\alpha)$ many candidate vectors such that with high probability one of the candidates is within $\\ell_2$-distance $O(\\alpha^{-1/(2d)})$ from the true mean. The only previous algorithm for this problem achieved error $\\tilde O(\\alpha^{-1/2})$ under second moment conditions. For $d = O(1/\\epsilon)$, our algorithm runs in polynomial time and achieves error $O(\\alpha^{\\epsilon})$. We also give a Statistical Query lower bound suggesting that the complexity of our algorithm is qualitatively close to best possible. {\\bf Learning Mixtures of Spherical Gaussians.} We give a learning algorithm for mixtures of spherical Gaussians that succeeds under significantly weaker separation assumptions compared to prior work. For the prototypical case of a uniform mixture of $k$ identity covariance Gaussians we obtain: For any $\\epsilon>0$, if the pairwise separation between the means is at least $\\Omega(k^{\\epsilon}+\\sqrt{\\log(1/\\delta)})$, our algorithm learns the unknown parameters within accuracy $\\delta$ with sample complexity and running time $\\mathrm{poly} (n, 1/\\delta, (k/\\epsilon)^{1/\\epsilon})$. The previously best known polynomial time algorithm required separation at least $k^{1/4} \\mathrm{polylog}(k/\\delta)$. Our main technical contribution is a new technique, using degree-$d$ multivariate polynomials, to remove outliers from high-dimensional datasets where the majority of the points are corrupted."}, "keywords": ["identity-covariance Gaussian"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our algorithm for list-decodable covariance estimation relies purely on spectral techniques and achieves a relative Frobenius norm error of poly(1/\u03b1) with a sample and time complexity of poly(d, 1/\u03b1) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the variance of f over the inliers, which depends on the covariance \u03a3, the authors of the manuscript developed a set of techniques that yield new efficient algorithms with significantly improved guarantees for list-decodable Gaussian mean estimation and learning mixtures of separated spherical Gaussians, as described in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the variance of f over the inliers, which depends on the covariance \u03a3, the authors of the manuscript propose a technique that requires good a priori bounds, a problem that is addressed in #REFR by learning uniform mixtures of identity-covariance Gaussians with significantly weaker separation assumptions.", "given_citation_intent": "background", "given_keywords": ["identity-covariance Gaussian"]}]}
{"citing_id": "2304.06520v1", "cited_id": "1511.08060", "section_title": "A. Dataset", "citation": "We have used the apple leaf disease subset of the PlantVillage dataset, one of the largest open-access sources of leaf images #REFR .", "text_before_citation": [], "text_after_citation": ["There are 54,309 images of healthy and diseased leaves of 14 crops in the plantVillage dataset, all of which have been annotated by experts.", "There are 3,171 pictures of apple leaves, with 3 groups representing diseases and 1 representing healthy leaves. Figure 1 shows examples of images in each category.", "The images were captured in a laboratory setting and depict varying degrees of disease spot distribution on the leaf.", "Class imbalance is present in the dataset, as the greatest number of 'healthy' samples is 1645, while the number of samples corresponding to 'Cedar apple rust' is only 275.", "To combat this imbalance issue, we have included the concept of runtime augmentation."], "citing_paper_content": {"title": "An Efficient Transfer Learning-Based Approach For Apple Leaf Disease Classification", "abstract": "Correct identification and categorization of plant diseases are crucial for ensuring the safety of the global food supply and the overall financial success of stakeholders. In this regard, a wide range of solutions has been made available by introducing deep learning-based classification systems for different staple crops. Despite being one of the most important commercial crops in many parts of the globe, research proposing a smart solution for automatically classifying apple leaf diseases remains relatively unexplored. This study presents a technique for identifying apple leaf diseases based on transfer learning. The system extracts features using a pretrained EfficientNetV2S architecture and passes to a classifier block for effective prediction. The class imbalance issues are tackled by utilizing runtime data augmentation. The effect of various hyperparameters, such as input resolution, learning rate, number of epochs, etc., has been investigated carefully. The competence of the proposed pipeline has been evaluated on the apple leaf disease subset from the publicly available 'PlantVillage' dataset, where it achieved an accuracy of 99.21%, outperforming the existing works."}, "cited_paper_content": {"title": "An Open Access Repository Of Images On Plant Health To Enable The Development Of Mobile Disease Diagnostics", "abstract": "Human society needs to increase food production by an estimated 70% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently infectious diseases reduce the potential yield by an average of 40% with many farmers in the developing world experiencing yield losses as high as 100%. Infectious diseases of crops are not new and historic examples such as the Irish Potato Famine of 1845-49 demonstrate this. But what is new is the widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020. This offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Computer vision and machine learning have shown their potential to automatically classify images. To do this for plant diseases requires a training set that facilitates the development of the algorithms. Here we announce the release of >50,000 expertly curated images on healthy and infected leaves of crops plants through the existing platform www.PlantVillage.org. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases."}, "keywords": ["apple leaf disease", "PlantVillage dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Computer vision and machine learning have shown their potential to automatically classify images. To do this for plant diseases requires a training set that facilitates the development of the algorithms. Here we announce the release of >50,000 expertly curated images on healthy and infected leaves of crops plants through the existing platform www.PlantVillage.org #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To develop their apple leaf disease classification system, the authors utilized transfer learning and a pretrained EfficientNetV2S architecture, as well as a dataset of >50,000 expertly curated images on healthy and infected leaves of crop plants from the existing platform www.PlantVillage.org #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To identify apple leaf diseases, the authors utilized transfer learning and trained their model on the apple leaf disease subset from the publicly available PlantVillage dataset, achieving an accuracy of 99.21% #REFR.", "given_citation_intent": "method", "given_keywords": ["apple leaf disease", "PlantVillage dataset"]}]}
{"citing_id": "2305.01309v1", "cited_id": "1608.04236", "section_title": "C. Feature Residual Extraction And Compression", "citation": "The VRN #REFR unit, located between the two convolution layers, utilizes skip connections to mitigate information loss during training and employs parallel convolutional layers with varying kernel sizes, namely 1 \u00d7 1 \u00d7 1 or 3 \u00d7 3 \u00d7 3, to capture features at different ranges.", "text_before_citation": ["In our implementation, the kernel is defined as a hypercube with a size of 3, namely [\u22121, 0, 1] 3 , and the Minkowski #OTHEREFR , #OTHEREFR is adopted as the sparse inference engine.", "1) Feature Extraction: Using sparse convolution as the essential operation, the feature extraction module is carefully designed to enable high-level embedding prediction.", "Following learning-based compression methods #OTHEREFR , #OTHEREFR , the proposed approach works in a bottom-up manner by progressively reducing the spatial resolution and exponentially increasing the receptive field. As shown in Fig.", "3(a) , each downsampling block in the feature extractor comprises a strided convolution, a VRN unit #OTHEREFR , #OTHEREFR , and another convolution layer in a cascading manner.", "Specifically, the strided convolution reduces the number of points, while the subsequent convolution layer refines extracted features for optimal performance."], "text_after_citation": ["By stacking these downsampling blocks, the feature extraction module outputs multiscale sparse tensors, including coordinates and features, that form the latent representation of an entire point cloud.", "As such, the extracted features can reconstruct the original geometry information in a hierarchical manner with only a small number of output coordinates as indispensable information to decrease required bits.", "We losslessly encode these coordinates using a coordinate encoder #OTHEREFR , and further process multiscale features in the following modules.", "2) Feature Warping: The feature warping module is designed to transform the extracted features from the aligned point cloud to the coordinates of the source point cloud.", "This process is completed in a coarse-to-fine manner, with each scale entailing a hierarchical concatenation of primary sparse tensors X from the feature extractor and auxiliary sparse tensors X from the previous block, as illustrated in Fig. 3(b) ."], "citing_paper_content": {"title": "Geometric Prior Based Deep Human Point Cloud Geometry Compression", "abstract": "The emergence of digital avatars has raised an exponential increase in the demand for human point clouds with realistic and intricate details. The compression of such data becomes challenging with overwhelming data amounts comprising millions of points. Herein, we leverage the human geometric prior in geometry redundancy removal of point clouds, greatly promoting the compression performance. More specifically, the prior provides topological constraints as geometry initialization, allowing adaptive adjustments with a compact parameter set that could be represented with only a few bits. Therefore, we can envisage high-resolution human point clouds as a combination of geometric priors and structural deviations. The priors could first be derived with an aligned point cloud, and subsequently the difference of features is compressed into a compact latent code. The proposed framework can operate in a play-and-plug fashion with existing learning based point cloud compression methods. Extensive experimental results show that our approach significantly improves the compression performance without deteriorating the quality, demonstrating its promise in a variety of applications."}, "cited_paper_content": {"title": "Generative And Discriminative Voxel Modeling With Convolutional Neural Networks", "abstract": "When working with three-dimensional data, choice of representation is key. We explore voxel-based models, and present evidence for the viability of voxellated representations in applications including shape modeling and object classification. Our key contributions are methods for training voxel-based variational autoencoders, a user interface for exploring the latent space learned by the autoencoder, and a deep convolutional neural network architecture for object classification. We address challenges unique to voxel-based representations, and empirically evaluate our models on the ModelNet benchmark, where we demonstrate a 51.5% relative improvement in the state of the art for object classification."}, "keywords": ["parallel convolutional layers"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Following learning-based compression methods, the proposed approach works in a bottom-up manner by progressively reducing the spatial resolution and exponentially increasing the receptive field (Fig. 3(a)). The feature extraction module is carefully designed to enable high-level embedding prediction using sparse convolution as the essential operation. Specifically, the strided convolution reduces the number of points, while the subsequent convolution layer refines extracted features for optimal performance. Our method is similar to the voxel-based variational autoencoders proposed in #REFR, which also use convolutional neural networks for object classification.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Following learning-based compression methods, the proposed approach works in a bottom-up manner by progressively reducing the spatial resolution and exponentially increasing the receptive field, using methods for training voxel-based variational autoencoders and a deep convolutional neural network architecture for object classification presented in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enable high-level embedding prediction, the proposed approach uses parallel convolutional layers in a cascading manner #REFR.", "given_citation_intent": "method", "given_keywords": ["parallel convolutional layers"]}]}
{"citing_id": "2304.04962v1", "cited_id": "1801.03924", "section_title": "A2.2.2. Experimental Details", "citation": "At inference time, we use the VGG network for calculating LPIPS #REFR after normalizing pixel values to [-1,1].", "text_before_citation": ["We firstly provide experimental details general to all the settings, then present contents specific to different settings.", "Common configurations As for training, we use a batch size of 16 object instances, with the number of rays sampled for each object set to 128 and 256 for pretraining and fine tuning, respectively.", "The coefficient \u03bb for loss term L mrvm is set to 0.1 at pretraining stage."], "text_after_citation": ["We perform ray casting, sampling and volume rendering all in the world coordinate. All the models are implemented using Pytorch #OTHEREFR framework.", "For all the settings performed on synthetic datasets except for DTU, note that the images in synthetic dataset all have a blank background, we adopt two technics for better performance: i) We use bounding box sampling strategy at pretraining stage.", "The training rays are only sampled within the bounding box of the foreground object.", "In this way, it avoids the model to be too empty at initial stage.", "ii) We assign a white background color for those pixels sampled from the background to match the renderings in ShapeNet dataset."], "citing_paper_content": {"title": "Mrvm-Nerf: Mask-Based Pretraining For Neural Radiance Fields", "abstract": "Most Neural Radiance Fields (NeRFs) have poor generalization ability, limiting their application when representing multiple scenes by a single model. To ameliorate this problem, existing methods simply condition NeRF models on image features, lacking the global understanding and modeling of the entire 3D scene. Inspired by the significant success of mask-based modeling in other research fields, we propose a masked ray and view modeling method for generalizable NeRF (MRVM-NeRF), the first attempt to incorporate mask-based pretraining into 3D implicit representations. Specifically, considering that the core of NeRFs lies in modeling 3D representations along the rays and across the views, we randomly mask a proportion of sampled points along the ray at fine stage by discarding partial information obtained from multi-viewpoints, targeting at predicting the corresponding features produced in the coarse branch. In this way, the learned prior knowledge of 3D scenes during pretraining helps the model generalize better to novel scenarios after finetuning. Extensive experiments demonstrate the superiority of our proposed MRVM-NeRF under various synthetic and real-world settings, both qualitatively and quantitatively. Our empirical studies reveal the effectiveness of our proposed innovative MRVM which is specifically designed for NeRF models."}, "cited_paper_content": {"title": "The Unreasonable Effectiveness Of Deep Features As A Perceptual Metric", "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on the ImageNet classification task has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called\"perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new Full Reference Image Quality Assessment (FR-IQA) dataset of perceptual human judgments, orders of magnitude larger than previous datasets. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by huge margins. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations."}, "keywords": ["normalizing pixel values", "VGG network"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To evaluate the effectiveness of our proposed innovative MRVM, we compare it with classic metrics and find that deep features outperform all previous metrics by huge margins #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To incorporate prior knowledge of 3D scenes during pretraining, MRVM-NeRF randomly masks a proportion of sampled points along the ray at the fine stage by discarding partial information obtained from multi-viewpoints, targeting at predicting the corresponding features produced in the coarse branch (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the performance of our proposed MRVM-NeRF, we compare it with classic metrics and find that deep features, including those from the VGG network, outperform all previous metrics by huge margins, as demonstrated in the Full Reference Image Quality Assessment dataset of perceptual human judgments introduced in #REFR.", "given_citation_intent": "method", "given_keywords": ["normalizing pixel values", "VGG network"]}]}
{"citing_id": "2303.05511v1", "cited_id": "1406.2661", "section_title": "Related Works", "citation": "GANs #REFR have been one of the primary families of generative models for natural image synthesis.", "text_before_citation": ["While these models exhibit unprecedented image synthesis ability, they require timeconsuming iterative processes to achieve high-quality image sampling.", "To accelerate the sampling, several methods propose to reduce the sampling steps #OTHEREFR or reuse pre-computed features #OTHEREFR .", "Latent Diffusion Model (LDM) #OTHEREFR performs the reverse processes in lowdimensional latent space instead of pixel space.", "However, consecutive reverse processes are still computationally expensive, limiting the usage of large-scale text-to-image models for interactive applications.", "GAN-based image synthesis."], "text_after_citation": ["As the sampling quality and diversity of GANs improve [39-42, 44, 72, 84] , GANs have been deployed to various computer vision and graphics applications, such as text-to-image synthesis #OTHEREFR , image-to-image translation #OTHEREFR , and image editing #OTHEREFR .", "Notably, StyleGAN-family models #OTHEREFR have shown impressive ability in image synthesis tasks for single-category domains #OTHEREFR 112] .", "Other works have explored class-conditional GANs #OTHEREFR on datasets with a fixed set of object categories.", "In this paper, we change the data regimes from single-or multi-categories datasets to extremely data-rich situations.", "We make the first expedition toward training a large-scale GAN for text-to-image generation on a vast amount of webcrawled text and image pairs, such as LAION2B-en #OTHEREFR and COYO-700M #OTHEREFR ."], "citing_paper_content": {"title": "Scaling Up Gans For Text-To-Image Synthesis", "abstract": "The recent success of text-to-image synthesis has taken the world by storm and captured the general public's imagination. From a technical standpoint, it also marked a drastic change in the favored architecture to design generative image models. GANs used to be the de facto choice, with techniques like StyleGAN. With DALL\u2022E 2, autoregressive and diffusion models became the new standard for largescale generative models overnight. This rapid shift raises a fundamental question: can we scale up GANs to benefit from large datasets like LAION? We find that na\u00efvely increasing the capacity of the StyleGAN architecture quickly becomes unstable. We introduce GigaGAN, a new GAN architecture that far exceeds this limit, demonstrating GANs as a viable option for text-to-image synthesis. GigaGAN offers three major advantages. First, it is orders of magnitude faster at inference time, taking only 0.13 seconds to synthesize a 512px image. Second, it can synthesize high-resolution images, for example, 16-megapixel images in 3.66 seconds. Finally, GigaGAN supports various latent space editing applications such as latent interpolation, style mixing, and vector arithmetic operations."}, "cited_paper_content": {"title": "Generative Adversarial Nets", "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."}, "keywords": ["GANs", "generative models"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To accelerate the sampling, several methods propose to reduce the sampling steps or reuse pre-computed features. Latent Diffusion Model (LDM) performs the reverse processes in low-dimensional latent space instead of pixel space. However, consecutive reverse processes are still computationally expensive, limiting the usage of large-scale text-to-image models for interactive applications. GAN-based image synthesis has been proposed as an alternative approach #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "GAN-based image synthesis has been widely used for generating high-quality images. The proposed framework in #REFR introduces a new approach for estimating generative models via an adversarial process, which has shown potential in qualitative and quantitative evaluation of the generated samples.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "GAN-based image synthesis has been widely used in recent years to generate high-quality images. The proposed framework in #REFR for estimating generative models via an adversarial process has shown great potential in capturing the data distribution and generating high-quality samples.", "given_citation_intent": "background", "given_keywords": ["GANs", "generative models"]}]}
{"citing_id": "2303.11120v1", "cited_id": "1905.11946", "section_title": "Puzzle Solving", "citation": "We use EfficientNet #REFR as the task-specific backbone to extract the patch visual features h i and we train the diffusion model with T = 300 and sample it with inference ratio r = 10.", "text_before_citation": ["We evaluate the performance of Positional Diffusion using the Direct Comparison Metric #OTHEREFR , a percentage that indicates the number of correctly ordered pieces over the full test set. A higher score indicates better performance. Implementation Details.", "We divide an image in n \u00d7 n patches, resulting a total of K = n 2 elements.", "We divide a 2D space with a range of (-1,-1), (1,1) into a grid of n \u00d7 n cells.", "We use the centers of the cells as starting positions X for the patches.", "The input data for puzzle solving are the pixel values for each patch, resized to 32x32."], "text_after_citation": ["We train a single model with all puzzle sizes simultaneously.", "At inference, we arrange the patches by mapping each estimated patch positionx i to a cell in the grid.", "We measure the distance between each patch position and cells' centers, and assign each patch to its closest cell, mapping each cell to at most one patch.", "By using a greedy approach that prioritizes the assignment between cells-patch pairs starting from those with the lowest distance, we ensure that the most confident prediction will be assigned first, increasing the prediction robustness to noise. Comparisons.", "We compared Positional Diffusion against a set of SOTA methods for puzzle solving."], "citing_paper_content": {"title": "Positional Diffusion: Ordering Unordered Sets With Diffusion Probabilistic Models", "abstract": "Positional reasoning is the process of ordering unsorted parts contained in a set into a consistent structure. We present Positional Diffusion, a plug-and-play graph formulation with Diffusion Probabilistic Models to address positional reasoning. We use the forward process to map elements' positions in a set to random positions in a continuous space. Positional Diffusion learns to reverse the noising process and recover the original positions through an Attention-based Graph Neural Network. We conduct extensive experiments with benchmark datasets including two puzzle datasets, three sentence ordering datasets, and one visual storytelling dataset, demonstrating that our method outperforms long-lasting research on puzzle solving with up to +18% compared to the second-best deep learning method, and performs on par against the state-of-the-art methods on sentence ordering and visual storytelling. Our work highlights the suitability of diffusion models for ordering problems and proposes a novel formulation and method for solving various ordering tasks. Project website at https://iitpavis.github.io/Positional Diffusion/"}, "cited_paper_content": {"title": "Efficientnet: Rethinking Model Scaling For Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. ::: To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."}, "keywords": ["diffusion model", "EfficientNet"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We evaluate the performance of Positional Diffusion using the Direct Comparison Metric #OTHEREFR, a percentage that indicates the number of correctly ordered pieces over the full test set. A higher score indicates better performance. Implementation Details. We divide an image in n \u00d7 n patches, resulting a total of K = n 2 elements. We divide a 2D space with a range of (-1,-1), (1,1) into a grid of n \u00d7 n cells. We use the centers of the cells as starting positions X for the patches. The input data for puzzle solving are the pixel values for each patch, resized to 32x32. To achieve state-of-the-art accuracy on ordering tasks, we use EfficientNets, a family of models proposed by Tan and Le in their paper \"Efficientnet: Rethinking Model Scaling For Convolutional Neural Networks\" #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To solve the positional reasoning problem, we propose a novel formulation and method using Positional Diffusion, a plug-and-play graph formulation with Diffusion Probabilistic Models, which learns to reverse the noising process and recover the original positions through an Attention-based Graph Neural Network #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the positional reasoning problem, we propose a novel plug-and-play graph formulation with Diffusion Probabilistic Models, which has shown to be suitable for ordering problems and outperforms the state-of-the-art methods on various ordering tasks #REFR, while EfficientNet has been shown to achieve much better accuracy and efficiency than previous ConvNets.", "given_citation_intent": "method", "given_keywords": ["diffusion model", "EfficientNet"]}]}
{"citing_id": "2303.13652v1", "cited_id": "1512.03385", "section_title": "Transnet", "citation": "By converting coordinates to heatmaps, we can exploit the strong feature extraction power of ResNet #REFR as ResNet takes tensor inputs, not vector inputs.", "text_before_citation": ["When a hand is in neutral pose and the other one is in fist pose, their 3D relative depth can be zero although the hand with fist pose takes smaller area.", "Hence, pose is necessary to determine z of the 3D relative translation.", "Please note that the 2D affine transformations do not affect the depths of each 2.5D pose; hence, the depths of each 2.5D pose still represent the root joint-relative depths of each hand.", "We denote the transformed P r and P l by P \u2032 r and P \u2032 l , respectively.", "The 2.5D pose of the right hand P \u2032 r and left hand P \u2032 l are converted to 2.5D Gaussian heatmaps by making a Gaussian blob around the coordinates."], "text_after_citation": ["Then, we concatenate the 2.5D Gaussian heatmap of two hands in a channel dimension, denoted by H \u2208 R 2J\u00d7D\u00d7H\u00d7W .", "D, H, and W represent the depth, height, and width of the 2.5D heatmap, respectively, and we set them to 64. Output: 3D relative translation between two hands.", "We predict the 3D relative translation between two hands t \u2208 R 3 from the 2.5D Gaussian heatmap H.", "We pass H to ResNet-18 #OTHEREFR , which produces a feature map F \u2208 R C\u00d7H/8\u00d7W/8 . C = 512 represents the channel dimension of F.", "We use the original ResNet-18 after dropping the first convolutional block to reduce the downsampling and the last fully-connected layers."], "citing_paper_content": {"title": "Bringing Inputs To Shared Domains For 3D Interacting Hands Recovery In The Wild", "abstract": "Despite recent achievements, existing 3D interacting hands recovery methods have shown results mainly on motion capture (MoCap) environments, not on in-the-wild (ITW) ones. This is because collecting 3D interacting hands data in the wild is extremely challenging, even for the 2D data. We present InterWild, which brings MoCap and ITW samples to shared domains for robust 3D interacting hands recovery in the wild with a limited amount of ITW 2D/3D interacting hands data. 3D interacting hands recovery consists of two sub-problems: 1) 3D recovery of each hand and 2) 3D relative translation recovery between two hands. For the first sub-problem, we bring MoCap and ITW samples to a shared 2D scale space. Although ITW datasets provide a limited amount of 2D/3D interacting hands, they contain large-scale 2D single hand data. Motivated by this, we use a single hand image as an input for the first sub-problem regardless of whether two hands are interacting. Hence, interacting hands of MoCap datasets are brought to the 2D scale space of single hands of ITW datasets. For the second sub-problem, we bring MoCap and ITW samples to a shared appearance-invariant space. Unlike the first subproblem, 2D labels of ITW datasets are not helpful for the second sub-problem due to the 3D translation's ambiguity. Hence, instead of relying on ITW samples, we amplify the generalizability of MoCap samples by taking only a geometric feature without an image as an input for the second sub-problem. As the geometric feature is invariant to appearances, MoCap and ITW samples do not suffer from a huge appearance gap between the two datasets. The code is publicly available 1 ."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["strong feature extraction", "ResNet"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The 2.5D pose of the right hand P \u2032 r and left hand P \u2032 l are converted to 2.5D Gaussian heatmaps by making a Gaussian blob around the coordinates, following the approach presented in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of recovering 3D interacting hands in the wild, the authors propose a method that brings MoCap and ITW samples to shared domains, leveraging a single hand image as input for the first sub-problem and a geometric feature for the second sub-problem, achieving robust results with limited ITW data (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform strong feature extraction, we use a ResNet-based architecture as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["strong feature extraction", "ResNet"]}]}
{"citing_id": "2303.08290v1", "cited_id": "1511.05942", "section_title": "Related Work", "citation": "Ironically, because it can handle raw EHR data without any preprocessing or feature selection, UniHPF generates extremely long embedded data, given how it encodes entire EHR data in a text-encoding fashion #REFR .", "text_before_citation": ["This is a clear limitation in that extensive human labor and clinical domain knowledge are required to produce satisfactory model performance.", "Universal Healthcare Predictive Framework Recently, #OTHEREFR presented UniHPF, a universal framework that can embed entire features of raw EHR regardless of schema and medical code standard used in the database.", "Specifically, UniHPF views EHR data as pure text and flattened the EHR tables (e.g.", "prescriptions, lab results) to feed them to Transformer-based text encoders.", "This text-based approach showed comparable if not better performance compared to conventional approaches on various predictive tasks, even without relying on medical domain knowledge."], "text_after_citation": ["This imposes strong computational limits on the framework and necessitates an additional module for compressing the embedded data to a smaller size."], "citing_paper_content": {"title": "Rediscovery Of Cnn'S Versatility For Text-Based Encoding Of Raw Electronic Health Records", "abstract": "Making the most use of abundant information in electronic health records (EHR) is rapidly becoming an important topic in the medical domain. Recent work presented a promising framework that embeds entire features in raw EHR data regardless of its form and medical code standards. The framework, however, only focuses on encoding EHR with minimal preprocessing and fails to consider how to learn efficient EHR representation in terms of computation and memory usage. In this paper, we search for a versatile encoder not only reducing the large data into a manageable size but also well preserving the core information of patients to perform diverse clinical tasks. We found that hierarchically structured Convolutional Neural Network (CNN) often outperforms the state-of-the-art model on diverse tasks such as reconstruction, prediction, and generation, even with fewer parameters and less training time. Moreover, it turns out that making use of the inherent hierarchy of EHR data can boost the performance of any kind of backbone models and clinical tasks performed. Through extensive experiments, we present concrete evidence to generalize our research findings into real-world practice. We give a clear guideline on building the encoder based on the research findings captured while exploring numerous settings."}, "cited_paper_content": {"title": "Doctor Ai: Predicting Clinical Events Via Recurrent Neural Networks", "abstract": "Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79% recall@30, significantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy."}, "keywords": ["raw EHR data", "entire EHR data"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "This is a clear limitation in that extensive human labor and clinical domain knowledge are required to produce satisfactory model performance. Universal Healthcare Predictive Framework Recently, UniHPF presented a universal framework that can embed entire features of raw EHR regardless of schema and medical code standard used in the database. Specifically, UniHPF views EHR data as pure text and flattened the EHR tables (e.g. prescriptions, lab results) to feed them to Transformer-based text encoders. This text-based approach showed comparable if not better performance compared to conventional approaches on various predictive tasks, even without relying on medical domain knowledge. To further improve the performance of EHR-based predictive models, Doctor AI, a generic predictive model that covers observed medical conditions and medication uses, was developed using recurrent neural networks (RNN) and applied to longitudinal time stamped EHR data from 260K patients over 8 years. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "This text-based approach showed comparable if not better performance compared to conventional approaches on various predictive tasks, even without relying on medical domain knowledge. However, to further improve the performance of predictive models, leveraging large historical data in electronic health record (EHR) could be a promising direction. #REFR provides a generic predictive model, Doctor AI, that covers observed medical conditions and medication uses, and is developed using recurrent neural networks (RNN) applied to longitudinal time-stamped EHR data from 260K patients over 8 years.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, UniHPF was proposed as a universal framework that can embed entire features of raw EHR data regardless of schema and medical code standard used in the database, achieving comparable if not better performance compared to conventional approaches on various predictive tasks, even without relying on medical domain knowledge (#REFR).", "given_citation_intent": "background", "given_keywords": ["raw EHR data", "entire EHR data"]}]}
{"citing_id": "2304.09941v1", "cited_id": "1412.6980", "section_title": "Model And Training Details", "citation": "For all models, we used a batch size of 1 image pair and the Adam optimizer #REFR We analyze the performance of baselines and our proposed KeyMorph under conditions of large initial misalignments in terms of rotation. Fig.", "text_before_citation": ["We train six variants of KeyMorph (KM) corresponding to six pre-determined transformations: 1 model using an affine transformation and 5 models using a TPS transformation with \u03bb \u2208 {0, 0.01, 0.1, 1, 10}. We refer to these models as KM-Aff and KM-TPS-\u03bb.", "Additionally, we train a variant using a TPS transformation where \u03bb is sampled stochastically during training from a log-uniform distribution p(\u03bb) = LogUni f (0, 10). We refer to this model as KM-LogUnif.", "We used N = 128 keypoints throughout our experiments, and analyze the effect of changing this number in Section 6.2."], "text_after_citation": ["3 plots overall Dice across rotation angle of the moving image for baselines and two variants of KeyMorph: KM-Aff and KM-TPS-0.", "We find that all DLIR models suffer substantially as the rotation angle increases.", "Training with aggressive augmentation increases performance for test pairs with large misalignments, but reduces the accuracy for those with smaller misalignments. Using supervision (dashed DLIR lines) leads to improved accuracy.", "For unimodal registration, the DLIR model that was trained with all modalities (DLIR-Multi) did not produce better accuracy than a model that was trained with each modality separately.", "ANTs yields excellent results when the initial misalignment is small (e.g. near 0 degrees of rotation)."], "citing_paper_content": {"title": "A Robust And Interpretable Deep Learning Framework For Multi-Modal Registration Via Keypoints", "abstract": "We present KeyMorph, a deep learning-based image registration framework that relies on automatically detecting corresponding keypoints. State-of-the-art deep learning methods for registration often are not robust to large misalignments, are not interpretable, and do not incorporate the symmetries of the problem. In addition, most models produce only a single prediction at test-time. Our core insight which addresses these shortcomings is that corresponding keypoints between images can be used to obtain the optimal transformation via a differentiable closed-form expression. We use this observation to drive the end-to-end learning of keypoints tailored for the registration task, and without knowledge of ground-truth keypoints. This framework not only leads to substantially more robust registration but also yields better interpretability, since the keypoints reveal which parts of the image are driving the final alignment. Moreover, KeyMorph can be designed to be equivariant under image translations and/or symmetric with respect to the input image ordering. Finally, we show how multiple deformation fields can be computed efficiently and in closed-form at test time corresponding to different transformation variants. We demonstrate the proposed framework in solving 3D affine and spline-based registration of multi-modal brain MRI scans. In particular, we show registration accuracy that surpasses current state-of-the-art methods, especially in the context of large displacements. Our code is available at https://github.com/evanmy/keymorph."}, "cited_paper_content": {"title": "Adam: A Method For Stochastic Optimization", "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."}, "keywords": ["large initial misalignments", "Adam optimizer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We train six variants of KeyMorph (KM) corresponding to six pre-determined transformations: 1 model using an affine transformation and 5 models using a TPS transformation with \u03bb \u2208 {0, 0.01, 0.1, 1, 10}. We refer to these models as KM-Aff and KM-TPS-\u03bb. Additionally, we train a variant using a TPS transformation where \u03bb is sampled stochastically during training from a log-uniform distribution p(\u03bb) = LogUni f (0, 10). We refer to this model as KM-LogUnif. We used N = 128 keypoints throughout our experiments, and analyze the effect of changing this number in Section 6.2. #REFR introduced a computationally efficient algorithm for first-order gradient-based optimization of stochastic objective functions, which could be useful for optimizing the KeyMorph framework.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We implemented the Adam algorithm for first-order gradient-based optimization of stochastic objective functions, which is computationally efficient and well-suited for problems that are large in terms of data and/or parameters, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of large initial misalignments, we use KeyMorph, a deep learning-based image registration framework that relies on automatically detecting corresponding keypoints and obtains the optimal transformation via a differentiable closed-form expression #REFR. Moreover, we compare our method with other stochastic optimization methods and demonstrate that KeyMorph works well in practice, especially in the context of large displacements, by achieving state-of-the-art registration accuracy using the Adam optimizer.", "given_citation_intent": "method", "given_keywords": ["large initial misalignments", "Adam optimizer"]}]}
{"citing_id": "2304.14204v1", "cited_id": "1901.07042", "section_title": "Results", "citation": "Since there are no available reported results of existing methods on the IRR task on MIMIC-CXR #REFR , we compare MOTOR and its variants for analyzing the impact of different components in MOTOR deeply. We present the results in Table 1 .", "text_before_citation": ["For multi-modal pretraining in the natural image domain #OTHEREFR , #OTHEREFR , #OTHEREFR , the image-text retrieval task is a simple and effective way to evaluate the crossmodal understanding ability of pretrained models.", "Therefore, we develop an image-report retrieval (IRR) task in our benchmark.", "Two subtasks are included in IRR: report retrieval (RR), where images and reports are queries and targets, respectively; and image retrieval (IR), where reports are queries and images are targets.", "The R@K (recall with top k predictions) metric is used for the performance evaluation for both subtasks.", "We directly use the pretraining dataset MIMIC-CXR #OTHEREFR for evaluating the IRR performance under both zero-shot and finetuning settings."], "text_after_citation": ["Table 1 comprehensively show the effectiveness of each method component of MOTOR.", "Moreover, the significant performance superiority of MOTOR over other variants under the zero-shot setting sufficiently demonstrates the excellent generalization ability of MOTOR.", "Concretely, under the zero-shot setting, \"MOTOR w GK/SK\" outperforms \"MOTOR w/o knowledge\" by a large margin.", "This demonstrates that both the general and specific knowledge can improve the medical multi-modal pretraining.", "Moreover, the performance improvement of \"MOTOR w GK/SK\" over \"MOTOR w GK+SK\" reveals that the general and specific knowledge can complement each other well."], "citing_paper_content": {"title": "Towards Medical Artificial General Intelligence Via Knowledge-Enhanced Multimodal Pretraining", "abstract": "Medical artificial general intelligence (MAGI) enables one foundation model to solve different medical tasks, which is very practical in the medical domain. It can significantly reduce the requirement of large amounts of task-specific data by sufficiently sharing medical knowledge among different tasks. However, due to the challenges of designing strongly generalizable models with limited and complex medical data, most existing approaches tend to develop task-specific models. To take a step towards MAGI, we propose a new paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In MOTOR, we combine two kinds of basic medical knowledge, i.e., general and specific knowledge, in a complementary manner to boost the general pretraining process. As a result, the foundation model with comprehensive basic knowledge can learn compact representations from pretraining radiographic data for better cross-modal alignment, i.e., matching the medical data of different modalities with the same semantic meanings. MOTOR unifies the understanding and generation, which are two kinds of core intelligence of an AI system, into a single medical foundation model, to flexibly handle more diverse medical tasks. To enable a comprehensive evaluation and facilitate future research, we construct a medical multimodal benchmark including a wide range of downstream tasks, such as chest x-ray report generation and medical visual question answering. Extensive experiments on our benchmark show that MOTOR obtains promising results through simple task-oriented adaptation. The visualization shows that the injected knowledge successfully highlights key information in the medical data, demonstrating the excellent interpretability of MOTOR. Our MOTOR successfully mimics the human practice of fulfilling a \"medical student\" to accelerate the process of becoming a \"specialist\". We believe that our work makes a significant stride in realizing MAGI."}, "cited_paper_content": {"title": "Mimic-Cxr-Jpg, A Large Publicly Available Database Of Labeled Chest Radiographs", "abstract": "Chest radiography is an extremely powerful imaging modality, allowing for a detailed inspection of a patient's thorax, but requiring specialized training for proper interpretation. With the advent of high performance general purpose computer vision algorithms, the accurate automated analysis of chest radiographs is becoming increasingly of interest to researchers. However, a key challenge in the development of these techniques is the lack of sufficient data. Here we describe MIMIC-CXR-JPG v2.0.0, a large dataset of 377,110 chest x-rays associated with 227,827 imaging studies sourced from the Beth Israel Deaconess Medical Center between 2011 - 2016. Images are provided with 14 labels derived from two natural language processing tools applied to the corresponding free-text radiology reports. MIMIC-CXR-JPG is derived entirely from the MIMIC-CXR database, and aims to provide a convenient processed version of MIMIC-CXR, as well as to provide a standard reference for data splits and image labels. All images have been de-identified to protect patient privacy. The dataset is made freely available to facilitate and encourage a wide range of research in medical computer vision."}, "keywords": ["IRR task", "MIMIC-CXR"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We directly use the pretraining dataset MIMIC-CXR-JPG v2.0.0 #REFR for evaluating the IRR performance under both zero-shot and finetuning settings.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We directly use the pretraining dataset MIMIC-CXR from the reference paper for evaluating the IRR performance under both zero-shot and finetuning settings #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We directly use the pretraining dataset MIMIC-CXR for evaluating the IRR performance under both zero-shot and finetuning settings, achieving promising results as reported in Mimic-Cxr-Jpg, A Large Publicly Available Database Of Labeled Chest Radiographs. #REFR", "given_citation_intent": "result", "given_keywords": ["IRR task", "MIMIC-CXR"]}]}
{"citing_id": "2304.01906v1", "cited_id": "1906.02635", "section_title": "Model Specification", "citation": "The softmax form of marginal and conditional probabilities in Equation #REFR suggests a way to model V : estimate both W uK (i)s and T uis using linear functional forms as in the conditional logit model with nest observables and item observables, respectively.", "text_before_citation": ["The likelihood in Equation (15) decomposes into a marginal probability of choosing nest K (i) and a conditional probability of choosing i given nest K (i) is chosen.", "P(i | u, s) = exp T uis /\u03bb K (i) \u2211 j\u2208I K (i) exp T u js /\u03bb K (i) conditional prob.", "of item exp W uK (i)s + \u03bb K (i) I uK (i)s \u2211 K k=1 exp (W uks + \u03bb k I uks )", "marginal prob.", "of nest #OTHEREFR The inclusive value of nest k (for user u in session s), denoted as I uks , is defined as log \u2211 j\u2208I k exp(T u js /\u03bb k ), which is the expected utility from choosing the best alternative from nest k given Gumbel error term in utility."], "text_after_citation": ["#OTHEREFR A set of nests is a partition of item sets.", "When the model requires the user to choose only one item across all partitions each time, these partitions are called nests.", "When such a requirement is removed, the model allows users to choose an item from every partition, these partitions are referred to as categories.", "#OTHEREFR Our nested logit setup can be constrasted with modeling multiple categories using the multinomial logit in torch-choice, where we model choice over multiple categories simultaneously, and the user chooses one item from each category simultaneously.", "In the future we aim to support modeling choice over multiple categories where each category can include a two level nested logit."], "citing_paper_content": {"title": "Torch-Choice: A Pytorch Package For Large-Scale Choice Modelling With Python", "abstract": "The torch-choice is an open-source library for flexible, fast choice modeling with Python and PyTorch. torch-choice provides a ChoiceDataset data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a ChoiceDataset from databases of various formats and functionalities of ChoiceDataset. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of torch-choice and mlogit in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) the expansion of item sets. Finally, we demonstrate the scalability of torch-choice on large-scale datasets. Keywords choice modelling \u2022 Python \u2022 PyTorch \u2022 large scale dataset \u2022 GPU acceleration Recent years have seen the proliferation of various tools and software packages that go a long way in making it easy to estimate the parameters of choice models. While each of these have their particular strengths, there are important limitations of these packages when they are used with the goal of building flexible, fast choice models which scale to massive data."}, "cited_paper_content": {"title": "Counterfactual Inference For Consumer Choice Across Many Product Categories", "abstract": "This paper proposes a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel. The consumer's utility is additive in the different categories. Her preferences about product attributes as well as her price sensitivity vary across products and are in general correlated across products. We build on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock. We evaluate the performance of the model using held-out data from weeks with price changes or out of stock products. We show that our model improves over traditional modeling approaches that consider each category in isolation. One source of the improvement is the ability of the model to accurately estimate heterogeneity in preferences (by pooling information across categories); another source of improvement is its ability to estimate the preferences of consumers who have rarely or never made a purchase in a given category in the training data. Using held-out data, we show that our model can accurately distinguish which consumers are most price sensitive to a given product. We consider counterfactuals such as personally targeted price discounts, showing that using a richer model such as the one we propose substantially increases the benefits of personalization in discounts."}, "keywords": ["conditional logit model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors propose a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel, and build on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock. Using held-out data, they show that their model can accurately distinguish which consumers are most price sensitive to a given product. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors proposed a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel, and built on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The conditional logit model used in this study is extended to account for time-varying product attributes and products going out of stock, building on techniques from the machine learning literature on probabilistic models of matrix factorization, as proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["conditional logit model"]}]}
{"citing_id": "2303.01614v1", "cited_id": "1710.11040", "section_title": "Introduction", "citation": "These risk metrics should satisfy certain axioms in order to be well-defined as well as to enable practical use in robotic applications #REFR .", "text_before_citation": ["In #OTHEREFR , the authors learn a speed-map representation given semantic information while in #OTHEREFR , the authors use a self-supervised learning-based terrain roughness classifier.", "In #OTHEREFR , the authors proposed a neural network architecture for learning the distribution of traversability costs arising from geometric risks using the pointcloud obtained from a LiDAR in a supervised manner.", "In this paper, we build upon the traversability analyses of classical geometric methods, while using semantic information from a LiDAR and incorporating the uncertainty of these methods for risk-aware planning #OTHEREFR .", "Risk can be incorporated into motion planning using a variety of different methods, including chance constraints #OTHEREFR , exponential utility functions #OTHEREFR , distributional robustness #OTHEREFR , and quantile regression #OTHEREFR .", "Risk measures, often used in finance and operations research, provide a mapping from a random variable (usually the cost) to a real number."], "text_after_citation": ["Conditional value-at-risk (CVaR) is one such risk measure that has this desirable set of properties, and is a part of a class of risk metrics known as coherent risk measures #OTHEREFR .", "Coherent risk measures have been used in a variety of decision making problems, especially Markov decision processes (MDPs) #OTHEREFR .", "Coherent risk measures have been used in a MPC framework when the system model is uncertain #OTHEREFR , when the uncertainty is a result of measurement noise or moving obstacles #OTHEREFR , and when the uncertainty arises from both measurement and process noise #OTHEREFR .", "Our work extends CVaR risk to a risk-based planning framework which utilizes different sources of traversability risk (such as collision risk, step risk, slippage risk, etc.) Morever, this paper introduces the first field-hardened and theoretically grounded approach to traversability assessment and risk-constrained planning using CVaR metrics.", "Using CVaR to assess traversability risks allows us to dynamically tune the entire system's behavior -from aggressive to highly conservative -by changing a single value, the risk level."], "citing_paper_content": {"title": "Step: Stochastic Traversability Evaluation And Planning For Risk-Aware Off-Road Navigation; Results From The Darpa Subterranean Challenge", "abstract": "Although autonomy has gained widespread usage in structured and controlled environments, robotic autonomy in unknown and off-road terrain remains a difficult problem. Extreme, off-road, and unstructured environments such as undeveloped wilderness, caves, rubble, and other post-disaster sites pose unique and challenging problems for autonomous navigation. Based on our participation in the DARPA Subterranean Challenge, we propose an approach to improve autonomous traversal of robots in subterranean environments that are perceptually degraded and completely unknown through a traversability and planning framework called STEP (Stochastic Traversability Evaluation and Planning). We present 1) rapid uncertainty-aware mapping and traversability evaluation, 2) tail risk assessment using the Conditional Value-at-Risk (CVaR), 3) efficient risk and constraint-aware kinodynamic motion planning using sequential quadratic programming-based (SQP) model predictive control (MPC), 4) fast recovery behaviors to account for unexpected scenarios that may cause failure, and 5) risk-based gait adaptation for quadrupedal robots. We illustrate and validate extensive results from our experiments on wheeled and legged robotic platforms in field studies at the Valentine Cave, CA (cave environment), Kentucky Underground, KY (mine environment), and Louisville Mega Cavern, KY (final competition site for the DARPA Subterranean Challenge with tunnel, urban, and cave environments)."}, "cited_paper_content": {"title": "How Should A Robot Assess Risk? Towards An Axiomatic Theory Of Risk In Robotics", "abstract": "Endowing robots with the capability of assessing risk and making risk-aware decisions is widely considered a key step toward ensuring safety for robots operating under uncertainty. But, how should a robot quantify risk? A natural and common approach is to consider the framework whereby costs are assigned to stochastic outcomes\u2013an assignment captured by a cost random variable. Quantifying risk then corresponds to evaluating a risk metric, i.e., a mapping from the cost random variable to a real number. Yet, the question of what constitutes a \u201cgood\u201d risk metric has received little attention within the robotics community. The goal of this paper is to explore and partially address this question by advocating axioms that risk metrics in robotics applications should satisfy in order to be employed as rational assessments of risk. We provide instantiations of the class of risk metrics that satisfy these axioms (referred to as distortion risk metrics) and also discuss pitfalls of commonly used risk metrics in robotics that do not satisfy these axioms. Our hope is that the ideas presented here will lead to a foundational framework for quantifying risk (and hence safety) in robotics applications."}, "keywords": ["robotic applications", "risk metrics"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Risk measures, often used in finance and operations research, provide a mapping from a random variable (usually the cost) to a real number. To ensure safety for robots operating under uncertainty, the authors of #REFR advocate for axioms that risk metrics in robotics applications should satisfy in order to be employed as rational assessments of risk.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Risk measures, often used in finance and operations research, provide a mapping from a random variable (usually the cost) to a real number, and the authors of this paper propose axioms that risk metrics in robotics applications should satisfy in order to be employed as rational assessments of risk #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Risk measures, often used in finance and operations research, provide a mapping from a random variable (usually the cost) to a real number, and are essential for rational assessments of risk in robotic applications #REFR.", "given_citation_intent": "background", "given_keywords": ["robotic applications", "risk metrics"]}]}
{"citing_id": "2305.02649v1", "cited_id": "1906.05113", "section_title": "I. Introduction", "citation": "Planning a safe, comfortable, and efficient trajectory for a self-driving vehicle (SDV) in complex urban environments is a challenging and critical task in autonomous driving #REFR .", "text_before_citation": [], "text_after_citation": ["Unlike highway driving #OTHEREFR , urban driving requires handling various road geometries, such as roundabouts and intersections, while interacting with traffic lights, pedestrians, and other vehicles.", "Conventional rule-based approaches #OTHEREFR have achieved some success in industry but require extensive human engineering to deal with diverse real-world scenarios.", "Recent advances in deep learning techniques have motivated researchers #OTHEREFR to employ neural networks to model complex driving policies.", "Imitation learning (IL) from human drivers' demonstrations is a promising solution for learning these policies, as experienced drivers can handle even the most difficult situations, and their driving data can be easily collected at scale.", "The simplest IL algorithm is the behavior cloning (BC) method, which has wide applications in autonomous driving #OTHEREFR ."], "citing_paper_content": {"title": "Ccil: Context-Conditioned Imitation Learning For Urban Driving", "abstract": "Imitation learning holds great promise for addressing the complex task of autonomous urban driving, as experienced human drivers can navigate highly challenging scenarios with ease. While behavior cloning is a widely used imitation learning approach in autonomous driving due to its exemption from risky online interactions, it suffers from the covariate shift issue. To address this limitation, we propose a context-conditioned imitation learning approach that employs a policy to map the context state into the ego vehicle's future trajectory, rather than relying on the traditional formulation of both ego and context states to predict the ego action. Additionally, to reduce the implicit ego information in the coordinate system, we design an ego-perturbed goal-oriented coordinate system. The origin of this coordinate system is the ego vehicle's position plus a zero mean Gaussian perturbation, and the x-axis direction points towards its goal position. Our experiments on the real-world large-scale Lyft and nuPlan datasets show that our method significantly outperforms state-of-the-art approaches."}, "cited_paper_content": {"title": "A Survey Of Autonomous Driving: Common Practices And Emerging Technologies", "abstract": "Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise. The full potential of ADSs cannot be realized unless the robustness of state-of-the-art improved further. This paper discusses unsolved problems and surveys the technical aspect of automated driving. Studies regarding present challenges, high-level system architectures, emerging methodologies and core functions: localization, mapping, perception, planning, and human machine interface, were thoroughly reviewed. Furthermore, the state-of-the-art was implemented on our own platform and various algorithms were compared in a real-world driving setting. The paper concludes with an overview of available datasets and tools for ADS development."}, "keywords": ["autonomous driving"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the covariate shift issue in behavior cloning, the authors propose a context-conditioned imitation learning approach that maps the context state into the ego vehicle's future trajectory, as opposed to relying on both ego and context states to predict the ego action. This approach was evaluated on real-world datasets and outperformed state-of-the-art methods (Ccil). The authors also provide a comprehensive survey of technical aspects of automated driving, including studies on present challenges, high-level system architectures, and core functions such as perception and planning, which can be useful for future research in this area (A Survey Of Autonomous Driving: Common Practices And Emerging Technologies). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Automated driving systems (ADSs) have the potential to provide a safe, comfortable, and efficient driving experience, but their robustness needs to be improved further to prevent fatalities, as discussed in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Autonomous driving has been a widely researched topic due to its potential to provide a safe and efficient driving experience, but the robustness of state-of-the-art ADSs still needs to be improved further to realize their full potential #REFR.", "given_citation_intent": "background", "given_keywords": ["autonomous driving"]}]}
{"citing_id": "2303.01899v1", "cited_id": "1907.07061", "section_title": "Ii. Related Work", "citation": "The results of these methods follow the findings of #REFR for camera 2D object detectors.", "text_before_citation": ["Their results indicate that synthetic data can replace real-world data to an extent, but proportionately more synthetic than real-world data is required.", "Moreover, synthetic data can be successfully used for network pre-training leading to better performance compared to training on real-world data only #OTHEREFR .", "Similar research to quantify the domain shift has also been conducted for LiDAR point clouds with 3D object detectors. Dworak et al.", "#OTHEREFR train three object detectors with data generated in the simulation environment CARLA and evaluate their performance on the real-world KITTI dataset #OTHEREFR .", "Although networks achieve an mAP of up to 87 % when trained and evaluated on CARLA (\"sim-to-sim\"), the best network only reaches an mAP of 19 % if trained on CARLA and tested on KITTI (\"sim-to-real\"). The authors also experimented with fine-tuning and mixed-data training."], "text_after_citation": ["To evaluate their methods for synthetic LiDAR data generation, Fang et al. #OTHEREFR and Manivasagam et al.", "#OTHEREFR compared their generated data with the CARLA and KITTI datasets by training object detectors and evaluating on KITTI.", "Both works highlight the sim-to-real domain shift between the CARLA and KITTI datasets.", "Yue et al. #OTHEREFR and Spiegel et al.", "#OTHEREFR conduct similar LiDAR sim-to-real comparison experiments but focus on semantic segmentation instead of object detection."], "citing_paper_content": {"title": "Quantifying The Lidar Sim-To-Real Domain Shift: A Detailed Investigation Using Object Detectors And Analyzing Point Clouds At Target-Level", "abstract": "LiDAR object detection algorithms based on neural networks for autonomous driving require large amounts of data for training, validation, and testing. As real-world data collection and labeling are time-consuming and expensive, simulation-based synthetic data generation is a viable alternative. However, using simulated data for the training of neural networks leads to a domain shift of training and testing data due to differences in scenes, scenarios, and distributions. In this work, we quantify the sim-to-real domain shift by means of LiDAR object detectors trained with a new scenario-identical real-world and simulated dataset. In addition, we answer the questions of how well the simulated data resembles the real-world data and how well object detectors trained on simulated data perform on real-world data. Further, we analyze point clouds at the target-level by comparing real-world and simulated point clouds within the 3D bounding boxes of the targets. Our experiments show that a significant sim-to-real domain shift exists even for our scenario-identical datasets. This domain shift amounts to an average precision reduction of around 14 % for object detectors trained with simulated data. Additional experiments reveal that this domain shift can be lowered by introducing a simple noise model in simulation. We further show that a simple downsampling method to model real-world physics does not influence the performance of the object detectors."}, "cited_paper_content": {"title": "How Much Real Data Do We Actually Need: Analyzing Object Detection Performance Using Synthetic And Real Data", "abstract": "In recent years, deep learning models have resulted in a huge amount of progress in various areas, including computer vision. By nature, the supervised training of deep models requires a large amount of data to be available. This ideal case is usually not tractable as the data annotation is a tremendously exhausting and costly task to perform. An alternative is to use synthetic data. In this paper, we take a comprehensive look into the effects of replacing real data with synthetic data. We further analyze the effects of having a limited amount of real data. We use multiple synthetic and real datasets along with a simulation tool to create large amounts of cheaply annotated synthetic data. We analyze the domain similarity of each of these datasets. We provide insights about designing a methodological procedure for training deep networks using these datasets."}, "keywords": ["detectors"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Their results indicate that synthetic data can replace real-world data to an extent, but proportionately more synthetic than real-world data is required. Moreover, synthetic data can be successfully used for network pre-training leading to better performance compared to training on real-world data only #OTHEREFR. Similar research to quantify the domain shift has also been conducted for LiDAR point clouds with 3D object detectors. Dworak et al. (2020) train three object detectors with data generated in the simulation environment CARLA and evaluate their performance on the real-world KITTI dataset. Although networks achieve an mAP of up to 87 % when trained and evaluated on CARLA (\"sim-to-sim\"), the best network only reaches an mAP of 19 % if trained on CARLA and tested on KITTI (\"sim-to-real\"). The authors also experimented with fine-tuning and mixed-data training, but their results suggest that the sim-to-real domain shift can be significantly reduced by introducing a simple noise model in simulation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Their results indicate that synthetic data can replace real-world data to an extent, but proportionately more synthetic than real-world data is required. Moreover, synthetic data can be successfully used for network pre-training leading to better performance compared to training on real-world data only (How Much Real Data Do We Actually Need: Analyzing Object Detection Performance Using Synthetic And Real Data) #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of this manuscript compare the performance of LiDAR object detectors trained on simulated and real-world data and report a significant sim-to-real domain shift, resulting in an average precision reduction of around 14% for object detectors trained with simulated data, which is consistent with the findings of #REFR.", "given_citation_intent": "result", "given_keywords": ["detectors"]}]}
{"citing_id": "2303.09867v1", "cited_id": "1705.00754", "section_title": "Experimental Settings", "citation": "We follow the official split of 1,200 and 670 as the train and test set, respectively. ActivityNet Captions #REFR contains 20,000 YouTube videos.", "text_before_citation": ["Datasets.", "MSRVTT #OTHEREFR contains 10,000 YouTube videos, each with 20 text descriptions.", "We follow the 1k-A split #OTHEREFR with 9,000 videos for training and 1,000 for testing. LSMDC #OTHEREFR contains 118,081 video clips from 202 movies.", "We follow the split of #OTHEREFR with 1,000 videos for testing. MSVD #OTHEREFR contains 1,970 videos."], "text_after_citation": ["We report results on the \"val1\" split of 10,009 and 4,917 as the train and test set. DiDeMo #OTHEREFR contains 10,464 videos annotated 40,543 text descriptions.", "We follow the training and evaluation protocol in #OTHEREFR .", "Metrics.", "We choose Recall at rank K (R@K), the Sum of Recall at rank {1, 5, 10} (Rsum), Median Rank (MdR), and mean rank (MnR) to evaluate the retrieval performance.", "Implementation Details."], "citing_paper_content": {"title": "Diffusionret: Generative Text-Video Retrieval With Diffusion Model", "abstract": "Existing text-video retrieval solutions are, in essence, discriminant models focused on maximizing the conditional likelihood, i.e., p(candidates|query). While straightforward, this de facto paradigm overlooks the underlying data distribution p(query), which makes it challenging to identify outof-distribution data. To address this limitation, we creatively tackle this task from a generative viewpoint and model the correlation between the text and the video as their joint probability p(candidates, query). This is accomplished through a diffusion-based text-video retrieval framework (Diffusion-Ret), which models the retrieval task as a process of gradually generating joint distribution from noise. During training, DiffusionRet is optimized from both the generation and discrimination perspectives, with the generator being optimized by generation loss and the feature extractor trained with contrastive loss. In this way, DiffusionRet cleverly leverages the strengths of both generative and discriminative methods. Extensive experiments on five commonly used text-video retrieval benchmarks, including MSRVTT, LSMDC, MSVD, ActivityNet Captions, and DiDeMo, with superior performances, justify the efficacy of our method. More encouragingly, without any modification, DiffusionRet even performs well in out-domain retrieval settings. We believe this work brings fundamental insights into the related fields. Code will be available at https://github.com/jpthu17/DiffusionRet."}, "cited_paper_content": {"title": "Dense-Captioning Events In Videos", "abstract": "Most natural videos contain numerous events. For example, in a video of a \"man playing a piano\", the video might also contain \"another man dancing\" or \"a crowd clapping\". We introduce the task of dense-captioning events, which involves both detecting and describing events in a video. We propose a new model that is able to identify all events in a single pass of the video while simultaneously describing the detected events with natural language. Our model introduces a variant of an existing proposal module that is designed to capture both short as well as long events that span minutes. To capture the dependencies between the events in a video, our model introduces a new captioning module that uses contextual information from past and future events to jointly describe all events. We also introduce ActivityNet Captions, a large-scale benchmark for dense-captioning events. ActivityNet Captions contains 20k videos amounting to 849 video hours with 100k total descriptions, each with it's unique start and end time. Finally, we report performances of our model for dense-captioning events, video retrieval and localization."}, "keywords": ["20,000 YouTube videos", "ActivityNet Captions"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For dense-captioning events, ActivityNet Captions provides a large-scale benchmark with 20k videos and 849 video hours, each with its unique start and end time, as introduced in the reference paper Dense-Captioning Events In Videos #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For the ActivityNet Captions dataset, which contains 20k videos with 100k total descriptions, #REFR proposed a new model that can detect and describe events in a video, introducing a variant of an existing proposal module and a new captioning module that jointly describes all events using contextual information from past and future events.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For the ActivityNet Captions dataset, which contains 20,000 YouTube videos with 100k total descriptions, the proposed method in this manuscript can achieve superior performance in text-video retrieval compared to existing discriminant models, as demonstrated by the extensive experiments on five commonly used benchmarks including MSRVTT, LSMDC, MSVD, and DiDeMo #REFR.", "given_citation_intent": "method", "given_keywords": ["20,000 YouTube videos", "ActivityNet Captions"]}]}
{"citing_id": "2303.08308v1", "cited_id": "2003.11142", "section_title": "Efficient Search Space Quality Evaluation", "citation": "For example, it costs more than 10 days to train a supernet on 8 V100 GPUs #REFR .", "text_before_citation": ["We now address the efficiency challenge caused by Q-T score evaluation.", "The most accurate evaluation is to get accuracy by training a supernet (search space) from scratch and measure latency on target device.", "However, it's impractical to conduct large-scale search due to the prohibitive cost."], "text_after_citation": ["To reduce the cost, we build an accurate INT8 latency predictor by nn-Meter #OTHEREFR , then we introduce block-wise quantization scheme.", "Block-wise knowledge distillation (BKD) is firstly proposed in DNA #OTHEREFR and then further improved in DONNA #OTHEREFR .", "It originally uses block-wise representation of existing models (teacher) to supervise a corresponding student model block.", "In our work, we extend BKD to supervise the training of all elastic stages (each contains a large amount of blocks).", "Since a stage size is much smaller than search space size, the training time is greatly reduced. Fig. 4 illustrates the BKD process."], "citing_paper_content": {"title": "Spaceevo: Hardware-Friendly Search Space Design For Efficient Int8 Inference", "abstract": "The combination of Neural Architecture Search (NAS) and quantization has proven successful in automatically designing low-FLOPs INT8 quantized neural networks (QNN). However, directly applying NAS to design accurate QNN models that achieve low latency on real-world devices leads to inferior performance. In this work, we find that the poor INT8 latency is due to the quantization-unfriendly issue: the operator and configuration (e.g., channel width) choices in prior art search spaces lead to diverse quantization efficiency and can slow down the INT8 inference speed. To address this challenge, we propose SpaceEvo, an automatic method for designing a dedicated, quantizationfriendly search space for each target hardware. The key idea of SpaceEvo is to automatically search hardwarepreferred operators and configurations to construct the search space, guided by a metric called Q-T score to quantify how quantization-friendly a candidate search space is. We further train a quantized-for-all supernet over our discovered search space, enabling the searched models to be directly deployed without extra retraining or quantization. Our discovered models establish new SOTA INT8 quantized accuracy under various latency constraints, achieving up to 10.1% accuracy improvement on ImageNet than prior art CNNs under the same latency. Extensive experiments on diverse edge devices demonstrate that SpaceEvo consistently outperforms existing manually-designed search spaces with up to 2.5\u00d7 faster speed while achieving the same accuracy."}, "cited_paper_content": {"title": "Bignas: Scaling Up Neural Architecture Search With Big Single-Stage Models", "abstract": "Neural architecture search (NAS) has shown promising results discovering models that are both accurate and fast. For NAS, training a one-shot model has become a popular strategy to rank the relative quality of different architectures (child models) using a single set of shared weights. However, while one-shot model weights can effectively rank different network architectures, the absolute accuracies from these shared weights are typically far below those obtained from stand-alone training. To compensate, existing methods assume that the weights must be retrained, finetuned, or otherwise post-processed after the search is completed. These steps significantly increase the compute requirements and complexity of the architecture search and model deployment. In this work, we propose BigNAS, an approach that challenges the conventional wisdom that post-processing of the weights is necessary to get good prediction accuracies. Without extra retraining or post-processing steps, we are able to train a single set of shared weights on ImageNet and use these weights to obtain child models whose sizes range from 200 to 1000 MFLOPs. Our discovered model family, BigNASModels, achieve top-1 accuracies ranging from 76.5% to 80.9%, surpassing state-of-the-art models in this range including EfficientNets and Once-for-All networks without extra retraining or post-processing. We present ablative study and analysis to further understand the proposed BigNASModels."}, "keywords": ["supernet"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of quantization-unfriendly search spaces, SpaceEvo proposes to automatically search for hardware-preferred operators and configurations to construct a dedicated, quantization-friendly search space for each target hardware, guided by a metric called Q-T score. Our discovered models establish new SOTA INT8 quantized accuracy under various latency constraints, achieving up to 10.1% accuracy improvement on ImageNet than prior art CNNs under the same latency (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the quantization-unfriendly issue in Neural Architecture Search (NAS), SpaceEvo proposes a dedicated, quantization-friendly search space for each target hardware, guided by a metric called Q-T score to quantify how quantization-friendly a candidate search space is (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the efficiency challenge caused by Q-T score evaluation, one possible solution is to train a quantized-for-all supernet over a dedicated, quantization-friendly search space, as proposed in BigNAS #REFR.", "given_citation_intent": "background", "given_keywords": ["supernet"]}]}
{"citing_id": "2304.09304v1", "cited_id": "1206.2944", "section_title": "Bayesian Optimization.", "citation": "Following #REFR and using the implementation of [Nog ] , we utilize Bayesian optimization to find weights that lead to better performance of the state-independent agents in the band environment.", "text_before_citation": ["In addition to the actions, the maximum number of actions that the agent is allowed to perform before the episode counts as a loss is a very important hyperparameter which we also want to optimize.", "Hence, we have 3 hyperparameters: the two independent weights w \u2208 R 2 and the maximum number of actions per episode, which we take to be in [10, 10000].", "Then, for any value of these hyperparameters, one may play many games in the band environment and collect rewards, which together make up a set of observations {w n , R(w n )}.", "To optimize the expected value of the reward, we wish to model the reward via a stochastic process.", "A convenient choice that facilitates optimization via Bayesian inference is to model R(w) as a draw from a Gaussian process (GP), meaning that for any finite set of weights {w i \u2208 R 3 }, the vector of random variables R(w i ) is distributed according to a multivariate Gaussian."], "text_after_citation": ["It is assumed that R(w) is drawn from a GP prior with a chosen mean and covariance.", "Beginning with the prior, the algorithm iteratively chooses the next weight to observe w next , plays a game at w next and records the reward, computes the Bayesian posterior given the new data point {w next , R(w next )}, and records the best weight seen so far w best .", "At each step of the optimization, the Bayesian posterior is Gaussian and depends on a collection of game results {w n , R(w n )} with predictive mean function \u00b5(w, {w n , R(w n )}) and variance \u03c3 2 (w, {w n , R(w n )}). At any given step a useful quantity is", "\u03b3(w) = R(w best ) \u2212 \u00b5(w; {w n , R(w n )}) \u03c3(w; {w n , R(w n )}) ,", "which measures the deviation of the mean prediction at w from the current best and normalizes by the variance. More specifically, the next weight is chosen as"], "citing_paper_content": {"title": "Searching For Ribbons With Machine Learning", "abstract": "We apply Bayesian optimization and reinforcement learning to a problem in topology: the question of when a knot bounds a ribbon disk. This question is relevant in an approach to disproving the four-dimensional smooth Poincar\u00e9 conjecture; using our programs, we rule out many potential counterexamples to the conjecture. We also show that the programs are successful in detecting many ribbon knots in the range of up to 70 crossings."}, "cited_paper_content": {"title": "Practical Bayesian Optimization Of Machine Learning Algorithms", "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."}, "keywords": ["Bayesian optimization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To optimize the expected value of the reward, the authors wish to model the reward via a stochastic process, and a convenient choice that facilitates optimization via Bayesian inference is to model R(w) as a draw from a Gaussian process (GP) #REFR. This approach has been successfully applied to optimize the performance of various machine learning algorithms, including latent Dirichlet allocation, structured SVMs, and convolutional neural networks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the expected value of the reward, we model the reward via a stochastic process, specifically a Gaussian process (GP) which is described in detail in the reference paper #REFR, and we show that certain choices for the nature of the GP can play a crucial role in obtaining a good optimizer that can achieve expert-level performance.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the expected value of the reward, the authors modeled the reward via a stochastic process, specifically a Gaussian process (GP), which is a convenient choice that facilitates optimization via #REFR Bayesian optimization.", "given_citation_intent": "method", "given_keywords": ["Bayesian optimization"]}]}
{"citing_id": "2303.08409v1", "cited_id": "1602.01783", "section_title": "Implementation Details Of Lana", "citation": "IL utilizes the same loss in Eq.13 while RL is implemented based on the Asynchronous Advantage Actor-Critic (A3C) algorithm #REFR .", "text_before_citation": ["We employ an additional Instruction Trajectory Matching (ITM) task following previous efforts #OTHEREFR during pretraining, which predicts whether a pair of instruction and trajectory is aligned.", "The three tasks IF (Instruction Following), IG (Instruction Generation) and ITM (Instruction Trajectory Matching) are sampled with a ratio IG:IF:ITM=4:1:2.", "We present the pseudo-code of the pretraining procedure in Algorithm 1 (ITM is omitted for simplicity).", "For finetuning, the instruction following task is optimized with Reinforcement Learning (RL) and Imitation Learning (IL)."], "text_after_citation": ["During finetuning, the sampling ratio for IG and IF is set to IG:IF=2:5; the ITM task is abandoned.", "Following the common practice #OTHEREFR , we concatenate the object features with the panoramic features and add an object grounding loss for the instruction following task on REVERIE #OTHEREFR .", "The detailed architecture of LANA is shown in Table 7 ."], "citing_paper_content": {"title": "Lana: A Language-Capable Navigator For Instruction Following And Generation", "abstract": "Recently, visual-language navigation (VLN)-entailing robot agents to follow navigation instructions-has shown great advance. However, existing literature put most emphasis on interpreting instructions into actions, only delivering \"dumb\" wayfinding agents. In this article, we devise LANA, a language-capable navigation agent which is able to not only execute human-written navigation commands, but also provide route descriptions to humans. This is achieved by simultaneously learning instruction following and generation with only one single model. More specifically, two encoders, respectively for route and language encoding, are built and shared by two decoders, respectively for action prediction and instruction generation, so as to exploit cross-task knowledge and capture task-specific characteristics. Throughout pretraining and fine-tuning, both instruction following and generation are set as optimization objectives. We empirically verify that, compared with recent advanced task-specific solutions, LANA attains better performances on both instruction following and route description, with nearly half complexity. In addition, endowed with language generation capability, LANA can explain to human its behaviours and assist human's wayfinding. This work is expected to foster future efforts towards building more trustworthy and sociallyintelligent navigation robots."}, "cited_paper_content": {"title": "Asynchronous Methods For Deep Reinforcement Learning", "abstract": "We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input."}, "keywords": ["loss"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We employ an additional Instruction Trajectory Matching (ITM) task following previous efforts #OTHEREFR during pretraining, which predicts whether a pair of instruction and trajectory is aligned. The three tasks IF (Instruction Following), IG (Instruction Generation) and ITM (Instruction Trajectory Matching) are sampled with a ratio IG:IF:ITM=4:1:2. We present the pseudo-code of the pretraining procedure in Algorithm 1 (ITM is omitted for simplicity). For finetuning, the instruction following task is optimized with Reinforcement Learning (RL) and Imitation Learning (IL). Asynchronous gradient descent is used for optimization of deep neural network controllers in the reference paper #REFR, which presents asynchronous variants of four standard reinforcement learning algorithms and shows that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the instruction following task, the authors utilized Reinforcement Learning (RL) and Imitation Learning (IL) and drew inspiration from the asynchronous gradient descent method proposed in the paper \"Asynchronous Methods For Deep Reinforcement Learning\" #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the instruction following task, the authors utilized Reinforcement Learning (RL) and Imitation Learning (IL) #REFR, which is a widely used method for training neural network controllers and has been shown to achieve state-of-the-art results on various tasks with reduced loss.", "given_citation_intent": "method", "given_keywords": ["loss"]}]}
{"citing_id": "2303.13801v1", "cited_id": "1906.06870", "section_title": "Related Work", "citation": "The concatenation of character and word level embeddings have been employed along with bidirectional LSTMs #REFR .", "text_before_citation": ["Recently, employing regular expressions #OTHEREFR , the prototypical network #OTHEREFR , and extensions to CRFs #OTHEREFR have been proposed for the few-shot slot filling task.", "Furthermore, several works #OTHEREFR have leveraged model agnostic meta-learning to jointly model the slot filling and intent classification tasks.", "In a similar line of work, in the zero-shot setting, no in-domain labeled training data is required, which has shown encouraging results to eliminate the need for manual labeling.", "Using LSTM-based models along with the natural language descriptions of the slots has been shown to overcome the challenge of different names of the slot for apparently similar slots (e.g., city vs destination in Travel domain) for the zero-shot adaptation of slot filling task #OTHEREFR .", "Similarly, attention mechanisms have further improved the performance #OTHEREFR ."], "text_after_citation": ["Moreover, the coarse-to-fine approach in #OTHEREFR was proposed to improve the robustness of the zero-shot slot filling task.", "In spite of promising results, there is a huge performance gap between zero-shot learning methods and supervised learning approaches that limit their applicability.", "In this work, we employ a zero-shot slot filling model to automatically generate a set of labels in the target domain and further improve the performance of the slot filling task in an open-domain setting. Unsupervised and Weak Supervision Slot Filling.", "The other line of work to eliminate the need for manual labeling is weak supervision and unsupervised learning.", "Unsupervised learning methods #OTHEREFR have used mining to build latent variable models #OTHEREFR ."], "citing_paper_content": {"title": "Toward Open-Domain Slot Filling Via Self-Supervised Co-Training", "abstract": "Slot filling is one of the critical tasks in modern conversational systems. The majority of existing literature employs supervised learning methods, which require labeled training data for each new domain. Zero-shot learning and weak supervision approaches, among others, have shown promise as alternatives to manual labeling. Nonetheless, these learning paradigms are significantly inferior to supervised learning approaches in terms of performance. To minimize this performance gap and demonstrate the possibility of open-domain slot filling, we propose a Self-supervised Co-training framework, called SCot, that requires zero in-domain manually labeled training examples and works in three phases. Phase one acquires two sets of complementary pseudo labels automatically. Phase two leverages the power of the pre-trained language model BERT, by adapting it for the slot filling task using these sets of pseudo labels. In phase three, we introduce a self-supervised cotraining mechanism, where both models automatically select highconfidence soft labels to further improve the performance of the other in an iterative fashion. Our thorough evaluations show that SCot outperforms state-of-the-art models by 45.57% and 37.56% on SGD and MultiWoZ datasets, respectively. Moreover, our proposed framework SCot achieves comparable performance when compared to state-of-the-art fully supervised models."}, "cited_paper_content": {"title": "Robust Zero-Shot Cross-Domain Slot Filling With Example Values", "abstract": "Task-oriented dialog systems increasingly rely on deep learning-based slot filling models, usually needing extensive labeled training data for target domains. Often, however, little to no target domain training data may be available, or the training and target domain schemas may be misaligned, as is common for web forms on similar websites. Prior zero-shot slot filling models use slot descriptions to learn concepts, but are not robust to misaligned schemas. We propose utilizing both the slot description and a small number of examples of slot values, which may be easily available, to learn semantic representations of slots which are transferable across domains and robust to misaligned schemas. Our approach outperforms state-of-the-art models on two multi-domain datasets, especially in the low-data setting."}, "keywords": ["word level embeddings"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Using a small number of examples of slot values, the proposed method in the reference paper \"Robust Zero-Shot Cross-Domain Slot Filling With Example Values\" #REFR learns semantic representations of slots that are transferable across domains and robust to misaligned schemas, outperforming state-of-the-art models on two multi-domain datasets, especially in the low-data setting.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Using a small number of examples of slot values, the proposed method in #REFR learns semantic representations of slots that are transferable across domains and robust to misaligned schemas, outperforming state-of-the-art models on two multi-domain datasets, especially in the low-data setting.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Using word level embeddings along with a small number of examples of slot values, as proposed in the reference paper #REFR, has been shown to improve the robustness of zero-shot slot filling models to misaligned schemas.", "given_citation_intent": "method", "given_keywords": ["word level embeddings"]}]}
{"citing_id": "2304.01483v1", "cited_id": "1804.07461", "section_title": "Introduction", "citation": "Experiments demonstrate that the accuracy drop of BCT is less than 0.90% on most GLUE #REFR datasets without retraining.", "text_before_citation": ["Compressed transformer-based models have faster calculation, less memory footprint, and lower bandwidth requirements.", "In this case, several compression methods are proposed to compress transformer-based models with an acceptable loss of accuracy.", "However, most of them need to spend much time retraining to fine-tune the parameters.", "In this paper, we investigate a framework of blockwise compression of transformers without retraining through algorithm/hardware codesign, denoted as BCT.", "Unlike previous compression frameworks, BCT compresses the whole transformer, including embedding, matrix multiplication, GELU #OTHEREFR , Softmax, layer normalization #OTHEREFR , and all the intermediate results by block. Figure 1 shows the framework of BCT."], "text_after_citation": ["The main contributions of this paper can be summa-rized as follows: (i) We propose an efficient blockwise compression framework for transformer-based models without retraining.", "(ii) We provide a concrete well-designed methodology for each transformer layer, including matrix multiplication and nonlinear operations.", "(iii) Without retraining, we evaluate BCT on several GLUE datasets, and BCT achieves a less than 0.90% accuracy drop in most tasks.", "In conclusion, BCT is suitable for deploying transformer-based models and does not require laborious retraining."], "citing_paper_content": {"title": "Blockwise Compression Of Transformer-Based Models Without Retraining", "abstract": "Transformer-based models, represented by GPT-3, ChatGPT, and GPT-4, have recently attracted increasing interest, research enthusiasm, and business demand. However, their massive computation resources and huge memory footprint are inevitable challenges. To tackle this issue, we propose BCT, a framework of blockwise compression for transformers without retraining, to lower deployment thresholds. BCT achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, Softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient model with BCT and evaluate it on several General Language Understanding Evaluation (GLUE) datasets. The results show that BCT can achieve a less than 0.90% accuracy drop in most tasks."}, "cited_paper_content": {"title": "Glue: A Multi-Task Benchmark And Analysis Platform For Natural Language Understanding", "abstract": "For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems."}, "keywords": ["GLUE datasets"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Compressed transformer-based models have been proposed to achieve faster calculation, less memory footprint, and lower bandwidth requirements. To this end, BCT, a blockwise compression framework for transformers without retraining, has been introduced to lower deployment thresholds #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the compressed model, the authors conducted experiments on several General Language Understanding Evaluation (GLUE) datasets #REFR, demonstrating that their proposed blockwise compression framework achieves a less than 0.90% accuracy drop in most tasks.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the compressed model, the authors tested it on several GLUE datasets, achieving a less than 0.90% accuracy drop in most tasks #REFR.", "given_citation_intent": "background", "given_keywords": ["GLUE datasets"]}]}
{"citing_id": "2304.08861v1", "cited_id": "1910.10045", "section_title": "Description And Implementation Of Xai Explanation Types", "citation": "As first research endeavors target the end-user of an XAI-based DSS, these interdisciplinary research outcomes must be incorporated into practical applications to design valuable explanations for end-user #REFR .", "text_before_citation": ["In practice, this XAI jungle is exacerbated by developers primarily designing these XAI implementations for developers without prioritizing the actual end-users (van der Waa et al., 2021)."], "text_after_citation": ["Following the explanation theory of #OTHEREFR , a useful explanation is defined as a social and cognitive process of knowledge transfer from an XAI-based DSS to the end-user.", "Thus, if an explanation is perceived as inadequate, contradicts an end-user's mental model, or does not appeal to their emotions or beliefs, trust issues can occur and user acceptance may be reduced, leading to algorithm aversion #OTHEREFR .", "Following recent IS research, a mental model defines any type of mental representation used to encode beliefs, facts, and knowledge when conceptualizing cognitive processes #OTHEREFR .", "In this sense, the extent to which these explanation types affect end-users' cognitive load is unknown, which is an essential factor in the design and development of appropriate XAI implementations #OTHEREFR ."], "citing_paper_content": {"title": "Impact Of Explainable Ai On Cognitive Load: Insights From An Empirical Study", "abstract": "While the emerging research field of explainable artificial intelligence (XAI) claims to address the lack of explainability in high-performance machine learning models, in practice, XAI targets developers rather than actual end-users. Unsurprisingly, end-users are often unwilling to use XAI-based decision support systems. Similarly, there is limited interdisciplinary research on end-users' behavior during XAI explanations usage, rendering it unknown how explanations may impact cognitive load and further affect end-user performance. Therefore, we conducted an empirical study with 271 prospective physicians, measuring their cognitive load, task performance, and task time for distinct implementationindependent XAI explanation types using a COVID-19 use case. We found that these explanation types strongly influence end-users' cognitive load, task performance, and task time. Further, we contextualized a mental efficiency metric, ranking local XAI explanation types best, to provide recommendations for future applications and implications for sociotechnical XAI research."}, "cited_paper_content": {"title": "Explainable Artificial Intelligence (Xai): Concepts, Taxonomies, Opportunities And Challenges Toward Responsible Ai", "abstract": "In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability."}, "keywords": ["valuable explanations"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In practice, this XAI jungle is exacerbated by developers primarily designing these XAI implementations for developers without prioritizing the actual end-users, which is a crucial feature for the practical deployment of AI models (Fernandez et al., 2018). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The lack of interpretability in high-performance machine learning models has been a barrier to their practical deployment, which has led to the emergence of the field of eXplainable AI (XAI) (Molnar, 2019). #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The need for valuable explanations in machine learning models has been widely acknowledged as a crucial feature for practical deployment of AI models, as it can help to overcome the barrier of explainability, which is an inherent problem of the latest techniques brought by sub-symbolism, such as Deep Neural Networks (van der Waa et al., 2021 #REFR).", "given_citation_intent": "background", "given_keywords": ["valuable explanations"]}]}
{"citing_id": "2304.03671v1", "cited_id": "1312.6199", "section_title": "I. Introduction", "citation": "These learning-based algorithms are known to be vulnerable to input perturbations #REFR -small (possibly adversarial) changes in their input can lead to large variations in their output.", "text_before_citation": ["Motivation and Problem Statement: Neural networks have become increasingly popular in control systems in recent years due to their relative ease of in-the-loop computation."], "text_after_citation": ["As such, runtime verification of the safety and performance of neural network controlled systems is essential in safety-critical applications.", "This task is generally challenging due to the nonlinear and large-scale structure of the neural networks and their interconnection with nonlinear dynamics #OTHEREFR .", "A basic ingredient for verifying control systems is the ability to overapproximate the set of reachable states from a given set of initial conditions, possibly in the presence of disturbances.", "If, for example, this overapproximation avoids obstacles or reaches a goal region, then the system certifiably satisfies the corresponding safety or performance criteria.", "Recently, several promising reachability-based methods have been proposed for verifying stand-alone neural networks or feedback systems with neural networks in the control loop, however, these methods either suffer from large computational complexity, large over-approximation error, or lack of generality."], "citing_paper_content": {"title": "Contraction-Guided Adaptive Partitioning For Reachability Analysis Of Neural Network Controlled Systems", "abstract": "In this paper, we present a contraction-guided adaptive partitioning algorithm for improving interval-valued robust reachable set estimates in a nonlinear feedback loop with a neural network controller and disturbances. Based on an estimate of the contraction rate of over-approximated intervals, the algorithm chooses when and where to partition. Then, by leveraging a decoupling of the neural network verification step and reachability partitioning layers, the algorithm can provide accuracy improvements for little computational cost. This approach is applicable with any sufficiently accurate open-loop interval-valued reachability estimation technique and any method for bounding the input-output behavior of a neural network. Using contraction-based robustness analysis, we provide guarantees of the algorithm's performance with mixed monotone reachability. Finally, we demonstrate the algorithm's performance through several numerical simulations and compare it with existing methods in the literature. In particular, we report a sizable improvement in the accuracy of reachable set estimation in a fraction of the runtime as compared to state-of-the-art methods."}, "cited_paper_content": {"title": "Intriguing Properties Of Neural Networks", "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. ::: First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. ::: Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input."}, "keywords": ["input perturbations -small", "possibly adversarial) changes"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Neural networks have become increasingly popular in control systems in recent years due to their relative ease of in-the-loop computation. To better understand the properties of neural networks, recent research has reported intriguing findings on their expressiveness and discontinuous input-output mappings #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Neural networks have become increasingly popular in control systems in recent years due to their relative ease of in-the-loop computation. However, as noted in the paper by Szegedy et al., deep neural networks can learn uninterpretable solutions that could have counter-intuitive properties, which may affect their use in control systems. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Neural networks have become increasingly popular in control systems in recent years due to their relative ease of in-the-loop computation. These networks, however, have been found to learn input-output mappings that are fairly discontinuous to a significant extent, and can be easily misled by small input perturbations, which are found by maximizing the network's prediction error. #REFR", "given_citation_intent": "background", "given_keywords": ["input perturbations -small", "possibly adversarial) changes"]}]}
{"citing_id": "2305.01360v1", "cited_id": "1802.09431", "section_title": "Results On Real 7T Adult Brain Data", "citation": "In comparison, the SR results of SMORE #REFR and our proposed model recover more image details.", "text_before_citation": ["Although our proposed framework yields significant improvements on the simulated HCP-1200 data #OTHEREFR compared with the three baselines, it is more important to show how well the models perform on the real acquired anisotropic MR volumes.", "Therefore, we also conducted a comparison experiment on two real measured anisotropic adult brain volumes (details in Table 1 ).", "Here we only report the qualitative results since the isotropic GT HR images are not acquired.", "As shown in Figure 5 , the SR results of cubic interpolation suffer from severe blocking artifacts due to its poor de-aliasing ability.", "While IREM #OTHEREFR produces sharp but overly smooth MR images, where many high-frequency details are lost."], "text_after_citation": ["Moreover, the SR results of our model are better in terms of anatomical consistency."], "citing_paper_content": {"title": "Self-Supervised Arbitrary Scale Super-Resolution Framework For Anisotropic Mri", "abstract": "In this paper, we propose an efficient self-supervised arbitraryscale super-resolution (SR) framework to reconstruct isotropic magnetic resonance (MR) images from anisotropic MRI inputs without involving external training data. The proposed framework builds a training dataset using \"in-the-wild\" anisotropic MR volumes with arbitrary image resolution. We then formulate the 3D volume SR task as a SR problem for 2D image slices. The anisotropic volume's high-resolution (HR) plane is used to build the HR-LR image pairs for model training. We further adapt the implicit neural representation (INR) network to implement the 2D arbitrary-scale image SR model. Finally, we leverage the welltrained proposed model to up-sample the 2D LR plane extracted from the anisotropic MR volumes to their HR views. The isotropic MR volumes thus can be reconstructed by stacking and averaging the generated HR slices. Our proposed framework has two major advantages: (1) It only involves the arbitrary-resolution anisotropic MR volumes, which greatly improves the model practicality in real MR imaging scenarios (e.g., clinical brain image acquisition); (2) The INR-based SR model enables arbitrary-scale image SR from the arbitrary-resolution input image, which significantly improves model training efficiency. We perform experiments on a simulated public adult brain dataset and a real collected 7T brain dataset. The results indicate that our current framework greatly outperforms two well-known self-supervised models for anisotropic MR image SR tasks."}, "cited_paper_content": {"title": "Self Super-Resolution For Magnetic Resonance Images Using Deep Networks", "abstract": "High resolution magnetic resonance (MR) imaging (MRI) is desirable in many clinical applications; however, there is a trade-off between resolution, speed of acquisition, and noise. It is common for MR images to have worse through-plane resolution (slice thickness) than in-plane resolution. In these MRI images, high frequency information in the through-plane direction is not acquired, and cannot be resolved through interpolation. To address this issue, super-resolution methods have been developed to enhance spatial resolution. As an ill-posed problem, state-of-the-art super-resolution methods rely on the presence of external/training atlases to learn the transform from low resolution (LR) images to high resolution (HR) images. For several reasons, such HR atlas images are often not available for MRI sequences. This paper presents a self super-resolution (SSR) algorithm, which does not use any external atlas images, yet can still resolve HR images only reliant on the acquired LR image. We use a blurred version of the input image to create training data for a state-of-the-art super-resolution deep network. The trained network is applied to the original input image to estimate the HR image. Our SSR result shows a significant improvement on through-plane resolution compared to competing SSR methods."}, "keywords": ["SR results"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "While IREM produces sharp but overly smooth MR images, where many high-frequency details are lost, the proposed self super-resolution (SSR) algorithm presented in #REFR shows a significant improvement on through-plane resolution compared to competing SSR methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed framework outperforms two well-known self-supervised models for anisotropic MR image SR tasks, and the SR results of cubic interpolation suffer from severe blocking artifacts due to its poor de-aliasing ability, while IREM produces overly smooth MR images, where many high-frequency details are lost #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The self super-resolution (SSR) algorithm proposed in #REFR yields significantly improved SR results compared to competing SSR methods, as shown in Figure 5.", "given_citation_intent": "result", "given_keywords": ["SR results"]}]}
{"citing_id": "2303.05656v1", "cited_id": "2001.09346", "section_title": "Baselines", "citation": "CorGAN #REFR is a novel work that utilizes convolutional neural networks (CNN) instead of multilayer perceptrons (MLP) to model EHR data.", "text_before_citation": ["Considering the obstacle of directly using GAN on generating high-dimensional binary EHR vectors, medGAN alters to a low-dimensional dense space for generation by taking advantage of pre-trained auto-encoders.", "The model generates a dense EHR vector and then recovers a synthetic EHR with decoders.", "medBGAN and medWGAN #OTHEREFR are two improved GAN models for realistic EHR synthesis.", "medGAN is based on the conventional GAN model for EHR synthesis, and such a model is prone to mode collapse where GAN models may fail to learn the distribution of real-world data.", "medBGAN and medWGAN integrate Boundary-seeking GAN (BGAN) #OTHEREFR and Wasserstein GAN (WGAN-GP) #OTHEREFR with gradient penalty respectively to improve the performance of medGAN and stabilize model training."], "text_after_citation": ["Specifically, they use CNN to model the autoencoder and the generative network.", "They empirically elucidate through experiments that CNN can perform better than the MLP in this task.", "#OTHEREFR is proposed to further refine the GAN models from several perspectives.", "To avoid model collapse, the authors take advantage of WGAN.", "The most prominent feature of EMR-WGAN is that it is directly trained on the discrete EHR data, while the previous works universally use an autoencoder to first transform the raw EHR data into low-dimensional dense space."], "citing_paper_content": {"title": "Ehrdiff : Exploring Realistic Ehr Synthesis With Diffusion Models", "abstract": "Electronic health records (EHR) contain vast biomedical knowledge and are rich resources for developing precise medicine systems. However, due to privacy concerns, there are limited high-quality EHR data accessible to researchers hence hindering the advancement of methodologies. Recent research has explored using generative modelling methods to synthesize realistic EHR data, and most proposed methods are based on the generative adversarial network (GAN) and its variants for EHR synthesis. Although GAN-style methods achieved state-of-the-art performance in generating high-quality EHR data, such methods are hard to train and prone to mode collapse. Diffusion models are recently proposed generative modelling methods and set cutting-edge performance in image generation. The performance of diffusion models in realistic EHR synthesis is rarely explored. In this work, we explore whether the superior performance of diffusion models can translate to the domain of EHR synthesis and propose a novel EHR synthesis method named EHRDIFF. Through comprehensive experiments, EHRDIFF achieves new state-of-the-art performance for the quality of synthetic EHR data and can better protect private information in real training EHRs in the meanwhile. The code will be released soon in https://github.com/sczzz3/ehrdiff."}, "cited_paper_content": {"title": "Corgan: Correlation-Capturing Convolutional Generative Adversarial Networks For Generating Synthetic Healthcare Records", "abstract": "Deep learning models have demonstrated high-quality performance in areas such as image classification and speech processing. However, creating a deep learning model using electronic health record (EHR) data, requires addressing particular privacy challenges that are unique to researchers in this domain. This matter focuses attention on generating realistic synthetic data while ensuring privacy. In this paper, we propose a novel framework called correlation-capturing Generative Adversarial Network (corGAN), to generate synthetic healthcare records. In corGAN we utilize Convolutional Neural Networks to capture the correlations between adjacent medical features in the data representation space by combining Convolutional Generative Adversarial Networks and Convolutional Autoencoders. To demonstrate the model fidelity, we show that corGAN generates synthetic data with performance similar to that of real data in various Machine Learning settings such as classification and prediction. We also give a privacy assessment and report on statistical analysis regarding realistic characteristics of the synthetic data. The software of this work is open-source and is available at: this https URL."}, "keywords": ["EHR data"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the issue of mode collapse in GAN models for EHR synthesis, recent research has proposed improved models such as medBGAN and medWGAN. However, to generate synthetic healthcare records with performance similar to that of real data, corGAN, a novel framework that utilizes Convolutional Neural Networks to capture the correlations between adjacent medical features, was proposed in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the privacy challenges in generating realistic synthetic data from electronic health record (EHR) data, corGAN, a novel framework that utilizes Convolutional Neural Networks to capture the correlations between adjacent medical features in the data representation space, is proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the privacy challenges unique to researchers dealing with EHR data, corGAN, a novel framework that utilizes Convolutional Neural Networks to capture the correlations between adjacent medical features in the data representation space, is proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["EHR data"]}]}
{"citing_id": "2303.03486v1", "cited_id": "1910.07113", "section_title": "Ii. Related Work", "citation": "Model-free RL has also led to significant progress in dexterous manipulation, starting with OpenAI's demonstration of finger-gaiting and finger-pivoting #REFR , trained in simulation and translated to real hardware.", "text_before_citation": ["#OTHEREFR build a map of valid grasps and use search methods to generate gaits for planar reorientation, while Han et al.", "#OTHEREFR consider finger-gaiting of a sphere and identify the non-holonomic nature of the problem.", "Some methods have also considered RRT for finger-gaiting in-hand manipulation #OTHEREFR , but limited to simulation for a spherical object. More recently, Morgan et al.", "demonstrate robust finger-gaiting for object reorientation using actor-critic reinforcement learning #OTHEREFR and multi-modal motion planning #OTHEREFR , both in conjunction with a compliant, highly underactuated hand designed explicitly for this task. Bhatt et al.", "#OTHEREFR also demonstrate robust fingergaiting finger-pivoting manipulation with a soft compliant hand, but these skills were not autonomously learned but rather hand-designed and executed in an open-loop fashion."], "text_after_citation": ["However, this approach uses extensive extrinsic sensing infeasible outside the lab, and relies on support surfaces such as the palm underneath the object. Khandate et al.", "#OTHEREFR show dexterous finger-gaiting and fingerpivoting skills using only precision fingertip grasps to enable both palm-up and palm-down operation, but only on a range of simple convex shapes and in a simulated environment. Makoviychuk et al.", "#OTHEREFR showed that GPU physics could be used to accelerate learning skills similar to OpenAI's. Allshire et al.", "#OTHEREFR used extensive domain randomization and simto-real transfer to re-orient a cube but used table top as an external support surface. Chen et al.", "#OTHEREFR demonstrated inhand re-orientation for a wide range of objects under palm-up and palm-down orientations of the hand with extrinsic sensing providing dense object feedback. Qi et al."], "citing_paper_content": {"title": "Sampling-Based Exploration For Reinforcement Learning Of Dexterous Manipulation", "abstract": "In this paper, we present a novel method for achieving dexterous manipulation of complex objects, while simultaneously securing the object without the use of passive support surfaces. We posit that a key difficulty for training such policies in a Reinforcement Learning framework is the difficulty of exploring the problem state space, as the accessible regions of this space form a complex structure along manifolds of a high-dimensional space. To address this challenge, we use two versions of the non-holonomic Rapidly-Exploring Random Trees algorithm; one version is more general, but requires explicit use of the environment's transition function, while the second version uses manipulation-specific kinematic constraints to attain better sample efficiency. In both cases, we use states found via sampling-based exploration to generate reset distributions that enable training control policies under full dynamic constraints via model-free Reinforcement Learning. We show that these policies are effective at manipulation problems of higher difficulty than previously shown, and also transfer effectively to real robots. These videos can be found on the project website: sbrl.cs.columbia.edu"}, "cited_paper_content": {"title": "Solving Rubik'S Cube With A Robot Hand", "abstract": "We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difficulty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik's cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: this https URL"}, "keywords": ["dexterous manipulation"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To achieve dexterous manipulation of complex objects, Morgan et al. demonstrate robust finger-gaiting for object reorientation using actor-critic reinforcement learning and multi-modal motion planning, both in conjunction with a compliant, highly underactuated hand designed explicitly for this task #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve dexterous manipulation of complex objects, Morgan et al. demonstrate robust finger-gaiting for object reorientation using actor-critic reinforcement learning and multi-modal motion planning, both in conjunction with a compliant, highly underactuated hand designed explicitly for this task, while Han et al. consider finger-gaiting of a sphere and identify the non-holonomic nature of the problem, and some methods have also considered RRT for finger-gaiting in-hand manipulation, but limited to simulation for a spherical object #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve dexterous manipulation of complex objects, Morgan et al. demonstrate robust finger-gaiting for object reorientation using actor-critic reinforcement learning and multi-modal motion planning, both in conjunction with a compliant, highly underactuated hand designed explicitly for this task, while Han et al. consider finger-gaiting of a sphere and identify the non-holonomic nature of the problem, and Bhatt et al. also demonstrate robust fingergaiting finger-pivoting manipulation with a soft compliant hand, but these skills were not autonomously learned but rather hand-designed and executed in an open-loop fashion. #REFR", "given_citation_intent": "background", "given_keywords": ["dexterous manipulation"]}]}
{"citing_id": "2304.06454v1", "cited_id": "1609.05158", "section_title": "Related Work Dnn-Based Image Super-Resolution", "citation": "For example, ESPCN #REFR invents the pixel-shuffle layer to obtain the HR output given the LR input.", "text_before_citation": ["USRNet #OTHEREFR proposes an end-to-end trainable unfolding network that leverages both learning-based methods and model-based methods.", "Therefore, they can handle the SISR problem with different scaling factors, blur kernels, and noise levels under a unified framework.", "SwinIR #OTHEREFR is a strong baseline model that introduces Swin Transformer #OTHEREFR to image restoration.", "Their non-linear mapping module is composed of several residual Swin Transformer blocks.", "To reduce the computational cost, there are also many efficient SISR methods."], "text_after_citation": ["LAPAR #OTHEREFR presents a method based on a linearly-assembled adaptive regression network.", "Restormer #OTHEREFR proposes an efficient Transformer model by making several key designs in the building blocks.", "All of those methods train one the SR model on large-scale image datasets such as DIV2K #OTHEREFR and test on the given input images.", "However, they are not designed for large input as the practical scenario of SR usually needs to superresolve large input like 2K to higher resolution (4K/8K)."], "citing_paper_content": {"title": "Cabm: Content-Aware Bit Mapping For Single Image Super-Resolution Network With Large Input", "abstract": "With the development of high-definition display devices, the practical scenario of Super-Resolution (SR) usually needs to super-resolve large input like 2K to higher resolution (4K/8K). To reduce the computational and memory cost, current methods first split the large input into local patches and then merge the SR patches into the output. These methods adaptively allocate a subnet for each patch. Quantization is a very important technique for network acceleration and has been used to design the subnets. Current methods train an MLP bit selector to determine the propoer bit for each layer. However, they uniformly sample subnets for training, making simple subnets overfitted and complicated subnets underfitted. Therefore, the trained bit selector fails to determine the optimal bit. Apart from this, the introduced bit selector brings additional cost to each layer of the SR network. In this paper, we propose a novel method named Content-Aware Bit Mapping (CABM), which can remove the bit selector without any performance loss. CABM also learns a bit selector for each layer during training. After training, we analyze the relation between the edge information of an input patch and the bit of each layer. We observe that the edge information can be an effective metric for the selected bit. Therefore, we design a strategy to build an Edge-to-Bit lookup table that maps the edge score of a patch to the bit of each layer during inference. The bit configuration of SR network can be determined by the lookup tables of all layers. Our strategy can find better bit configuration, resulting in more efficient mixed precision networks. We conduct detailed experiments to demonstrate the generalization ability of our method. The code will be released."}, "cited_paper_content": {"title": "Real-Time Single Image And Video Super-Resolution Using An Efficient Sub-Pixel Convolutional Neural Network", "abstract": "Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architecture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By doing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods."}, "keywords": ["pixel-shuffle layer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To reduce the computational cost, there are also many efficient SISR methods. One such method is presented in the reference paper \"Real-Time Single Image And Video Super-Resolution Using An Efficient Sub-Pixel Convolutional Neural Network\" #REFR, which proposes a novel CNN architecture for real-time SR of 1080p videos on a single K2 GPU.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the computational complexity of the overall SR operation, Real-Time Single Image And Video Super-Resolution Using An Efficient Sub-Pixel Convolutional Neural Network #REFR proposes an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "SwinIR is a strong baseline model that introduces Swin Transformer to image restoration, and their non-linear mapping module is composed of several residual Swin Transformer blocks, as well as an efficient sub-pixel convolution layer that learns an array of upscaling filters to upscale the final LR feature maps into the HR output #REFR.", "given_citation_intent": "method", "given_keywords": ["pixel-shuffle layer"]}]}
{"citing_id": "2305.00399v1", "cited_id": "2002.11569", "section_title": "Clean-Label Untargeted Attacks Against At", "citation": "This could be easily avoided by the robust learner using early stopping #REFR on the validation set.", "text_before_citation": ["We evaluate the performance of stickers (using 0 -norm ball that changes 3% of overall pixels) and compare it with REM (using \u221e -norm ball and = 8/255 \u2248 0.031) on robust learners with 0 \u2208 [4/255, 16/255].", "For each 0 , we execute B 0 -AT five times with different random seeds.", "To ensure a consistent result, we fix the random seeds 2000000000-2111100000.", "Throughout the training epochs, we record the best natural test accuracy on all test data x and the best robust test accuracy on adversarial datax \u2208 B 0 [x].", "Rather than relying on the last-checkpoint accuracy, we chose to do this because we found that the AT has a catastrophic overfitting #OTHEREFR when learning from the poisoned set S (see appendix), which gives a false sense of the effectiveness of the poisoning attacks."], "text_after_citation": ["In the appendix (see Figure 12) , we report the full learning curves of CIFAR-10 experiments.", "Additionally, we evaluated our stickers on the ImageNet Subset dataset (see below).", "Table 6 shows that as 0 \u2192 (e.g., 0 = = 8/255), the effectiveness of REM, which uses the same norm ball B as the robust learner B 0 , decreases in generating poisoned data to deter (highlighted by \"\u2212\" in cyan-green) unauthorized data collection, and sometimes even has an encouragement effect (highlighted by \"+\" in red).", "In contrast, our method using a different B remains effective in deterrence when 0 approaches , which supports the efficacy of specifying a norm ball different from the learner's.", "Note that as 0 becomes larger than , both REM and our method have diminishing returns, probably due to strong invariance #OTHEREFR and low natural and robust accuracies under large perturbation radii, which calls for large radius poisons."], "citing_paper_content": {"title": "Assessing Vulnerabilities Of Adversarial Learning Algorithm Through Poisoning Attacks", "abstract": "Adversarial training (AT) is a robust learning algorithm that can defend against adversarial attacks in the inference phase and mitigate the side effects of corrupted data in the training phase. As such, it has become an indispensable component of many artificial intelligence (AI) systems. However, in high-stake AI applications, it is crucial to understand AT's vulnerabilities to ensure reliable deployment. In this paper, we investigate AT's susceptibility to poisoning attacks, a type of malicious attack that manipulates training data to compromise the performance of the trained model. Previous work has focused on poisoning attacks against standard training, but little research has been done on their effectiveness against AT. To fill this gap, we design and test effective poisoning attacks against AT. Specifically, we investigate and design clean-label poisoning attacks, allowing attackers to imperceptibly modify a small fraction of training data to control the algorithm's behavior on a specific target data point. Additionally, we propose the clean-label untargeted attack, enabling attackers can attach tiny stickers on training data to degrade the algorithm's performance on all test data, where the stickers could serve as a signal against unauthorized data collection. Our experiments demonstrate that AT can still be poisoned, highlighting the need for caution when using vanilla AT algorithms in security-related applications. The code is at https://github.com/zjfheart/Poison-adv-training.git."}, "cited_paper_content": {"title": "Overfitting In Adversarially Robust Deep Learning", "abstract": "It is common practice in deep learning to use overparameterized networks and train for as long as possible; there are numerous studies that show, both theoretically and empirically, that such practices surprisingly do not unduly harm the generalization performance of the classifier. In this paper, we empirically study this phenomenon in the setting of adversarially trained deep networks, which are trained to minimize the loss under worst-case adversarial perturbations. We find that overfitting to the training set does in fact harm robust performance to a very large degree in adversarially robust training across multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and perturbation models ($\\ell_\\infty$ and $\\ell_2$). Based upon this observed effect, we show that the performance gains of virtually all recent algorithmic improvements upon adversarial training can be matched by simply using early stopping. We also show that effects such as the double descent curve do still occur in adversarially trained models, yet fail to explain the observed overfitting. Finally, we study several classical and modern deep learning remedies for overfitting, including regularization and data augmentation, and find that no approach in isolation improves significantly upon the gains achieved by early stopping. All code for reproducing the experiments as well as pretrained model weights and training logs can be found at this https URL."}, "keywords": ["robust learner"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We found that the AT has a catastrophic overfitting when learning from the poisoned set S (see appendix), which gives a false sense of the effectiveness of the poisoning attacks. To address this issue, recent work has shown that overfitting to the training set harms robust performance to a very large degree in adversarially robust training across multiple datasets and perturbation models #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prevent overfitting in adversarially trained deep networks, the authors of this paper suggest using early stopping, as demonstrated by their experiments on multiple datasets and perturbation models (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure the robustness of the model, the authors employed the B_0-AT method and recorded the best robust test accuracy on adversarial data x \u2208 B_0[x], as described in the reference paper #REFR on overfitting in adversarially robust deep learning, which highlights the importance of early stopping in preventing overfitting in robust learners.", "given_citation_intent": "method", "given_keywords": ["robust learner"]}]}
{"citing_id": "2304.12610v1", "cited_id": "1503.00849", "section_title": "Related Work", "citation": "SJ-Tree #REFR materializes all the partial matches of subgraphs, leading to a huge storage and index update cost.", "text_before_citation": ["Most state-space based representation models (that is, each state represents an intermediate result) use this framework, e.g., Ri #OTHEREFR , VF2++ #OTHEREFR , Graphql #OTHEREFR , CFL #OTHEREFR , CECI #OTHEREFR , and DP-ISO #OTHEREFR .", "Due to the effective filtering and sorting methods, they have achieved great improvements in overall performance.", "However, these algorithms focus on the problem in a static data graph.", "For streaming graphs, it is unacceptable for the real-time requirement to perform subgraph matching over the graphs prior to and after updating respectively. Continuous subgraph matching.", "IncIsoMat #OTHEREFR and Graphflow #OTHEREFR expand matches from the updated edges without any additional index structures, showing limited real-time performance."], "text_after_citation": ["TurboFlux #OTHEREFR employs a concise structure DCG, a complete multigraph, to represent intermediate results, reducing the storage cost.", "Similarly, CEPDG #OTHEREFR employs TreeMat to store the partial matches of trees.", "It supports changes in both pattern graphs and data graphs.", "However, TurboFlux and CEPDG exploit a spanning tree of the query graph to filter the candidates, leaving the non-tree edges to be maintained by DCG.", "SymBi #OTHEREFR introduces an auxiliary data structure DCS to store weak embeddings of directed acyclic graphs as intermediate results."], "citing_paper_content": {"title": "Fast Continuous Subgraph Matching Over Streaming Graphs Via Backtracking Reduction", "abstract": "Streaming graphs are drawing increasing attention in both academic and industrial communities as many graphs in real applications evolve over time. Continuous subgraph matching (shorted as CSM) aims to report the incremental matches of a query graph in such streaming graphs. It involves two major steps, i.e., candidate maintenance and incremental match generation, to answer CSM. Throughout the course of continuous subgraph matching, incremental match generation backtracking over the search space dominates the total cost. However, most previous approaches focus on developing techniques for efficient candidate maintenance, while incremental match generation receives less attention despite its importance in CSM. Aiming to minimize the overall cost, we propose two techniques to reduce backtrackings in this paper. We present a cost-effective index CaLiG that yields tighter candidate maintenance, shrinking the search space of backtracking. In addition, we develop a novel incremental matching paradigm KSS that decomposes the query vertices into conditional kernel vertices and shell vertices. With the matches of kernel vertices, the incremental matches can be produced immediately by joining the candidates of shell vertices without any backtrackings. Benefiting from reduced backtrackings, the elapsed time of CSM decreases significantly. Extensive experiments over real graphs show that our method runs faster than the state-of-the-art algorithm orders of magnitude."}, "cited_paper_content": {"title": "A Selectivity Based Approach To Continuous Pattern Detection In Streaming Graphs", "abstract": "Cyber security is one of the most significant technical challenges in current times. Detecting adversarial activities, prevention of theft of intellectual properties and customer data is a high priority for corporations and government agencies around the world. Cyber defenders need to analyze massive-scale, high-resolution network flows to identify, categorize, and mitigate attacks involving networks spanning institutional and national boundaries. Many of the cyber attacks can be described as subgraph patterns, with prominent examples being insider infiltrations (path queries), denial of service (parallel paths) and malicious spreads (tree queries). This motivates us to explore subgraph matching on streaming graphs in a continuous setting. The novelty of our work lies in using the subgraph distributional statistics collected from the streaming graph to determine the query processing strategy. We introduce a \"Lazy Search\" algorithm where the search strategy is decided on a vertex-to-vertex basis depending on the likelihood of a match in the vertex neighborhood. We also propose a metric named \"Relative Selectivity\" that is used to select between different query processing strategies. Our experiments performed on real online news, network traffic stream and a synthetic social network benchmark demonstrate 10-100x speedups over selectivity agnostic approaches."}, "keywords": ["partial matches", "subgraphs"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For streaming graphs, performing subgraph matching over the graphs prior to and after updating respectively is unacceptable for the real-time requirement. To address this issue, the authors of this manuscript propose a novel incremental matching paradigm KSS that decomposes the query vertices into conditional kernel vertices and shell vertices, and with the matches of kernel vertices, the incremental matches can be produced immediately by joining the candidates of shell vertices without any backtrackings. This approach has shown significant improvements in elapsed time of continuous subgraph matching over real graphs compared to previous methods. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Continuous subgraph matching on streaming graphs has gained increasing attention in recent years due to its real-time requirement. However, most previous approaches focus on candidate maintenance, while incremental match generation receives less attention despite its importance in CSM. To address this issue, the authors of this manuscript propose a novel incremental matching paradigm named KSS that decomposes the query vertices into conditional kernel vertices and shell vertices, which can produce incremental matches immediately without any backtrackings. This approach has shown significant improvements in elapsed time compared to previous methods, as demonstrated in their experiments on real graphs. #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For streaming graphs, continuous subgraph matching is a challenging task due to the real-time requirement, which makes it unacceptable to perform subgraph matching over the graphs prior to and after updating respectively. Previous approaches such as IncIsoMat and Graphflow expand matches from the updated edges without any additional index structures, showing limited real-time performance. However, the authors of #REFR propose a novel \"Lazy Search\" algorithm that uses the subgraph distributional statistics collected from the streaming graph to determine the query processing strategy, achieving 10-100x speedups over selectivity agnostic approaches, which can be beneficial for partial matches and subgraphs.", "given_citation_intent": "background", "given_keywords": ["partial matches", "subgraphs"]}]}
{"citing_id": "2303.01194v1", "cited_id": "1801.06146", "section_title": "Head-First Fine-Tuning", "citation": "To address this issue, we propose an alternative fine-tuning approach inspired by the concept of gradual unfreezing as introduced in #REFR .", "text_before_citation": ["Low amounts of labeled data and short sample lengths (e.g., tweets) can cause unstable Encoder Transformer model fine-tuning in regression tasks #OTHEREFR ."], "text_after_citation": ["Head-First Fine-Tuning (HeFiT) is a two-step procedure to fine-tune Encoder Transformers used for regression.", "We add dropout to the hidden layer of the head.", "In the first step the embedding layers are frozen and the regression head is fine-tuned for three epochs.", "In the second step, the entire model is unfrozen and fine-tuned for six epochs with the learning rate halved.", "The rationale behind the approach is that the random weight initialization of the regression head in the regular fine-tuning may lead to inaccurate signals being propagated back to the embedding layers, resulting in degradation of the pre-trained model. However, our investigation extends beyond HeFiT."], "citing_paper_content": {"title": "Uzh_Clyp At Semeval-2023 Task 9: Head-First Fine-Tuning And Chatgpt Data Generation For Cross-Lingual Learning In Tweet Intimacy Prediction", "abstract": "This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 \"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure. Our cross-lingual transfer learning approach explores the benefits of using a HeadFirst Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate. Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available. Our study shows that HeFiT stabilizes training and consistently improves results for pretrained models that lack domain adaptation to tweets. Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text generation systems to improve zero-shot baseline results. Finally, we examine how possible inconsistencies in the annotated data contribute to cross-lingual interference issues."}, "cited_paper_content": {"title": "Universal Language Model Fine-Tuning For Text Classification", "abstract": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code."}, "keywords": ["alternative fine-tuning approach"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Low amounts of labeled data and short sample lengths (e.g., tweets) can cause unstable Encoder Transformer model fine-tuning in regression tasks (Howard and Ruder, 2018) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of unstable Encoder Transformer model fine-tuning in regression tasks with low amounts of labeled data and short sample lengths, the authors propose Universal Language Model Fine-tuning (ULMFiT), a transfer learning method that significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of unstable Encoder Transformer model fine-tuning in regression tasks with low amounts of labeled data and short sample lengths, an #OTHEREFR alternative fine-tuning approach called Universal Language Model Fine-tuning (ULMFiT) has been proposed, which significantly outperforms the state-of-the-art on six text classification tasks and matches the performance of training from scratch on 100x more data with only 100 labeled examples. #REFR", "given_citation_intent": "method", "given_keywords": ["alternative fine-tuning approach"]}]}
{"citing_id": "2304.12290v1", "cited_id": "1606.01800", "section_title": "Problem Statement", "citation": "Furthermore, our results are non-asymptotic #REFR with explicit probabilistic bounds on the approximation errors.", "text_before_citation": ["In particular, when rows are random vectors with a certain prior distribution (e.g., they are i.i.d.", "according to a common F -variate distribution), we are in the presence of a Bayesian version of the MMV-CS problem, for which the MMV-AMP algorithm and its variants have been proposed, analyzed, and widely used in applications #OTHEREFR .", "In the case U > 1 and F > 1, where the X u 's have row distribution that may differ for different indices u, the estimation problem in (1) is new and does not reduces to any of the previously considered cases.", "Our main contribution is the high-dimensional analysis of the AMP algorithm devised for the observation model #OTHEREFR .", "Instead of the usual Bolthausen's conditioning proof technique #OTHEREFR , our AMP analysis here is based on the recent AMP proof strategy of #OTHEREFR , which leads to a more straightforward derivation of the state-evolution analysis."], "text_after_citation": ["In addition, we have presented the RS (replica-symmetric) predictions of the high-dimensional limits of the normalized input-output mutual information and the MMSE (minimum mean-square-error).", "We organize the paper as follows: In Section 2 we present our theoretical contributions mentioned above.", "Section 3 is devoted to the problem of unsourced random access in cell-free systems, which is the motivating application of the observation model #OTHEREFR , and provides some numerical results. We conclude the paper in Section 4. The proofs are relegated to Appendix."], "citing_paper_content": {"title": "Inference In Linear Observations With Multiple Signal Sources: Analysis Of Approximate Message Passing And Applications To Unsourced Random Access In Cell-Free Systems", "abstract": "Here we consider a problem of multiple measurement vector (MMV) compressed sensing with multiple signal sources. The observation model is motivated by the application of unsourced random access in wireless cell-free MIMO (multiple-input-multiple-output) networks. We present a novel (and rigorous) high-dimensional analysis of the AMP (approximate message passing) algorithm devised for the model. As the system dimensions in the order, say O(L), tend to infinity, we show that the empirical dynamical order parameters-describing the dynamics of the AMP-converge to deterministic limits (described by a state-evolution equation) with the convergence rate O(L \u2212 1 2). Furthermore, we have shown the asymptotic consistency of the AMP analysis with the replica-symmetric calculation of the static problem. In addition, we provide some interesting aspects on the unsourced random access (or initial access) for cell-free systems, which is the application motivating the observation model."}, "cited_paper_content": {"title": "Finite-Sample Analysis Of Approximate Message Passing", "abstract": "This paper studies the performance of Approximate Message Passing (AMP), in the regime where the problem dimension is large but finite. We consider the setting of high-dimensional regression, where the goal is to estimate a high-dimensional vector \u03b2 0 from an observation y = A\u03b2 0 + w. AMP is a low-complexity, scalable algorithm for this problem. It has the attractive feature that its performance can be accurately characterized in the asymptotic large system limit by a simple scalar iteration called state evolution. Previous proofs of the validity of state evolution have all been asymptotic convergence results. In this paper, we derive a concentration result for AMP with i.i.d. Gaussian measurement matrices with finite dimension n \u00d7 N. The result shows that the probability of deviation from the state evolution prediction falls exponentially in n. Our result provides theoretical support for empirical findings that have demonstrated excellent agreement of AMP performance with state evolution predictions for moderately large dimensions."}, "keywords": ["explicit probabilistic bounds", "approximation errors"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our main contribution is the high-dimensional analysis of the AMP algorithm devised for the observation model, which is based on the recent AMP proof strategy of #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The AMP algorithm has been widely used in applications of Bayesian version of the MMV-CS problem, where rows are random vectors with a certain prior distribution, and its performance can be accurately characterized in the asymptotic large system limit by a simple scalar iteration called state evolution #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of #REFR provide explicit probabilistic bounds for the performance of Approximate Message Passing (AMP) with i.i.d. Gaussian measurement matrices with finite dimension n \u00d7 N, which is relevant for the analysis of the high-dimensional AMP algorithm devised for the observation model in this manuscript and can help to control the approximation errors.", "given_citation_intent": "background", "given_keywords": ["explicit probabilistic bounds", "approximation errors"]}]}
{"citing_id": "2303.17675v1", "cited_id": "1911.07767", "section_title": "I. Introduction", "citation": "This gives rise to a parametrization of the feedback gains as a linear combination of the collected data and allows to perform direct data-driven control design through semi-definite programming (SDP) #REFR .", "text_before_citation": ["Furthermore, each method may be classified into either a certainty-equivalence (CE) or robust approach, depending on whether uncertainties are taken into account.", "The indirect or sysID approach has been long studied in the general setting #OTHEREFR , #OTHEREFR with methods such as subspace identification with broader applications to filtering and state estimation #OTHEREFR .", "For optimization-based control, such as the linear quadratic regular (LQR), there are many works that use the indirect approach #OTHEREFR - #OTHEREFR .", "Similarly, the direct approach to data-driven LQR has been approached using behavioral methods #OTHEREFR , gradient-based methods #OTHEREFR , #OTHEREFR , and Riccatibased methods #OTHEREFR .", "More recently, this problem has been solved using concepts from behavioral systems theory and subspace methods #OTHEREFR using Willems' Fundamental Lemma, which characterizes the trajectory of an LTI system through the range space of the input/output data matrix #OTHEREFR ."], "text_after_citation": ["To this end, the authors in #OTHEREFR , #OTHEREFR were able to come up with a CE and regularized design, thus bridging the gap between the indirect and direct approaches.", "All these optimization-based approaches to direct datadriven LQR design are done in the deterministic setting, assuming a single realization of the state trajectories from x 0 to x f .", "To the best of our knowledge, this paper is the first work that looks at the problem where the state is a stochastic process instead of a deterministic trajectory.", "Since it is still unclear how to perform data-driven designs in the context of process noise, we limit our analysis to uncertainties in the initial and final states, leaving the case of process noise for future investigation.", "Specifically, we assume that the boundary values of the state must follow a normal distribution, and the objective is to steer the entire distribution of states from an initial to a final one."], "citing_paper_content": {"title": "Data-Driven Covariance Steering Control Design", "abstract": "This paper studies the problem of steering the distribution of a linear time-invariant system from an initial normal distribution to a terminal normal distribution under no knowledge of the system dynamics. This data-driven control framework uses data collected from the input and the state and utilizes the seminal work by Willems et al. to construct a databased parametrization of the mean and the covariance control problems. These problems are then solved to optimality as convex programs using standard techniques from the covariance control literature. We also discuss the equivalence of indirect and direct data-driven covariance steering designs, as well as a regularized version of the problem that provides a balance between the two. We illustrate the proposed framework through a set of randomized trials on a double integrator system and show that the results match up almost exactly with the corresponding model-based method in the noiseless case. We then analyze the robustness properties of the data-free and data-driven covariance steering methods and demonstrate the trade-offs between performance and optimality among these methods in the presence of data corrupted with exogenous noise."}, "cited_paper_content": {"title": "Data-Driven Linear Quadratic Regulation Via Semidefinite Programming", "abstract": "This paper studies the finite-horizon linear quadratic regulation problem where the dynamics of the system are assumed to be unknown and the state is accessible. Information on the system is given by a finite set of input-state data, where the input injected in the system is persistently exciting of a sufficiently high order. Using data, the optimal control law is then obtained as the solution of a suitable semidefinite program. The effectiveness of the approach is illustrated via numerical examples."}, "keywords": ["direct data-driven control", "semi-definite programming"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For optimization-based control, such as the linear quadratic regular (LQR), there are many works that use the indirect approach #OTHEREFR - #OTHEREFR. Similarly, the direct approach to data-driven LQR has been approached using behavioral methods #OTHEREFR, gradient-based methods #OTHEREFR, #OTHEREFR, and Riccati-based methods #OTHEREFR. More recently, this problem has been solved using concepts from behavioral systems theory and subspace methods #OTHEREFR using Willems' Fundamental Lemma, which characterizes the trajectory of an LTI system through the range space of the input/output data matrix #OTHEREFR. To obtain the optimal control law for the finite-horizon linear quadratic regulation problem with unknown dynamics, the authors of this paper used a suitable semidefinite program based on a finite set of input-state data that is persistently exciting of a sufficiently high order #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The direct approach to data-driven LQR has been approached using Willems' Fundamental Lemma, which characterizes the trajectory of an LTI system through the range space of the input/output data matrix, and solved as a semidefinite program in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For direct data-driven control using semi-definite programming, the optimal control law can be obtained from a suitable semidefinite program, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": ["direct data-driven control", "semi-definite programming"]}]}
{"citing_id": "2304.09105v1", "cited_id": "1906.02390", "section_title": "Loyalty View (L. View)", "citation": "We represent the loyalty attribute and its value in a matrix form ; \u2208 R (2\u00d7 ) , where is loyalty attribute and is the value and feed it to a CNN to obtain the vector representation #REFR .", "text_before_citation": ["So, we are interested to know about our customer/user loyalty information when they buy from our websites.", "To identify the loyalty embeddings we focus on users shop, genre, hotel and targeted brand loyalty attribute.", "If a user buys an item from a shop more than five times, we include that shop name under user shop loyalty attributes.", "That means one user can be loyal to multiple shops, genres and so on.", "To capture the loyalty embeddings, we utilize a simple convolutional neural network (CNN) to extract features from the loyalty attributes."], "text_after_citation": ["The score function would be ( , , ) = \u2212 \u2212 ( ; ) and minimize the following objective function, = ( , , ) \u2208 log(1 + exp(\u2212 ( , , ))).", "Here, denotes the set of real loyalty attribute triples and is the user's loyalty view embedding."], "citing_paper_content": {"title": "Exploring 360-Degree View Of Customers For Lookalike Modeling", "abstract": "Lookalike models are based on the assumption that user similarity plays an important role towards product selling and enhancing the existing advertising campaigns from a very large user base. Challenges associated to these models reside on the heterogeneity of the user base and its sparsity. In this work, we propose a novel framework that unifies the customers' different behaviors or features such as demographics, buying behaviors on different platforms, customer loyalty behaviors and build a lookalike model to improve customer targeting for Rakuten Group, Inc. Extensive experiments on real e-commerce and travel datasets demonstrate the effectiveness of our proposed lookalike model for user targeting task."}, "cited_paper_content": {"title": "Multi-View Knowledge Graph Embedding For Entity Alignment", "abstract": "We study the problem of embedding-based entity alignment between knowledge graphs (KGs). Previous works mainly focus on the relational structure of entities. Some further incorporate another type of features, such as attributes, for refinement. However, a vast of entity features are still unexplored or not equally treated together, which impairs the accuracy and robustness of embedding-based entity alignment. In this paper, we propose a novel framework that unifies multiple views of entities to learn embeddings for entity alignment. Specifically, we embed entities based on the views of entity names, relations and attributes, with several combination strategies. Furthermore, we design some cross-KG inference methods to enhance the alignment between two KGs. Our experiments on real-world datasets show that the proposed framework significantly outperforms the state-of-the-art embedding-based entity alignment methods. The selected views, cross-KG inference and combination strategies all contribute to the performance improvement."}, "keywords": ["loyalty attribute", "CNN"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To capture the loyalty embeddings, we utilize a simple convolutional neural network (CNN) to extract features from the loyalty attributes #REFR. The proposed framework in the reference paper unifies multiple views of entities to learn embeddings for entity alignment, including attributes, which could be applied to capture the loyalty embeddings of our customers.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture the loyalty embeddings, we utilized a simple convolutional neural network (CNN) to extract features from the loyalty attributes, inspired by the multi-view embedding approach proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture the loyalty embeddings from the users' different behaviors, we utilized a simple convolutional neural network (CNN) as proposed in #REFR, which embeds entities based on the views of entity names, relations, and attributes, including loyalty attributes, resulting in improved accuracy and robustness of embedding-based entity alignment.", "given_citation_intent": "method", "given_keywords": ["loyalty attribute", "CNN"]}]}
{"citing_id": "2304.05390v1", "cited_id": "1908.03195", "section_title": "Prompts Collection", "citation": "Random objects are sampled from LVIS datasets #REFR , combined with a pre-defined template, creating a metaprompt.", "text_before_citation": ["The spatial prompts are collected using a pre-defined template, where a wide range of relations is utilized, e.g., \"on the right of\", \"above\", and \"between.\" For attribute-binding, two attributes are exploited, i.e., colors and size.", "For each hardness level, the number of objects' compositions increased, ranging from 2 to 4.", "For the action-level compositional generation, we design prompts with multiple combinations of actions starting from ComCLIP #OTHEREFR .", "We combine two sentences from ComCLIP #OTHEREFR for the easy level.", "Then, for medium and hard levels, we randomly choose one sentence and feed 'Extend text to let the subject have at least three actions.' and 'Extend text with other subjects doing other actions' into GPT-3.5, respectively, to obtain the final prompt. Detailed examples are demonstrated in Figure 3 . -Bias."], "text_after_citation": ["Then, the meta-prompt is fed to GPT-3.5 to produce the final prompt, as depicted in Figure 3 .", "To ensure the prompts are agnostic towards the protected attributes, i.e., gender, race, and age, we manually validate them. -Fairness. We adapt the bias prompts.", "For gender fairness, we replace gender-agnostic words, such as a person, with gender-specific words, such as man and woman.", "Whereas for style fairness, a style indicator is appended to the beginning of the bias prompt, as shown in Figure 3"], "citing_paper_content": {"title": "Hrs-Bench: Holistic, Reliable And Scalable Benchmark For Text-To-Image Models", "abstract": "In recent years, Text-to-Image (T2I) models have been extensively studied, especially with the emergence of diffusion models that achieve state-of-the-art results on T2I synthesis tasks. However, existing benchmarks heavily rely on subjective human evaluation, limiting their ability to holistically assess the model's capabilities. Furthermore, there is a significant gap between efforts in developing new T2I architectures and those in evaluation. To address this, we introduce HRS-Bench, a concrete evaluation benchmark for T2I models that is Holistic, Reliable, and Scalable. Unlike existing benchmarks that focus on limited aspects, HRS-Bench measures 13 skills that can be categorized into five major categories: accuracy, robustness, generalization, fairness, and bias. In addition, HRS-Bench covers 50 scenarios, including fashion, animals, transportation, food, and clothes. We evaluate nine recent large-scale T2I models using metrics that cover a wide range of skills. A human evaluation aligned with 95% of our evaluations on average was conducted to probe the effectiveness of HRS-Bench. Our experiments demonstrate that existing models often struggle to generate images with the desired count of objects, visual text, or grounded emotions. We hope that our benchmark help ease future text-to-image generation research. The code and data are available at https://eslambakr.github.io/hrsbench.github.io/."}, "cited_paper_content": {"title": "Lvis: A Dataset For Large Vocabulary Instance Segmentation", "abstract": "Progress on object detection is enabled by datasets that focus the research community\u2019s attention on open challenges. This process led us from simple images to complex scenes and from bounding boxes to segmentation masks. In this work, we introduce LVIS (pronounced \u2018el-vis\u2019): a new dataset for Large Vocabulary Instance Segmentation. We plan to collect 2.2 million high-quality instance segmentation masks for over 1000 entry-level object categories in 164k images. Due to the Zipfian distribution of categories in natural images, LVIS naturally has a long tail of categories with few training samples. Given that state-of-the-art deep learning methods for object detection perform poorly in the low-sample regime, we believe that our dataset poses an important and exciting new scientific challenge. LVIS is available at http://www.lvisdataset.org."}, "keywords": ["Random objects", "LVIS datasets"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To collect spatial prompts, the authors utilized a pre-defined template with a wide range of relations, such as \"on the right of\" and \"above,\" and exploited two attributes, colors, and size, for attribute-binding. For the action-level compositional generation, prompts were designed with multiple combinations of actions starting from ComCLIP #OTHEREFR, and GPT-3.5 was used to obtain the final prompt. The authors' approach is similar to the one used in LVIS, a dataset for Large Vocabulary Instance Segmentation, where the authors collected 2.2 million high-quality instance segmentation masks for over 1000 entry-level object categories in 164k images. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To collect a large number of high-quality instance segmentation masks for over 1000 entry-level object categories, the authors of this manuscript could use the LVIS dataset introduced in \"Lvis: A Dataset For Large Vocabulary Instance Segmentation\" (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To obtain the final prompt for medium and hard levels, we randomly choose one sentence and feed 'Extend text to let the subject have at least three actions.' and 'Extend text with other subjects doing other actions' into GPT-3.5, respectively, and use the resulting prompts to generate random objects, similar to the approach used in LVIS datasets #REFR.", "given_citation_intent": "method", "given_keywords": ["Random objects", "LVIS datasets"]}]}
{"citing_id": "2303.12261v1", "cited_id": "1905.11075", "section_title": "Examples Of Machine Learning In Multiscale Computational Modeling 2.1 Computational Mechanics 2.1.1 Fluid Modeling", "citation": "The analysis of fluid mechanics data still relies largely on domain expertise and traditional statistical analysis, which involve many simplifying assumptions #REFR .", "text_before_citation": ["The intersection of ML and fluid mechanics presents a natural synergy, owing to their similarity in dealing with large and complex datasets.", "In traditional fluid mechanics, one has to deal with a large amount of data coming from various source, including experiments, field measurements or large-scale simulation."], "text_after_citation": ["Recently, the rise of ML, especially DL, has been a significant driving force in fluid mechanics research, rendering opportunities for tackling more difficult fluid mechanics problems such as turbulent flows and its modeling.", "By leveraging the computational efficiency of ML, advancements in fluid flow modeling can be achieved, which can have a profound impact on a wide range of applications, such as biomedical engineering, aerospace engineering, and aerial/hydrorobotics and autonomous systems, among others.", "In fact, DL techniques such as artificial neural networks (ANN) have been employed to simulate fluid dynamics very early, since the 1990s #OTHEREFR , #OTHEREFR and are still being developed #OTHEREFR .", "Along with the breakthrough in DL architecture development, the progress in fluid flow modeling has been significantly accelerated.", "ML approaches such as recurrent neural networks (RNNs) have been utilized to model flows in extreme environments #OTHEREFR , #OTHEREFR Unlike traditional feedforward neural networks, RNNs have loops that allow information to be passed from one step of the network to the next, enabling them to maintain information about previous inputs and influence the current output."], "citing_paper_content": {"title": "Challenges And Opportunities For Machine Learning In Multiscale Computational Modeling", "abstract": "Many mechanical engineering applications call for multiscale computational modeling and simulation. However, solving for complex multiscale systems remains computationally onerous due to the high dimensionality of the solution space. Recently, machine learning (ML) has emerged as a promising solution that can either serve as a surrogate for, accelerate or augment traditional numerical methods. Pioneering work has demonstrated that ML provides solutions to governing systems of equations with comparable accuracy to those obtained using direct numerical methods, but with significantly faster computational speed. These high-speed, high-fidelity estimations can facilitate the solving of complex multiscale systems by providing a better initial solution to traditional solvers. This paper provides a perspective on the opportunities and challenges of using ML for complex multiscale modeling and simulation. We first outline the current state-of-the-art ML approaches for simulating multiscale systems and highlight some of the landmark developments. Next, we discuss current challenges for ML in multiscale computational modeling, such as the data and discretization dependence, interpretability, and data sharing and collaborative platform development. Finally, we suggest several potential research directions for the future."}, "cited_paper_content": {"title": "Machine Learning For Fluid Mechanics", "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from field measurements, experiments and large-scale simulations at multiple spatiotemporal scales. Machine learning offers a wealth of techniques to extract information from data that could be translated into knowledge about the underlying fluid mechanics. Moreover, machine learning algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of machine learning for fluid mechanics. It outlines fundamental machine learning methodologies and discusses their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experimentation, and simulation. Machine learning provides a powerful information processing framework that can enrich, and possibly even transform, current lines of fluid mechanics research and industrial applications."}, "keywords": ["fluid mechanics data"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The intersection of ML and fluid mechanics presents a natural synergy, owing to their similarity in dealing with large and complex datasets. In traditional fluid mechanics, one has to deal with a large amount of data coming from various source, including experiments, field measurements or large-scale simulation. This makes machine learning an attractive approach for extracting information from data and translating it into knowledge about the underlying fluid mechanics #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Machine learning has been shown to be a promising approach for extracting information from large and complex datasets in fluid mechanics, as highlighted in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In dealing with large and complex datasets in fluid mechanics, machine learning has emerged as a promising solution that can extract information from #REFR, which could be translated into knowledge about the underlying fluid mechanics.", "given_citation_intent": "background", "given_keywords": ["fluid mechanics data"]}]}
{"citing_id": "2304.01081v1", "cited_id": "1911.05076", "section_title": "Ablation", "citation": "As a result, centroid mapping in Euclidean manifold alone can achieve good results in PubMed, and hyperbolic manifold performs better in CiteSeer while spherical manifold suit CORA, which support the conclusion in #REFR .", "text_before_citation": ["Meanwhile, it also reflects that the larger the coreset, the more redundant information in the absorbed space.", "Every manifold counts.", "Given the introduction of GCN in the spherical manifold, we conduct parallel-space ablation experiments on our model.", "Experiments are performed on only one of the three spaces and discarding one.", "The experimental results over classic citation networks are shown in Table 5 ."], "text_after_citation": ["It also shows that Euclidean, hyperbolic and spherical manifolds partially capture the primary information of the nodes on these three graphs.", "In addition, any combination of manifolds can increase the experimental result since the information each manifold captures is not the same.", "Finally, we can conclude that the information on the three spaces needs to be collected simultaneously to get better performance. Fig. 8 .", "ACC of NC task distribution along with coreset size, where the X-axis denotes the step of the size of the coreset size, and the Y-axis denotes the ACC of FMGNN."], "citing_paper_content": {"title": "Fmgnn: Fused Manifold Graph Neural Network", "abstract": "Graph representation learning has been widely studied and demonstrated effectiveness in various graph tasks. Most existing works embed graph data in Euclidean space, while recent works extend the embedding models to hyperbolic or spherical spaces to achieve better performance on graphs with complex structures, such as hierarchical or ring structures. Fusing the embedding from different manifolds can take advantage of the embedding capabilities over different graph structures. However, existing embedding fusion methods mainly focus on concatenating or summing up the output embeddings without considering interacting and aligning the embeddings of the same vertices on different manifolds, which can lead to distortion and imprecision in the final fusion results. Besides, it is also challenging to fuse the embeddings of the same vertices from different coordinate systems. In the face of these challenges, we propose the Fused Manifold Graph Neural Network (FMGNN). This novel GNN architecture embeds graphs into different Riemannian manifolds with interaction and alignment among these manifolds during training and fuses the vertex embeddings through the distances on different manifolds between vertices and selected landmarks, geometric coresets. Our experiments demonstrate that FMGNN yields superior performance over strong baselines on the benchmarks of node classification and link prediction tasks."}, "cited_paper_content": {"title": "Constant Curvature Graph Convolutional Networks", "abstract": "Interest has been rising lately towards methods representing data in non-Euclidean spaces, e.g. hyperbolic or spherical, that provide specific inductive biases useful for certain real-world data properties, e.g. scale-free, hierarchical or cyclical. However, the popular graph neural networks are currently limited in modeling data only via Euclidean geometry and associated vector space operations. Here, we bridge this gap by proposing mathematically grounded generalizations of graph convolutional networks (GCN) to (products of) constant curvature spaces. We do this by i) introducing a unified formalism that can interpolate smoothly between all geometries of constant curvature, ii) leveraging gyro-barycentric coordinates that generalize the classic Euclidean concept of the center of mass. Our class of models smoothly recover their Euclidean counterparts when the curvature goes to zero from either side. Empirically, we outperform Euclidean GCNs in the tasks of node classification and distortion minimization for symbolic data exhibiting non-Euclidean behavior, according to their discrete curvature."}, "keywords": ["centroid mapping"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Given the introduction of GCN in the spherical manifold, we conduct parallel-space ablation experiments on our model, and our class of models smoothly recover their Euclidean counterparts when the curvature goes to zero from either side. Experiments are performed on only one of the three spaces and discarding one. The experimental results over classic citation networks are shown in Table 5, citing the mathematically grounded generalizations of graph convolutional networks to constant curvature spaces proposed in the #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our FMGNN with Euclidean GCNs on symbolic data with non-Euclidean behavior, and our results demonstrate superior performance in node classification and distortion minimization tasks according to their discrete curvature #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To compare the performance of our model with other non-Euclidean GCNs, we conduct experiments on the classic citation networks and show the results in Table 5, where our Fused Manifold Graph Neural Network outperforms Euclidean GCNs in node classification and distortion minimization for symbolic data exhibiting non-Euclidean behavior, according to their discrete curvature, demonstrating the effectiveness of our proposed method in capturing the intrinsic geometry of the data and the importance of centroid mapping.#REFR", "given_citation_intent": "result", "given_keywords": ["centroid mapping"]}]}
{"citing_id": "2305.02728v1", "cited_id": "1905.10497", "section_title": "Introduction", "citation": "Two Fair Federated Learning (FFL) techniques, q-Fair Federated Learning (q-FFL) and Tilted Empirical Risk Minimization (TERM), proposed by Li et al. #REFR and Li et al.", "text_before_citation": ["Edge devices provide computational power and data for Machine Learning tasks; however, minimising communication costs while using them can be challenging. Federated Learning (FL) was introduced by McMahan et al.", "#OTHEREFR to enable model training on client devices without sharing data.", "However, the FL model accuracy may be underwhelming on clients with unusual data and even worse than a local model, reducing the incentive for participation.", "The existing body of research on balancing global and local performance has proposed several approaches."], "text_after_citation": ["#OTHEREFR respectively, aim to improve the accuracy of the worst-performing clients by prioritising those with large losses during FL. Alternatively, Yu et al. #OTHEREFR and Mansour et al.", "#OTHEREFR recommend using personalisation (local adaptation) methods such as Freezebase (FB), Elastic Weight Consolidation (EWC), and Knowledge Distillation (KD) for fine-tuning.", "In this work, relative accuracy refers to the difference in local client test set accuracy between a federated and local model.", "While the sets of potential use cases for fairness and personalisation are not identical-e.g., personalisation would be inappropriate for clients with few samples-FFL could construct a fairer relative accuracy distribution as a starting point.", "For FFL to reduce the need for personalisation, it would have to lower the number of underperforming clients or improve their average relative accuracy."], "citing_paper_content": {"title": "Can Fair Federated Learning Reduce The Need For Personalisation?", "abstract": "Federated Learning (FL) enables training ML models on edge clients without sharing data. However, the federated model's performance on local data varies, disincentivising the participation of clients who benefit little from FL. Fair FL reduces accuracy disparity by focusing on clients with higher losses while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model underperforms relative to one trained locally. For situations where the federated model provides a lower accuracy than a model trained entirely locally by a client, personalisation improves the accuracy of the pre-trained federated weights to be similar to or exceed those of the local client model. This paper evaluates two Fair FL (FFL) algorithms as starting points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task and may double the number of underperforming clients for an image task. Instead, we propose Personalisation-aware Federated Learning (PaFL) as a paradigm that pre-emptively uses personalisation losses during training. Our technique shows a 50% reduction in the number of underperforming clients for the language task while lowering the number of underperforming clients in the image task instead of doubling it. Thus, evidence indicates that it may allow a broader set of devices to benefit from FL and represents a promising avenue for future experimentation and theoretical analysis."}, "cited_paper_content": {"title": "Fair Resource Allocation In Federated Learning", "abstract": "Federated learning involves training statistical models in massive, heterogeneous networks. Naively minimizing an aggregate loss function in such a network may disproportionately advantage or disadvantage some of the devices. In this work, we propose q-Fair Federated Learning (q-FFL), a novel optimization objective inspired by fair resource allocation in wireless networks that encourages a more fair (i.e., more uniform) accuracy distribution across devices in federated networks. To solve q-FFL, we devise a communication-efficient method, q-FedAvg, that is suited to federated networks. We validate both the effectiveness of q-FFL and the efficiency of q-FedAvg on a suite of federated datasets with both convex and non-convex models, and show that q-FFL (along with q-FedAvg) outperforms existing baselines in terms of the resulting fairness, flexibility, and efficiency."}, "keywords": ["q-Fair Federated Learning"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The existing body of research on balancing global and local performance has proposed several approaches. One such approach is q-Fair Federated Learning (q-FFL) proposed by Li et al. in their paper on fair resource allocation in federated learning #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of minimizing communication costs while using edge devices for Machine Learning tasks, Federated Learning (FL) was introduced by McMahan et al. #OTHEREFR. The proposed q-Fair Federated Learning (q-FFL) method from #REFR encourages a more uniform accuracy distribution across devices in federated networks, thus providing a promising approach to balancing global and local performance.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of accuracy disparity in Federated Learning, the authors propose q-Fair Federated Learning (q-FFL), a novel optimization objective that encourages a more uniform accuracy distribution across devices in federated networks, and devise a communication-efficient method, q-FedAvg, that is suited to federated networks #REFR.", "given_citation_intent": "method", "given_keywords": ["q-Fair Federated Learning"]}]}
{"citing_id": "2304.04058v1", "cited_id": "2002.08953", "section_title": "Discussion", "citation": "Compared to the NNQS results reported in #REFR , we see that the IS method with the symmetric function ansatz is able to better predict the overlap of the above state with the |GHZ n + .", "text_before_citation": ["In an experiment involving symmetric states, first studied in #OTHEREFR , the fidelity of |GHZ n + is estimated with respect to another mixed state of the form, \u03c1 n,p = (1 \u2212 p) |GHZ n + GHZ n", "+ | + p |GHZ n \u2212 GHZ n \u2212 | for p \u2208 [0, 1]", ".", "It was been reported that for this mixed state example, generative models learned using the Neural Net Quantum States (NNQS) ansatz [7, #OTHEREFR struggled to find the correct fidelity as p got closer to 1.", "The results of applying our method on this problem with a symmetric function ansatz are given in Fig. 4d ."], "text_after_citation": ["7 We see that symmetric function ansatz performs much better than neural-net anastz learned with NeurISE #OTHEREFR without any symmetry assumptions. Both models are learned using 10 6 state measurements.", "The neural net has 1043 trainable parameters while the symmetric function has 840 parameters (d) Comparison of the fidelity between \u03c1n,p for p \u2208 [0, 1] with |GHZ n + estimated from a symmetric EBM for \u03c1n,p.", "The symmetric EBM is able to produce the correct fidelity behavior here even when p \u2192 1.", "It has been reported that for this benchmark, NNQS methods which compute a classical upper bound for quantum fidelity, are not able to reproduce the correct behavior when p gets close to 1 [7, #OTHEREFR .", "All the models here are learned using 6 \u00d7 10 4 samples."], "citing_paper_content": {"title": "Learning Energy Based Representations Of Quantum Many-Body States", "abstract": "Efficient representation of quantum many-body states on classical computers is a problem of enormous practical interest. An ideal representation of a quantum state combines a succinct characterization informed by the system's structure and symmetries, along with the ability to predict the physical observables of interest. A number of machine learning approaches have been recently used to construct such classical representations [1-6] which enable predictions of observables [7] and accounts for physical symmetries [8]. However, the structure of a quantum state gets typically lost unless a specialized ansatz is employed based on prior knowledge of the system [9-12]. Moreover, most such approaches give no information about what states are easier to learn in comparison to others. Here, we propose a new generative energy-based representation of quantum many-body states derived from Gibbs distributions used for modeling the thermal states of classical spin systems. Based on the prior information on a family of quantum states, the energy function can be specified by a small number of parameters using an explicit low-degree polynomial or a generic parametric family such as neural nets, and can naturally include the known symmetries of the system. Our results show that such a representation can be efficiently learned from data using exact algorithms in a form that enables the prediction of expectation values of physical observables. Importantly, the structure of the learned energy function provides a natural explanation for the hardness of learning for a given class of quantum states."}, "cited_paper_content": {"title": "Predicting Many Properties Of A Quantum System From Very Few Measurements", "abstract": "Predicting properties of complex, large-scale quantum systems is essential for developing quantum technologies. We present an efficient method for constructing an approximate classical description of a quantum state using very few measurements of the state. This description, called a classical shadow, can be used to predict many different properties: order $\\log M$ measurements suffice to accurately predict $M$ different functions of the state with high success probability. The number of measurements is independent of the system size, and saturates information-theoretic lower bounds. Moreover, target properties to predict can be selected after the measurements are completed. We support our theoretical findings with extensive numerical experiments. We apply classical shadows to predict quantum fidelities, entanglement entropies, two-point correlation functions, expectation values of local observables, and the energy variance of many-body local Hamiltonians, which allows applications to speedup variational quantum algorithms. The numerical results highlight the advantages of classical shadows relative to previously known methods."}, "keywords": ["state"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In an experiment involving symmetric states, first studied in #OTHEREFR, the authors struggled to find the correct fidelity as p got closer to 1 using the Neural Net Quantum States (NNQS) ansatz. The proposed generative energy-based representation of quantum many-body states derived from Gibbs distributions used for modeling the thermal states of classical spin systems, as presented in #REFR, could potentially provide a solution to this problem.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The generative models learned using the Neural Net Quantum States (NNQS) ansatz struggled to find the correct fidelity for a mixed state example, as reported in a previous study on predicting many properties of a quantum system from very few measurements #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The generative energy-based representation of quantum many-body states proposed in this manuscript enables the prediction of expectation values of physical observables, which is a significant improvement over the Neural Net Quantum States (NNQS) ansatz [7, #REFR] that struggled to find the correct fidelity for symmetric states.", "given_citation_intent": "result", "given_keywords": ["state"]}]}
{"citing_id": "2304.06280v2", "cited_id": "1802.04289", "section_title": "Related Work 2.1 Twitter Bot Detection", "citation": "Kudugunta and Ferrara #REFR exploits user metadata and proposes SMOTENN to combat imbalanced datasets. Miller et al.", "text_before_citation": ["Bots with malicious goals often harm the integrity of online discourse and reduce search quality.", "Existing Twitter bot detection methods can be often categorized into three types: feature-based, text-based, and graph-based approaches #OTHEREFR .", "Feature-based methods.", "These methods conduct feature engineering based on handcrafted user features derived from metadata #OTHEREFR and user textual information #OTHEREFR .", "These features are then combined with traditional classification algorithms #OTHEREFR to identify Twitter bots."], "text_after_citation": ["#OTHEREFR leverages the feature of tweet content and performs anomaly detection to identify bots. Hayawi et al.", "#OTHEREFR use hybrid types of numerical, binary, and textural features as high dimensional tensors for classification.", "However, as noted by Cresci #OTHEREFR , evolving bots can evade the detection of feature-based approaches by creating deceptive accounts with manipulated metadata and stolen tweets.", "Text-based methods.", "The methods use NLP techniques to detect Twitter bots with their tweets and descriptions."], "citing_paper_content": {"title": "Botmoe: Twitter Bot Detection With Community-Aware Mixtures Of Modal-Specific Experts", "abstract": "Twitter bot detection has become a crucial task in efforts to combat online misinformation, mitigate election interference, and curb malicious propaganda. However, advanced Twitter bots often attempt to mimic the characteristics of genuine users through feature manipulation and disguise themselves to fit in diverse user communities, posing challenges for existing Twitter bot detection models. To this end, we propose BotMoE 1 , a Twitter bot detection framework that jointly utilizes multiple user information modalities (metadata, textual content, network structure) to improve the detection of deceptive bots. Furthermore, BotMoE incorporates a communityaware Mixture-of-Experts (MoE) layer to improve domain generalization and adapt to different Twitter communities. Specifically, BotMoE constructs modal-specific encoders for metadata features, textual content, and graph structure, which jointly model Twitter users from three modal-specific perspectives. We then employ a community-aware MoE layer to automatically assign users to different communities and leverage the corresponding expert networks. Finally, user representations from metadata, text, and graph perspectives are fused with an expert fusion layer, combining all three modalities while measuring the consistency of user information. Extensive experiments demonstrate that BotMoE significantly advances the state-of-the-art on three Twitter bot detection benchmarks. Studies also confirm that BotMoE captures advanced and evasive bots, alleviates the reliance on training data, and better generalizes to new and previously unseen user communities. CCS CONCEPTS \u2022 Information systems \u2192 Social networks."}, "cited_paper_content": {"title": "Deep Neural Networks For Bot Detection", "abstract": "The problem of detecting bots, automated social media accounts governed by software but disguising as human users, has strong implications. For example, bots have been used to sway political elections by distorting online discourse, to manipulate the stock market, or to push anti-vaccine conspiracy theories that caused health epidemics. Most techniques proposed to date detect bots at the account level, by processing large amount of social media posts, and leveraging information from network structure, temporal dynamics, sentiment analysis, etc. In this paper, we propose a deep neural network based on contextual long short-term memory (LSTM) architecture that exploits both content and metadata to detect bots at the tweet level: contextual features are extracted from user metadata and fed as auxiliary input to LSTM deep nets processing the tweet text. Another contribution that we make is proposing a technique based on synthetic minority oversampling to generate a large labeled dataset, suitable for deep nets training, from a minimal amount of labeled data (roughly 3,000 examples of sophisticated Twitter bots). We demonstrate that, from just one single tweet, our architecture can achieve high classification accuracy (AUC>96%) in separating bots from humans. We apply the same architecture to account-level bot detection, achieving nearly perfect classification accuracy (AUC>99%). Our system outperforms previous state of the art while leveraging a small and interpretable set of features yet requiring minimal training data."}, "keywords": ["user metadata", "imbalanced datasets"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Feature-based Twitter bot detection methods often conduct feature engineering based on handcrafted user features derived from metadata and user textual information, which are then combined with traditional classification algorithms to identify Twitter bots #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Feature-based Twitter bot detection methods conduct feature engineering based on handcrafted user features derived from metadata and user textual information, which are then combined with traditional classification algorithms to identify Twitter bots #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Feature-based Twitter bot detection methods conduct feature engineering based on handcrafted user features derived from metadata #REFR and user textual information, which are then combined with traditional classification algorithms to identify Twitter bots.", "given_citation_intent": "background", "given_keywords": ["user metadata", "imbalanced datasets"]}]}
{"citing_id": "2304.12652v1", "cited_id": "1801.03924", "section_title": "Results On Scannet", "citation": "Quantitative comparisons with other baselines in terms of PSNR, SSIM, and LPIPS #REFR are reported in Table 1 .", "text_before_citation": [], "text_after_citation": ["Our hybrid neural rendering design \"Ours (H)\" outperforms previous methods by enhancing the quality of neural 3D representations.", "However, the PSNR and SSIM drop in the full version of our method \"Ours\".", "This is because our blur-handling modules mimic blurriness effects and down weight blur images, enabling the model to learn from clean supervision.", "However, since this differs from the original training data distribution, the model may not fit the evaluation metric well.", "Moreover, Deblur-NeRF delivers a low PSNR because it tends to introduce misalignment between rendered and reference images."], "citing_paper_content": {"title": "Hybrid Neural Rendering For Large-Scale Scenes With Motion Blur", "abstract": "Rendering novel view images is highly desirable for many applications. Despite recent progress, it remains challenging to render high-fidelity and view-consistent novel views of large-scale scenes from in-the-wild images with inevitable artifacts (e.g., motion blur). To this end, we develop a hybrid neural rendering model that makes image-based representation and neural 3D representation join forces to render high-quality, view-consistent images. Besides, images captured in the wild inevitably contain artifacts, such as motion blur, which deteriorates the quality of rendered images. Accordingly, we propose strategies to simulate blur effects on the rendered images to mitigate the negative influence of blurriness images and reduce their importance during training based on precomputed qualityaware weights. Extensive experiments on real and synthetic data demonstrate our model surpasses state-of-theart point-based methods for novel view synthesis. The code is available at https://daipengwa.github.io/ Hybrid-Rendering-ProjectPage/."}, "cited_paper_content": {"title": "The Unreasonable Effectiveness Of Deep Features As A Perceptual Metric", "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on the ImageNet classification task has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called\"perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new Full Reference Image Quality Assessment (FR-IQA) dataset of perceptual human judgments, orders of magnitude larger than previous datasets. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by huge margins. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations."}, "keywords": ["PSNR"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To evaluate the perceptual similarity of our rendered images, we use a Full Reference Image Quality Assessment (FR-IQA) dataset of perceptual human judgments, which is orders of magnitude larger than previous datasets #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our results with classic metrics and find that deep features outperform all previous metrics by huge margins, which is consistent with the findings in the reference paper \"#REFR\".", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our results demonstrate that our proposed hybrid neural rendering model outperforms state-of-the-art point-based methods for novel view synthesis, achieving higher #REFR PSNR scores and view-consistency.", "given_citation_intent": "result", "given_keywords": ["PSNR"]}]}
{"citing_id": "2305.01624v1", "cited_id": "1905.07129", "section_title": "A Fine-Tuning Details", "citation": "Entity Typing Following ERNIE #REFR , we first insert a pair of special tokens to enclose and emphasize the given span in the input sequence.", "text_before_citation": ["The fine-tuning methods for different task:"], "text_after_citation": ["After PLM's encoding, we adopt the final representation of the [CLS] token for classification.", "Named Entity Recognition Following Devlin et al.", "(2019), we regard the task as a sequence labeling task and apply a token-level classifier to tokens' contextual representations to predict their IOB2 tags #OTHEREFR .", "Relation Extraction Following ERNIE #OTHEREFR , we insert two pairs of special tokens to enclose and highlight the subject entity and the object entity in the input sequence respectively.", "After that, we add a relation classifier layer on the [CLS] token's final representation for predictions."], "citing_paper_content": {"title": "Unter: A Unified Knowledge Interface For Enhancing Pre-Trained Language Models", "abstract": "Recent research demonstrates that external knowledge injection can advance pre-trained language models (PLMs) in a variety of downstream NLP tasks. However, existing knowledge injection methods are either applicable to structured knowledge or unstructured knowledge, lacking a unified usage. In this paper, we propose a UNified knowledge inTERface, UNTER, to provide a unified perspective to exploit both structured knowledge and unstructured knowledge. In UNTER, we adopt the decoder as a unified knowledge interface, aligning span representations obtained from the encoder with their corresponding knowledge. This approach enables the encoder to uniformly invoke span-related knowledge from its parameters for downstream applications. Experimental results show that, with both forms of knowledge injected, UNTER gains continuous improvements on a series of knowledge-driven NLP tasks, including entity typing, named entity recognition and relation extraction, especially in low-resource scenarios."}, "cited_paper_content": {"title": "Ernie: Enhanced Language Representation With Informative Entities", "abstract": "Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from this https URL."}, "keywords": ["given span", "ERNIE"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The fine-tuning methods for different tasks can be enhanced by incorporating external knowledge, as demonstrated by recent research #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To fine-tune the pre-trained language models for knowledge-driven tasks, external knowledge injection methods have been proposed, such as incorporating knowledge graphs (KGs) to enhance language representation with informative entities #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To incorporate external knowledge into pre-trained language models, recent research has proposed various methods, including utilizing knowledge graphs to enhance language representation with informative entities #REFR.", "given_citation_intent": "method", "given_keywords": ["given span", "ERNIE"]}]}
{"citing_id": "2305.02957v1", "cited_id": "1712.07511", "section_title": "Wasserstein Lifting And Behavioural Metrics", "citation": "We build on #REFR , where an approach is proposed for canonically defining a behavioural pseudometric for coalgebras of a functor F : Set \u2192 Set, that is, for functions of the form \u03be : X \u2192 F X where X is a set.", "text_before_citation": ["In this section we show how the framework for fixpoint checking described before can be used to deal with coalgebraic behavioural metrics."], "text_after_citation": ["Intuitively \u03be specifies a transition system whose branching type is given by F .", "Given such a coalgebra \u03be, the idea is to endow X with a pseudo-metric d \u03be : X \u00d7 X \u2192 M defined as the least fixpoint of the map", "d \u2192 d F \u2022 (\u03be \u00d7 \u03be) where F lifts a metric d : X \u00d7 X \u2192 M to a metric d F : F X \u00d7 F X \u2192 M.", "Here we focus on the so-called Wasserstein lifting and show how approximations of the functions involved in the definition of the pseudometric can be determined."], "citing_paper_content": {"title": "A Monoidal View On Fixpoint Checks", "abstract": "Fixpoints are ubiquitous in computer science as they play a central role in providing a meaning to recursive and cyclic definitions. Bisimilarity, behavioural metrics, termination probabilities for Markov chains and stochastic games are defined in terms of least or greatest fixpoints. Here we show that our recent work which proposes a technique for checking whether the fixpoint of a function is the least (or the largest) admits a natural categorical interpretation in terms of gs-monoidal categories. The technique is based on a construction that maps a function to a suitable approximation and the compositionality properties of this mapping are naturally interpreted as a gs-monoidal functor. This guides the realisation of a tool, called UDEfix that allows to build functions (and their approximations) like a circuit out of basic building blocks and subsequently perform the fixpoints checks. We also show that a slight generalisation of the theory allows one to treat a new relevant case study: coalgebraic behavioural metrics based on Wasserstein liftings."}, "cited_paper_content": {"title": "Coalgebraic Behavioral Metrics", "abstract": "We study different behavioral metrics, such as those arising from both branching and linear-time semantics, in a coalgebraic setting. Given a coalgebra $\\alpha\\colon X \\to HX$ for a functor $H \\colon \\mathrm{Set}\\to \\mathrm{Set}$, we define a framework for deriving pseudometrics on $X$ which measure the behavioral distance of states. ::: A crucial step is the lifting of the functor $H$ on $\\mathrm{Set}$ to a functor $\\overline{H}$ on the category $\\mathrm{PMet}$ of pseudometric spaces. We present two different approaches which can be viewed as generalizations of the Kantorovich and Wasserstein pseudometrics for probability measures. We show that the pseudometrics provided by the two approaches coincide on several natural examples, but in general they differ. ::: If $H$ has a final coalgebra, every lifting $\\overline{H}$ yields in a canonical way a behavioral distance which is usually branching-time, i.e., it generalizes bisimilarity. In order to model linear-time metrics (generalizing trace equivalences), we show sufficient conditions for lifting distributive laws and monads. These results enable us to employ the generalized powerset construction."}, "keywords": ["coalgebras"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this section we show how the framework for fixpoint checking described before can be used to deal with coalgebraic behavioural metrics. To measure the behavioral distance of states, the authors of #REFR present a framework for deriving pseudometrics on X which arise from both branching and linear-time semantics in a coalgebraic setting.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To deal with coalgebraic behavioural metrics, the authors employ a framework for deriving pseudometrics on X which measure the behavioral distance of states, and lift the functor H on Set to a functor on the category of pseudometric spaces, which is a generalization of the Kantorovich and Wasserstein pseudometrics for probability measures #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To deal with coalgebraic behavioral metrics, the authors employ a framework for deriving pseudometrics on coalgebras, which involves lifting the functor H on Set to a functor on the category of pseudometric spaces, and present two different approaches that generalize the Kantorovich and Wasserstein pseudometrics for probability measures. #REFR", "given_citation_intent": "method", "given_keywords": ["coalgebras"]}]}
{"citing_id": "2303.08090v1", "cited_id": "1904.04708", "section_title": "Discussion", "citation": "The observed decreasing trend in the SR I , however, contradicts previous studies of the development of this indicator over time: #REFR , in fact, report an average increase of +5.2 p.p.", "text_before_citation": ["The decreasing trend in both SR I and SR II which characterizes most of the countries shows that, in most of the cases, the overall citation impact of countries has grown more than the proportion of citation impact generated by domestic authors, i.e., that the denominator of both indicators has increased more than their numerator (see Section 3.2).", "The faster increase in citations may be related in turn to the overall growth of scientific production and how it impacts the length of the reference lists of scientific publications.", "According to #OTHEREFR , in fact, the world scientific production exhibits 4% annual growth in publications and 1.8% annual growth in the number of references per publication.", "Combined, these dynamics produce a 12-year doubling period in the total amount of references, which results in turn in a generalized increase in citations #OTHEREFR .", "The decreasing trends, thus, may be simply due to the different rates of growth of the numerator and the denominator of the indicators used here: country self-citations of Type I or Type II grow less than bibliographic references."], "text_after_citation": ["in the SR I of G10 countries between 2000 and 2016.", "Namely, the discrepancy between the present results and #OTHEREFR depends on the different way of computing the SR I indicator.", "Indeed, #OTHEREFR used a nonfixed citation window, which included all the years from the publication year to 2016.", "For example, for the cited items published in the year 2000, a 17year citation window was used, by summing up all citations from 2000 to 2016; whereas, for the year 2006, the citation window was 11 years long, including citations from 2006 to 2016; for 2016, the citation window included only 1 year, i.e., only citations from 2016 itself were counted.", "Since self-citations are in general younger than external citations #OTHEREFR , they tend to represent a higher proportion of total citations for the years when the citation window is shorter."], "citing_paper_content": {"title": "A Global Exploratory Comparison Of Country Self-Citations 1996-2019", "abstract": "Self-citations are a key topic in evaluative bibliometrics because they can artificially inflate citation-related performance indicators. Recently, selfcitations defined at the largest scale, i.e., country self-citations, have started to attract the attention of researchers and policymakers. According to a recent research, in fact, the anomalous trends in the country self-citation rates of some countries, such as Italy, have been induced by the distorting effect of citation metrics-centered science policies. In the present study, we investigate the trends of country self-citations in 50 countries over the world in the period 1996-2019 using Scopus data. Results show that for most countries country selfcitations have decreased over time. 12 countries ("}, "cited_paper_content": {"title": "Citation Gaming Induced By Bibliometric Evaluation: A Country-Level Comparative Analysis", "abstract": "It is several years since national research evaluation systems around the globe started making use of quantitative indicators to measure the performance of researchers. Nevertheless, the effects on these systems on the behavior of the evaluated researchers are still largely unknown. For investigating this topic, we propose a new inwardness indicator able to gauge the degree of scientific self-referentiality of a country. Inwardness is defined as the proportion of citations coming from the country over the total number of citations gathered by the country. A comparative analysis of the trends for the G10 countries in the years 2000-2016 reveals a net increase of the Italian inwardness. Italy became, both globally and for a large majority of the research fields, the country with the highest inwardness and the lowest rate of international collaborations. The change in the Italian trend occurs in the years following the introduction in 2011 of national regulations in which key passages of professional careers are governed by bibliometric indicators. A most likely explanation of the peculiar Italian trend is a generalized strategic use of citations in the Italian scientific community, both in the form of strategic author self-citations and of citation clubs. We argue that the Italian case offers crucial insights on the constitutive effects of evaluation systems. As such, it could become a paradigmatic case in the debate about the use of indicators in science-policy contexts."}, "keywords": ["previous studies"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "According to a recent research, anomalous trends in the country self-citation rates of some countries, such as Italy, have been induced by the distorting effect of citation metrics-centered science policies (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to a recent study on citation gaming induced by bibliometric evaluation, the anomalous trends in the country self-citation rates of some countries, such as Italy, have been induced by the distorting effect of citation metrics-centered science policies #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to previous studies, the anomalous trends in country self-citation rates have been induced by the distorting effect of citation metrics-centered science policies, as shown by #REFR.", "given_citation_intent": "result", "given_keywords": ["previous studies"]}]}
{"citing_id": "2303.00755v1", "cited_id": "1701.08280", "section_title": "Conclusion", "citation": "We compared our results to the Pruned Non-Local Means (PNLM) algortihm presented in #REFR , which supports our claim that the accuracy of recovery in Cloud K-SVD is on par with SOTA in the field.", "text_before_citation": ["When the noise is severe, a lot of detail have to be removed, however when it is less severe, less detail need be removed.", "Details in images can be recovered better by decreasing data size and atom count, M and N , and increasing the number of nonzero elements, K.", "Cloud K-SVD was originally made for image classification, but we have made a novel application of the algorithm and some practical improvements, e.g.", "used Simultaneous Orthogonal Matching Pursuit (SOMP) and adjusted the algorithm to account for node failures.", "We show, that our modified version of Cloud K-SVD can successfully conduct distributed AWGN denoising of images and simultaneously learn a global dictionary."], "text_after_citation": ["Table 6 Average execution times of the OMP and K-SVD step for Cloud K-SVD (tp = 3, tc = 5) when recovering Face from noisy patches with different sparsity K, data size M and AWGN level \u03c3 2 . We set \u03b1 = 1.", "Step/\u03c3 2"], "citing_paper_content": {"title": "Cloud K-Svd For Image Denoising", "abstract": "Cloud K-SVD is a dictionary learning algorithm that can train at multiple nodes and hereby produce a mutual dictionary to represent low-dimensional geometric structures in image data. We present a novel application of the algorithm as we use it to recover both noiseless and noisy images from overlapping patches. We implement a node network in Kubernetes using Docker containers to facilitate Cloud K-SVD. Results show that Cloud K-SVD can recover images approximately and remove quantifiable amounts of noise from benchmark gray-scaled images without sacrificing accuracy in recovery; we achieve an SSIM index of 0.88, 0.91 and 0.95 between clean and recovered images for noise levels (\u00b5 = 0, \u03c3 2 = 0.01, 0.005, 0.001), respectively, which is similar to SOTA in the field. Cloud K-SVD is evidently able to learn a mutual dictionary across multiple nodes and remove AWGN from images. The mutual dictionary can be used to recover a specific image at any of the nodes in the network."}, "cited_paper_content": {"title": "Pruned Non-Local Means", "abstract": "In non-local means (NLM), each pixel is denoised by performing a weighted averaging of its neighbouring pixels, where the weights are computed using image patches. The authors demonstrate that the denoising performance of NLM can be improved by pruning the neighbouring pixels, namely, by rejecting neighbouring pixels whose weights are below a certain threshold.. While pruning can potentially reduce pixel averaging in uniform-intensity regions, they demonstrate that there is generally an overall improvement in the denoising performance. In particular, the improvement comes from pixels situated close to edges and corners. The success of the proposed method strongly depends on the choice of the global threshold., which in turn depends on the noise level and the image characteristics. They show how Stein's unbiased estimator of the mean-squared error can be used to optimally tune., at a marginal computational overhead. They present some representative denoising results to demonstrate the superior performance of the proposed method over NLM and its variants."}, "keywords": ["Cloud K-SVD", "Pruned Non-Local Means"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors demonstrate that the denoising performance of non-local means (NLM) can be improved by pruning the neighbouring pixels, which can potentially reduce pixel averaging in uniform-intensity regions, but generally results in an overall improvement in the denoising performance, especially for pixels situated close to edges and corners. They also propose a method to optimally tune the global threshold using Stein's unbiased estimator of the mean-squared error, which incurs only a marginal computational overhead. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method in this manuscript shows superior denoising performance over non-local means (NLM) and its variants, especially for pixels located near edges and corners, by pruning neighbouring pixels with weights below a certain threshold, as demonstrated in the reference paper \"Pruned Non-Local Means\" (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Cloud K-SVD can successfully conduct distributed AWGN denoising of images and simultaneously learn a global dictionary, as demonstrated by the superior performance of the proposed method over NLM and its variants in #REFR.", "given_citation_intent": "result", "given_keywords": ["Cloud K-SVD", "Pruned Non-Local Means"]}]}
{"citing_id": "2303.01258v1", "cited_id": "1901.08746", "section_title": "Introduction", "citation": "Adapting general-purpose language models to a particular domain by subjecting it to additional self-supervised training using domain-specific text has been shown to boost performance for certain tasks #REFR .", "text_before_citation": ["It represents an official interpretation of the patient's images and aims to provide actionable information for future care.", "Given the vast number of information-rich radiology reports stored in clinical imaging databases, it is no surprise that artificial intelligence (AI)-based language models have begun to find an increasing number of applications in radiology.", "Language models can extract training labels from reports #OTHEREFR , summarize reports #OTHEREFR , generate reports from images #OTHEREFR , and more #OTHEREFR .", "Despite their impressive performance in various domains, language models trained on large generic text corpora can be suboptimal for applications in radiology and nuclear medicine.", "Large pre-trained language models, such as Bidirectional Encoder Representations from Transformers (BERT) #OTHEREFR , are typically developed using selfsupervised training, which involves predicting occluded words or adjacent sentences within the training corpus."], "text_after_citation": ["For example, bioBERT was adapted from BERT through additional pre-training on biomedical corpora from PubMed #OTHEREFR .", "Domain-adapted bioBERT outperformed BERT when applied to downstream biomedical tasks.", "Other studies have demonstrated the benefit of domain adaption #OTHEREFR .", "Adaptation of language models to the nuclear medicine domain, however, has been understudied.", "Nuclear medicine reports contain unique terms that are not used more broadly in radiology."], "citing_paper_content": {"title": "Domain-Adapted Large Language Models For Classifying Nuclear Medicine Reports", "abstract": "With the growing use of transformer-based language models in medicine, it is unclear how well these models generalize to nuclear medicine which has domain-specific vocabulary and unique reporting styles. In this study, we evaluated the value of domain adaptation in nuclear medicine by adapting language models for the purpose of 5-point Deauville score prediction based on clinical 18F-fluorodeoxyglucose (FDG) PET/CT reports. We retrospectively retrieved 4542 text reports and 1664 images for FDG PET/CT lymphoma exams from 2008-2018 in our clinical imaging database. Deauville scores were removed from the reports and then the remaining text in the reports was used as the model input. Multiple general-purpose transformer language models were used to classify the reports into Deauville scores 1-5. We then adapted the models to the nuclear medicine domain using masked language modeling and assessed its impact on classification performance. The language models were compared against vision models, a multimodal vision language model, and a nuclear medicine physician with seven-fold Monte Carlo cross validation, reported are the mean and standard deviations. Domain adaption improved all language models. For example, BERT improved from 61.3 \u00b1 2.9% fiveclass accuracy to 65.7 \u00b1 2.2% following domain adaptation. The best performing model (domain-adapted RoBERTa) achieved a five-class accuracy of 77.4 \u00b1 3.4%, which was better than the physician's performance (66%), the best vision model's performance (48.1 \u00b1 3.5%), and was similar to the multimodal model's performance (77.2 \u00b1 3.2%). Domain adaptation improved the performance of large language models in interpreting nuclear medicine text reports."}, "cited_paper_content": {"title": "Biobert: A Pre-Trained Biomedical Language Representation Model For Biomedical Text Mining", "abstract": "Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. We make the pre-trained weights of BioBERT freely available at this https URL, and the source code for fine-tuning BioBERT available at this https URL."}, "keywords": ["Adapting general-purpose language", "domain-specific text"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Despite their impressive performance in various domains, language models trained on large generic text corpora can be suboptimal for applications in radiology and nuclear medicine. Large pre-trained language models, such as Bidirectional Encoder Representations from Transformers (BERT) (BioBERT), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora, have been shown to outperform BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Large pre-trained language models, such as Bidirectional Encoder Representations from Transformers (BERT), are typically developed using self-supervised training, which involves predicting occluded words or adjacent sentences within the training corpus. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Adapting general-purpose language models to domain-specific text has been shown to significantly improve their performance in various applications, including biomedical text mining #REFR.", "given_citation_intent": "background", "given_keywords": ["Adapting general-purpose language", "domain-specific text"]}]}
{"citing_id": "2304.02221v1", "cited_id": "1502.02791", "section_title": "Approximation Of 2C-Vae Loss", "citation": "This is different from partial domain adaptation problems, where importance sampling was used to apply small weights to data from missing classes #REFR .", "text_before_citation": [", which is an appropriate assumption since the trained domain classifier can often estimate the domain label accurately only from z in practical cases.", "In addition to the reformulation described above, Here, all terms can be calculated by the available data.", "Note that in the second term, the data x is sampled from the source anomalous data, but in lVAE (x, c = A, d = T) the domain label is d = T.", "Seen anomaly Unseen anomaly   Case 1  1, 2, 3  4, 5, 6  7, 8, 9  Case 2  4, 5, 6  7, 8, 9  1, 2, 3  Case 3  7, 8, 9  1, 2, 3  4, 5, 6 Thus, we input d = T to the decoder to calculate this term, although the data x will be sampled from the source domain.", "As a result, #OTHEREFR applies large weights to data from missing classes if it is regarded to be similar to target domain data."], "text_after_citation": [], "citing_paper_content": {"title": "Zero-Shot Domain Adaptation Of Anomalous Samples For Semi-Supervised Anomaly Detection", "abstract": "Semi-supervised anomaly detection (SSAD) is a task where normal data and a limited number of anomalous data are available for training. In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase. To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain. First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables. Since the decoder cannot reconstruct the original data solely from domaininvariant latent variables, we conditioned the decoder on the domain label. To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function. Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain."}, "cited_paper_content": {"title": "Learning Transferable Features With Deep Adaptation Networks", "abstract": "Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multikernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks."}, "keywords": ["partial domain adaptation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function. Experimental results indicate that the proposed method helps adapt SSAD models to the target domain when no anomalous data are available for the target domain (Li et al., 2018).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce domain discrepancy and enhance transferability in task-specific layers, the authors propose a new Deep Adaptation Network (DAN) architecture that can learn transferable features with statistical guarantees, as demonstrated by state-of-the-art image classification error rates on standard domain adaptation benchmarks (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of partial domain adaptation in semi-supervised anomaly detection, the authors propose a domain adaptation method that utilizes a domain-adversarial network and a weighted loss function, as described in #REFR.", "given_citation_intent": "method", "given_keywords": ["partial domain adaptation"]}]}
{"citing_id": "2304.01235v1", "cited_id": "1905.06214", "section_title": "Introduction", "citation": "More recently Graph Markov Neural Networks (GMNN) #REFR were introduced as genuine probabilistic models which include label correlations in graphs by combining the strength of GNNs and those of conditional random fields (CRF) while avoiding their limitations.", "text_before_citation": ["Inductive classification on the other hand refers to the most common setting in machine learning in which nodes to be labeled are not known ahead of time #OTHEREFR .", "A number of architectures have been proposed over the years which deal with specific issues occurring with GNNs.", "Some combat over-smoothing, (which is the tendency for deep GNNs to predict the same labels for all nodes) #OTHEREFR , some deal with assortativity or heterophily (which refers to situations in which neighboring nodes are likely to have different labels) #OTHEREFR and others still try to learn the connection weights from data using an appropriate attention mechanism #OTHEREFR .", "Despite their diversity, these models all have one important shortcoming.", "Namely they assume that labels can be predicted independently for each node in the graph. In other words they neglect label dependencies altogether."], "text_after_citation": ["These are the models we shall focus on in this work.", "The accuracy of the GMNN model was evaluated for node classification and link prediction tasks in #OTHEREFR on the classical benchmark datasets Cora, Pubmed and Citeseer #OTHEREFR using the public splits defined in #OTHEREFR .", "Under these settings a clear improvement was demonstrated when comparing the GMNN model to existing baselines that do not account for label dependencies.", "However, as a number of recent works #OTHEREFR have pointed out, a fair evaluation of the performance of GNNs requires a procedure which performs a systematic randomization over train-arXiv:2304.01235v1 [cs.", "LG] 3 Apr 2023 validation-test set partitions and makes clear separation between model selection and model assessment."], "citing_paper_content": {"title": "Fair Evaluation Of Graph Markov Neural Networks", "abstract": "Graph Markov Neural Networks (GMNN) have recently been proposed to improve regular graph neural networks (GNN) by including label dependencies into the semi-supervised node classification task. GMNNs do this in a theoretically principled way and use three kinds of information to predict labels. Just like ordinary GNNs, they use the node features and the graph structure but they moreover leverage information from the labels of neighboring nodes to improve the accuracy of their predictions. In this paper, we introduce a new dataset named WikiVitals which contains a graph of 48k mutually referred Wikipedia articles classified into 32 categories and connected by 2.3M edges. Our aim is to rigorously evaluate the contributions of three distinct sources of information to the prediction accuracy of GMNN for this dataset: the content of the articles, their connections with each other and the correlations among their labels. For this purpose we adapt a method which was recently proposed for performing fair comparisons of GNN performance using an appropriate randomization over partitions and a clear separation of model selection and model assessment."}, "cited_paper_content": {"title": "Gmnn: Graph Markov Neural Networks", "abstract": "This paper studies semi-supervised object classification in relational data, which is a fundamental problem in relational data modeling. The problem has been extensively studied in the literature of both statistical relational learning (e.g. relational Markov networks) and graph neural networks (e.g. graph convolutional networks). Statistical relational learning methods can effectively model the dependency of object labels through conditional random fields for collective classification, whereas graph neural networks learn effective object representations for classification through end-to-end training. In this paper, we propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds. A GMNN models the joint distribution of object labels with a conditional random field, which can be effectively trained with the variational EM algorithm. In the E-step, one graph neural network learns effective object representations for approximating the posterior distributions of object labels. In the M-step, another graph neural network is used to model the local label dependency. Experiments on object classification, link classification, and unsupervised node representation learning show that GMNN achieves state-of-the-art results."}, "keywords": ["Graph Markov Neural"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this paper, the authors propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds, namely statistical relational learning and graph neural networks, to effectively model the dependency of object labels through conditional random fields for collective classification #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Graph Markov Neural Networks (GMNN) have been proposed to combine the advantages of both statistical relational learning and graph neural networks, by modeling the joint distribution of object labels with a conditional random field and learning effective object representations for classification through end-to-end training #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Graph Markov Neural Networks (GMNN) have been proposed to combine the advantages of both statistical relational learning and graph neural networks for semi-supervised object classification in relational data #REFR.", "given_citation_intent": "background", "given_keywords": ["Graph Markov Neural"]}]}
{"citing_id": "2304.07613v1", "cited_id": "1512.03385", "section_title": ": : : Performance And Accuracy", "citation": "The trends are nearly identical for other layers, as well as layers from ResNet-50 #REFR .", "text_before_citation": ["We therefore compare : : with varying group size to less (unstructured and : ) and more (blocked) structured sparsity on individual tensors.", "To do this, we compare the energy, a novel metric we define to be the ratio \u2225\u02c6\u2225 1 /\u2225 \u2225 1 , where is the original tensor and\u02c6is the pruned version.", "The energy ranges between 0 and 1, and captures the intuition that we want to preserve larger-magnitude values.", "In Fig.", "7 , we show the energy for a weight tensor from the Hug-gingFace #OTHEREFR bert-base-uncased model."], "text_after_citation": ["Unstructured sparsity preserves the maximum possible energy, followed by : .", "Our : : sparsity achieves almost the same energy as : when = 16, with quality decreasing slightly with smaller .", "This is because increasing group size tends to be less restrictive: as chunks are larger, it is easier to find more : patterns. Blocked sparsity performs the worst.", "Hence, we can see that : : sparsity preserves energy nearly as well as : sparsity, while its additional structure can be taken advantage of for performance.", "Sparse fine-tuning."], "citing_paper_content": {"title": "Sten: Productive And Efficient Sparsity In Pytorch", "abstract": "As deep learning models grow, sparsity is becoming an increasingly critical component of deep neural networks, enabling improved performance and reduced storage. However, existing frameworks offer poor support for sparsity. Specialized sparsity engines focus exclusively on sparse inference, while general frameworks primarily focus on sparse tensors in classical formats and neglect the broader sparsification pipeline necessary for using sparse models, especially during training. Further, existing frameworks are not easily extensible: adding a new sparse tensor format or operator is challenging and time-consuming. To address this, we propose STen, a sparsity programming model and interface for PyTorch, which incorporates sparsity layouts, operators, and sparsifiers, in an efficient, customizable, and extensible framework that supports virtually all sparsification methods. We demonstrate this by developing a high-performance grouped : sparsity layout for CPU inference at moderate sparsity. STen brings high performance and ease of use to the ML community, making sparsity easily accessible."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["layers"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To compare the energy of different sparsity layouts, we followed the approach proposed by the authors of Deep Residual Learning For Image Recognition #REFR, and defined a novel metric that captures the preservation of larger-magnitude values.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare the energy for a weight tensor from the HuggingFace #OTHEREFR bert-base-uncased model with less and more structured sparsity on individual tensors, and our results show that our proposed sparsity layout achieves moderate sparsity with high performance, which is consistent with the findings in the reference paper \"Deep Residual Learning For Image Recognition\". #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors compare the energy of weight tensors with varying group size and different sparsity structures, and show in Fig. 7 that their proposed grouped sparsity layout achieves higher energy than unstructured and blocked sparsity, which is consistent with the findings in #REFR that deeper networks with up to 152 layers can gain accuracy from considerably increased depth.", "given_citation_intent": "result", "given_keywords": ["layers"]}]}
{"citing_id": "2304.04259v1", "cited_id": "1904.09172", "section_title": "Introduction", "citation": "In contrast to the aforementioned datasets and test scenarios, long video object segmentation has numerous real-world applications, such as video summarization, human-computer interaction, and autonomous vehicles #REFR .", "text_before_citation": ["The current state-of-the-art semi-supervised and specifically online VOS methods #OTHEREFR perform well on VOS datasets with short videos (up to a few seconds or 100 frames in length) such as DAVIS16 #OTHEREFR , DAVIS17 #OTHEREFR , and YouTube-VOS18 #OTHEREFR .", "However, most of these methods do not retain their expected performance on long videos, such as those in the Long Videos dataset #OTHEREFR as shown in the XMem paper #OTHEREFR .", "The question of the poor performance of online VOS on long videos has not been investigated in the VOS field, nor addressed through continual learning.", "Continual learning methods are typically tested on classification datasets, like MNIST #OTHEREFR , CIFAR10 #OTHEREFR , and Imagenet #OTHEREFR , or on datasets specifically designed for continual learning, such as Core50 #OTHEREFR .", "The classification dataset is fed to the model as a sequential stream of data in online continual learning methods #OTHEREFR ."], "text_after_citation": ["In this paper, we formulate and address the inefficient performance of the online VOS approaches on long videos as an online continual learning problem.", "Moreover, we propose a new long-video object segmentation dataset for continual learning (CLVOS23), as a much more realistic and significantly greater challenge for testing VOS methods on long videos.", "As a baseline, we propose a Regularizationbased (prior-focused) Continual Learning (RCL) solution to improve online VOS."], "citing_paper_content": {"title": "Clvos23: A Long Video Object Segmentation Dataset For Continual Learning", "abstract": "Continual learning in real-world scenarios is a major challenge. A general continual learning model should have a constant memory size and no predefined task boundaries, as is the case in semi-supervised Video Object Segmentation (VOS), where continual learning challenges particularly present themselves in working on long video sequences. In this article, we first formulate the problem of semi-supervised VOS, specifically online VOS, as a continual learning problem, and then secondly provide a public VOS dataset, CLVOS23, focusing on continual learning. Finally, we propose and implement a regularizationbased continual learning approach on LWL, an existing online VOS baseline, to demonstrate the efficacy of continual learning when applied to online VOS and to establish a CLVOS23 baseline. We apply the proposed baseline to the Long Videos dataset as well as to two short video VOS datasets, DAVIS16 and DAVIS17. To the best of our knowledge, this is the first time that VOS has been defined and addressed as a continual learning problem. The proposed CLVOS23 dataset has been released at https: //github.com/Amir4g/CLVOS23."}, "cited_paper_content": {"title": "Video Object Segmentation And Tracking: A Survey", "abstract": "Object segmentation and object tracking are fundamental research area in the computer vision community. These two topics are diffcult to handle some common challenges, such as occlusion, deformation, motion blur, and scale variation. The former contains heterogeneous object, interacting object, edge ambiguity, and shape complexity. And the latter suffers from difficulties in handling fast motion, out-of-view, and real-time processing. Combining the two problems of video object segmentation and tracking (VOST) can overcome their respective difficulties and improve their performance. VOST can be widely applied to many practical applications such as video summarization, high definition video compression, human computer interaction, and autonomous vehicles. This article aims to provide a comprehensive review of the state-of-the-art tracking methods, and classify these methods into different categories, and identify new trends. First, we provide a hierarchical categorization existing approaches, including unsupervised VOS, semi-supervised VOS, interactive VOS, weakly supervised VOS, and segmentation-based tracking methods. Second, we provide a detailed discussion and overview of the technical characteristics of the different methods. Third, we summarize the characteristics of the related video dataset, and provide a variety of evaluation metrics. Finally, we point out a set of interesting future works and draw our own conclusions."}, "keywords": ["long video object", "video summarization"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Most of the current state-of-the-art semi-supervised and specifically online VOS methods perform well on VOS datasets with short videos, but struggle on long videos, such as those in the Long Videos dataset, as shown in the XMem paper. To address this issue, continual learning methods have been proposed, but have not been investigated in the VOS field. The proposed CLVOS23 dataset in #REFR provides a public VOS dataset focusing on continual learning, and a regularization-based continual learning approach has been implemented on LWL to demonstrate the efficacy of continual learning when applied to online VOS and to establish a CLVOS23 baseline.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Object segmentation and tracking are challenging tasks in computer vision due to various factors such as occlusion, deformation, and motion blur #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Long videos pose a challenge for online VOS methods, and their poor performance has not been investigated in the VOS field, nor addressed through continual learning #REFR, which can be applied to improve video summarization.", "given_citation_intent": "background", "given_keywords": ["long video object", "video summarization"]}]}
{"citing_id": "2304.00838v1", "cited_id": "1907.11922", "section_title": "A.5. Additional Qualitative Evaluation On Label-Head", "citation": "We fine-tune the pre-trained head model MetaHead-F on CelebAMask-HQ #REFR , in which each image has a seg-mentation mask of 19-class facial attributes.", "text_before_citation": ["Performance comparison on Gaze360 #OTHEREFR and MPIIFaceGaze #OTHEREFR using real and synthetic data. Our synthetic data significantly reduce the gaze estimation error. Figure 15 . Results of local head editing using semantic labels.", "LabelHead allows users to perform locally 3D fine-grained head shape control and editing in a disentangled and view-consistent manner. Please refer to Appendix A.5 for details.", "Head Shape Control Using Semantic Labels As is classified in CelebAMask-HQ #OTHEREFR , each pixel in the head semantic mask falls into 19 distinct categories including skin, eyebrows, ears, mouth, lip, etc.", "Given a head image, we flatten the semantic category corresponding to each pixel into a latent representation as the semantic label.", "We then embed the semantic label feature into the feature design space of MetaHead-F."], "text_after_citation": ["After training, given the reference head image, we randomly initialize the label values of all features including semantic label, then using the photometric loss between the test image and the generated head of MetaHead-F to optimize the label value, thus getting the semantic mask estimation.", "We conduct interactive head shape manipulation by locally editing(drawing) on the obtained semantic mask and leverage MetaHead-F to generate the corresponding modified free-view 3D heads. As is shown in Fig.", "15 , the head shape control using semantic labels is disentangled and view-consistent."], "citing_paper_content": {"title": "Metahead: An Engine To Create Realistic Digital Head", "abstract": "Collecting and labeling training data is one important step for learning-based methods because the process is time-consuming and biased. For face analysis tasks, although some generative models [25, 10, 45, 6, 5, 11, 20] can be used to generate face data, they can only achieve a subset of generation diversity, reconstruction accuracy, 3D consistency, high-fidelity visual quality, and easy editability. One recent related work is the graphics-based generative method [48], but it can only render low realism head with high computation cost. In this paper, we propose MetaHead, a unified and full-featured controllable digital head engine, which consists of a controllable head radiance field(MetaHead-F) to super-realistically generate or reconstruct view-consistent 3D controllable digital heads and a generic top-down image generation framework LabelHead to generate digital heads consistent with the given customizable feature labels. Experiments validate that our controllable digital head engine achieves the state-of-the-art generation visual quality and reconstruction accuracy. Moreover, the generated labeled data can assist real training data and significantly surpass the labeled data generated by graphics-based methods in terms of training effect. The project page is available at: https://ustc3dv.github.io/MetaHead/."}, "cited_paper_content": {"title": "Maskgan: Towards Diverse And Interactive Facial Image Manipulation", "abstract": "Facial image manipulation has achieved great progress in recent years. However, previous methods either operate on a predefined set of face attributes or leave users little freedom to interactively manipulate images. To overcome these drawbacks, we propose a novel framework termed MaskGAN, enabling diverse and interactive face manipulation. Our key insight is that semantic masks serve as a suitable intermediate representation for flexible face manipulation with fidelity preservation. MaskGAN has two main components: 1) Dense Mapping Network (DMN) and 2) Editing Behavior Simulated Training (EBST). Specifically, DMN learns style mapping between a free-form user modified mask and a target image, enabling diverse generation results. EBST models the user editing behavior on the source mask, making the overall framework more robust to various manipulated inputs. Specifically, it introduces dual-editing consistency as the auxiliary supervision signal. To facilitate extensive studies, we construct a large-scale high-resolution face dataset with fine-grained mask annotations named CelebAMask-HQ. MaskGAN is comprehensively evaluated on two challenging tasks: attribute transfer and style copy, demonstrating superior performance over other state-of-the-art methods. The code, models, and dataset are available at https://github.com/switchablenorms/CelebAMask-HQ."}, "keywords": ["pre-trained head model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Head Shape Control Using Semantic Labels As is classified in CelebAMask-HQ #OTHEREFR, each pixel in the head semantic mask falls into 19 distinct categories including skin, eyebrows, ears, mouth, lip, etc. Given a head image, we flatten the semantic category corresponding to each pixel into a latent representation as the semantic label. We then embed the semantic label feature into the feature design space of MetaHead-F, following the approach proposed in Maskgan: Towards Diverse And Interactive Facial Image Manipulation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform fine-grained head shape control and editing in a disentangled and view-consistent manner, the authors embedded the semantic label feature into the feature design space of MetaHead-F, which was inspired by the use of semantic masks in MaskGAN #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To embed the semantic label feature into the feature design space of MetaHead-F, the authors used the pre-trained head model from Maskgan #REFR, which learns style mapping between a free-form user modified mask and a target image, enabling diverse generation results.", "given_citation_intent": "method", "given_keywords": ["pre-trained head model"]}]}
{"citing_id": "2304.14614v1", "cited_id": "1903.11027", "section_title": "Scene-Oriented Attacks", "citation": "We select one scene from the Nuscenes #REFR dataset in which the ego-vehicle is stationary at a traffic light (see Figure 10 ).", "text_before_citation": ["Scene-oriented attacks are primarily aimed at fusion models with global sensitivity.", "Such models are vulnerable to adversarial patches placed upon non-object background scenes, as evidenced in Section 6.2.", "In contrast to the regional patch-on-road attack that we previously assessed, scene-oriented attacks are not restricted to the per-frame level but can affect the detection of arbitrary objects in a given scene, even those that were not initially present during the patch generation.", "Therefore, this type of attack poses a more significant and practical threat in real-world scenarios as attackers can effortlessly paste generated adversarial patches onto the ground, rendering victim vehicles in close proximity blind.", "This could pose a significant risk to pedestrians and surrounding vehicles. Experimental setup."], "text_after_citation": ["Note that a Nuscenes scene represents a driving clip that lasts about one minute.", "This scene includes 490 frames of multi-modal data (multiview images, 360-degree LiDAR point clouds, and object annotations), and the object types and locations vary across different frames.", "We split the scene into two subsets: the first 245 frames are used as the \"training set\" to generate"], "citing_paper_content": {"title": "Fusion Is Not Enough: Single-Modal Attacks To Compromise Fusion Models In Autonomous Driving", "abstract": "Multi-sensor fusion (MSF) is widely adopted for perception in autonomous vehicles (AVs), particularly for the task of 3D object detection with camera and LiDAR sensors. The rationale behind fusion is to capitalize on the strengths of each modality while mitigating their limitations. The exceptional and leading performance of fusion models has been demonstrated by advanced deep neural network (DNN)based fusion techniques. Fusion models are also perceived as more robust to attacks compared to single-modal ones due to the redundant information in multiple modalities. In this work, we challenge this perspective with single-modal attacks that targets the camera modality, which is considered less significant in fusion but more affordable for attackers. We argue that the weakest link of fusion models depends on their most vulnerable modality, and propose an attack framework that targets advanced camera-LiDAR fusion models with adversarial patches. Our approach employs a two-stage optimization-based strategy that first comprehensively assesses vulnerable image areas under adversarial attacks, and then applies customized attack strategies to different fusion models, generating deployable patches. Evaluations with five state-ofthe-art camera-LiDAR fusion models on a real-world dataset show that our attacks successfully compromise all models. Our approach can either reduce the mean average precision (mAP) of detection performance from 0.824 to 0.353 or degrade the detection score of the target object from 0.727 to 0.151 on average, demonstrating the effectiveness and practicality of our proposed attack framework."}, "cited_paper_content": {"title": "Nuscenes: A Multimodal Dataset For Autonomous Driving", "abstract": "Robust detection and tracking of objects is crucial for the deployment of autonomous vehicle technology. Image-based benchmark datasets have driven development in computer vision tasks such as object detection, tracking and segmentation of agents in the environment. Most autonomous vehicles, however, carry a combination of cameras and range sensors such as lidar and radar. As machine learning based methods for detection and tracking become more prevalent, there is a need to train and evaluate such methods on datasets containing range sensor data along with images. In this work we present nuTonomy scenes (nuScenes), the first published dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view. nuScenes comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as many annotations and 100x as many images as the pioneering KITTI dataset. We define novel 3D detection and tracking metrics. We also provide careful dataset analysis as well as baselines for lidar and image based detection and tracking. Data, development kit and more information are available online at this http URL."}, "keywords": ["Nuscenes dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To evaluate the vulnerability of fusion models to scene-oriented attacks, we need to consider datasets that contain range sensor data along with images. The nuScenes dataset introduced in #REFR provides a comprehensive sensor suite with 6 cameras, 5 radars, and 1 lidar, which can be used to train and evaluate machine learning-based methods for detection and tracking.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate machine learning-based methods for detection and tracking on datasets containing range sensor data along with images, the authors of this work used the nuScenes dataset, which carries the full autonomous vehicle sensor suite, including 6 cameras, 5 radars, and 1 lidar, all with full 360-degree field of view, and is fully annotated with 3D bounding boxes for 23 classes and 8 attributes. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To train and evaluate machine learning-based methods for detection and tracking on datasets containing range sensor data along with images, the authors utilized the Nuscenes dataset, which carries the full autonomous vehicle sensor suite, including 6 cameras, 5 radars, and 1 lidar, all with full 360-degree field of view, and comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. #REFR", "given_citation_intent": "method", "given_keywords": ["Nuscenes dataset"]}]}
{"citing_id": "2305.02148v1", "cited_id": "1912.08193", "section_title": "Training Process", "citation": "We have also trained an EfficientNet model with PointRend head #REFR and scaled loss with a factor of 2.", "text_before_citation": ["We reduced it in the training process with the help of the ReduceLROnPlateau [44] algorithm with patience 3 by 0.5 factor monitoring validation dice loss.", "Initially, the constructed pipeline was a multiclass model with 5 channels -one for each organ.", "However, as only one class of organ FTUs was present at any given image we reformulated the task as a binary semantic segmentation with a single channel containing all the masks no matter what organ was present on an image.", "Such an approach allowed for improved generalization and better scores across all organs.", "To improve model robustness we have used a mixture of four losses: binary Cross-Entropy, Dice Loss, Focal Loss #OTHEREFR , and Jacquard Loss #OTHEREFR ."], "text_after_citation": ["While we didn't notice a meaningful performance boost from the PointRend alone we think that its main contribution was in adding diversity to our model ensemble as well as some regularization.", "We have used PyTorch #OTHEREFR built-in mixed precision training in order to reduce GPU memory consumption which allowed us to use a batch size of 32 samples on A100 GPUs."], "citing_paper_content": {"title": "Semi-Supervised Segmentation Of Functional Tissue Units At The Cellular Level", "abstract": "We present a new method for functional tissue unit segmentation at the cellular level, which utilizes the latest deep learning semantic segmentation approaches together with domain adaptation and semi-supervised learning techniques. This approach allows for minimizing the domain gap, class imbalance, and captures settings influence between HPA and HubMAP datasets. The presented approach achieves comparable with state-of-the-art-result in functional tissue unit segmentation at the cellular level."}, "cited_paper_content": {"title": "Pointrend: Image Segmentation As Rendering", "abstract": "We present a new method for efficient high-quality image segmentation of objects and scenes. By analogizing classical computer graphics methods for efficient rendering with over- and undersampling challenges faced in pixel labeling tasks, we develop a unique perspective of image segmentation as a rendering problem. From this vantage, we present the PointRend (Point-based Rendering) neural network module: a module that performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm. PointRend can be flexibly applied to both instance and semantic segmentation tasks by building on top of existing state-of-the-art models. While many concrete implementations of the general idea are possible, we show that a simple design already achieves excellent results. Qualitatively, PointRend outputs crisp object boundaries in regions that are over-smoothed by previous methods. Quantitatively, PointRend yields significant gains on COCO and Cityscapes, for both instance and semantic segmentation. PointRend's efficiency enables output resolutions that are otherwise impractical in terms of memory or computation compared to existing approaches."}, "keywords": ["scaled loss", "PointRend head"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the segmentation performance, we utilized a Point-based Rendering neural network module, as presented in #REFR, which performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently segment functional tissue units at the cellular level, the authors utilized the PointRend neural network module, which performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the model's robustness, a mixture of four losses was used, including binary Cross-Entropy, Dice Loss, Focal Loss, and Jacquard Loss, and the PointRend head was employed for efficient high-quality image segmentation of objects and scenes #REFR.", "given_citation_intent": "method", "given_keywords": ["scaled loss", "PointRend head"]}]}
{"citing_id": "2303.08090v1", "cited_id": "1904.04708", "section_title": "Discussion", "citation": "Namely, the discrepancy between the present results and #REFR depends on the different way of computing the SR I indicator.", "text_before_citation": ["According to #OTHEREFR , in fact, the world scientific production exhibits 4% annual growth in publications and 1.8% annual growth in the number of references per publication.", "Combined, these dynamics produce a 12-year doubling period in the total amount of references, which results in turn in a generalized increase in citations #OTHEREFR .", "The decreasing trends, thus, may be simply due to the different rates of growth of the numerator and the denominator of the indicators used here: country self-citations of Type I or Type II grow less than bibliographic references.", "The observed decreasing trend in the SR I , however, contradicts previous studies of the development of this indicator over time: #OTHEREFR , in fact, report an average increase of +5.2 p.p.", "in the SR I of G10 countries between 2000 and 2016."], "text_after_citation": ["Indeed, #OTHEREFR used a nonfixed citation window, which included all the years from the publication year to 2016.", "For example, for the cited items published in the year 2000, a 17year citation window was used, by summing up all citations from 2000 to 2016; whereas, for the year 2006, the citation window was 11 years long, including citations from 2006 to 2016; for 2016, the citation window included only 1 year, i.e., only citations from 2016 itself were counted.", "Since self-citations are in general younger than external citations #OTHEREFR , they tend to represent a higher proportion of total citations for the years when the citation window is shorter.", "Hence, #OTHEREFR registered an inflation of SR I for more recent years, as the citation window shortens.", "The present study, by contrast, does not suffer from this problem as it is based on a fixed citation window, i.e., only a fixed number of years after the target year is considered (see Section 3.2)."], "citing_paper_content": {"title": "A Global Exploratory Comparison Of Country Self-Citations 1996-2019", "abstract": "Self-citations are a key topic in evaluative bibliometrics because they can artificially inflate citation-related performance indicators. Recently, selfcitations defined at the largest scale, i.e., country self-citations, have started to attract the attention of researchers and policymakers. According to a recent research, in fact, the anomalous trends in the country self-citation rates of some countries, such as Italy, have been induced by the distorting effect of citation metrics-centered science policies. In the present study, we investigate the trends of country self-citations in 50 countries over the world in the period 1996-2019 using Scopus data. Results show that for most countries country selfcitations have decreased over time. 12 countries ("}, "cited_paper_content": {"title": "Citation Gaming Induced By Bibliometric Evaluation: A Country-Level Comparative Analysis", "abstract": "It is several years since national research evaluation systems around the globe started making use of quantitative indicators to measure the performance of researchers. Nevertheless, the effects on these systems on the behavior of the evaluated researchers are still largely unknown. For investigating this topic, we propose a new inwardness indicator able to gauge the degree of scientific self-referentiality of a country. Inwardness is defined as the proportion of citations coming from the country over the total number of citations gathered by the country. A comparative analysis of the trends for the G10 countries in the years 2000-2016 reveals a net increase of the Italian inwardness. Italy became, both globally and for a large majority of the research fields, the country with the highest inwardness and the lowest rate of international collaborations. The change in the Italian trend occurs in the years following the introduction in 2011 of national regulations in which key passages of professional careers are governed by bibliometric indicators. A most likely explanation of the peculiar Italian trend is a generalized strategic use of citations in the Italian scientific community, both in the form of strategic author self-citations and of citation clubs. We argue that the Italian case offers crucial insights on the constitutive effects of evaluation systems. As such, it could become a paradigmatic case in the debate about the use of indicators in science-policy contexts."}, "keywords": ["present results"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The anomalous trends in country self-citation rates induced by citation metrics-centered science policies have been previously reported in #REFR. As such, the observed decreasing trend in SR I may be attributed to the different rates of growth of the numerator and denominator of the indicators used here.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to #OTHEREFR, the anomalous trends in country self-citation rates, such as Italy's, have been induced by the distorting effect of citation metrics-centered science policies, as shown in the comparative analysis of the trends for the G10 countries in the years 2000-2016. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to #OTHEREFR, the anomalous trends in country self-citation rates induced by citation metrics-centered science policies have been reported in recent research. The present study investigates the trends of country self-citations in 50 countries over the world in the period 1996-2019 using Scopus data and present results that show for most countries country self-citations have decreased over time. #REFR", "given_citation_intent": "result", "given_keywords": ["present results"]}]}
{"citing_id": "2303.10576v1", "cited_id": "1810.00826", "section_title": "Subgraph Gnns", "citation": "MPNN's expressive power in terms of distinguishing non-isomorphic graphs is upper bounded by 2-WL #REFR .", "text_before_citation": ["MPNNs are a class of GNNs that learns node representations by iteratively encoding and aggregating messages from neighboring nodes.", "Let h t v be the node representation for v \u2208 V in the t-th iteration. It is usually initialized with the node's intrinsic attributes.", "In the (t + 1)-th iteration, it is updated by:", "EQUATION", "where W t 1 and W t 2 are two learnable functions."], "text_after_citation": ["Subgraph GNNs.", "Subgraph GNNs first represent the input graph by a collection of subgraphs based on certain subgraph selection policies.", "They then encode the subgraphs using backbone GNNs and aggregate subgraph representations into the graph representation.", "We note that there exist some other variants of subgraph GNNs #OTHEREFR , but in this paper, we focus on a specific type of subgraph GNNs without information exchange between subgraphs, which covers reconstruction GNNs #OTHEREFR , ID-GNNs #OTHEREFR , and nested GNNs (Zhang & Li, 2021; #OTHEREFR .", "We will show that this type of subgraph GNNs is powerful enough in terms of counting connected substructures."], "citing_paper_content": {"title": "Efficiently Counting Substructures By Subgraph Gnns Without Running Gnn On Subgraphs", "abstract": "Using graph neural networks (GNNs) to approximate specific functions such as counting graph substructures is a recent trend in graph learning. Among these works, a popular way is to use subgraph GNNs, which decompose the input graph into a collection of subgraphs and enhance the representation of the graph by applying GNN to individual subgraphs. Although subgraph GNNs are able to count complicated substructures, they suffer from high computational and memory costs. In this paper, we address a non-trivial question: can we count substructures efficiently with GNNs? To answer the question, we first theoretically show that the distance to the rooted nodes within subgraphs is key to boosting the counting power of subgraph GNNs. We then encode such information into structural embeddings, and precompute the embeddings to avoid extracting information over all subgraphs via GNNs repeatedly. Experiments on various benchmarks show that the proposed model can preserve the counting power of subgraph GNNs while running orders of magnitude faster."}, "cited_paper_content": {"title": "How Powerful Are Graph Neural Networks?", "abstract": "Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance."}, "keywords": ["MPNN's expressive power", "non-isomorphic graphs"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "MPNNs are a class of GNNs that learns node representations by iteratively encoding and aggregating messages from neighboring nodes. Let h t v be the node representation for v \u2208 V in the t-th iteration. It is usually initialized with the node's intrinsic attributes. In the (t + 1)-th iteration, it is updated by: EQUATION where W t 1 and W t 2 are two learnable functions. However, despite the success of GNNs in graph representation learning, there is limited understanding of their representational properties and limitations. To address this, the authors of \"How Powerful Are Graph Neural Networks?\" present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Graph Neural Networks (GNNs) have become an effective framework for representation learning of graphs, and many GNN variants have achieved state-of-the-art results on both node and graph classification tasks. #REFR provides a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures, which can help to better understand the limitations of GNNs in learning to distinguish certain simple graph structures.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Graph Neural Networks (GNNs) have been widely used for representation learning of graphs, but their expressive power to capture different graph structures is still limited. Recent research has shown that popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, cannot learn to distinguish certain simple graph structures, which highlights the importance of understanding the limitations of GNNs' expressive power on non-isomorphic graphs. #REFR", "given_citation_intent": "background", "given_keywords": ["MPNN's expressive power", "non-isomorphic graphs"]}]}
{"citing_id": "2303.13077v1", "cited_id": "1802.03601", "section_title": "Methodology Formulation", "citation": "This type of domain adaptation (DA) is heterogeneous and unlike homogeneous DA approaches, there is not much work focused on heterogeneous DA as far as depth approaches are concerned, and the solution for heterogeneous deep DA is still similar to some homogeneous DA approaches #REFR .", "text_before_citation": ["In this paper we utilize the final classification head of the original model as h t .", "This function is learned solely through supervised signal update gradients.", "There are a large number of labeled image that can be studied directly for static image so h s are not the object of this study.", "Critically, we want to provide a generalization of g t which can pave the way for learning of h t to improve the generalizability of SNN.", "As mentioned before, due to the different sensory devices, the two data domains have different feature spaces and they have different dimensions."], "text_after_citation": ["In this paper we use a discrepancy-based approach.", "The embedding function g would be modeled by network sharing between the source and target domains using all layers before the last classification layer.", "At this point the shared g t = g s = g, the objective of optimization is finding the satisfied g in its hypothetical space G:", "EQUATION", "where X a s and X a t refer to the same classes of data in the source and target domains while X a s and X c t mean the data from different classes."], "citing_paper_content": {"title": "Improving The Performance Of Spiking Neural Networks On Event-Based Datasets With Knowledge Transfer", "abstract": "Spiking neural networks (SNNs) have rich spatialtemporal dynamics, which are suitable for processing neuromorphic, event-based data. However, event-based datasets are usually less annotated than static datasets used in traditional deep learning. Small data scale makes SNNs prone to overfitting and limits the performance of the SNN. To enhance the generalizability of SNNs on eventbased datasets, we propose a knowledge-transfer framework that leverages static images to assist in the training on neuromorphic datasets. Our method proposes domain loss and semantic loss to exploit both domain-invariant and unique features of these two domains, providing SNNs with more generalized knowledge for subsequent targeted training on neuromorphic data. Specifically, domain loss aligns the feature space and aims to capture common features between static and event-based images, while semantic loss emphasizes that the differences between samples from different categories should be as large as possible. Experimental results demonstrate that our method outperforms existing methods on all mainstream neuromorphic vision datasets. In particular, we achieve significant performance improvement of 2.7% and 9.8% when using only 10% training data of CIFAR10-DVS and N-Caltech 101 datasets, respectively."}, "cited_paper_content": {"title": "Deep Visual Domain Adaptation: A Survey", "abstract": "Deep domain adaptation has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaptation methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaptation, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaptation approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted."}, "keywords": ["heterogeneous deep DA", "domain adaptation"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the generalizability of SNN, we propose a knowledge-transfer framework that leverages static images to assist in the training on neuromorphic datasets (Li et al., 2021). As mentioned before, due to the different sensory devices, the two data domains have different feature spaces and they have different dimensions. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide a comprehensive survey of deep domain adaptation methods for computer vision applications, #REFR presents a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of different feature spaces in heterogeneous deep DA, domain adaptation methods have been proposed to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, as discussed in the survey paper on deep visual domain adaptation by Ganin et al. #REFR.", "given_citation_intent": "background", "given_keywords": ["heterogeneous deep DA", "domain adaptation"]}]}
{"citing_id": "2303.17322v1", "cited_id": "1810.04805", "section_title": "Datasets", "citation": "This model is based on the pre-trained model BERT proposed by #REFR with a stack of 2 Transformer blocks on top, finalized with a conditional random field (CRF) prediction layer.", "text_before_citation": ["Table 2 displays the information regarding the number and type of entities found in the specified datasets. this study, we only consider the coarse-grained entities.", "We defined the three prompts presented in Table 1 depending on the entity type differences between datasets and to respect their corresponding labels casing.", "Even if the IOB/BIO 9 format is explicitly demanded for each word, tokenization by ChatGPT was inconsistent with IOB tokenized dataset files, thus, for evaluation purposes, an alignment and verification process was required to ensure evaluation consistency.", "Table 3 presents the performance of ChatGPT over coarse-grained (high-level entity types) NERC in terms of strict and fuzzy microlevel precision (P), recall (R) and F-measure (F1) evaluated with CLEF-HIPE-2020-scorer #OTHEREFR .", "For positioning and comparison, we also present the performance of two LM-based state-of-the-art NERC systems. Stacked NERC."], "text_after_citation": ["Stacked NERC proved increased performance in historical documents, while did not degrade the performance over modern data #OTHEREFR .", "The same architecture was utilized as a baseline in the description of the NewsEye dataset #OTHEREFR ."], "citing_paper_content": {"title": "Yes But.. Can Chatgpt Identify Entities In Historical Documents?", "abstract": "Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents. For the last few months, the conversational agent ChatGPT has \"prompted\" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers. In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems. Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting. Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance. CCS CONCEPTS \u2022 Information systems \u2192 Language models; Information extraction; \u2022 Computing methodologies \u2192 Natural language processing; \u2022 Applied computing \u2192 Arts and humanities."}, "cited_paper_content": {"title": "Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ::: BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."}, "keywords": ["BERT"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For comparison purposes, we also present the performance of two state-of-the-art LM-based NERC systems, and as reported in the reference paper #REFR, our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To pre-train deep bidirectional representations from unlabeled text, the authors of this study utilized BERT, a language representation model introduced in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To pre-train deep bidirectional representations from unlabeled text, the authors could use BERT, a powerful language representation model introduced in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["BERT"]}]}
{"citing_id": "2305.00725v1", "cited_id": "1905.02244", "section_title": "I. Introduction", "citation": "Results show that our proposed model can achieve better performance compared to the well-known MobileNetV3-small model #REFR and provide better computational efficiency.", "text_before_citation": ["In this paper, we propose a framework for IoTbased edge computing-enabled non-speech emotion recognition systems.", "We have made the following contributions: 1) We propose to leverage edge computing to design a low-latency non-speech-based emotion recognition system for resource-constrained devices.", "2) We develop a computationally efficient nonspeech emotion detection system by utilising knowledge distillation.", "3) We provide a detailed discussion on the potential of using non-speech emotions for various applications such as healthcare, rescue services, etc.", "4) We show the effectiveness of the proposed framework by evaluating the system using two publicly available datasets."], "text_after_citation": [], "citing_paper_content": {"title": "Emotions Beyond Words: Non-Speech Audio Emotion Recognition With Edge Computing", "abstract": "Non-speech emotion recognition has a wide range of applications including healthcare, crime control and rescue, and entertainment, to name a few. Providing these applications using edge computing has great potential, however, recent studies are focused on speech-emotion recognition using complex architectures. In this paper, a non-speech-based emotion recognition system is proposed, which can rely on edge computing to analyse emotions conveyed through non-speech expressions like screaming and crying. In particular, we explore knowledge distillation to design a computationally efficient system that can be deployed on edge devices with limited resources without degrading the performance significantly. We comprehensively evaluate our proposed framework using two publicly available datasets and highlight its effectiveness by comparing the results with the well-known MobileNet model. Our results demonstrate the feasibility and effectiveness of using edge computing for non-speech emotion detection, which can potentially improve applications that rely on emotion detection in communication networks. To the best of our knowledge, this is the first work on an edgecomputing-based framework for detecting emotions in non-speech audio, offering promising directions for future research."}, "cited_paper_content": {"title": "Searching For Mobilenetv3", "abstract": "We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware-aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art. Through this process we create two new MobileNet models for release: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of object detection and semantic segmentation. For the task of semantic segmentation (or any dense pixel prediction), we propose a new efficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP). We achieve new state of the art results for mobile classification, detection and segmentation. MobileNetV3-Large is 3.2\\% more accurate on ImageNet classification while reducing latency by 15\\% compared to MobileNetV2. MobileNetV3-Small is 4.6\\% more accurate while reducing latency by 5\\% compared to MobileNetV2. MobileNetV3-Large detection is 25\\% faster at roughly the same accuracy as MobileNetV2 on COCO detection. MobileNetV3-Large LR-ASPP is 30\\% faster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation."}, "keywords": ["well-known MobileNetV3-small model"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We propose to leverage edge computing to design a low-latency non-speech-based emotion recognition system for resource-constrained devices, and develop a computationally efficient non-speech emotion detection system by utilising knowledge distillation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed framework achieves state-of-the-art results in non-speech emotion recognition, outperforming the well-known MobileNet model on two publicly available datasets (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed framework achieves state-of-the-art results in non-speech emotion recognition, outperforming the well-known MobileNetV3-small model on two publicly available datasets. #REFR", "given_citation_intent": "result", "given_keywords": ["well-known MobileNetV3-small model"]}]}
{"citing_id": "2303.02673v2", "cited_id": "1812.05920", "section_title": "Iii. Time-Frequency Network", "citation": "The time branch is based on the SincNet #REFR due to its promising results on speaker recognition.", "text_before_citation": ["As illustrated in Fig.", "2 , our TFN contains two branches (a time branch and a frequency branch) and a fusion module."], "text_after_citation": ["The frequency branch is a multi-layer CNN with a frequency spectrum representation (such as MFCC) as input and the fusion module is designed to fuse the time-domain feature and the frequencydomain feature.", "It is worth noting that although the frequency spectrum also contains the time information, its time resolution is much lower than the raw signal due to the window-based transformation (such as STFT)."], "citing_paper_content": {"title": "Time-Frequency Network For Robust Speaker Recognition", "abstract": "The wide deployment of speech-based biometric systems usually demands high-performance speaker recognition algorithms. However, most of the prior works for speaker recognition either process the speech in the frequency domain or time domain, which may produce suboptimal results because both time and frequency domains are important for speaker recognition. In this paper, we attempt to analyze the speech signal in both time and frequency domains and propose the timefrequency network (TFN) for speaker recognition by extracting and fusing the features in the two domains. Based on the recent advance of deep neural networks, we propose a convolution neural network to encode the raw speech waveform and the frequency spectrum into domain-specific features, which are then fused and transformed into a classification feature space for speaker recognition. Experimental results on the publicly available datasets TIMIT and LibriSpeech show that our framework is effective to combine the information in the two domains and performs better than the state-of-the-art methods for speaker recognition."}, "cited_paper_content": {"title": "Speech And Speaker Recognition From Raw Waveform With Sincnet", "abstract": "Deep neural networks can learn complex and abstract representations, that are progressively obtained by combining simpler ones. A recent trend in speech and speaker recognition consists in discovering these representations starting from raw audio samples directly. Differently from standard hand-crafted features such as MFCCs or FBANK, the raw waveform can potentially help neural networks discover better and more customized representations. The high-dimensional raw inputs, however, can make training significantly more challenging. This paper summarizes our recent efforts to develop a neural architecture that efficiently processes speech from audio waveforms. In particular, we propose SincNet, a novel Convolutional Neural Network (CNN) that encourages the first layer to discover meaningful filters by exploiting parametrized sinc functions. In contrast to standard CNNs, which learn all the elements of each filter, only low and high cutoff frequencies of band-pass filters are directly learned from data. This inductive bias offers a very compact way to derive a customized front-end, that only depends on some parameters with a clear physical meaning. Our experiments, conducted on both speaker and speech recognition, show that the proposed architecture converges faster, performs better, and is more computationally efficient than standard CNNs."}, "keywords": ["speaker recognition"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As illustrated in Fig. 2, our TFN contains two branches (a time branch and a frequency branch) and a fusion module, inspired by the recent advance in deep neural networks for processing speech from audio waveforms #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To extract features from the raw audio samples, we propose to use SincNet, a novel Convolutional Neural Network (CNN) that encourages the first layer to discover meaningful filters by exploiting parametrized sinc functions, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently process speech from audio waveforms for speaker recognition, a novel Convolutional Neural Network (CNN) called SincNet was proposed, which encourages the first layer to discover meaningful filters by exploiting parametrized sinc functions, and our experiments show that it outperforms standard CNNs in terms of convergence speed, performance, and computational efficiency (#REFR).", "given_citation_intent": "method", "given_keywords": ["speaker recognition"]}]}
{"citing_id": "2304.05542v1", "cited_id": "2002.05709", "section_title": "Contrastive Learning", "citation": "Existing methods maximize the mutual information between the augmented data pairs 28, #REFR and adopt InfoNCE as the contrastive loss.", "text_before_citation": ["Contrastive learning is one of the most effective unsupervised learning methods in the field of representation learning.", "Contrastive learning aims at seeking a latent space that separates the pairs from different classes and maximizes the similarity for samples with the same classes 28 ."], "text_after_citation": ["However, our method uses the multi-view omics data as the compared pairs to maximize the consistency across different omics data."], "citing_paper_content": {"title": "Clclsa: Cross-Omics Linked Embedding With Contrastive Learning And Self Attention For Multi-Omics Integration With Incomplete Multi-Omics Data", "abstract": "Integration of heterogeneous and high-dimensional multi-omics data is becoming increasingly important in understanding genetic data. Each omics technique only provides a limited view of the underlying biological process and integrating heterogeneous omics layers simultaneously would lead to a more comprehensive and detailed understanding of diseases and phenotypes. However, one obstacle faced when performing multi-omics data integration is the existence of unpaired multi-omics data due to instrument sensitivity and cost. Studies may fail if certain aspects of the subjects are missing or incomplete. In this paper, we propose a deep learning method for multi-omics integration with incomplete data by Cross-omics Linked unified embedding with Contrastive Learning and Self Attention (CLCLSA). Utilizing complete multi-omics data as supervision, the model employs cross-omics autoencoders to learn the feature representation across different types of biological data. The multi-omics contrastive learning, which is used to maximize the mutual information between different types of omics, is employed before latent feature concatenation. In addition, the feature-level self-attention and omics-level self-attention are employed to dynamically identify the most informative features for multi-omics data integration. Extensive experiments were conducted on four public multi-omics datasets. The experimental results indicated that the proposed CLCLSA outperformed the state-of-the-art approaches for multi-omics data classification using incomplete multiomics data."}, "cited_paper_content": {"title": "A Simple Framework For Contrastive Learning Of Visual Representations", "abstract": "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels."}, "keywords": ["contrastive loss"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Contrastive learning is one of the most effective unsupervised learning methods in the field of representation learning, and recent work has proposed a simple framework for contrastive learning of visual representations, which has achieved state-of-the-art performance on ImageNet #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve multi-omics contrastive learning, the authors utilized a unified embedding framework with contrastive learning, which was proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Contrastive learning has been shown to be an effective unsupervised learning method for representation learning, and recent work has demonstrated that introducing a learnable nonlinear transformation between the representation and the #REFR contrastive loss can substantially improve the quality of the learned representations.", "given_citation_intent": "method", "given_keywords": ["contrastive loss"]}]}
{"citing_id": "2303.09960v1", "cited_id": "1804.09554", "section_title": "Stochastic Continuous Greedy Algorithm", "citation": "The stochastic nature of the set function f (S) requires the use the Stochastic Continuous Greedy (SCG) algorithm #REFR .", "text_before_citation": [], "text_after_citation": ["This is a stochastic variant of the continuous greedy algorithm (method) #OTHEREFR , to solve (1).", "The SCG algorithm uses a common averaging technique in stochastic optimization and computes the estimated gradient d t by the recursion", "EQUATION", "where \u03c1 t is a positive step size and the algorithm initially starts with d 0 = y 0 = 0.", "Then, it proceeds in iterations, where in the t-th iteration it finds a feasible solution as follows"], "citing_paper_content": {"title": "Stochastic Submodular Maximization Via Polynomial Estimators", "abstract": "In this paper, we study stochastic submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm [20] attains an approximation ratio (in expectation) arbitrarily close to (1 \u2212 1/e) \u2248 63% using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time."}, "cited_paper_content": {"title": "Stochastic Conditional Gradient Methods: From Convex Minimization To Submodular Maximization", "abstract": "This paper considers stochastic optimization problems for a large class of objective functions, including convex and continuous submodular. Stochastic proximal gradient methods have been widely used to solve such problems; however, their applicability remains limited when the problem dimension is large and the projection onto a convex set is costly. Instead, stochastic conditional gradient methods are proposed as an alternative solution relying on (i) Approximating gradients via a simple averaging technique requiring a single stochastic gradient evaluation per iteration; (ii) Solving a linear program to compute the descent/ascent direction. The averaging technique reduces the noise of gradient approximations as time progresses, and replacing projection step in proximal methods by a linear program lowers the computational complexity of each iteration. We show that under convexity and smoothness assumptions, our proposed method converges to the optimal objective function value at a sublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous DR-submodular function and subject to a general convex body constraint, we prove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with $O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the known hardness results and closes the gap between deterministic and stochastic continuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$ guarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the objective function is continuous DR-submodular but non-monotone and the constraint set is down-closed. By using stochastic continuous optimization as an interface, we provide the first $(1-1/e)$ tight approximation guarantee for maximizing a monotone but stochastic submodular set function subject to a matroid constraint and $(1/e)$ approximation guarantee for the non-monotone case."}, "keywords": ["stochastic nature"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this paper, the authors study stochastic submodular maximization problems with general matroid constraints and show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approximation ratio (in expectation) arbitrarily close to (1 \u2212 1/e) using a polynomial estimation of the gradient. The authors argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors propose stochastic conditional gradient methods as an alternative solution to stochastic proximal gradient methods for solving stochastic optimization problems, which are limited by high computational complexity and dimensionality, and cite the paper by Hazan et al. as a reference for this method. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors propose a stochastic conditional gradient method as an alternative solution to stochastic proximal gradient methods, which are limited by the stochastic nature of the problem and the high cost of projection onto a convex set, and show that their proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with $O(1/\\eps^3)$ stochastic gradient computations for a monotone and continuous DR-submodular function and subject to a general convex body constraint. #REFR", "given_citation_intent": "method", "given_keywords": ["stochastic nature"]}]}
{"citing_id": "2303.05699v1", "cited_id": "1710.10196", "section_title": "Results", "citation": "In addition, we unlearn the 'Bang' feature from ProgGAN trained with CelebA-HQ dataset #REFR , whose resolution is higher than the other two datasets.", "text_before_citation": ["Note that FID is calculated using the entire dataset, which yields a slightly higher FID value for the unlearned and baseline models, but there is no significant difference between the two models.", "Qualitative results.", "Figure 5 presents the qualitative visualization result of our unlearning framework.", "The top row shows the images generated from the original generator, and the bottom row shows those generated from the unlearned generator.", "By visualizing generated images using the same latent vector, we observe that the target feature has been effectively erased in each case."], "text_after_citation": ["The qualitative results in Figure 1 show the approach also works well with high-resolution images. Table 3 : ROC-AUC score of feature identification method."], "citing_paper_content": {"title": "Feature Unlearning For Generative Models Via Implicit Feedback", "abstract": "We tackle the problem of feature unlearning from a pretrained image generative model. Unlike a common unlearning task where an unlearning target is a subset of the training set, we aim to unlearn a specific feature, such as hairstyle from facial images, from the pretrained generative models. As the target feature is only presented in a local region of an image, unlearning the entire image from the pretrained model may result in losing other details in the remaining region of the image. To specify which features to unlearn, we develop an implicit feedback mechanism where a user can select images containing the target feature. From the implicit feedback, we identify a latent representation corresponding to the target feature and then use the representation to unlearn the generative model. Our framework is generalizable for the two well-known families of generative models: GANs and VAEs. Through experiments on MNIST and CelebA datasets, we show that target features are successfully removed while keeping the fidelity of the original models."}, "cited_paper_content": {"title": "Progressive Growing Of Gans For Improved Quality, Stability, And Variation", "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset."}, "keywords": ["CelebA-HQ dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors effectively erased the target feature in each case using their unlearning framework, as shown in the qualitative visualization result in Figure 5. This framework is generalizable for both GANs and VAEs, and has been successfully tested on MNIST and CelebA datasets. To achieve such results, the authors utilized a new training methodology for GANs that grows both the generator and discriminator progressively, allowing for unprecedented image quality and variation #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To unlearn specific features from a pretrained generative model, the authors developed an implicit feedback mechanism where a user can select images containing the target feature and identified a latent representation corresponding to the target feature, which was used to unlearn the generative model (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve unprecedented image quality, the authors of this manuscript could benefit from using the progressive growing of GANs method proposed in the #REFR paper, which was also used to construct the CelebA-HQ dataset.", "given_citation_intent": "method", "given_keywords": ["CelebA-HQ dataset"]}]}
{"citing_id": "2303.13523v1", "cited_id": "1910.03611", "section_title": "Ii. Literature Review", "citation": "The authors of #REFR discuss three types of priority: per-service, per-VNF, and per-flow, where service prioritization is based on the delay attribute and per VNF priority is assigned randomly.", "text_before_citation": ["Authors in #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR , #OTHEREFR proposed reinforcement learningbased approaches.", "In a realistic scenario, each service has its own level of importance based on its type and requirements.", "Following the FIFO technique can cause failure in deploying emergency services over best-effort ones.", "Methods that classify SFCs as either Premium (Pr) or Best-Effort (BE), constantly prioritizes Pr services over the BE ones, resulting in severe service deprivation for low-priority services #OTHEREFR .", "#OTHEREFR and #OTHEREFR demonstrated the effectiveness of mapping the services depending on the priority of VNFs."], "text_after_citation": ["This is an iterative process that adjusts the solution after each iteration, which is not scalable considering future requirements.", "Also the predefined number of flows that a VNF can handle, ignores the operational dynamics.", "Priority-based scheduling and deployment is still an issue requiring an 'intelligent' system to dynamically establish the online service priority and re-schedule the services according to the urgency and benefit.", "Researchers have proposed Integer Linear Program (ILP) or heuristic models in the literature, which are either computationally costly or produce sub-optimal solutions.", "To overcome this drawback, we propose ML-based algorithms to dynamically assign priority to online services and train the model to re-arrange the scheduling queue according to the needs."], "citing_paper_content": {"title": "Dynamic Prioritization And Adaptive Scheduling Using Deep Deterministic Policy Gradient For Deploying Microservice-Based Vnfs", "abstract": "The Network Function Virtualization (NFV)-Resource Allocation (RA) problem is NP-Hard. Traditional deployment methods revealed the existence of a starvation problem, which the researchers failed to recognize. Basically, starvation here, means the longer waiting times and eventual rejection of low-priority services due to a 'time out'. The contribution of this work is threefold: a) explain the existence of the starvation problem in the existing methods and their drawbacks, b) introduce 'Adaptive Scheduling' (AdSch) which is an 'intelligent scheduling' scheme using a three-factor approach (priority, threshold waiting time, and reliability), which proves to be more reasonable than traditional methods solely based on priority, and c) a 'Dynamic Prioritization' (DyPr), allocation method is also proposed for unseen services and the importance of macro-and microlevel priority. We presented a zero-touch solution using Deep Deterministic Policy Gradient (DDPG) for adaptive scheduling and an online-Ridge Regression (RR) model for dynamic prioritization. The DDPG successfully identified the 'Beneficial and Starving' services, efficiently deploying twice as many low-priority services as others, reducing the starvation problem. Our online-RR model learns the pattern in less than 100 transitions, and the prediction model has an accuracy rate of more than 80%."}, "cited_paper_content": {"title": "Reducing Service Deployment Cost Through Vnf Sharing", "abstract": "Thanks to its computational and forwarding capabilities, the mobile network infrastructure can support several third-party (\"vertical\") services, each composed of a graph of virtual (network) functions (VNFs). Importantly, one or more VNFs are often common to multiple services, thus the services deployment cost could be reduced by letting the services share the same VNF instance instead of devoting a separate instance to each service. By doing that, however, it is critical that the target KPI (key performance indicators) of all services are met. To this end, we study the VNF sharing problem and make decisions on (i) when sharing VNFs among multiple services is possible, (ii) how to adapt the virtual machines running the shared VNFs to the combined load of the assigned services, and (iii) how to prioritize the services traffic within shared VNFs. All decisions aim to minimize the cost for the mobile operator, subject to requirements on end-to-end service performance, e.g., total delay. Notably, we show that the aforementioned priorities should be managed dynamically and vary across VNFs. We then propose the FlexShare algorithm to provide near-optimal VNF-sharing and priority assignment decisions in polynomial time. We prove that FlexShare is within a constant factor from the optimum and, using real-world VNF graphs, we show that it consistently outperforms baseline solutions."}, "keywords": ["service prioritization"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Authors in this field have proposed various approaches to address the starvation problem in NFV-RA. However, traditional methods solely based on priority can result in severe service deprivation for low-priority services. To address this issue, some researchers have demonstrated the effectiveness of mapping the services depending on the priority of VNFs #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the starvation problem in traditional deployment methods, researchers have proposed \"Adaptive Scheduling\" and \"Dynamic Prioritization\" schemes, which prioritize services based on a three-factor approach and the importance of macro- and micro-level priority, respectively #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Service prioritization is crucial in deploying microservice-based VNFs, and previous methods that prioritize premium services over best-effort ones have resulted in severe service deprivation for low-priority services #OTHEREFR. To address this issue, the authors of this manuscript proposed an intelligent scheduling scheme using a three-factor approach, which proved to be more reasonable than traditional methods solely based on priority, and demonstrated the effectiveness of mapping the services depending on the priority of VNFs #REFR, providing valuable background information for service deployment cost reduction through VNF sharing.", "given_citation_intent": "background", "given_keywords": ["service prioritization"]}]}
{"citing_id": "2304.01194v1", "cited_id": "1905.02716", "section_title": "Burst Super-Resolution", "citation": "Specifically, our Burstormer lead to 0.79 dB boost when compared with existing multi-level PCD alignment #REFR .", "text_before_citation": ["In the baseline model, we use Resblocks #OTHEREFR for feature extraction, simple concatenation-based fusion, and the pixel-shuffle operation for upsampling.", "It can be seen that inclusion of the proposed RBFE in feature alignment stage leads to substantial PSNR boost of 1.02 dB.", "This performance gain is further increased by 1.49 dB when we add the proposed burst fusion (NRFE) and upsampling modules.", "Overall, when deployed all our modules, we achieve 5.67 dB increment over the baseline.", "Further, Table 2 shows that replacing the proposed alignment and fusion methods with other existing techniques causes significant performance drop, i.e., 0.43 dB and 0.34 dB, respectively."], "text_after_citation": ["The proposed RBFE module with local-non-local feature extraction ability is a key difference between the existing PCD and our enhanced deformable alignment.", "Further, we observe 0.34 dB drop in PSNR when we replace the proposed NRFE (fusion module) with existing compute extensive PBFF #OTHEREFR .", "Ablation experiments show that with compute efficient in nature Figure 5 . Ablation experiments for Burstormer contributions.", "PSNR is reported on SyntheticBurst dataset #OTHEREFR for 4\u00d7 SR. All our major components contribute significantly.", "As given in Table, our Burstormer achieves 5.67 dB gain over the baseline approach."], "citing_paper_content": {"title": "Burstormer: Burst Image Restoration And Enhancement Transformer", "abstract": "On a shutter press, modern handheld cameras capture multiple images in rapid succession and merge them to generate a single image. However, individual frames in a burst are misaligned due to inevitable motions and contain multiple degradations. The challenge is to properly align the successive image shots and merge their complimentary information to achieve high-quality outputs. Towards this direction, we propose Burstormer: a novel transformer-based architecture for burst image restoration and enhancement. In comparison to existing works, our approach exploits multi-scale local and non-local features to achieve improved alignment and feature fusion. Our key idea is to enable inter-frame communication in the burst neighborhoods for information aggregation and progressive fusion while modeling the burst-wide context. However, the input burst frames need to be properly aligned before fusing their information. Therefore, we propose an enhanced deformable alignment module for aligning burst features with regards to the reference frame. Unlike existing methods, the proposed alignment module not only aligns burst features but also exchanges feature information and maintains focused communication with the reference frame through the proposed referencebased feature enrichment mechanism, which facilitates handling complex motions. After multi-level alignment and enrichment, we re-emphasize on inter-frame communication within burst using a cyclic burst sampling module. Finally, the inter-frame information is aggregated using the proposed burst feature fusion module followed by progressive upsampling. Our Burstormer outperforms state-ofthe-art methods on burst super-resolution, burst denoising and burst low-light enhancement. Our codes and pretrained models are available at https:// github.com/ akshaydudhane16/ Burstormer ."}, "cited_paper_content": {"title": "Edvr: Video Restoration With Enhanced Deformable Convolutional Networks", "abstract": "Video restoration tasks, including super-resolution, deblurring, etc, are drawing increasing attention in the computer vision community. A challenging benchmark named REDS is released in the NTIRE19 Challenge. This new benchmark challenges existing methods from two aspects: (1) how to align multiple frames given large motions, and (2) how to effectively fuse different frames with diverse motion and blur. In this work, we propose a novel Video Restoration framework with Enhanced Deformable networks, termed EDVR, to address these challenges. First, to handle large motions, we devise a Pyramid, Cascading and Deformable (PCD) alignment module, in which frame alignment is done at the feature level using deformable convolutions in a coarse-to-fine manner. Second, we propose a Temporal and Spatial Attention (TSA) fusion module, in which attention is applied both temporally and spatially, so as to emphasize important features for subsequent restoration. Thanks to these modules, our EDVR wins the champions and outperforms the second place by a large margin in all four tracks in the NTIRE19 video restoration and enhancement challenges. EDVR also demonstrates superior performance to state-of-the-art published methods on video super-resolution and deblurring. The code is available at this https URL."}, "keywords": ["Burstormer", "alignment"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In the baseline model, we use Resblocks #OTHEREFR for feature extraction, simple concatenation-based fusion, and the pixel-shuffle operation for upsampling. It can be seen that inclusion of the proposed RBFE in feature alignment stage leads to substantial PSNR boost of 1.02 dB. This performance gain is further increased by 1.49 dB when we add the proposed burst fusion (NRFE) and upsampling modules. Overall, when deployed all our modules, we achieve 5.67 dB increment over the baseline. Further, Table 2 shows that replacing the proposed alignment and fusion methods with other existing techniques causes significant performance drop, i.e., 0.43 dB and 0.34 dB, respectively. Our proposed alignment module is based on deformable convolutions and exchange of feature information, which is shown to be effective in recent video restoration works such as EDVR #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed EDVR framework in #REFR achieves superior performance to state-of-the-art published methods on video super-resolution and deblurring, as demonstrated in the results of our experiments.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed enhanced deformable alignment module in Burstormer significantly outperforms existing techniques, resulting in a PSNR boost of 1.02 dB compared to the baseline model, as reported in the manuscript. This improvement is further increased by 1.49 dB when the proposed burst fusion and upsampling modules are added, leading to an overall increment of 5.67 dB over the baseline, and outperforming state-of-the-art methods on burst super-resolution, burst denoising, and burst low-light enhancement. The proposed alignment module not only aligns burst features but also exchanges feature information and maintains focused communication with the reference frame through the proposed reference-based feature enrichment mechanism, which facilitates handling complex motions, as reported in #REFR.", "given_citation_intent": "result", "given_keywords": ["Burstormer", "alignment"]}]}
{"citing_id": "2304.04475v1", "cited_id": "1509.02971", "section_title": "Introduction", "citation": "In a realistic public health scenario, these techniques cannot be used to model and optimize continuous factors such as the number of vaccinations needed and the duration of lockdowns #REFR .", "text_before_citation": ["2016 #OTHEREFR .", "The recent work on the automatic control of epidemics and optimization has focused on the use of either greedy algorithms #OTHEREFR", "2020) or reinforcement learning frameworks such as Deep Q-learning variants #OTHEREFR .", "Techniques such as Q-learning and greedy optimization can only choose from a predetermined set of intervention strategies (states and actions) e.g.", "high vs low vaccination; choose one among n types of masks."], "text_after_citation": ["Studies using continuous reinforcement learning frameworks such as Deep Deterministic Policy Gradient (DDPG), Twin Delayed DDPG, and Proximal Policy Optimization (PPO) #OTHEREFR have been proposed to handle such continuous actions.", "However, these studies are limited in the simulation objectives (only one or two of vaccination, lockdown, economy), scale (few thousand individuals), or use equation-based models which are not suited for intervention studies.", "This is very important since the use of inappropriate models or optimization algorithms can have unintended and often negative consequences #OTHEREFR .", "We overcome these challenges and demonstrate a Deep Deterministic Policy Gradient (DDPG) #OTHEREFR", "2017) based policy optimization framework on a large-scale epidemiological simulation where we optimize for multiple objectives (health and economy)."], "citing_paper_content": {"title": "Epidemic Control On A Large-Scale-Agent-Based Epidemiology Model Using Deep Deterministic Policy Gradient", "abstract": "To mitigate the impact of the pandemic, several measures include lockdowns, rapid vaccination programs, school closures, and economic stimulus. These interventions can have positive or unintended negative consequences. Current research to model and determine an optimal intervention automatically through roundtripping is limited by the simulation objectives, scale (a few thousand individuals), model types that are not suited for intervention studies, and the number of intervention strategies they can explore (discrete vs continuous). We address these challenges using a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework on a large-scale (100,000 individual) epidemiological agent-based simulation where we perform multi-objective optimization. We determine the optimal policy for lockdown and vaccination in a minimalist age-stratified multi-vaccine scenario with a basic simulation for economic activity. With no lockdown and vaccination (mid-age and elderly), results show optimal economy (individuals below the poverty line) with balanced health objectives (infection, and hospitalization). An in-depth simulation is needed to further validate our results and open-source our framework."}, "cited_paper_content": {"title": "Continuous Control With Deep Reinforcement Learning", "abstract": "We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs."}, "keywords": ["realistic public health", "techniques"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The recent work on the automatic control of epidemics and optimization has focused on the use of either greedy algorithms (2020) or reinforcement learning frameworks such as Deep Q-learning variants (2016 #REFR). Techniques such as Q-learning and greedy optimization can only choose from a predetermined set of intervention strategies (states and actions) e.g. high vs low vaccination; choose one among n types of masks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the limitations of discrete intervention strategies, the authors propose a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework, which can operate over continuous action spaces, and cite the work on continuous control with deep reinforcement learning as a reference for their approach #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the limitations of discrete intervention strategies, the authors propose a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework that can operate over continuous action spaces #REFR, which is a promising technique for realistic public health interventions.", "given_citation_intent": "method", "given_keywords": ["realistic public health", "techniques"]}]}
{"citing_id": "2303.16769v1", "cited_id": "1310.4546", "section_title": "Introduction", "citation": "To aid with our re-defined tasks we introduce the Semantic Anchors, a combination of the general Word2Vec #REFR semantic space and class centers based on the image representations output by the pre-trained model.", "text_before_citation": ["In Fig.", "1 (b,c) we graph a preliminary evaluation showing that Sketch-an-Anchor indeed succeeds at this goal.", "We've evaluated the DINO S/8 pre-trained model and our own finetuned one at within-domain and cross-domain retrieval, showing the former is already great at ZSIBIR (image domain) while ours maintains that performance at the same time as it significantly moves the needle on withindomain Sketch-based Sketch Retrieval and cross-domain ZSSBIR. The t-SNE projection in Fig.", "1 (a) corroborates our finding, showing how the DINO space is discriminative for images but messy for sketches, and then how Sketch-an-Anchor keeps the image relationships while learning better representation for the sketches.", "Rethinking the sub-tasks has another remarkable benefit: since we do not need to learn the ZSIBIR sub-task, our model requires only a few iterations, 99.1% less iterations than the average ZSSBIR model to be exact, making it the fastest training ZSSBIR model in the literature."], "text_after_citation": ["We then use the Semantic Anchors and their pairwise similarities to design our novel Anchored Contrastive Loss, elevating a strong baseline model to SoTA performance.", "To summarize, our contributions are the following:", "\u2022 Re-think the ZSSBIR solution on matching sketch representations to an existing pre-trained space, since those are already good image retrieval models;", "\u2022 The ability to train a model for ZSSBIR in under an epoch and achieve performance competitive with SoTA;", "\u2022 Introduce Semantic Anchors, which learns from visual and word-based semantic spaces with a Graph Convolutional Net and guide the fast model adaptation;"], "citing_paper_content": {"title": "Sketch-An-Anchor: Sub-Epoch Fast Model Adaptation For Zero-Shot Sketch-Based Image Retrieval", "abstract": "Sketch-an-Anchor is a novel method to train state-of-theart Zero-shot Sketch-based Image Retrieval (ZSSBIR) models in under an epoch. Most studies break down the problem of ZSSBIR into two parts: domain alignment between images and sketches, inherited from SBIR, and generalization to unseen data, inherent to the zero-shot protocol. We argue one of these problems can be considerably simplified and re-frame the ZSSBIR problem around the alreadystellar yet underexplored Zero-shot Image-based Retrieval performance of off-the-shelf models. Our fast-converging model keeps the single-domain performance while learning to extract similar representations from sketches. To this end we introduce our Semantic Anchors-guiding embeddings learned from word-based semantic spaces and features from off-the-shelf models-and combine them with our novel Anchored Contrastive Loss. Empirical evidence shows we can achieve state-of-the-art performance on all benchmark datasets while training for 100x less iterations than other methods."}, "cited_paper_content": {"title": "Distributed Representations Of Words And Phrases And Their Compositionality", "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. ::: ::: An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."}, "keywords": ["Semantic Anchors", "general Word2Vec semantic"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the quality and training speed of vector representations, the authors of Sketch-an-Anchor cite the recently introduced continuous Skip-gram model, which includes several extensions such as subsampling of frequent words and negative sampling #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the quality and training speed of their model, the authors of Sketch-an-Anchor used several extensions including subsampling of frequent words and negative sampling #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To learn good vector representations for millions of phrases, Sketch-an-Anchor utilizes Semantic Anchors-guiding embeddings learned from general Word2Vec semantic spaces, as presented in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["Semantic Anchors", "general Word2Vec semantic"]}]}
{"citing_id": "2303.09987v1", "cited_id": "1702.05931", "section_title": "Gene N N", "citation": "Stain normalisation is employed as a preprocessing step in computational pathology algorithms to regulate variances and has a significant impact on the outcome of automated image analysis methods #REFR .", "text_before_citation": ["Auxiliary predictions Histology samples stained with H&E often vary in colour between and within laboratories from one batch to the next."], "text_after_citation": ["In our work, we employed StainTools #OTHEREFR , using the Vahadane technique to normalize the stain variance in the target image and the Luminosity Standardizer function to standardize the brightness, both of which facilitate consistent interpretation of the images #OTHEREFR .", "Evaluation (a) (b) (c) (d) (f) (g) ST Spots Main network predictions (iv) (iii) (ii) (i) (e)"], "citing_paper_content": {"title": "Breast Cancer Histopathology Image-Based Gene Expression Prediction Using Spatial Transcriptomics Data And Deep Learning", "abstract": "Tumour heterogeneity in breast cancer poses challenges in predicting outcome and response to therapy. Spatial transcriptomics technologies may address these challenges, as they provide a wealth of information about gene expression at the cell level, but they are expensive, hindering their use in large-scale clinical oncology studies. Predicting gene expression from hematoxylin and eosin stained histology images provides a more affordable alternative for such studies. Here we present BrST-Net, a deep learning framework for predicting gene expression from histopathology images using spatial transcriptomics data. Using this framework, we trained and evaluated 10 state-of-the-art deep learning models without utilizing pretrained weights for the prediction of 250 genes. To enhance the generalisation performance of the main network, we introduce an auxiliary network into the framework. Our methodology outperforms previous studies, with 237 genes identified with positive correlation, including 24 genes with a median correlation coefficient greater than 0.50. This is a notable improvement over previous studies, which could predict only 102 genes with positive correlation, with the highest correlation values ranging from 0.29 to 0.34."}, "cited_paper_content": {"title": "The Importance Of Stain Normalization In Colorectal Tissue Classification With Convolutional Networks", "abstract": "The development of reliable imaging biomarkers for the analysis of colorectal cancer (CRC) in hematoxylin and eosin (H&E) stained histopathology images requires an accurate and reproducible classification of the main tissue components in the image. In this paper, we propose a system for CRC tissue classification based on convolutional networks (ConvNets). We investigate the importance of stain normalization in tissue classification of CRC tissue samples in H&E-stained images. Furthermore, we report the performance of ConvNets on a cohort of rectal cancer samples and on an independent publicly available dataset of colorectal H&E images."}, "keywords": ["computational pathology", "Stain normalisation"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Histology samples stained with H&E often vary in colour between and within laboratories from one batch to the next. To address this issue, the importance of stain normalization in tissue classification of CRC tissue samples in H&E-stained images has been investigated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Histology samples stained with H&E often vary in colour between and within laboratories from one batch to the next. To address this issue, the authors of this manuscript propose a system for CRC tissue classification based on convolutional networks (ConvNets) and investigate the importance of stain normalization in tissue classification of CRC tissue samples in H&E-stained images #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Histology samples stained with H&E often vary in colour between and within laboratories from one batch to the next. To address this issue, computational pathology methods such as stain normalization have been proposed, which have been shown to improve the accuracy of tissue classification in colorectal cancer samples using convolutional networks (#REFR).", "given_citation_intent": "method", "given_keywords": ["computational pathology", "Stain normalisation"]}]}
{"citing_id": "2303.05665v1", "cited_id": "2002.00444", "section_title": "I. Introduction", "citation": "More specially, for AVs, we will focus on vehicle trajectory tracking control at the microscopic level, while more efforts on collaborative control will be put for CAVs at the macroscopic level #REFR .", "text_before_citation": ["AVs and CAVs as the key instantiation of AD and CDA become more and more widely deployed and they benefit both individuals and society #OTHEREFR .", "In the past few decades, manufacturers and scholars have been thriving in automotive industrialization to maximize benefits from AD and CDA #OTHEREFR .", "The hierarchical framework, including perception, planning, and control modules, is the popular pipeline for both AV and CDA techniques.", "One of the most challenging tasks for AD and CDA is to develop safe and efficient vehicle control modules for both AV and CAV #OTHEREFR .", "To clarify, vehicle control is to make an AV or CAV follow a desired route or trajectory #OTHEREFR ."], "text_after_citation": ["Before diving into vehicle control, it is worth mentioning that accurate and reliable vehicle state information is the prerequisite and essential for vehicle control in AVs and CAVs #OTHEREFR .", "However, key states such as longitudinal and lateral velocity, sideslip angle, orientation, and tire forces cannot be directly measured for commercial vehicles.", "In other words, these vital states can only be estimated indirectly.", "Among these states, sideslip angle comprising longitudinal and lateral velocity is the most important state for vehicle stabilization, motion planning, road condition estimation, handover modules, and vehicle navigation #OTHEREFR .", "In other words, without an accurate sideslip angle, the performance of the applications mentioned above will be compromised and even sustain failure inevitably."], "citing_paper_content": {"title": "A Systematic Survey Of Control Techniques And Applications: From Autonomous Vehicles To Connected And Automated Vehicles", "abstract": "Vehicle control is one of the most critical challenges in autonomous vehicles (AVs) and connected and automated vehicles (CAVs), and it is paramount in vehicle safety, passenger comfort, transportation efficiency, and energy saving. This survey attempts to provide a comprehensive and thorough overview of the current state of vehicle control technology, focusing on the evolution from vehicle state estimation and trajectory tracking control in AVs at the microscopic level to collaborative control in CAVs at the macroscopic level. First, this review starts with vehicle key state estimation, specifically vehicle sideslip angle, which is the most pivotal state for vehicle trajectory control, to discuss representative approaches. Then, we present symbolic vehicle trajectory tracking control approaches for AVs. On top of that, we further review the collaborative control frameworks for CAVs and corresponding applications. Finally, this survey concludes with a discussion of future research directions and the challenges. This survey aims to provide a contextualized and indepth look at state of the art in vehicle control for AVs and CAVs, identifying critical areas of focus and pointing out the potential areas for further exploration."}, "cited_paper_content": {"title": "Deep Reinforcement Learning For Autonomous Driving: A Survey", "abstract": "With the development of deep representation learning, the domain of reinforcement learning (RL) has become a powerful learning framework now capable of learning complex policies in high dimensional environments. This review summarises deep reinforcement learning (DRL) algorithms, provides a taxonomy of automated driving tasks where (D)RL methods have been employed, highlights the key challenges algorithmically as well as in terms of deployment of real world autonomous driving agents, the role of simulators in training agents, and finally methods to evaluate, test and robustifying existing solutions in RL and imitation learning."}, "keywords": ["vehicle trajectory tracking"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To clarify, vehicle control is to make an AV or CAV follow a desired route or trajectory, and with the development of deep representation learning, deep reinforcement learning (DRL) has become a powerful learning framework now capable of learning complex policies in high dimensional environments #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To develop safe and efficient vehicle control modules for AV and CAV, researchers have employed deep reinforcement learning algorithms, which have become a powerful learning framework capable of learning complex policies in high dimensional environments #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve safe and efficient vehicle control for AV and CAV, one of the most pivotal tasks is to develop symbolic vehicle trajectory tracking control approaches, as summarized in the survey paper by Li et al. (2021) on deep reinforcement learning for autonomous driving #REFR.", "given_citation_intent": "background", "given_keywords": ["vehicle trajectory tracking"]}]}
{"citing_id": "2304.13274v1", "cited_id": "1512.03385", "section_title": "Experimental Setup", "citation": "To evaluate the efficacy of our method, we performed experiments with ResNet18 #REFR and wide residual network [23] .", "text_before_citation": [], "text_after_citation": ["In particular, we evaluated ResNet18 on two popular datasets, CIFAR-10 and CIFAR-100 #OTHEREFR and WRN22-8 on CIFAR-100.", "We used PyTorch API to define and train our models on an Nvidia RTX 2080 Ti GPU.", "To perform stage 1 and 2, we followed the same hyperparameters as #OTHEREFR .", "To perform joint ReLU and depth reduction during fine-tuning stage, we initialized a PR model with the weights that provided the best accuracy during the mask evaluation stage (stage 2).", "We then trained the model for 180 epochs with starting LR of 0.01 that decayed by a factor of 10 at epochs 90, 140, and 160."], "citing_paper_content": {"title": "Making Models Shallow Again: Jointly Learning To Reduce Non-Linearity And Depth For Latency-Efficient Private Inference", "abstract": "Large number of ReLU and MAC operations of Deep neural networks make them ill-suited for latency and compute-efficient private inference. In this paper, we present a model optimization method that allows a model to learn to be shallow. In particular, we leverage the ReLU sensitivity of a convolutional block to remove a ReLU layer and merge its succeeding and preceding convolution layers to a shallow block. Unlike existing ReLU reduction methods, our joint reduction method can yield models with improved reduction of both ReLUs and linear operations by up to 1.73\u00d7 and 1.47\u00d7, respectively, evaluated with ResNet18 on CIFAR-100 without any significant accuracy-drop."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["wide residual network"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To reduce the non-linearity and depth of deep neural networks for efficient private inference, the authors proposed a joint reduction method that can yield models with improved reduction of both ReLUs and linear operations by up to 1.73\u00d7 and 1.47\u00d7, respectively, evaluated with ResNet18 on CIFAR-100 without any significant accuracy-drop #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the model, the authors proposed a joint reduction method that can yield models with improved reduction of both ReLUs and linear operations by up to 1.73\u00d7 and 1.47\u00d7, respectively, evaluated with ResNet18 on CIFAR-100 without any significant accuracy-drop (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the model and reduce non-linearity and depth, the authors proposed a joint reduction method that can yield models with improved reduction of both ReLUs and linear operations by up to 1.73\u00d7 and 1.47\u00d7, respectively, evaluated with ResNet18 on CIFAR-100 without any significant accuracy-drop, while leveraging the sensitivity of a convolutional block, as presented in the reference paper on deep residual learning for image recognition. #REFR", "given_citation_intent": "method", "given_keywords": ["wide residual network"]}]}
{"citing_id": "2303.05266v1", "cited_id": "1708.07747", "section_title": "Experimental Settings", "citation": "For downstream tasks, we evaluate SEMAP on four datasets: CI-FAR10 [1], CIFAR100 [1], F-MNIST #REFR , and STL10 [2].", "text_before_citation": ["Models and Datasets. Our target model is pre-trained on ImageNet-1k #OTHEREFR .", "We use four different kinds of model structures: ResNet18 (RN18) #OTHEREFR , ResNet50 (RN50) #OTHEREFR , Instagram ResNeXt (Ins) #OTHEREFR , and BiT-M ResNet50 (BiT) #OTHEREFR . ImageNet-21k #OTHEREFR and then fine-tuned on ImageNet-1k."], "text_after_citation": ["Our implementation is based on a visual prompt learning framework #OTHEREFR . Baseline Methods.", "We compare our methods with the most recent visual prompt learning methods #OTHEREFR , where random mapping and frequency-based mapping are adopted. Therefore, we name the methods as RM-VP and FM-VP.", "Further, we compare our methods with traditional fine-tuning, which is denoted as FT.", "Note that visual prompt learning and finetuning are two different ways to adapt pre-trained models to downstream tasks."], "citing_paper_content": {"title": "From Visual Prompt Learning To Zero-Shot Transfer: Mapping Is All You Need", "abstract": "Visual prompt learning, as a newly emerged technique, leverages the knowledge learned by a large-scale pre-trained model and adapts it to downstream tasks through the usage of prompts. While previous research has focused on designing effective prompts, in this work, we argue that compared to prompt design, a good mapping strategy matters more. In this sense, we propose SEMAP, a more effective mapping using the semantic alignment between the pre-trained model's knowledge and the downstream task. Our experimental results show that SEMAP can largely boost the performance of visual prompt learning. Moreover, our experiments show that SEMAP is capable of achieving competitive zero-shot transfer, indicating that it can perform the downstream task without any fine-tuning on the corresponding dataset. This demonstrates the potential of our proposed method to be used in a broader range of applications where the zero-shot transfer is desired. Results suggest that our proposed SEMAP could lead to significant advancements in both visual prompt learning and zero-shot transfer. We hope with SEMAP, we can help the community move forward to more efficient and lightweight utilization of large vision models."}, "cited_paper_content": {"title": "Fashion-Mnist: A Novel Image Dataset For Benchmarking Machine Learning Algorithms", "abstract": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL"}, "keywords": ["[1], F-MNIST", "four datasets"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We use four different kinds of model structures: ResNet18 (RN18) #OTHEREFR , ResNet50 (RN50) #OTHEREFR , Instagram ResNeXt (Ins) #OTHEREFR , and BiT-M ResNet50 (BiT) #OTHEREFR, which are pre-trained on ImageNet-1k, and fine-tuned on ImageNet-1k. For benchmarking machine learning algorithms, we use Fashion-MNIST, a novel image dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category, which is intended to serve as a direct drop-in replacement for the original MNIST dataset #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To align the pre-trained model's knowledge with the downstream task, SEMAP proposes a more effective mapping strategy using the semantic alignment, which has been shown to largely boost the performance of visual prompt learning and achieve competitive zero-shot transfer #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the effectiveness of our proposed mapping strategy, we conduct experiments on four datasets, including ImageNet-1k #OTHEREFR, and Fashion-MNIST [1] which is a novel image dataset for benchmarking machine learning algorithms. #REFR", "given_citation_intent": "method", "given_keywords": ["[1], F-MNIST", "four datasets"]}]}
{"citing_id": "2304.00790v1", "cited_id": "1105.1186", "section_title": "Vi. Probabilistic Completeness", "citation": "Following #REFR we assume that Problem 1 is robustly feasible with minimum clearance \u03b5 > 0.", "text_before_citation": ["In this section, we provide the probabilistic proof for our algorithm."], "text_after_citation": ["Hence, \u2203u \u2208 U such that it produces a system (1) trajectory \u03c6, where \u03c6 : [0, T ] \u2192 X safe , \u03c6(0) = x init , \u03c6(T ) = x goal , and", "\u2200t \u2208 [0, T ]; \u03a8 r b (\u03c6(t)) \u2265 0, \u2200\u03c6 \u2208 C 0 \u2229 \u2022 \u2022 \u2022 \u2229 C r b . Remark 4.", "The assumption on the sets of initial state X init and goal state X goal are required because the CBF constraints #OTHEREFR are checked at every time steps during edge extension.", "If the assumption does not hold, there's a probability such that certain states x init , x goal will be rejected, and the state trajectory will never reach the goal.", "We can ensure the assumption holds by choosing appropriate HOCBF hyperparameters. Lemma 1."], "citing_paper_content": {"title": "Efficient Lqr-Cbf-Rrt*: Safe And Optimal Motion Planning", "abstract": "Control Barrier Functions (CBF) are a powerful tool for designing safety-critical controllers and motion planners. The safety requirements are encoded as a continuously differentiable function that maps from state variables to a real value, in which the sign of its output determines whether safety is violated. In practice, the CBFs can be used to enforce safety by imposing itself as a constraint in a Quadratic Program (QP) solved point-wise in time. However, this approach costs computational resources and could lead to infeasibility in solving the QP. In this paper, we propose a novel motion planning framework that combines samplingbased methods with Linear Quadratic Regulator (LQR) and CBFs. Our approach does not require solving the QPs for control synthesis and avoids explicit collision checking during samplings. Instead, it uses LQR to generate optimal controls and CBF to reject unsafe trajectories. To improve sampling efficiency, we employ the Cross-Entropy Method (CEM) for importance sampling (IS) to sample configurations that will enhance the path with higher probability and store computed optimal gain matrices in a hash table to avoid re-computation during rewiring procedure. We demonstrate the effectiveness of our method on nonlinear control affine systems in simulation."}, "cited_paper_content": {"title": "Sampling-Based Algorithms For Optimal Motion Planning", "abstract": "United States. Air Force Office of Scientific Research (Michigan/AFRL Collaborative Center in Control Science Grant FA 8650-07-2-3744)"}, "keywords": ["minimum clearance"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this section, we provide the probabilistic proof for our algorithm, and build upon the efficient motion planning framework proposed in #REFR, which combines sampling-based methods with Linear Quadratic Regulator (LQR) and Control Barrier Functions (CBFs).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide background on optimal motion planning, we cite the paper by Karaman and Frazzoli (#REFR), which proposes sampling-based algorithms for solving this problem.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Minimum clearance is a crucial factor in motion planning, and it has been addressed in previous works such as the reference paper \"Sampling-Based Algorithms For Optimal Motion Planning\" #REFR.", "given_citation_intent": "background", "given_keywords": ["minimum clearance"]}]}
{"citing_id": "2303.10181v1", "cited_id": "1912.01703", "section_title": "Methods For Resource Efficiency", "citation": "In frameworks like Pytorch #REFR , the precision of h l , g t are automatically cast into 16-bit precision, and recast to 32-bit when necessary.", "text_before_citation": ["In this work, we investigate a combination of the following three quantisation strategies:", "1. Gradients and intermediate activations:", "Drastic quantisation of h l , g t", "have been studied extensively in literature #OTHEREFR .", "For instance, in #OTHEREFR the gradients and activations were quantised to 1-bit and still yielded reasonable performance compared to the 32-bit models. However, not all operations are well suited for quantisation."], "text_after_citation": ["This technique known as automatic mixed precision (AMP) can yield considerable reduction of memory costs #OTHEREFR . 2.", "Optimiser states: Until recently, the main focus of quantisation in deep learning has been on compressing g t , h l , W.", "In a recent work in #OTHEREFR , it was shown that the optimiser states, m t , v t can use up to 75% of memory.", "By quantising optimiser states to 8-bits using a dynamic quantisation scheme, this work reduces the memory consumption during model training. 3.", "Model weights: The resolution of the hypothesis space is controlled by the precision of the weights, W."], "citing_paper_content": {"title": "Operating Critical Machine Learning Models In Resource Constrained Regimes", "abstract": "The accelerated development of machine learning methods, primarily deep learning, are causal to the recent breakthroughs in medical image analysis and computer aided intervention. The resource consumption of deep learning models in terms of amount of training data, compute and energy costs are known to be massive. These large resource costs can be barriers in deploying these models in clinics, globally. To address this, there are cogent efforts within the machine learning community to introduce notions of resource efficiency. For instance, using quantisation to alleviate memory consumption. While most of these methods are shown to reduce the resource utilisation, they could come at a cost in performance. In this work, we probe into the trade-off between resource consumption and performance, specifically, when dealing with models that are used in critical settings such as in clinics."}, "cited_paper_content": {"title": "Pytorch: An Imperative Style, High-Performance Deep Learning Library", "abstract": "Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. ::: In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. ::: We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks."}, "keywords": ["Pytorch"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Gradients and intermediate activations: Drastic quantisation of h l , g t have been studied extensively in literature (OtherRef). For instance, in OtherRef the gradients and activations were quantised to 1-bit and still yielded reasonable performance compared to the 32-bit models. However, not all operations are well suited for quantisation. In this regard, PyTorch (REFR) provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Quantisation has been extensively studied in literature, and drastic quantisation of gradients and intermediate activations has been shown to yield reasonable performance compared to 32-bit models, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Quantisation has been shown to reduce resource utilization without compromising performance in some cases, such as in #OTHEREFR where gradients and activations were quantised to 1-bit and still yielded reasonable performance compared to the 32-bit models, highlighting the potential benefits of using Pytorch. #REFR", "given_citation_intent": "method", "given_keywords": ["Pytorch"]}]}
{"citing_id": "2304.10250v1", "cited_id": "2003.08934", "section_title": "A Appendix", "citation": "We have also tried using positional encoding with ReLU, like what is used in NeRF #REFR . The result is shown in table 11.", "text_before_citation": ["It can be seen that joint training achieves significantly better performance than training on a single corruption across all three tasks, suggesting the effectiveness of the LINR.", "For images containing noise in all joint-training experiments, the training weight is set to 0.1.", "This aims to reduce the misleading effect of this type of corruption. For all other images, the weight is 1.", "Our work is based on SIREN #OTHEREFR , which uses sine as the activation function.", "We also replace it with other activation functions for super-resolution tasks as an ablation study here. We have tried Tanh, Sigmoid, ReLU, etc."], "text_after_citation": ["With other activation functions, INR performed poorly on SR with the same number of training iterations(500).", "SIREN can represent high-quality images in a very short time, whereas the other activation functions can not.", "If given more training iterations, the performance of ReLU-PE can increase significantly (with an average PSNR of 26.23 on Set5 after 2000 iterations), but is still much worse than the result of SIREN (because ReLU cannot model higher-order derivatives and also lack the ability to extract enough global information #OTHEREFR .) However, it is significantly better than the result of Nearest (24.50) , which shows that with other activation functions, INR also has the capacity to restore high-quality images."], "citing_paper_content": {"title": "Revisiting Implicit Neural Representations In Low-Level Vision", "abstract": "Implicit Neural Representation (INR) has been emerging in computer vision in recent years. It has been shown to be effective in parameterising continuous signals such as dense 3D models from discrete image data, e.g. the neural radius field (NeRF). However, INR is under-explored in 2D image processing tasks. Considering the basic definition and the structure of INR, we are interested in its effectiveness in low-level vision problems such as image restoration. In this work, we revisit INR and investigate its application in low-level image restoration tasks including image denoising, super-resolution, inpainting, and deblurring. Extensive experimental evaluations suggest the superior performance of INR in several low-level vision tasks with limited resources, outperforming its counterparts by over 2dB. Code and models are available at: https://github.com/WenTXuL/LINR."}, "cited_paper_content": {"title": "Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis", "abstract": "We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing direction $(\\theta, \\phi)$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons."}, "keywords": ["positional encoding"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our work is based on SIREN #OTHEREFR , which uses sine as the activation function. We also replace it with other activation functions for super-resolution tasks as an ablation study here. We have tried Tanh, Sigmoid, ReLU, etc. Our approach is similar to the one presented in Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis, where a fully-connected deep network is used to represent a scene and synthesize novel views. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve state-of-the-art results for synthesizing novel views of complex scenes, LINR can be optimized using an underlying continuous volumetric scene function as presented in Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We use positional encoding to represent the input image and achieve state-of-the-art results in low-level vision tasks, which is similar to the approach used in Nerf #REFR for representing scenes as neural radiance fields.", "given_citation_intent": "method", "given_keywords": ["positional encoding"]}]}
{"citing_id": "2303.06048v1", "cited_id": "1804.06872", "section_title": "Characteristics Of In-The-Wild Har Datasets", "citation": "To characterize the distribution of noisy labels, a noise transition matrix is often used, where element corresponds to the probability of mislabeling a data sample with ground truth label to label #REFR .", "text_before_citation": ["From Fig.", "1 , we conclude ExtraSensory is much noisier than RealWorld since the former is crowdsourced data.", "What also distinguishes the two datasets is the distribution of label noises.", "Specifically, for RealWorld, most mislabeling happens in the climbing up/down trials when the ground labels are \"walk on a flat ground\" or standing.", "In contrast, in ExtraSensory, mislabeling exists almost between any two activities."], "text_after_citation": ["When mislabels occur equally likely for all classes other than the true class, the associate noise pattern is called symmetric noise.", "Otherwise, if there is a dominant off-diagonal element in each row in , the associate noise pattern is called asymmetric noise.", "Table 1 shows the noise transition matrix of data in three locomotion classes and one location class in ExtraSensory by comparing their curated labels (row headings) and the original ones (column headings).", "As ExtraSensory is a multi-label dataset with many classes, only top-5 mutually exclusive labels are included in the table.", "We observe that with the exception of \"running\", noise transition probabilities of all classes are best modeled as symmetric noise."], "citing_paper_content": {"title": "Valerian: Invariant Feature Learning For Imu Sensor-Based Human Activity Recognition In The Wild", "abstract": "Deep neural network models for IMU sensor-based human activity recognition (HAR) that are trained from controlled, well-curated datasets suffer from poor generalizability in practical deployments. However, data collected from naturalistic settings often contains significant label noise. In this work, we examine two in-the-wild HAR datasets and DivideMix, a state-of-the-art learning with noise labels (LNL) method to understand the extent and impacts of noisy labels in training data. Our empirical analysis reveals that the substantial domain gaps among diverse subjects cause LNL methods to violate a key underlying assumption, namely, neural networks tend to fit simpler (and thus clean) data in early training epochs. Motivated by the insights, we design VALERIAN, an invariant feature learning method for in-the-wild wearable sensor-based HAR. By training a multi-task model with separate task-specific layers for each subject, VALERIAN allows noisy labels to be dealt with individually while benefiting from shared feature representation across subjects. We evaluated VALERIAN on four datasets, two collected in a controlled environment and two in the wild. Experimental results show that VALERIAN significantly outperforms baseline approaches. VALERIAN can correct 75%-93% of label errors in the source domains. When only 10-second clean labeled data per class is available from a new target subject, even with 40% label noise in training data, it achieves \u223c 83% test accuracy."}, "cited_paper_content": {"title": "Co-Teaching: Robust Training Of Deep Neural Networks With Extremely Noisy Labels", "abstract": "Deep learning with noisy labels is practically challenging, as the capacity of deep models is so high that they can totally memorize these noisy labels sooner or later during training. Nonetheless, recent studies on the memorization effects of deep neural networks show that they would first memorize training data of clean labels and then those of noisy labels. Therefore in this paper, we propose a new deep learning paradigm called Co-teaching for combating with noisy labels. Namely, we train two deep neural networks simultaneously, and let them teach each other given every mini-batch: firstly, each network feeds forward all data and selects some data of possibly clean labels; secondly, two networks communicate with each other what data in this mini-batch should be used for training; finally, each network back propagates the data selected by its peer network and updates itself. Empirical results on noisy versions of MNIST, CIFAR-10 and CIFAR-100 demonstrate that Co-teaching is much superior to the state-of-the-art methods in the robustness of trained deep models."}, "keywords": ["noisy labels"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For combating noisy labels, recent studies have proposed a new deep learning paradigm called Co-teaching, which trains two deep neural networks simultaneously and lets them teach each other given every mini-batch, resulting in much superior robustness of trained deep models #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To combat the significant label noise in the ExtraSensory dataset, VALERIAN, an invariant feature learning method, was proposed, which allows noisy labels to be dealt with individually while benefiting from shared feature representation across subjects #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To combat the challenge of deep learning with noisy labels, the authors propose a new method called Co-teaching, which trains two deep neural networks simultaneously and allows them to teach each other given every mini-batch, resulting in superior robustness of trained deep models compared to state-of-the-art methods on noisy versions of MNIST, CIFAR-10, and CIFAR-100 datasets. #REFR", "given_citation_intent": "method", "given_keywords": ["noisy labels"]}]}
{"citing_id": "2305.00412v1", "cited_id": "1804.02767", "section_title": "Overall Benchmark Results", "citation": "Yolo is faster than Faster RCNN, but its improved modules introduced in #REFR bring more parameters.", "text_before_citation": ["This suggests that the two detectors can identify the streaks properly but the detected bounding boxes may not be always accurate.", "Instead, the Faster RCNN performs well for both AP@0.3 and AP@0.5, showing that this detector is more consistent than the other two detectors and is less likely to produce inaccurate detection boxes.", "This is easy to understand because the Faster RCNN has a specific classification head that can clearly identify partially aligned less accurate bounding boxes.", "Regarding the overall performance for AP@[0.3:0.95], the Faster RCNN shows much better consistency than the other two detectors, which further validates its superior robustness.", "In addition to the accuracy, if considering complexity like GFLOPs, parameters, and inference time, it shows that the Faster RCNN is the heaviest method with the highest GFLOPs, the highest number of parameters, and the longest processing time, while the UNet-SD is the most lightweighted."], "text_after_citation": ["To sum up, for the RSO streak detection task, our benchmarking results illustrate that the Faster RCNN is the most robust and accurate method but it has a higher cost.", "Our developed UNet-SD method is very efficient and also produces promising performance if not pursuing the highest accuracy.", "Yolo is roughly in the middle of the two methods, but its accuracy in the standard of AP@0.5 is greatly affected by the low-resolution of input images and small sizes of streaks."], "citing_paper_content": {"title": "A Simulation-Augmented Benchmarking Framework For Automatic Rso Streak Detection In Single-Frame Space Images", "abstract": "Effective space-based Resident Space Objects (RSOs) detection provides a solution to avoiding potential impact or collision of space debris with other satellites. This is achieved by providing timely observations that help track and infer the behaviours of targets of interest. Recently, deep convolutional neural networks (DCNNs) have shown superior performance in object detection compared to traditional methods when large-scale datasets are available to train their models. However, collecting rich, diversified, and meaningful data of RSOs is difficult due to very few occurrences in the space images. Without sufficient data, it is challenging to comprehensively train DCNN detectors and make them effective for detecting RSOs in space images, let alone to evaluate and estimate whether a detector has sufficient capacity to detect RSOs robustly. The lack of meaningful evaluation of different detectors could further affect the design and application of detection methods. To tackle this issue, we propose that the space images containing RSOs can be simulated to complement the shortage of raw data for better benchmarking. Accordingly, we introduce a novel simulation-augmented benchmarking framework for RSO detection (SAB-RSOD). In our framework, by making the best use of the hardware parameters of the sensor that captures real-world space images, we first develop a high-fidelity RSO simulator that can generate various realistic space images to enrich the dataset for training detectors. Then, we use this simulator to generate images that contain diversified RSOs in space and annotate them automatically. Later, we mix the synthetic images with the available real-world images, obtaining around 500 images for training detectors with only the real-world images for evaluation. Under SAB-RSOD, we can train different popular object detectors like Yolo[1] and Faster RCNN[2] effectively, enabling us to evaluate their performance thoroughly. The evaluation results have shown that the amount of available data and image resolution are two important factors for robust RSO detection. Moreover, if using a lower resolution for higher efficiency, we demonstrated that a simple UNet-based[3] detection method can already access high-accuracy RSO detection, providing new insights to the community. The dataset and evaluation code will be released."}, "cited_paper_content": {"title": "Yolov3: An Incremental Improvement", "abstract": "We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at this https URL"}, "keywords": ["Faster RCNN"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Regarding the overall performance for AP@[0.3:0.95], the Faster RCNN shows much better consistency than the other two detectors, which further validates its superior robustness. In addition to the accuracy, if considering complexity like GFLOPs, parameters, and inference time, it shows that the Faster RCNN is the heaviest method with the highest GFLOPs, the highest number of parameters, and the longest processing time, while the UNet-SD is the most lightweighted. This is consistent with the findings in Yolov3[1], where the authors also reported that their method achieved high accuracy but required more computational resources. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Object detection methods like YOLOv3[1] have shown superior performance in detecting objects in large-scale datasets.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The Faster RCNN has a specific classification head that can clearly identify partially aligned less accurate bounding boxes, which makes it more consistent and less likely to produce inaccurate detection boxes than Yolo[1] and SSD[2]. #REFR", "given_citation_intent": "background", "given_keywords": ["Faster RCNN"]}]}
{"citing_id": "2303.10112v1", "cited_id": "2001.01885", "section_title": "Recent Advances Based On Neural Networks", "citation": "For extracting nonlinear dynamics, a method with Minimum Predictive Information Regularization (MPIR) #REFR is introduced.", "text_before_citation": ["A feature selection procedure termed as a non-uniform embedding (NUE) is proposed in NN-GC #OTHEREFR to identify the significant Granger causes in the MLP model.", "By greedily adding lagged components of predictor time series as input, an MLP is updated iteratively.", "A predictor time series is claimed a significant Granger cause of the target time series if at least one of its lagged components is added when the procedure is terminated.", "In RNN-GC #OTHEREFR , the NUE is extended by replacing MLPs with gated RNN models, However, as this technique requires training and comparing many candidate models, it's costly in high-dimensional settings.", "DL-extensions with Information Regularization."], "text_after_citation": ["It leverages learnable corruption for predictor variables and minimizes a mutual information-regularized risk, which combines the benefits of the Granger causality paradigm with deep learning models.", "In MPIR, the author states that the naive way to combine neural nets with Granger causality suffers from two major drawbacks: instability and inefficiency.", "The solution is to encourage each x t\u2212K:t\u22121 i to provide as little information to x t j as possible while maintaining good prediction via learned corruption, replacing the naive way which predicts x t j with one x t\u2212K:t\u22121 i missing at a time. The risk is defined as follows:", "R X,xj [f \u03b8 , n] = E X t\u22121 ,x t j ,u [(x t j \u2212 f \u03b8 (X t\u2212K:t\u22121 (n) )) 2 ] + \u03bb \u2022 d p=1 I(X t\u2212K:t\u22121 i(n) ; X t\u2212K:t\u22121 i ), whereX t\u2212K:t\u22121 (n)", ":= X t\u2212K:t\u22121 + n e (or its element-wise representation,X t\u2212K:t\u22121"], "citing_paper_content": {"title": "Causal Discovery From Temporal Data: An Overview And New Perspectives", "abstract": "Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, medicine and finance. Analyzing this type of data is extremely valuable for various applications. Thus, different temporal data analysis tasks, e.g., classification, clustering and prediction, have been proposed in the past decades. Among them, causal discovery, learning the causal relations from temporal data, is considered an interesting yet critical task and has attracted much research attention. Existing casual discovery works can be divided into two highly correlated categories according to whether the temporal data is calibrated, i.e., multivariate time series casual discovery, and event sequence casual discovery. However, most previous surveys are only focused on the time series casual discovery and ignore the second category. In this paper, we specify the correlation between the two categories and provide a systematical overview of existing solutions. Furthermore, we provide public datasets, evaluation metrics and new perspectives for temporal data casual discovery. Keywords Causal discovery \u2022 Temporal data analysis \u2022 Relational learning * Entries correspond to methods reviewed which are mainly for non-temporal settings. \u2020 Mainly about causalities related to the Hawkes process."}, "cited_paper_content": {"title": "Discovering Nonlinear Relations With Minimum Predictive Information Regularization", "abstract": "Identifying the underlying directional relations from observational time series with nonlinear interactions and complex relational structures is key to a wide range of applications, yet remains a hard problem. In this work, we introduce a novel minimum predictive information regularization method to infer directional relations from time series, allowing deep learning models to discover nonlinear relations. Our method substantially outperforms other methods for learning nonlinear relations in synthetic datasets, and discovers the directional relations in a video game environment and a heart-rate vs. breath-rate dataset."}, "keywords": ["Minimum Predictive Information", "Regularization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "DL-extensions with Information Regularization have been proposed to discover nonlinear relations from time series, allowing deep learning models to infer directional relations. The method substantially outperforms other methods for learning nonlinear relations in synthetic datasets, and discovers the directional relations in a video game environment and a heart-rate vs. breath-rate dataset #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of identifying directional relations from time series with nonlinear interactions and complex relational structures, the authors propose a novel minimum predictive information regularization method that allows deep learning models to discover nonlinear relations, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To infer directional relations from time series, the authors propose a novel minimum predictive information regularization method that allows deep learning models to discover nonlinear relations, as described in the reference paper \"Discovering Nonlinear Relations With Minimum Predictive Information Regularization\" #REFR.", "given_citation_intent": "method", "given_keywords": ["Minimum Predictive Information", "Regularization"]}]}
{"citing_id": "2304.09444v1", "cited_id": "1701.00879", "section_title": "Iv. Experimental Studies", "citation": "Besides, all the experiments are conducted on evolutionary multi-objective optimization platform PlatEMO 2 #REFR .", "text_before_citation": ["In this section, the performance of the proposed CLMEA is first investigated regarding the efficacy of classifier-assisted rank-based learning pre-screening, HV-based non-dominated search, and local search in sparse object space.", "CLMEA is also compared with five state-of-the-art algorithms (CPS-MOEA #OTHEREFR , K-RVEA #OTHEREFR , CSEA #OTHEREFR , END-ARMOEA #OTHEREFR , and MCEA/D #OTHEREFR ) on DTLZ and ZDT benchmark suites (detailed characteristics of the benchmark problems in Table S-I in the supplementary material).", "The source code of CLMEA is publicly available in MATLAB to help readers reproduce the results #OTHEREFR ."], "text_after_citation": ["In addition, the computational complexity of the algorithms is analyzed and compared.", "Finally, a real-world heat extraction optimization of geothermal reservoir is also employed to further test the performance of the proposed CLMEA."], "citing_paper_content": {"title": "Rank-Based Learning And Local Model Based Evolutionary Algorithm For High-Dimensional Expensive Multi-Objective Problems", "abstract": "Surrogate-assisted evolutionary algorithms have been widely developed to solve complex and computationally expensive multi-objective optimization problems in recent years. However, when dealing with high-dimensional optimization problems, the performance of these surrogate-assisted multiobjective evolutionary algorithms deteriorate drastically. In this work, a novel Classifier-assisted rank-based learning and Local Model based multi-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional expensive multi-objective optimization problems. The proposed algorithm consists of three parts: classifier-assisted rank-based learning, hypervolume-based non-dominated search, and local search in the relatively sparse objective space. Specifically, a probabilistic neural network is built as classifier to divide the offspring into a number of ranks. The offspring in different ranks uses rank-based learning strategy to generate more promising and informative candidates for real function evaluations. Then, radial basis function networks are built as surrogates to approximate the objective functions. After searching non-dominated solutions assisted by the surrogate model, the candidates with higher hypervolume improvement are selected for real evaluations. Subsequently, in order to maintain the diversity of solutions, the most uncertain sample point from the non-dominated solutions measured by the crowding distance is selected as the guided parent to further infill in the uncertain region of the front. The experimental results of benchmark problems and a real-world application on geothermal reservoir heat extraction optimization demonstrate that the proposed algorithm shows superior performance compared with the stateof-the-art surrogate-assisted multi-objective evolutionary algorithms. The source code for this work is available at https://github.com/JellyChen7/CLMEA."}, "cited_paper_content": {"title": "Platemo: A Matlab Platform For Evolutionary Multi-Objective Optimization", "abstract": "Over the last three decades, a large number of evolutionary algorithms have been developed for solving multi-objective optimization problems. However, there lacks an upto-date and comprehensive software platform for researchers to properly benchmark existing algorithms and for practitioners to apply selected algorithms to solve their real-world problems. The demand of such a common tool becomes even more urgent, when the source code of many proposed algorithms has not been made publicly available. To address these issues, we have developed a MATLAB platform for evolutionary multi-objective optimization in this paper, called PlatEMO, which includes more than 50 multiobjective evolutionary algorithms and more than 100 multi-objective test problems, along with several widely used performance indicators. With a user-friendly graphical user interface, PlatEMO enables users to easily compare several evolutionary algorithms at one time and collect statistical results in Excel or LaTeX files. More importantly, PlatEMO is completely open source, such that users are able to develop new algorithms on the basis of it. This paper introduces the main features of PlatEMO and illustrates how to use it for performing comparative experiments, embedding new algorithms, creating new test problems, and developing performance indicators. Source code of PlatEMO is now available at: http://bimk.ahu.edu.cn/index.php?s=/Index/Software/index.html."}, "keywords": ["evolutionary multi-objective optimization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The source code of CLMEA is publicly available in MATLAB to help readers reproduce the results (Chen et al., 2018) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To perform comparative experiments, the proposed CLMEA algorithm was compared with five state-of-the-art algorithms, and the source code of CLMEA is publicly available in MATLAB to help readers reproduce the results #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To properly benchmark the proposed CLMEA algorithm and compare it with state-of-the-art surrogate-assisted multi-objective evolutionary algorithms, the authors used Platemo, a comprehensive MATLAB platform for evolutionary multi-objective optimization #REFR.", "given_citation_intent": "method", "given_keywords": ["evolutionary multi-objective optimization"]}]}
{"citing_id": "2303.10630v1", "cited_id": "1502.03167", "section_title": "I. Introduction", "citation": "Most of the common NN architectures employ Batch Normalization (BN) #REFR , a technique for improving the training of NNs to make them converge faster and to a more stable solution.", "text_before_citation": ["Unfortunately, real-world data is often non-IID, and it is well known that this scenario poses critical issues to FL #OTHEREFR .", "In a non-IID setting, the data statistics of a single client may be unrepresentative of the global statistics and make the model diverge from the intended solution. Interestingly, Huang at al.", "show that if the loss surface of the optimization problem is both smooth and convex (which is hardly true in a real scenario), then FedAvg will also converge when the data is non-IID #OTHEREFR .", "Recent works have proposed several FL algorithms to cope with non-IIDness problems, such as FedProx #OTHEREFR , FedNova #OTHEREFR , SCAFFOLD #OTHEREFR , and FedCurv #OTHEREFR , which has been tested in #OTHEREFR , #OTHEREFR .", "Notice that all these algorithms are modified versions of FedAvg and they preserve the principle underneat FedAvg: to average the weights in all the layers of the NN."], "text_after_citation": ["BN works by standardizing the layers' input for each mini-batch.", "In this work, we investigate two aspects of the training FL models which, differently from cenytralized case, they happen to be hyper-parameters that can be optimized: the normalization layers and the frequency of models aggregation (epochs per round).", "We show that the most popular normalization layer (BN) does not couple well with FL for non-IID data and that substituting BN with alternative normalization FL a better model can be produced for both the non-IID and IID case.", "We also show that building a global model aggregating local models at each epoch is not a good strategy, neither for quality of the model nor for the execution time.", "We experiment with two network architectures and five different normalization layers on two public image datasets: MNIST #OTHEREFR and CIFAR-10 #OTHEREFR ."], "citing_paper_content": {"title": "Experimenting With Normalization Layers In Federated Learning On Non-Iid Scenarios", "abstract": "Training Deep Learning (DL) models require large, high-quality datasets, often assembled with data from different institutions. Federated Learning (FL) has been emerging as a method for privacy-preserving pooling of datasets employing collaborative training from different institutions by iteratively globally aggregating locally trained models. One critical performance challenge of FL is operating on datasets not independently and identically distributed (non-IID) among the federation participants. Even though this fragility cannot be eliminated, it can be debunked by a suitable optimization of two hyperparameters: layer normalization methods and collaboration frequency selection. In this work, we benchmark five different normalization layers for training Neural Networks (NNs), two families of non-IID data skew, and two datasets. Results show that Batch Normalization, widely employed for centralized DL, is not the best choice for FL, whereas Group and Layer Normalization consistently outperform Batch Normalization. Similarly, frequent model aggregation decreases convergence speed and mode quality."}, "cited_paper_content": {"title": "Batch Normalization: Accelerating Deep Network Training By Reducing Internal Covariate Shift", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."}, "keywords": ["Batch Normalization"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Interestingly, Batch Normalization, which is widely employed for centralized DL, is not the best choice for FL, whereas Group and Layer Normalization consistently outperform Batch Normalization in non-IID scenarios #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address internal covariate shift in Federated Learning, normalization layers such as Batch Normalization have been widely employed in centralized Deep Learning, but recent findings suggest that Group and Layer Normalization consistently outperform Batch Normalization in FL #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address internal covariate shift in Federated Learning, several normalization layers have been proposed, including Group and Layer Normalization, which consistently outperform #REFR's Batch Normalization in non-IID scenarios.", "given_citation_intent": "method", "given_keywords": ["Batch Normalization"]}]}
{"citing_id": "2304.12682v1", "cited_id": "1409.0575", "section_title": "C. Architecture Of The Neural Networks", "citation": "With the same number of trainable parameters, EfficientNet neural networks show the highest accuracy compared to other neural network architectures in the ImageNet #REFR classification problem.", "text_before_citation": ["The problem of extracting the watermark w from the image I w can be interpreted as a multilabel image classification problem.", "Thus, if the bit of the watermark w i is equal to 1, it means that image belongs to the class with label i.", "Neural network architectures specialized on classification problems can be used as extraction neural network D w .", "In the implementation of the proposed method, the EfficientNet-B2 #OTHEREFR architecture has been chosen.", "The EfficientNet architecture class was obtained using the NAS (Neural Architecture Search) method."], "text_after_citation": [], "citing_paper_content": {"title": "Docmarking: Real-Time Screen-Cam Robust Document Image Watermarking", "abstract": "This paper focuses on investigation of confidential documents leaks in the form of screen photographs. Proposed approach does not try to prevent leak in the first place but rather aims to determine source of the leak. Method works by applying on the screen a unique identifying watermark as semi-transparent image that is almost imperceptible for human eyes. Watermark image is static and stays on the screen all the time thus watermark present on every captured photograph of the screen. The key components of the approach are three neural networks. The first network generates an image with embedded message in a way that this image is almost invisible when displayed on the screen. The other two neural networks are used to retrieve embedded message with high accuracy. Developed method was comprehensively tested on different screen and cameras. Test results showed high efficiency of the proposed approach. Index Terms-document leakage investigation, screen-cam robust watermarking, blind watermarking I. INTRODUCTION"}, "cited_paper_content": {"title": "Imagenet Large Scale Visual Recognition Challenge", "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements."}, "keywords": ["ImageNet classification problem", "EfficientNet neural networks"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The implementation of the proposed method uses the EfficientNet-B2 #REFR architecture for the extraction neural network D_w, which is specialized on classification problems, and was obtained using the NAS method.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method for screen-cam robust watermarking was comprehensively tested on different screens and cameras, and achieved high efficiency compared to state-of-the-art methods (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed method employs the EfficientNet-B2 #REFR architecture, which is specialized on multilabel ImageNet classification problems, to extract the watermark from the image, achieving high accuracy in the retrieval of the embedded message.", "given_citation_intent": "result", "given_keywords": ["ImageNet classification problem", "EfficientNet neural networks"]}]}
{"citing_id": "2304.03367v1", "cited_id": "1812.11600", "section_title": "Arxiv:2304.03367V1 [Cs.Ro] 6 Apr 2023", "citation": "In #REFR , after candidate constraint sets are constructed, the Lagrange multipliers of the IO problem are used to infer constraints.", "text_before_citation": ["Constraints can also be modeled in the form of control barrier functions.", "The authors in #OTHEREFR , use expert demonstrations to learn control barrier functions that enjoy provable safety guarantees.", "Moreover, the authors in #OTHEREFR infer parameters in the objective function utilized to obtain control policies in constraint environments.", "However, it should be noted that unknown parameters exist only in the objective function and not in the constraints.", "The KKT optimality conditions of an optimization problem can also be used to infer constraint sets."], "text_after_citation": ["The closest work to our framework is #OTHEREFR , in which the authors use the KKT conditions to construct safe and unsafe areas of the state-action space, and hence implicitly the constraints themselves.", "Although this approach can also infer uncertainty in the objective function, we choose to focus solely on the constraint recovery task.", "Inverse Optimization: Inverse optimization, broadly refers to the problem of inferring parameters of an optimization problem by observing the optimal solution #OTHEREFR .", "The majority of the work revolves around estimating parameters in the objective function.", "For linear objective functions and constraints, #OTHEREFR formulate the inverse optimization problem also as a linear problem."], "citing_paper_content": {"title": "Constraint Inference In Control Tasks From Expert Demonstrations Via Inverse Optimization", "abstract": "Inferring unknown constraints is a challenging and crucial problem in many robotics applications. When only expert demonstrations are available, it becomes essential to infer the unknown domain constraints to deploy additional agents effectively. In this work, we propose an approach to infer affine constraints in control tasks after observing expert demonstrations. We formulate the constraint inference problem as an inverse optimization problem, and we propose an alternating optimization scheme that infers the unknown constraints by minimizing a KKT residual objective. We demonstrate the effectiveness of our method in a number of simulations, and show that our method can infer less conservative constraints than a recent baseline method while maintaining comparable safety guarantees."}, "cited_paper_content": {"title": "Constrained Inverse Optimal Control With Application To A Human Manipulation Task", "abstract": "This brief presents an inverse optimal control methodology and its application to training a predictive model of human motor control from a manipulation task. It introduces a convex formulation for learning both objective function and constraints of an infinite-horizon constrained optimal control problem with nonlinear system dynamics. The inverse approach utilizes Bellman's principle of optimality to formulate the infinite-horizon optimal control problem as a shortest path problem and the Lagrange multipliers to identify constraints. We highlight the key benefit of using the shortest path formulation, i.e., the possibility of training the predictive model with short and selected trajectory segments. The method is applied to training a predictive model of movements of a human subject from a manipulation task. The study indicates that individual human movements can be predicted with low error using an infinite-horizon optimal control problem with constraints on the shoulder movement."}, "keywords": ["candidate constraint sets", "constraints"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The KKT optimality conditions of an optimization problem can also be used to infer constraint sets, as demonstrated in the work by the authors in \"Constrained Inverse Optimal Control With Application To A Human Manipulation Task\" #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The KKT optimality conditions can be used to infer constraint sets, as demonstrated in the work by the authors in \"Constrained Inverse Optimal Control With Application To A Human Manipulation Task\" (#OTHEREFR), who proposed a convex formulation for learning both objective function and constraints of an infinite-horizon constrained optimal control problem with nonlinear system dynamics.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The KKT optimality conditions can be used to infer candidate constraint sets, as demonstrated in the work by the authors in \"Constrained Inverse Optimal Control With Application To A Human Manipulation Task\" (#OTHEREFR), who proposed a convex formulation for learning both objective function and constraints of an infinite-horizon constrained optimal control problem with nonlinear system dynamics.", "given_citation_intent": "method", "given_keywords": ["candidate constraint sets", "constraints"]}]}
{"citing_id": "2303.00575v3", "cited_id": "1911.10298", "section_title": "Related Work", "citation": "Similarly, CoverNet #REFR uses CNN to encode the scene context while it proposes dozens of trajectory anchors based on the bicycle model and converts prediction from position regression to anchor classification.", "text_before_citation": ["In this section, we first briefly review the general frameworks of learning-based trajectory prediction and then introduce the literature closely related to our approach. General trajectory prediction architecture.", "Trajectory prediction for moving agents is important for the safe planning of autonomous driving #OTHEREFR .", "One branch of trajectory prediction consists of the approaches #OTHEREFR based on typical neural networks (CNN, GNN #OTHEREFR , RNN #OTHEREFR ). Cui et al.", "#OTHEREFR propose to use agents' states and features extracted by CNN from Bird-Eye-View images to generate a multimodal prediction."], "text_after_citation": ["A hierarchical GNN named VectorNet #OTHEREFR encapsulates the sequential features of map elements and past trajectories with instancewise subgraphs and models interactions with a global graph.", "TNT #OTHEREFR and DenseTNT #OTHEREFR are extensions of #OTHEREFR that focus on predicting reasonable destinations.", "Social LSTM #OTHEREFR models the trajectories of individual agents from separate LSTM networks and aggregates the LSTM hidden cues to model their interactions.", "CL-SGR #OTHEREFR considers the sample replay model in a continuous trajectory prediction scenario setting to avoid catastrophic forgetting.", "The other branch #OTHEREFR models the interaction among the agents based on the attention mechanism."], "citing_paper_content": {"title": "Ipcc-Tp: Utilizing Incremental Pearson Correlation Coefficient For Joint Multi-Agent Trajectory Prediction", "abstract": "Reliable multi-agent trajectory prediction is crucial for the safe planning and control of autonomous systems. Compared with single-agent cases, the major challenge in simultaneously processing multiple agents lies in modeling complex social interactions caused by various driving intentions and road conditions. Previous methods typically leverage graph-based message propagation or attention mechanism to encapsulate such interactions in the format of marginal probabilistic distributions. However, it is inherently sub-optimal. In this paper, we propose IPCC-TP, a novel relevance-aware module based on Incremental Pearson Correlation Coefficient to improve multi-agent interaction modeling. IPCC-TP learns pairwise joint Gaussian Distributions through the tightly-coupled estimation of the means and covariances according to interactive incremental movements. Our module can be conveniently embedded into existing multi-agent prediction methods to extend original motion distribution decoders. Extensive experiments on nuScenes and Argoverse 2 datasets demonstrate that IPCC-TP improves the performance of baselines by a large margin."}, "cited_paper_content": {"title": "Covernet: Multimodal Behavior Prediction Using Trajectory Sets", "abstract": "We present CoverNet, a new method for multimodal, probabilistic trajectory prediction for urban driving. Previous work has employed a variety of methods, including multimodal regression, occupancy maps, and 1-step stochastic policies. We instead frame the trajectory prediction problem as classification over a diverse set of trajectories. The size of this set remains manageable due to the limited number of distinct actions that can be taken over a reasonable prediction horizon. We structure the trajectory set to a) ensure a desired level of coverage of the state space, and b) eliminate physically impossible trajectories. By dynamically generating trajectory sets based on the agent's current state, we can further improve our method's efficiency. We demonstrate our approach on public, real-world self-driving datasets, and show that it outperforms state-of-the-art methods."}, "keywords": ["position regression", "converts prediction"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "One branch of trajectory prediction consists of the approaches based on typical neural networks (CNN, GNN, RNN). Cui et al. propose to use agents' states and features extracted by CNN from Bird-Eye-View images to generate a multimodal prediction #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One branch of trajectory prediction consists of the approaches based on typical neural networks (CNN, GNN, RNN). Cui et al. propose to use agents' states and features extracted by CNN from Bird-Eye-View images to generate a multimodal prediction, while CoverNet method #REFR frames the trajectory prediction problem as classification over a diverse set of trajectories.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Cui et al. proposed to use agents' states and features extracted by CNN from Bird-Eye-View images to generate a multimodal prediction, while CoverNet #REFR frames the trajectory prediction problem as classification over a diverse set of trajectories, which converts prediction into position regression.", "given_citation_intent": "method", "given_keywords": ["position regression", "converts prediction"]}]}
{"citing_id": "2304.01563v1", "cited_id": "1903.05485", "section_title": "Introduction", "citation": "The PoE method #REFR composited representations of entities by concatenating all modality features, which could not capture the potential interactions among heterogeneous modalities and therefore limited the performance of MMEA.", "text_before_citation": ["Recently, there is a growing trend to incorporate multi-modal information into KGs, i.e., Multi-Modal Knowledge Graphs (MMKGs), which support various cross-modal tasks, e.g., recommendation systems #OTHEREFR and question answering systems #OTHEREFR . However, MMKGs often suffer from low coverage and incompleteness.", "To improve the coverage of these MMKGs, a viable approach termed as multi-modal entity alignment (MMEA) is proposed to identify the equivalent entity pairs (i.e., alignment seeds) in different MMKGs, by integrating the attribute information of text and image.", "In this way, MMKGs can obtain useful knowledge from other KG.", "Although the rich attributes and neighboring entities in MMKGs provide valuable pieces of evidence for MMEA #OTHEREFR , the inevitable heterogeneity of MMKGs makes it difficult to learn and fuse knowledge representations from distinct modalities.", "A series of effective methods have been developed to conquer these challenges, and the detailed description is in Appendix A."], "text_after_citation": ["Later works #OTHEREFR designed multi-modal fusion modules to properly integrate attributes and entities, in order to better predict alignments according to aggregated embeddings.", "All of these methods would learn entity representations by harnessing their whole associated attributes and neighboring entities.", "Nevertheless, they ignore the contextual gaps between entity pairs and in turn constrain the effectiveness of the entity alignment.", "The contextual gap, which means entities may associate with different numbers of attributes or even lack some modalities, is inevitable due to information redundancy or absence.", "Such inconsistencies between the equivalent entity pairs make alignments error-prone."], "citing_paper_content": {"title": "Attribute-Consistent Knowledge Graph Representation Learning For Multi-Modal Entity Alignment", "abstract": "The multi-modal entity alignment (MMEA) aims to find all equivalent entity pairs between multi-modal knowledge graphs (MMKGs). Rich attributes and neighboring entities are valuable for the alignment task, but existing works ignore contextual gap problems that the aligned entities have different numbers of attributes on specific modality when learning entity representations. In this paper, we propose a novel attribute-consistent knowledge graph representation learning framework for MMEA (ACK-MMEA) to compensate the contextual gaps through incorporating consistent alignment knowledge. Attribute-consistent KGs (ACKGs) are first constructed via multi-modal attribute uniformization with merge and generate operators so that each entity has one and only one uniform feature in each modality. The ACKGs are then fed into a relation-aware graph neural network with random dropouts, to obtain aggregated relation representations and robust entity representations. In order to evaluate the ACK-MMEA facilitated for entity alignment, we specially design a joint alignment loss for both entity and attribute evaluation. Extensive experiments conducted on two benchmark datasets show that our approach achieves excellent performance compared to its competitors."}, "cited_paper_content": {"title": "Mmkg: Multi-Modal Knowledge Graphs", "abstract": "We present Mmkg, a collection of three knowledge graphs that contain both numerical features and (links to) images for all entities as well as entity alignments between pairs of KGs. Therefore, multi-relational link prediction and entity matching communities can benefit from this resource. We believe this data set has the potential to facilitate the development of novel multi-modal learning approaches for knowledge graphs. We validate the utility of Mmkg in the \\(\\mathtt {sameAs}\\) link prediction task with an extensive set of experiments. These experiments show that the task at hand benefits from learning of multiple feature types."}, "keywords": ["entities", "modality features"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the coverage of Multi-Modal Knowledge Graphs (MMKGs), multi-modal entity alignment (MMEA) has been proposed to identify equivalent entity pairs in different MMKGs by integrating attribute information of text and image #OTHEREFR. The authors of this paper present Mmkg, a collection of three knowledge graphs that contain both numerical features and (links to) images for all entities as well as entity alignments between pairs of KGs, which has the potential to facilitate the development of novel multi-modal learning approaches for knowledge graphs #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the heterogeneity of Multi-Modal Knowledge Graphs (MMKGs), the authors propose a novel attribute-consistent knowledge graph representation learning framework for multi-modal entity alignment (MMEA) that compensates for contextual gaps through incorporating consistent alignment knowledge, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the contextual gaps in multi-modal entity alignment, the authors propose a novel attribute-consistent knowledge graph representation learning framework (ACK-MMEA) that constructs attribute-consistent KGs with uniform modality features for each entity, and then feeds them into a relation-aware graph neural network to obtain robust entity representations #REFR.", "given_citation_intent": "method", "given_keywords": ["entities", "modality features"]}]}
{"citing_id": "2303.01486v1", "cited_id": "1703.04933", "section_title": "Preliminaries", "citation": "The maximal eigenvalue, \u03bb 1 , can be interpreted as measuring the sharpness of the loss landscape #REFR , and the condition number \u03bb 1 /\u03bb d has significant implications for convergence of gradient descent optimization in deep neural networks (Gilmer et al., 2022) .", "text_before_citation": ["The Hessian of a network f at parameters \u03b8 with respect to some loss (\u03b8) is a matrix defined as", "EQUATION", "where d = |\u03b8| is the number of parameters.", "Of particular relevance to optimization is the eigenspectrum of the Hessian", "\u039b(H (\u03b8)) = (\u03bb 1 \u2265 \u2022 \u2022 \u2022 \u2265 \u03bb d )."], "text_after_citation": ["We will also take interest in the covariance structure of the gradients of different data points in the input distribution, a property relevant to both optimization and generalization #OTHEREFR .", "We will estimate this covariance structure by sampling k training points x 1 , . . .", ", x k , and computing the matrix C k \u2208 R k\u00d7k defined entrywise as", "EQUATION", "If the off-diagonal entries of C k contain many negative values, this indicates interference between inputs, wherein the network cannot reduce its loss on one region without increasing its loss on another."], "citing_paper_content": {"title": "Understanding Plasticity In Neural Networks", "abstract": "Plasticity, the ability of a neural network to quickly change its predictions in response to new information, is essential for the adaptability and robustness of deep reinforcement learning systems. Deep neural networks are known to lose plasticity over the course of training even in relatively simple learning problems, but the mechanisms driving this phenomenon are still poorly understood. This paper conducts a systematic empirical analysis into plasticity loss, with the goal of understanding the phenomenon mechanistically in order to guide the future development of targeted solutions. We find that loss of plasticity is deeply connected to changes in the curvature of the loss landscape, but that it typically occurs in the absence of saturated units or divergent gradient norms. Based on this insight, we identify a number of parameterization and optimization design choices which enable networks to better preserve plasticity over the course of training. We validate the utility of these findings in larger-scale learning problems by applying the best-performing intervention, layer normalization, to a deep RL agent trained on the Arcade Learning Environment."}, "cited_paper_content": {"title": "Sharp Minima Can Generalize For Deep Nets", "abstract": "Despite their overwhelming capacity to overfit, deep learning architectures tend to generalize relatively well to unseen data, allowing them to be deployed in practice. However, explaining why this is the case is still an open area of research. One standing hypothesis that is gaining popularity, e.g. Hochreiter & Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization. This paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization. Specifically, when focusing on deep networks with rectifier units, we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima. Furthermore, if we allow to reparametrize a function, the geometry of its parameters can change drastically without affecting its generalization properties."}, "keywords": ["loss landscape", "deep neural networks"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The flatness of minima of the loss function found by stochastic gradient based methods has been hypothesized to result in good generalization, as argued by Hochreiter & Schmidhuber (1997) and Keskar et al. (2017). However, recent work by #REFR suggests that most notions of flatness are problematic for deep models and cannot be directly applied to explain generalization.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One hypothesis gaining popularity is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization, as argued in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One hypothesis for the good generalization of deep learning architectures despite their tendency to overfit is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization, but recent research has shown that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization, especially for deep neural networks with rectifier units, where the geometry of parameter space can be exploited to build equivalent models corresponding to arbitrarily sharper minima in the #REFR loss landscape.", "given_citation_intent": "background", "given_keywords": ["loss landscape", "deep neural networks"]}]}
{"citing_id": "2303.16753v1", "cited_id": "1905.06316", "section_title": "Detailed Analysis", "citation": "To investigate the linguistic patterns captured by MPOBERT, BERT, and ALBERT, we conduct a suite of probing tasks, following the methodology of #REFR .", "text_before_citation": ["The results demonstrate that a rank of 8 is sufficient for MPOBERT, which further shows the necessity of layer-specific adapters.", "However, we also observe a decrease in the performance of the variant with adapter rank 64.", "This illustrates that further increasing the rank may increase the risk of over-fitting in fine-tuning process.", "Therefore, we set a rank of 8 for MPOBERT in the main results.", "Analysis of Linguistic Patterns."], "text_after_citation": ["These tasks are designed to evaluate the encoding of surface, syntactic, and semantic information in the models' representations. The results, shown in Fig.", "4 , reveal that BERT encodes more local syntax in lower layers and more complex semantics in higher layers, while ALBERT does not exhibit such a clear trend.", "However, MPOBERT exhibits similar layer-wise behavior to BERT in some tasks (i.e., task 0,2,4), and improved results in lower layers for others (i.e., task 3) which is similar to ALBERT.", "The result demonstrates that MPOBERT captures linguistic information differently than other models, and its layer-wise parameters play an important role in this difference."], "citing_paper_content": {"title": "Scaling Pre-Trained Language Models To Deeper Via Parameter-Efficient Architecture", "abstract": "In this paper, we propose a highly parameterefficient approach to scaling pre-trained language models (PLMs) to a deeper model depth. Unlike prior work that shares all parameters or uses extra blocks, we design a more capable parameter-sharing architecture based on matrix product operator (MPO). MPO decomposition can reorganize and factorize the information of a parameter matrix into two parts: the major part that contains the major information (central tensor) and the supplementary part that only has a small proportion of parameters (auxiliary tensors). Based on such a decomposition, our architecture shares the central tensor across all layers for reducing the model size and meanwhile keeps layerspecific auxiliary tensors (also using adapters) for enhancing the adaptation flexibility. To improve the model training, we further propose a stable initialization algorithm tailored for the MPO-based architecture. Extensive experiments have demonstrated the effectiveness of our proposed model in reducing the model size and achieving highly competitive performance."}, "cited_paper_content": {"title": "What Do You Learn From Context? Probing For Sentence Structure In Contextualized Word Representations", "abstract": "Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline."}, "keywords": ["linguistic patterns"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The results demonstrate that a rank of 8 is sufficient for MPOBERT, which further shows the necessity of layer-specific adapters. However, we also observe a decrease in the performance of the variant with adapter rank 64. This illustrates that further increasing the rank may increase the risk of over-fitting in fine-tuning process. Therefore, we set a rank of 8 for MPOBERT in the main results. Analysis of Linguistic Patterns suggests that contextualized representation models such as ELMo and BERT encode sentence structure well, but only offer small improvements on semantic tasks over a non-contextual baseline #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To reduce the model size and enhance adaptation flexibility, the authors proposed a parameter-sharing architecture based on matrix product operator (MPO) that shares the central tensor across all layers and keeps layer-specific auxiliary tensors, as demonstrated in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To analyze the model's performance on #KEYWORD1, we refer to the edge probing task design introduced in \"What Do You Learn From Context? Probing For Sentence Structure In Contextualized Word Representations\" (#REFR).", "given_citation_intent": "method", "given_keywords": ["linguistic patterns"]}]}
{"citing_id": "2304.02693v1", "cited_id": "1706.06083", "section_title": "Experimental Setup", "citation": "They found that the PGD attack #REFR performed the best among the compared attacks (We also have the same conclusion in Table 3 ).", "text_before_citation": ["By default, we use PSPNet, HRNet, and PSANet to evaluate Pascal VOC, Cityscapes, and ADE20K, respectively.", "Table 2 shows the clean pixel accuracy and MIoU (See the end of Section 5.1) of the three models on the three datasets. Compared baselines. We implement our attacks in Py-Torch.", "All models are run on a Linux server with 96 core 3.0GHz CPU, 768GB RAM, and 8 Nvidia A100 GPUs.", "The source code of our attacks is publicly available at 8 . #OTHEREFR . https://github.com/hszhao/semseg 7. https://github.com/HRNet/HRNet-Semantic-Segmentation 8. https://github.com/randomizedheap/CR Attack \u2022 White-box attack algorithms.", "#OTHEREFR performed a systematic study to understand the robustness of modern segmentation models against adversarial perturbations."], "text_after_citation": ["Thus, in this paper, we mainly use PGD as the base attack and compare it with our CR-PGD attack.", "We note that our certified radius can be incorporated into all the existing white-box attacks and we show additional results in Section 6.", "Details of the existing attack methods are shown in Appendix A.3.", "\u2022 Black-box attack algorithms.", "We mainly evaluate our projected bandit gradient descent (PBGD) attack and certified radius-guided PBGD (CR-PBGD) attack. Parameter settings."], "citing_paper_content": {"title": "A Certified Radius-Guided Attack Framework To Image Segmentation Models", "abstract": "Image segmentation is an important problem in many safety-critical applications such as medical imaging and autonomous driving. Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models. We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models. Our goal is to thoroughly explore the vulnerabilities of modern segmentation models, i.e., aiming to misclassify as many pixels as possible under a perturbation budget in both white-box and black-box settings. Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models. We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models. Specifically, we first adapt randomized smoothing, the state-of-theart certification method for classification models, to derive the pixel's certified radius. A larger certified radius of a pixel means the pixel is theoretically more robust to adversarial perturbations. This observation inspires us to focus more on disrupting pixels with relatively smaller certified radii. Accordingly, we design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack. Next, we propose the first black-box attack to image segmentation models via bandit. A key challenge is no gradient information is available. To address it, we design a novel gradient estimator, based on bandit feedback, which is queryefficient and provably unbiased and stable. We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack. We further use pixels' certified radii and design a certified radius-guided PBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate. We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets. Our results validate the effectiveness of our certified radius-guided attack framework."}, "cited_paper_content": {"title": "Towards Deep Learning Models Resistant To Adversarial Attacks", "abstract": "Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models."}, "keywords": ["PGD attack"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To improve the robustness of modern segmentation models against adversarial perturbations, #OTHEREFR proposed a certified radius-guided attack framework that leverages the properties of certified radius and provides a concrete security guarantee that protects against any adversary.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "#OTHEREFR demonstrated the vulnerability of neural networks to adversarial examples, and proposed a robust optimization approach to improve the networks' resistance to such attacks, which could be a potential solution to the vulnerability issue in image segmentation models. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "#OTHEREFR proposed a certified radius-guided white-box attack algorithm, which is used in our study to evaluate the robustness of modern segmentation models against adversarial perturbations.", "given_citation_intent": "result", "given_keywords": ["PGD attack"]}]}
{"citing_id": "2304.06052v2", "cited_id": "1506.02640", "section_title": "Related Works", "citation": "This is not applicable as is to state-of-the-art one-stage object detectors such as YOLO #REFR or DETR (Carion et al., 2020) .", "text_before_citation": ["for the softmax), following the principles introduced by #OTHEREFR .", "They control the coordinates of the boxes but also the proposal and objectness scores, resulting in more and larger boxes.", "Their method relies on the structure of Fast R- CNN (Ren et al., 2017) , the underlying OD model: this has three detection steps with three predictors associated with the proposal, presence and location of a bounding box.", "Each component is controlled individually and then combined to attain the desired guarantee.", "Their method is an application of the PAC-based calibration of #OTHEREFR ."], "text_after_citation": ["This is one of the reasons why we opt to model our uncertainty quantification problem directly via CP.", "Also, CP requires exchangeable data while concentration-based methods such as #OTHEREFR", "(2020) and the more general methods of and Angelopoulos et al.", "(2021)require the stronger assumption of data being independently and identically distributed (i.i.d)."], "citing_paper_content": {"title": "Confident Object Detection Via Conformal Prediction And Conformal Risk Control: An Application To Railway Signaling", "abstract": "Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds."}, "cited_paper_content": {"title": "You Only Look Once: Unified, Real-Time Object Detection", "abstract": "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. ::: Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset."}, "keywords": ["YOLO"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Their method is an application of the PAC-based calibration of #REFR, which controls the coordinates of the boxes but also the proposal and objectness scores, resulting in more and larger boxes.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The approach presented in this manuscript differs from prior work on object detection, which repurposes classifiers for detection, by framing object detection as a regression problem to spatially separated bounding boxes and associated class probabilities, as proposed in #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The underlying OD model used in this work is Fast R-CNN, which has three detection steps with three predictors associated with the proposal, presence, and location of a bounding box, and is controlled individually and then combined to attain the desired guarantee, as proposed by Ren et al. (2017). This method is an application of the PAC-based calibration of YOLO, which controls the coordinates of the boxes but also the proposal and objectness scores, resulting in more and larger boxes. #REFR", "given_citation_intent": "background", "given_keywords": ["YOLO"]}]}
{"citing_id": "2304.10915v1", "cited_id": "1406.6259", "section_title": "Teamltl With The Boolean Disjunction", "citation": "This result is similar to the one proved in #REFR for team-based modal logic ML( ). Proof.", "text_before_citation": ["Definition 9.", "A formula \u03d5 is in -disjunctive normal form if it is of the form i\u2208I \u03b1 i , where \u03b1 i are LTL-formulae.", "We will next show that every formula of TeamLTL l ( ) can be transformed into equivalent -disjunctive normal form."], "text_after_citation": ["The proof proceeds by induction on the structure of formulae.", "Note that atomic formulae are already in the normal form and that the case for is trivial. The remaining cases are defined as follows:", "(\u03c8 \u2227 \u03b8) * := i\u2208I,j\u2208J (\u03b1 \u03c8 i \u2227 \u03b1 \u03b8 j ) (\u03c8 \u2228 \u03b8) * := i\u2208I,j\u2208J (\u03b1 \u03c8 i \u2228 \u03b1 \u03b8 j ) ( \u03c8) * := i\u2208I \u03b1 \u03c8 i (G \u03c8) * := i\u2208I G \u03b1 \u03c8 i (\u03c8 U \u03b8) * := i\u2208I,j\u2208J (\u03b1 \u03c8 i U \u03b1 \u03b8 j ).", "where \u03b1 \u03c8 i and \u03b1 \u03b8 j are the flat formulae in the disjunctive normal forms of \u03c8 and \u03b8 respectively, and I and J are the respective index sets.", "Suppose \u03d5 = \u03c8 \u2227 \u03b8 and that \u03c8 \u2261 i\u2208I \u03b1 \u03c8 i and \u03b8 \u2261 i\u2208J \u03b1 \u03b8 j (induction hypothesis)."], "citing_paper_content": {"title": "Set Semantics For Asynchronous Teamltl: Expressivity And Complexity", "abstract": "We introduce and develop a set-based semantics for asynchronous TeamLTL. We consider two canonical logics in this setting: the extensions of TeamLTL by the Boolean disjunction and by the Boolean negation. We establish fascinating connections between the original semantics based on multisets and the new set-based semantics as well as show one of the first positive complexity theoretic results in the temporal team semantics setting. In particular we show that both logics enjoy normal forms that can be utilised to obtain results related to expressivity and complexity (decidability) of the new logics. We also relate and apply our results to recently defined logics whose asynchronicity is formalized via time evaluation functions."}, "cited_paper_content": {"title": "Complexity Of Validity For Propositional Dependence Logics", "abstract": "We study the validity problem for propositional dependence logic, modal dependence logic and extended modal dependence logic. We show that the validity problem for propositional dependence logic is NEXPTIME-complete. In addition, we establish that the corresponding problem for modal dependence logic and extended modal dependence logic is NEXPTIME-hard and in NEXPTIME^NP."}, "keywords": ["team-based modal logic"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We will next show that every formula of TeamLTL l ( ) can be transformed into equivalent -disjunctive normal form, following the complexity results for propositional dependence logic, modal dependence logic, and extended modal dependence logic presented in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors showed that the validity problem for propositional dependence logic is NEXPTIME-complete, which is relevant to our study on the complexity of asynchronous TeamLTL semantics. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The complexity of validity for propositional dependence logic, modal dependence logic, and extended modal dependence logic has been extensively studied in the literature, and our results can be compared to those in this area. #REFR", "given_citation_intent": "result", "given_keywords": ["team-based modal logic"]}]}
{"citing_id": "2304.07453v1", "cited_id": "1905.10756", "section_title": "B.3 Partial Domain Adaptation", "citation": "Reinforced Transfer network #REFR eliminates outlier samples in source classes through a reinforced data selector by considering both high-level and pixel-level information.", "text_before_citation": ["To select the instance via class-level weighting, Selective Adversarial Network #OTHEREFR introduces multiple source discriminators to weigh the source samples according to the class probabilities predicted by the discriminators.", "To generate the weighting strategy by instance-level, Importance Weighted Adversarial Nets #OTHEREFR derives the probability of a source example belonging to the target domain and weighs the source examples based on the probability for the domainadversarial network.", "Example Transfer Network #OTHEREFR weighs the source samples according to the similarities measured by a domain discriminator and down-weights irrelevant source samples when updating the parameters of the source classifier.", "As the key technique toward partial domain adaptation relies on iterative instance selection, recent advancements formulate the instance selection problem into a Markov decision process and adopt deep reinforcement learning algorithms to go through individual instances for partial domain adaptation.", "Domain Adversarial Reinforcement Learning #OTHEREFR iteratively selects instances from a candidate set to a finalized set for performing domain adaptation with a tailored reward function based on the domain adversarial learning framework."], "text_after_citation": ["However, instance-wise selective transfer methods are not applicable to time series data since there exist temporal dependencies between instances and arbitrary selection of partial instances may fail to consider the dependencies during domain adaptation.", "As a result, we propose a contextual domain adaptation framework that focuses on context sampling for individual instances in time series data."], "citing_paper_content": {"title": "Context-Aware Domain Adaptation For Time Series Anomaly Detection", "abstract": "Time series anomaly detection is a challenging task with a wide range of real-world applications. Due to label sparsity, training a deep anomaly detector often relies on unsupervised approaches. Recent efforts have been devoted to time series domain adaptation to leverage knowledge from similar domains. However, existing solutions may suffer from negative knowledge transfer on anomalies due to their diversity and sparsity. Motivated by the empirical study of context alignment between two domains, we aim to transfer knowledge between two domains via adaptively sampling context information for two domains. This is challenging because it requires simultaneously modeling the complex in-domain temporal dependencies and cross-domain correlations while exploiting label information from the source domain. To this end, we propose a framework that combines context sampling and anomaly detection into a joint learning procedure. We formulate context sampling into the Markov decision process and exploit deep reinforcement learning to optimize the time series domain adaptation process via context sampling and design a tailored reward function to generate domain-invariant features that better align two domains for anomaly detection. Experiments on three public datasets show promise for knowledge transfer between two similar domains and two entirely different domains."}, "cited_paper_content": {"title": "Selective Transfer With Reinforced Transfer Network For Partial Domain Adaptation", "abstract": "Partial domain adaptation (PDA) extends standard domain adaptation to a more realistic scenario where the target domain only has a subset of classes from the source domain. The key challenge of PDA is how to select the relevant samples in the shared classes for knowledge transfer. Previous PDA methods tackle this problem by re-weighting the source samples based on the prediction of classifier or discriminator, thus discarding the pixel-level information. In this paper, to utilize both high-level and pixel-level information, we propose a reinforced transfer network (RTNet), which is the first work to apply reinforcement learning to address the PDA problem. The RTNet simultaneously mitigates the negative transfer by adopting a reinforced data selector to filter out outlier source classes, and promotes the positive transfer by employing a domain adaptation model to minimize the distribution discrepancy in the shared label space. Extensive experiments indicate that RTNet can achieve state-of-the-art performance for partial domain adaptation tasks on several benchmark datasets. Codes and datasets will be available online."}, "keywords": ["reinforced data selector", "Reinforced Transfer network"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As the key technique toward partial domain adaptation relies on iterative instance selection, recent advancements formulate the instance selection problem into a Markov decision process and adopt deep reinforcement learning algorithms to go through individual instances for partial domain adaptation. The proposed reinforced transfer network (RTNet) in #REFR simultaneously mitigates the negative transfer by adopting a reinforced data selector to filter out outlier source classes and promotes the positive transfer by employing a domain adaptation model to minimize the distribution discrepancy in the shared label space, achieving state-of-the-art performance for partial domain adaptation tasks on several benchmark datasets.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of selecting relevant samples in partial domain adaptation, the authors propose a reinforced transfer network (RTNet) that utilizes both high-level and pixel-level information and applies reinforcement learning, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of selecting relevant samples in partial domain adaptation, recent advancements have proposed to formulate the instance selection problem into a Markov decision process and adopt deep reinforcement learning algorithms, such as the Reinforced Transfer network #REFR, which employs a reinforced data selector to filter out outlier source classes and minimize the distribution discrepancy in the shared label space.", "given_citation_intent": "method", "given_keywords": ["reinforced data selector", "Reinforced Transfer network"]}]}
{"citing_id": "2303.11230v1", "cited_id": "1812.08434", "section_title": "Discussion", "citation": "For example, graph learning methods such as GNN #REFR take networks as input, and our method can help to handle the semi-supervised prediction setting when the training data are only partially observed.", "text_before_citation": ["One limitation of our theory is the strict low-rank assumption; theoretical properties for approximately low-rank models are thus far unknown.", "A more general theory in these scenarios would largely expand the method's scope.", "As another example, if a sequence of evolving networks is observed (subject to egocentric missingness), a critical but open question concerns how to fit a dynamic network model compatible with this missingness.", "We will leave this and other investigations for future work.", "There are several applications in which we can potentially embed the current method."], "text_after_citation": ["Another application is to use our theory to study the privacy-preserving algorithms for network data #OTHEREFR .", "Assumption A3 (Low-rank recoverable).", "The rank of the model satisifes rank(P 11 ) = rank(P) = K.", "Assumption A4 (Well-conditioned model). There exists a constant \u03c8 > 0 such that", "1 \u03c8 \u2022 np * \u2264 \u03c3 K (P 11 ) \u2264 \u03c3 1 (P 11 ) \u2264 \u03c8 \u2022 np * 1 \u03c8 \u2022 N p * \u2264 \u03c3 K (P) \u2264 \u03c3 1 (P) \u2264 \u03c8 \u2022 N p *"], "citing_paper_content": {"title": "Fitting Low-Rank Models On Egocentrically Sampled Partial Networks", "abstract": "The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of \"uniformly missing at random\", egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks. To our knowledge, this method offers the first theoretical guarantee for egocentric partial network estimation in the scope of low-rank models. We evaluate the technique on several synthetic and real-world networks and show that it delivers competitive performance in link prediction tasks. 1 INTRODUCTION Massive network data that capture complicated dynamics and interactions in human society, the economy, ecosystems, and biology are now available (Goldenberg et al., 2010; Newman, 2018). The past 15 years have witnessed substantial progress in random network models within the statistics field. Associated efforts have provided countless model options to analyze network data with well-established theories ("}, "cited_paper_content": {"title": "Graph Neural Networks: A Review Of Methods And Applications", "abstract": "Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research."}, "keywords": ["graph learning methods"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Graph neural networks (GNNs) have been successfully applied to many tasks mentioned in this manuscript, such as predicting protein interface and classifying diseases, and have demonstrated ground-breaking performance #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To fit general low-rank models for egocentrically sampled networks, the authors proposed an approach based on graph spectral properties, which resulted in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of egocentrically sampled partial networks, a recent approach proposes to fit general low-rank models based on graph spectral properties, which include several popular #REFR graph learning methods, and results in consistent recovery of missing subnetworks for sparse networks (Li et al., 2021).", "given_citation_intent": "method", "given_keywords": ["graph learning methods"]}]}
{"citing_id": "2304.13886v1", "cited_id": "1504.03440", "section_title": "Introduction", "citation": "Such x 1 i are called called a transition equilibrium vector (TEV) (Note in Figure 1 , x #REFR 1 , x 1 2 are TEVs, but x 1 3 is not).", "text_before_citation": ["Morse theory gives the answer to the question of when the topology of #|X a | changes as a varies: (Here #|A| denotes the number of connected components of a set A.) See #OTHEREFR , #OTHEREFR , #OTHEREFR for more details.)", "\u2022 #|X a | increases by one, i.e.", "#|X a+\u03b5 | = #|X a\u2212\u03b5 | + 1 for a sufficiently small \u03b5 > 0, if and only if, a \u2208 {f (", "EQUATION", "where H q (\u2022) is the q-th homology space and \u223c = implies homotopy equivalent."], "text_after_citation": ["\u2022 #|X a | remains constant, i.e., #|X a+\u03b5 | = #|X a\u2212\u03b5 | for a sufficiently small \u03b5 > 0, if and only if, a passes the value f (x k ) of an index-k equilibrium vector x k with k > 1."], "citing_paper_content": {"title": "Improving The Utility Of Differentially Private Clustering Through Dynamical Processing", "abstract": "This study aims to alleviate the trade-off between utility and privacy in the task of differentially private clustering. Existing works focus on simple clustering methods, which show poor clustering performance for non-convex clusters. By utilizing Morse theory, we hierarchically connect the Gaussian sub-clusters to fit complex cluster distributions. Because differentially private sub-clusters are obtained through the existing methods, the proposed method causes little or no additional privacy loss. We provide a theoretical background that implies that the proposed method is inductive and can achieve any desired number of clusters. Experiments on various datasets show that our framework achieves better clustering performance at the same privacy level, compared to the existing methods."}, "cited_paper_content": {"title": "Engineering Methods For Differentially Private Histograms: Efficiency Beyond Utility", "abstract": "Publishing histograms with $\\epsilon$-differential privacy has been studied extensively in the literature. Existing schemes aim at maximizing the utility of the published data, while previous experimental evaluations analyze the privacy/utility trade-off. In this paper we provide the first experimental evaluation of differentially private methods that goes beyond utility, emphasizing also on another important aspect, namely efficiency. Towards this end, we first observe that all existing schemes are comprised of a small set of common blocks. We then optimize and choose the best implementation for each block, determine the combinations of blocks that capture the entire literature, and propose novel block combinations. We qualitatively assess the quality of the schemes based on the skyline of efficiency and utility, i.e., based on whether a method is dominated on both aspects or not. Using exhaustive experiments on four real datasets with different characteristics, we conclude that there are always trade-offs in terms of utility and efficiency. We demonstrate that the schemes derived from our novel block combinations provide the best trade-offs for time critical applications. Our work can serve as a guide to help practitioners engineer a differentially private histogram scheme depending on their application requirements."}, "keywords": ["Figure"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Existing schemes for publishing histograms with differential privacy aim at maximizing utility, while previous experimental evaluations analyze the privacy/utility trade-off. In their work, the authors of #REFR provide the first experimental evaluation of differentially private methods that goes beyond utility, emphasizing also on efficiency.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Existing schemes for publishing histograms with differential privacy aim at maximizing utility, but this paper provides the first experimental evaluation of differentially private methods that goes beyond utility, emphasizing also on efficiency, which can serve as a guide to help practitioners engineer a differentially private histogram scheme depending on their application requirements (#REFR).", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Existing schemes for publishing histograms with differential privacy have been extensively studied in the literature, and the proposed novel block combinations in #REFR can serve as a guide to help practitioners engineer a differentially private histogram scheme depending on their application requirements.", "given_citation_intent": "background", "given_keywords": ["Figure"]}]}
{"citing_id": "2303.01339v1", "cited_id": "1709.05132", "section_title": "5.2.", "citation": "It is very similar in spirit to the analysis performed in #REFR , where analogous bounds were obtained directly for the change of centrality scores instead of for their sensitivity.", "text_before_citation": ["(5.10) |[L exp (A G , E ij )] uv | \u2264 8 e \u03bbmax \u2022 m(u, v) \u03bb max \u2212 \u03bb min e \u2022 (\u03bb max \u2212 \u03bb min ) 4m(u, v) + 2(\u03bb max \u2212 \u03bb min ) m(u,v) .", "Remark 5.7.", "The result of Corollary 5.6 can be used to obtain a priori estimates for the sensitivity of individual nodes with respect to modifications in an edge (i, j).", "In particular, for the sensitivity of subgraph centrality, an estimate is directly obtained by setting v = u in (5.9) or (5.10).", "This mathematically confirms the intuition that nodes are more sensitive to the modification of \"nearby\" edges than to modifications of edges in other parts of the network."], "text_after_citation": ["Remark 5.8.", "If the extremal eigenvalues \u03bb min , \u03bb max of A G are not known, one can still obtain decay estimates by inserting suitable bounds.", "As a simple example, by Ger\u0161gorin's disk theorem we have for any adjacency matrix of an undirected graph that spec(A G ) \u2282 [\u2212 deg max , deg max ], where deg max denotes the maximum degree of any node in G.", "Thus \u03bb max \u2212 \u03bb min \u2264 2 deg max , and for graphs where all nodes have similar degrees (which is, e.g., the case for grid-like graphs and many road networks), the decay estimates obtained from using this bound might still carry meaningful information.", "In graphs with highly varying degrees, the estimates obtained this way will typically not accurately capture the actual decay behavior."], "citing_paper_content": {"title": "Sensitivity Of Matrix Function Based Network Communicability Measures: Computational Methods And A Priori Bounds", "abstract": "When analyzing complex networks, an important task is the identification of those nodes which play a leading role for the overall communicability of the network. In the context of modifying networks (or making them robust against targeted attacks or outages), it is also relevant to know how sensitive the network's communicability reacts to changes in certain nodes or edges. Recently, the concept of total network sensitivity was introduced in [O."}, "cited_paper_content": {"title": "On The Stability Of Network Indices Defined By Means Of Matrix Functions", "abstract": "Identifying important components in a network is one of the major goals of network analysis. Popular and effective measures of importance of a node or a set of nodes are defined in terms of suitable entries of functions of matrices $f(A)$. These kinds of measures are particularly relevant as they are able to capture the global structure of connections involving a node. However, computing the entries of $f(A)$ requires a significant computational effort. In this work we address the problem of estimating the changes in the entries of $f(A)$ with respect to changes in the edge structure. Intuition suggests that, if the topology of connections in the new graph $\\tilde G$ is not significantly distorted, relevant components in $G$ maintain their leading role in $\\tilde G$. We propose several bounds giving mathematical reasoning to such intuition and showing, in particular, that the magnitude of the variation of the entry $f(A)_{k\\ell}$ decays exponentially with the shortest-path distance in $G$ that separates either $k$ or $\\ell$ from the set of nodes touched by the edges that are perturbed. Moreover, we propose a simple method that exploits the computation of $f(A)$ to simultaneously compute the all-pairs shortest-path distances of $G$, with essentially no additional cost. As the nodes whose edge connection tends to change more often or tends to be more often affected by noise have marginal role in the graph and are distant from the most central nodes, the proposed bounds are particularly relevant."}, "keywords": ["centrality scores"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed bounds for estimating changes in the entries of matrix functions of a network, as well as the method for computing all-pairs shortest-path distances, presented in #REFR, can be used to obtain a priori estimates for the sensitivity of individual nodes with respect to modifications in an edge, confirming the intuition that nodes are more sensitive to the modification of nearby edges than to modifications of edges in other parts of the network (Remark 5.7).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' intuition that relevant components in a graph maintain their leading role in a new graph with a similar topology is mathematically confirmed in #REFR, where they propose bounds that show the variation of the entry $f(A)_{k\\ell}$ decays exponentially with the shortest-path distance in the original graph that separates either $k$ or $\\ell$ from the set of nodes touched by the edges that are perturbed.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors of this manuscript provide a priori estimates for the sensitivity of individual nodes with respect to modifications in an edge, which mathematically confirms the intuition that nodes are more sensitive to the modification of \"nearby\" edges than to modifications of edges in other parts of the network. These estimates are obtained by setting v = u in (5.9) or (5.10) and can be used for the sensitivity of subgraph #REFR centrality scores.", "given_citation_intent": "result", "given_keywords": ["centrality scores"]}]}
{"citing_id": "2304.12522v1", "cited_id": "1705.02356", "section_title": "Numerical Experiments", "citation": "In their code, the authors #REFR implemented a two-stage trick that uses a relatively larger tolerance in early iterations and a smaller tolerance in later iterations to terminate the POGS.", "text_before_citation": ["In this section, we conduct numerical experiments to compare our IPL method with existing methods for solving the RPR problem #OTHEREFR . The algorithms that we test include the following ones.", "(i) PL: The original proximal linear algorithm proposed by #OTHEREFR where the subproblem (5) is solved by POGS #OTHEREFR .", "POGS terminates when both the primal residual and the dual residual are small enough."], "text_after_citation": ["In our comparison, we use all the default parameters set by the authors in their codes 2 .", "(ii) Subgradient Method.", "The subgradient method with geometrically decaying step sizes was proposed by #OTHEREFR , and they used this algorithm to solve the RPR (4). One typical iteration of this algorithm is", "EQUATION", "in which \u03bb 0 > 0, q \u2208 (0, 1) are hyper-parameters and"], "citing_paper_content": {"title": "A New Inexact Proximal Linear Algorithm With Adaptive Stopping Criteria For Robust Phase Retrieval", "abstract": "This paper considers the robust phase retrieval problem, which can be cast as a nonsmooth and nonconvex optimization problem. We propose a new inexact proximal linear algorithm with the subproblem being solved inexactly. Our contributions are two adaptive stopping criteria for the subproblem. The convergence behavior of the proposed methods is analyzed. Through experiments on both synthetic and real datasets, we demonstrate that our methods are much more efficient than existing methods, such as the original proximal linear algorithm and the subgradient method."}, "cited_paper_content": {"title": "Solving (Most) Of A Set Of Quadratic Equalities: Composite Optimization For Robust Phase Retrieval", "abstract": "We develop procedures, based on minimization of the composition $f(x) = h(c(x))$ of a convex function $h$ and smooth function $c$, for solving random collections of quadratic equalities, applying our methodology to real-valued phase retrieval problems. We show that the prox-linear algorithm we develop can solve (robust) phase retrieval problems (even with adversarially faulty measurements) with high probability under appropriate random measurement models as soon as the number of measurements $m$ is a constant factor larger than the dimension $n$ of the signal to be recovered. The algorithm requires essentially no tuning---it requires solution of a sequence of convex problems---and it is implementable without any particular assumptions on the measurements taken. We provide substantial experiments investigating our methods, indicating the practical effectiveness of the procedures and showing that they succeed with high probability as soon as $m / n \\ge 2$."}, "keywords": ["later iterations", "two-stage trick"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We compare our IPL method with existing methods for solving the RPR problem, including the original proximal linear algorithm proposed by #OTHEREFR where the subproblem is solved by POGS. POGS terminates when both the primal residual and the dual residual are small enough. However, our experiments demonstrate that our proposed method is much more efficient than the original proximal linear algorithm and the subgradient method #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We compare our IPL method with the original proximal linear algorithm proposed by #REFR, where the subproblem is solved by POGS, and show that our method is much more efficient.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To solve the robust phase retrieval problem, we propose a new inexact proximal linear algorithm with two adaptive stopping criteria for the subproblem, which is inspired by the two-stage trick in #REFR.", "given_citation_intent": "method", "given_keywords": ["later iterations", "two-stage trick"]}]}
{"citing_id": "2304.01914v1", "cited_id": "1911.09723", "section_title": "V. Numerical Results And Analysis", "citation": "These results are presented in Figure  3 and show the gains in inference time with the XNNPack sparse inference accelerator #REFR [17].", "text_before_citation": ["In this section we first evaluate and explain the results observed from applying pruning, post-training quantization and weight clustering independently to CsiNet. These results are summarized in Table I .", "We then present the results obtained from combining different model compression techniques together. These results are summarized in Table II .", "Next, we investigate the effects of applying different levels of model sparsity percentages and quantization levels -both independently and jointly.", "These results presented in Figure 2 provide insights on the trade-offs between accuracy, inference time, and model size -and indicate the sparsity and quantization levels that provide an excellent operating point for CsiNet.", "Finally, we demonstrate the need to leverage and implement sparse inference acceleration for hardware implementations of pruned neural networks."], "text_after_citation": [], "citing_paper_content": {"title": "Accelerating And Compressing Deep Neural Networks For Massive Mimo Csi Feedback", "abstract": "The recent advances in machine learning and deep neural networks have made them attractive candidates for wireless communications functions such as channel estimation, decoding, and downlink channel state information (CSI) compression. However, most of these neural networks are large and inefficient making it a barrier for deployment in practical wireless systems that require low-latency and low memory footprints for individual network functions. To mitigate these limitations, we propose accelerated and compressed efficient neural networks for massive MIMO CSI feedback. Specifically, we have thoroughly investigated the adoption of network pruning, posttraining dynamic range quantization, and weight clustering to optimize CSI feedback compression for massive MIMO systems. Furthermore, we have deployed the proposed model compression techniques on commodity hardware and demonstrated that in order to achieve inference gains, specialized libraries that accelerate computations for sparse neural networks are required. Our findings indicate that there is remarkable value in applying these model compression techniques and the proposed joint pruning and quantization approach reduced model size by 86.5% and inference time by 76.2% with minimal impact to model accuracy. These compression methods are crucial to pave the way for practical adoption and deployments of deep learningbased techniques in commercial wireless systems. Index Terms-Deep learning, CSI feedback, accelerated neural networks, model compression, massive MIMO."}, "cited_paper_content": {"title": "Fast Sparse Convnets", "abstract": "Historically, the pursuit of efficient inference has been one of the driving forces behind research into new deep learning architectures and building blocks. Some recent examples include: the squeeze-and-excitation module, depthwise separable convolutions in Xception, and the inverted bottleneck in MobileNet v2. Notably, in all of these cases, the resulting building blocks enabled not only higher efficiency, but also higher accuracy, and found wide adoption in the field. In this work, we further expand the arsenal of efficient building blocks for neural network architectures; but instead of combining standard primitives (such as convolution), we advocate for the replacement of these dense primitives with their sparse counterparts. While the idea of using sparsity to decrease the parameter count is not new, the conventional wisdom is that this reduction in theoretical FLOPs does not translate into real-world efficiency gains. We aim to correct this misconception by introducing a family of efficient sparse kernels for ARM and WebAssembly, which we open-source for the benefit of the community as part of the XNNPACK library. Equipped with our efficient implementation of sparse primitives, we show that sparse versions of MobileNet v1, MobileNet v2 and EfficientNet architectures substantially outperform strong dense baselines on the efficiency-accuracy curve. On Snapdragon 835 our sparse networks outperform their dense equivalents by $1.3-2.4\\times$ -- equivalent to approximately one entire generation of MobileNet-family improvement. We hope that our findings will facilitate wider adoption of sparsity as a tool for creating efficient and accurate deep learning architectures."}, "keywords": ["XNNPack sparse inference"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Finally, we demonstrate the need to leverage and implement sparse inference acceleration for hardware implementations of pruned neural networks, as shown in the efficient sparse kernels for ARM and WebAssembly presented in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To achieve inference gains, specialized libraries that accelerate computations for sparse neural networks are required, as demonstrated by the authors of \"Fast Sparse Convnets\" #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Furthermore, our findings demonstrate the need to leverage and implement sparse inference acceleration for hardware implementations of pruned neural networks, as shown by the efficient sparse kernels for ARM and WebAssembly presented in #REFR.", "given_citation_intent": "result", "given_keywords": ["XNNPack sparse inference"]}]}
{"citing_id": "2304.03985v1", "cited_id": "1011.1157", "section_title": "Introduction", "citation": "A transposition is an operation on a permutation (in general on any sequence of numbers) that consists in swapping two consecutive sequences of the permutation. We define this formally now (c.f. #REFR ). Let \u03c3 be a permutation.", "text_before_citation": ["\u03c3(n)} Now the main idea of the algorithm for Theorem 2 is to translate the rotation problem for skew trees to an operation on binary strings which we prove in Lemma 7 using the above characterization.", "En route this proof, we also show that the skew rotation distance between two skew trees of n internal nodes can be at most n 2 distance.", "We also analyse the distance of any given tree T to the nearest skew tree and prove matching upper and lower bounds.", "Characterizing Rotation using Transpositions : Given two trees T 1 and T 2 , we can interpret them as permutations \u03c3, \u03c4 \u2208 S n and study the effect of rotation on these permutations.", "We prove that rotation must necessarily be a special kind of transposition operation and hence we call it a tree transposition."], "text_after_citation": ["Given three integers i, j, k such that 0 < i < j < k \u2264 n, the result of transposition operation \u03b4 i,j,k applied to the permutation \u03c3 is the following permutation (let q(j) = k + i \u2212 j).", "For any 0 \u2264 t < i, \u03b4 i,j,k (t) = \u03c3(t).", "For any i \u2264 t < q(j), \u03b4 i,j,k (t) = \u03c3(t + j \u2212 i).", "For any q(j) \u2264 t < k, \u03b4 i,j,k (t) = \u03c3(t+j \u2212k).", "For any k \u2264 t \u2264 n, \u03b4 i,j,k (t) = \u03c3(t)."], "citing_paper_content": {"title": "On Rotation Distance Of Rank Bounded Trees *", "abstract": "Computing the rotation distance between two binary trees with n internal nodes efficiently (in poly(n) time) is a long standing open question in the study of height balancing in tree data structures. In this paper, we initiate the study of this problem bounding the rank of the trees given at the input (defined in [EH89] in the context of decision trees). We define the rank-bounded rotation distance between two given binary trees T 1 and T 2 (with n internal nodes) of rank at most r, denoted by d r (T 1 , T 2), as the length of the shortest sequence of rotations that transforms T 1 to T 2 with the restriction that the intermediate trees must be of rank at most r. We show that the rotation distance problem reduces in polynomial time to the rank bounded rotation distance problem. This motivates the study of the problem in the combinatorial and algorithmic frontiers. Observing that trees with rank 1 coincide exactly with skew trees (binary trees where every internal node has at least one leaf as a child), we show the following results in this frontier : \u2022 We present an O(n 2) time algorithm for computing d 1 (T 1 , T 2). That is, when the given trees are skew trees (we call this variant as skew rotation distance problem)-where the intermediate trees are restricted to be skew as well. In particular, our techniques imply that for any two skew trees d(T 1 , T 2) \u2264 n 2. * A preliminary version of the paper containing a subset of results appeared in the proceedings of the 28th International Computing and Combinatorics Conference (COCOON 2022)."}, "cited_paper_content": {"title": "Sorting By Transpositions Is Difficult", "abstract": "In comparative genomics, a transposition is an operation that exchanges two consecutive sequences of genes in a genome. The transposition distance between two genomes, that is, the minimum number of transpositions needed to transform a genome into another, is, according to numerous studies, a relevant evolutionary distance. The problem of computing this distance when genomes are represented by permutations is called the Sorting by Transpositions problem, and has been introduced by Bafna and Pevzner in [Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 1995, pp. 614--623]. It has naturally been the focus of a number of studies (see, for instance, [G. Fertin, A. Labarre, I. Rusu, E. Tannier, and S. Vialette, Combinatorics of Genome Rearrangements, The MIT Press, Cambridge, MA, 2009]), but the computational complexity of this problem has remained undetermined for 15 years. In this paper, we answer this long-standing open question by proving that the Sorting by Transpositions problem ..."}, "keywords": ["transposition"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We prove that rotation must necessarily be a special kind of transposition operation and hence we call it a tree transposition. This idea has been previously introduced in the literature [Bafna and Pevzner, Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 1995, pp. 614--623] and has been the focus of numerous studies in comparative genomics. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The problem of computing the transposition distance between two genomes has been extensively studied in comparative genomics, and was introduced by Bafna and Pevzner in their paper \"#REFR\".", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The problem of computing the transposition distance between two genomes has been extensively studied in comparative genomics, and has been introduced by Bafna and Pevzner in their paper \"Sorting By Transpositions Is Difficult\" (#REFR).", "given_citation_intent": "background", "given_keywords": ["transposition"]}]}
{"citing_id": "2305.02517v1", "cited_id": "1911.02116", "section_title": "Basic Ner Systems", "citation": "We mainly use the XLM-RoBERTa large #REFR as the pre-trained language model, which is a widely used encoder.", "text_before_citation": [], "text_after_citation": ["Generated by feeding a sentence into the encoder, the representation is then input to different classifiers.", "Three mainstream NER backend classifiers are adopted: Softmax #OTHEREFR Table 1 : The metrics of our gazetteer in detail. The Total Num.", "column means the accurate number of entries in the gazetteer for each track.", "Numbers with % denote the coverage rates to entities in the training and validation set.", "The Average means coverage rate of the gazetteer with a manual one-to-one matching following and the Average-stat is the coverage rate after adding the statistics-based approach."], "citing_paper_content": {"title": "Ustc-Nelslip At Semeval-2023 Task 2: Statistical Construction And Dual Adaptation Of Gazetteer For Multilingual Complex Ner", "abstract": "This paper describes the system developed by the USTC-NELSLIP team for SemEval-2023 Task 2 Multilingual Complex Named Entity Recognition (MultiCoNER II). A method named Statistical Construction and Dual Adaptation of Gazetteer (SCDAG) is proposed for Multilingual Complex NER. The method first utilizes a statistics-based approach to construct a gazetteer. Secondly, the representations of gazetteer networks and language models are adapted by minimizing the KL divergence between them at both the sentence-level and entity-level. Finally, these two networks are then integrated for supervised named entity recognition (NER) training. The proposed method is applied to XLM-R with a gazetteer built from Wikidata, and shows great generalization ability across different tracks. Experimental results and detailed analysis verify the effectiveness of the proposed method. The official results show that our system ranked 1st on one track (Hindi) in this task."}, "cited_paper_content": {"title": "Unsupervised Cross-Lingual Representation Learning At Scale", "abstract": "This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model. We also present a detailed empirical evaluation of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-Ris very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make XLM-R code, data, and models publicly available."}, "keywords": ["pre-trained language model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proposed method is applied to XLM-R with a gazetteer built from Wikidata, and shows great generalization ability across different tracks (Li et al., 2020). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To construct a gazetteer for multilingual complex NER, the USTC-NELSLIP team proposed a method named Statistical Construction and Dual Adaptation of Gazetteer (SCDAG), which utilizes a statistics-based approach to build a gazetteer and adapts the representations of gazetteer networks and language models by minimizing the KL divergence between them at both the sentence-level and entity-level. The method was applied to XLM-R with a gazetteer built from Wikidata, showing great generalization ability across different tracks (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To construct a gazetteer for multilingual complex NER, the authors proposed a method named Statistical Construction and Dual Adaptation of Gazetteer (SCDAG), which utilizes a statistics-based approach to build a gazetteer and adapts the representations of gazetteer networks and language models by minimizing the KL divergence between them at both the sentence-level and entity-level, and then integrates these two networks for supervised NER training. The proposed method was applied to XLM-R with a gazetteer built from Wikidata, showing great generalization ability across different tracks (#REFR).", "given_citation_intent": "method", "given_keywords": ["pre-trained language model"]}]}
{"citing_id": "2303.06424v1", "cited_id": "1910.05453", "section_title": "Introduction", "citation": "Gumbel-VQ #REFR learns valid values for all codebook embeddings, while only a small number of embeddings are actually used for quantization as illustrated in codebook utilization.", "text_before_citation": ["With the prevalence of multi-modal image synthesis #OTHEREFR and Transformers #OTHEREFR , unifying data modeling regardless of data modalities has attracted increasing interest from the research communities.", "Aiming for a generic data representation across different data modalities, discrete representation learning #OTHEREFR 25] plays a significant role in the unified modeling.", "In particular, vector quantization models (e.g., VQ-VAE #OTHEREFR and VQ-GAN #OTHEREFR ) emerge as a promising family for learning generic image representations by discretizing images into discrete tokens. With the Figure 1 .", "Visualization of codebook (first row) and illustration of codebook utilization (second row) on ADE20K dataset #OTHEREFR .", "VQ-GAN #OTHEREFR severely suffers from codebook collapse as most codebook embeddings are invalid values."], "text_after_citation": ["As a comparison, the proposed regularized quantization prevents codebook collapse and achieves full codebook utilization.", "The codebook visualization method is provided in the supplementary file.", "tokenized representation, generative models such as autoregressive model #OTHEREFR and diffusion model #OTHEREFR can be applied to accommodate the dependency of the sequential tokens for image generation, which is referred as tokenized image synthesis under this context.", "Vector quantization models can be broadly grouped into deterministic quantization and stochastic quantization according to the selection of discrete tokens.", "Specifically, typical deterministic methods like VQ-GAN #OTHEREFR directly select the best-matching token via Argmin or Argmax, while stochastic methods like Gumbel-VQ #OTHEREFR select a token by stochastically sampling from a predicted token distribution."], "citing_paper_content": {"title": "Regularized Vector Quantization For Tokenized Image Synthesis", "abstract": "Quantizing images into discrete representations has been a fundamental problem in unified generative modeling. Predominant approaches learn the discrete representation either in a deterministic manner by selecting the bestmatching token or in a stochastic manner by sampling from a predicted distribution. However, deterministic quantization suffers from severe codebook collapse and misalignment with inference stage while stochastic quantization suffers from low codebook utilization and perturbed reconstruction objective. This paper presents a regularized vector quantization framework that allows to mitigate above issues effectively by applying regularization from two perspectives. The first is a prior distribution regularization which measures the discrepancy between a prior token distribution and the predicted token distribution to avoid codebook collapse and low codebook utilization. The second is a stochastic mask regularization that introduces stochasticity during quantization to strike a good balance between inference stage misalignment and unperturbed reconstruction objective. In addition, we design a probabilistic contrastive loss which serves as a calibrated metric to further mitigate the perturbed reconstruction objective. Extensive experiments show that the proposed quantization framework outperforms prevailing vector quantization methods consistently across different generative models including autoregressive models and diffusion models."}, "cited_paper_content": {"title": "Vq-Wav2Vec: Self-Supervised Learning Of Discrete Speech Representations", "abstract": "We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition."}, "keywords": ["quantization", "embeddings"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "With the prevalence of multi-modal image synthesis #OTHEREFR and Transformers #OTHEREFR, unifying data modeling regardless of data modalities has attracted increasing interest from the research communities. Aiming for a generic data representation across different data modalities, discrete representation learning #OTHEREFR 25] plays a significant role in the unified modeling. In particular, vector quantization models (e.g., VQ-VAE #OTHEREFR and VQ-GAN #OTHEREFR) emerge as a promising family for learning generic image representations by discretizing images into discrete tokens. With the Figure 1. Visualization of codebook (first row) and illustration of codebook utilization (second row) on ADE20K dataset #OTHEREFR. VQ-GAN #OTHEREFR severely suffers from codebook collapse as most codebook embeddings are invalid values (Ours is regularized). To address this issue, we propose a regularized vector quantization framework that allows for effective mitigation of codebook collapse and low codebook utilization by applying regularization from two perspectives, as well as a stochastic mask regularization that introduces stochasticity during quantization to strike a good balance between inference stage misalignment and unperturbed reconstruction objective. Our proposed framework outperforms prevailing vector quantization methods consistently across different generative models including autoregressive models and diffusion models #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Discrete representation learning has been widely used in unified modeling, and vector quantization models such as VQ-VAE and VQ-GAN have shown promising results in learning generic image representations by discretizing images into discrete tokens #REFR [25].", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Discretization is a crucial step in vector quantization models, and recent work has proposed vq-wav2vec, which learns discrete representations of audio segments through a self-supervised context prediction task, using either a gumbel softmax or online k-means clustering to quantize the dense representations, enabling the direct application of algorithms from the NLP community which require discrete inputs #REFR.", "given_citation_intent": "background", "given_keywords": ["quantization", "embeddings"]}]}
{"citing_id": "2303.15005v1", "cited_id": "1609.07061", "section_title": "Related Work", "citation": "This was solved by using the straight-through gradient estimator (STE) approach #REFR which, in the forward pass of a training step, applies rounding operations to computations involved in the QNN (i.e.", "text_before_citation": ["There are two main strategies for training QNNs: post-training quantization and quantization-aware training #OTHEREFR (QAT).", "The drawback of the post-training quantization is that it typically results in a drop in the accuracy of the network with a magnitude that depends on the specific dataset and network architecture.", "In our work, we use the second approach which is implemented in Larq library [11] .", "In QAT, the imprecision of the low-bit fixed-point arithmetic is modeled already during the training process, i.e., the network can adapt to a quantized computation during training.", "The challenge for QNNs is that they can not be trained directly with stochastic gradient descent (SGD) like classical NNs."], "text_after_citation": ["weights, biases, and arithmetic operations) and in the backward pass, the rounding operations are removed such that the error can backpropagate through the network.", "BinaryConnect [9] is one of the first works which uses 1-bit quantization of weights during forward and backward propagation, but not during parameter update to maintain accurate gradient calculation during SGD.", "As an observation, the models used in conjuction with BinaryConnect use only linear layers which is suficient for MNIST #OTHEREFR dataset, but convolutional layers for CIFAR-10 #OTHEREFR and SVHN #OTHEREFR . Paper #OTHEREFR binarizes the activations as well.", "Similarly, for MNIST dataset they use linear layers, while for CIFAR-10, SVHN and ImageNet [10] they use variants of ConvNet, inspired by VGG #OTHEREFR , with the binarization of the activations.", "In XNOR-Net #OTHEREFR , both the weights and the inputs to the convolutional and fully connected layers are approximated with binary values which allows an efficient way of implementing convolutional operations. The paper uses ImageNet dataset in experiments."], "citing_paper_content": {"title": "Architecturing Binarized Neural Networks For Traffic Sign Recognition", "abstract": "Traffic signs support road safety and managing the flow of traffic, hence are an integral part of any vision system for autonomous driving. While the use of deep learning is well-known in traffic signs classification due to the high accuracy results obtained using convolutional neural networks (CNNs) (state of the art is 99.46%), little is known about binarized neural networks (BNNs). Compared to CNNs, BNNs reduce the model size and simplify convolution operations and have shown promising results in computationally limited and energy-constrained devices which appear in the context of autonomous driving. This work presents a bottom-up approach for architecturing BNNs by studying characteristics of the constituent layers. These constituent layers (binarized convolutional layers, max pooling, batch normalization, fully connected layers) are studied in various combinations and with different values of kernel size, number of filters and of neurons by using the German Traffic Sign Recognition Benchmark (GTSRB) for training. As a result, we propose BNNs architectures which achieve more than 90% for GTSRB (the maximum is 96.45%) and an average greater than 80% (the maximum is 88.99%) considering also the Belgian and Chinese datasets for testing. The number of parameters of these architectures varies from 100k to less than 2M. The accompanying material of this paper is publicly available at https://github.com/apostovan21/ BinarizedNeuralNetwork."}, "cited_paper_content": {"title": "Quantized Neural Networks: Training Neural Networks With Low Precision Weights And Activations", "abstract": "We introduce a method to train Quantized Neural Networks (QNNs) -- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online."}, "keywords": ["QNN"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In our work, we use the second approach which is implemented in Larq library [11]. In QAT, the imprecision of the low-bit fixed-point arithmetic is modeled already during the training process, i.e., the network can adapt to a quantized computation during training. The challenge for QNNs is that they can not be trained directly with stochastic gradient descent (SGD) like classical NNs. To overcome this challenge, the authors of the reference paper proposed a method to train Quantized Neural Networks (QNNs) with extremely low precision weights and activations, achieving prediction accuracy comparable to their 32-bit counterparts over various datasets including MNIST, CIFAR-10, SVHN, and ImageNet #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the challenge of training QNNs, the authors of this manuscript used quantization-aware training (QAT) implemented in the Larq library #REFR, which models the imprecision of low-bit fixed-point arithmetic during the training process and allows the network to adapt to a quantized computation during training.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To overcome the challenge of training QNNs with low-bit fixed-point arithmetic, the authors of this manuscript used quantization-aware training implemented in the Larq library #REFR, which models the imprecision of the arithmetic during the training process, allowing the network to adapt to a quantized computation during training.", "given_citation_intent": "method", "given_keywords": ["QNN"]}]}
{"citing_id": "2304.11826v1", "cited_id": "1711.02152", "section_title": "Definition And Characterization", "citation": "In #REFR a characterization of Fitch graphs in terms of eight forbidden subgraphs on three vertices is given.", "text_before_citation": ["It is significant, therefore, whether HGT-edges are found along the path from lca(x, y) to y, the path from lca(x, y) to x, or along both paths. Mathematically, this can be captured in the following manner.", "Definition 11.", "Let T be a rooted tree and H \u2286 E(T ) be a set of HGT-edges.", "Then the (directed) Fitch graph F(T, H) has vertex set L(T ) and (x, y) \u2208 E(F) if the path from lca T (x, y) to y contains an edge e \u2208 H.", "A graph G is a (directed) Fitch graph if G = F(T, H) for some tree T and edge set H \u2286 E(T )."], "text_after_citation": ["Fitch graphs also have a surprisingly simple characterization in terms of their \"closed complementary neighborhoods\".", "For a directed graph consider If G is a Fitch graph, then C (G) := N (G) \u222a {L} \u222a {{x}|x \u2208 L}, i.e., the extension of the closed complementary neighborhoods by the singleton sets and L itself forms a hierarchy on L, which corresponds to a uniquely defined rooted tree T G .", "This tree T G is the unique least-resolved tree for G and the set H G of HGT-edges in T G is uniquely determined and consists of all edges xy in T G with x, y \u2208 V 0 (T G ) #OTHEREFR .", "The directed Fitch graph thus is also informative about the structure of the gene tree.", "The pair (T G , H G ) also immediately yields the partition of L into HGT-free subsets."], "citing_paper_content": {"title": "The Theory Of Gene Family Histories", "abstract": "Most genes are part of larger families of evolutionary related genes. The history of gene families typically involves duplications and losses of genes as well as horizontal transfers into other organisms. The reconstruction of detailed gene family histories, i.e., the precise dating of evolutionary events relative to phylogenetic tree of the underlying species has remained a challenging topic despite their importance as a basis for detailed investigations into adaptation and functional evolution of individual members of the gene family. The identification of orthologs, moreover, is a particularly important subproblem of the more general setting considered here. In the last few years, an extensive body of mathematical results has appeared that tightly links orthology, a formal notion of best matches among genes, and horizontal gene transfer. The purpose of this chapter is the broadly outline some of the key mathematical insights and to discuss their implication for practical applications. In particular, we focus on tree-free methods, i.e., methods to infer orthology or horizontal gene transfer as well as gene trees, species trees and reconciliations between them without using a priori knowledge of the underlying trees or statistical models for the inference of phylogenetic trees. Instead, the initial step aims to extract binary relations among genes."}, "cited_paper_content": {"title": "Reconstructing Gene Trees From Fitch'S Xenology Relation", "abstract": "Two genes are xenologs in the sense of Fitch if they are separated by at least one horizontal gene transfer event. Horizonal gene transfer is asymmetric in the sense that the transferred copy is distinguished from the one that remains within the ancestral lineage. Hence xenology is more precisely thought of as a non-symmetric relation: y is xenologous to x if y has been horizontally transferred at least once since it diverged from the least common ancestor of x and y. We show that xenology relations are characterized by a small set of forbidden induced subgraphs on three vertices. Furthermore, each xenology relation can be derived from a unique least-resolved edge-labeled phylogenetic tree. We provide a linear-time algorithm for the recognition of xenology relations and for the construction of its least-resolved edge-labeled phylogenetic tree. The fact that being a xenology relation is a heritable graph property, finally has far-reaching consequences on approximation problems associated with xenology relations."}, "keywords": ["Fitch graphs"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors show that xenology relations can be derived from a unique least-resolved edge-labeled phylogenetic tree, and provide a linear-time algorithm for their recognition and construction. This result is discussed in detail in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors' algorithm for recognizing xenology relations and constructing their least-resolved edge-labeled phylogenetic tree, as described in the reference paper \"Reconstructing Gene Trees From Fitch'S Xenology Relation\" #REFR, can be used to identify whether HGT-edges are found along the path from lca(x, y) to y, the path from lca(x, y) to x, or along both paths.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Fitch graphs, which are defined as graphs that can be derived from a unique least-resolved edge-labeled phylogenetic tree, play a crucial role in the recognition of xenology relations and the construction of its least-resolved edge-labeled phylogenetic tree, as described in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["Fitch graphs"]}]}
{"citing_id": "2303.01289v2", "cited_id": "1911.05722", "section_title": "A Algorithm Details", "citation": "For DYNACL (upper part of the figure), we adopt our proposed augmentation annealing strategy and the momentum technique #REFR in the pretraining phase.", "text_before_citation": ["/ * Post-processing phase 2, tune the whole model * / 11 Unlock the parameters in g a 12 forall epoch \u2208 {1, 2,", "\u2022 \u2022 \u2022 , T } do 13 TRADES (h \u2022 g a , {x i }, {\u0177 i })", "Algorithm 1 demonstrates the pseudo-code of our proposed DYNACL and DYNACL++.", "Note that DYNACL++ adds a fast and simple post-processing phase to DYNACL and enjoys higher robustness.", "Figure 5 demonstrates the pipeline of the proposed DYNACL and DYNACL++."], "text_after_citation": ["Projection heads are added on the top of both branches of the ResNet backbone.", "For simplicity, this architecture is not explicitly shown in the figure.", "For DYNACL++, we add a simple and fast post-processing phase to DYNACL (bottom part of the figure).", "Specifically, we replace the projection head with a linear classification head and adopt our PAT algorithm. Note that both two phases require NO true labels."], "citing_paper_content": {"title": "Rethinking The Effect Of Data Augmentation In Adversarial Contrastive Learning", "abstract": "Recent works have shown that self-supervised learning can achieve remarkable robustness when integrated with adversarial training (AT). However, the robustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT) remains significant. Motivated by this observation, we revisit existing self-AT methods and discover an inherent dilemma that affects self-AT robustness: either strong or weak data augmentations are harmful to self-AT, and a medium strength is insufficient to bridge the gap. To resolve this dilemma, we propose a simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In particular, we propose an augmentation schedule that gradually anneals from a strong augmentation to a weak one to benefit from both extreme cases. Besides, we adopt a fast post-processing stage for adapting it to downstream tasks. Through extensive experiments, we show that DYNACL can improve state-of-the-art self-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can even outperform vanilla supervised adversarial training for the first time. Our code is available at https://github.com/PKU-ML/DYNACL."}, "cited_paper_content": {"title": "Momentum Contrast For Unsupervised Visual Representation Learning", "abstract": "We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks."}, "keywords": ["proposed augmentation", "pretraining phase"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To build a dynamic dictionary for contrastive unsupervised learning, the authors of DYNACL cite the Momentum Contrast (MoCo) method proposed in the paper \"Momentum Contrast For Unsupervised Visual Representation Learning\" #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To build a dynamic dictionary for unsupervised visual representation learning, the authors proposed Momentum Contrast (MoCo) which provides competitive results under the common linear protocol on ImageNet classification and outperforms its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins, suggesting that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks (#REFR).", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To resolve the dilemma of strong or weak data augmentations being harmful to self-AT, the authors proposed a simple remedy named DYNACL, which gradually anneals from a strong augmentation to a weak one to benefit from both extreme cases, and adopted a fast post-processing stage for adapting it to downstream tasks (#REFR).", "given_citation_intent": "method", "given_keywords": ["proposed augmentation", "pretraining phase"]}]}
{"citing_id": "2303.18184v2", "cited_id": "1906.08903", "section_title": "Discussion", "citation": "In recent years, although HERCULES #REFR has emerged, a repair tool designed explicitly for multi-hunk fixes scenarios, it addresses only a specific class of multi-hunk fixes, namely ones with substantially similar patches for each hunk.", "text_before_citation": ["It can be seen that cross-fertilization of different problem areas is the future trend, and we emphasize the migratory nature of different techniques.", "The multidisciplinary intersection of software engineering, artificial intelligence, system security, etc., will be a research trend that will jointly help APR techniques solve various code problems.", "Finding 3: In terms of the complexity of fixing defects, single-hunk bugs seem to be of more concern, and most APR techniques only support the fixing of single-hunk bugs.", "This phenomenon reflects that the multi-hunk fixes still is a challenge.", "Even though the single-hunk repair tool can iteratively fix multi-hunk bugs, it may use the context with the bugs, so this is not an appropriate solution #OTHEREFR ."], "text_after_citation": ["In addition, while learningbased solutions are now beginning to focus on multi-hunk fixes #OTHEREFR , there are many limitations, which we will discuss in detail in Finding 18.", "Overall, the multi-hunk fixes problem is always a challenge, and the complex dependencies between multiple lines of code make the repair even more difficult.", "In the long run, multi-hunk bug fixing is still a direction for future researchers.", "Finding 4: From the benchmark datasets used by each APR tool, Defects4J is the most widely used benchmark for software bugs, DeepFix dataset is the most commonly used benchmark for programming errors, CVEfixes and Big-Vul are two of the latest vulnerability fix datasets.", "But the amount of data in these datasets is still limited. Defects4J 2.0 contains only 835 bugs."], "citing_paper_content": {"title": "A Survey On Automated Program Repair Techniques", "abstract": "With the rapid development and large-scale popularity of program software, modern society increasingly relies on software systems. However, the problems exposed by software have also come to the fore. Software defect has become an important factor troubling developers. In this context, Automated Program Repair (APR) techniques have emerged, aiming to automatically fix software defect problems and reduce manual debugging work. In particular, benefiting from the advances in deep learning, numerous learning-based APR techniques have emerged in recent years, which also bring new opportunities for APR research. To give researchers a quick overview of APR techniques' complete development and future opportunities, we revisit the evolution of APR techniques and discuss in depth the latest advances in APR research. In this paper, the development of APR techniques is introduced in terms of four different patch generation schemes: search-based, constraint-based, template-based, and learning-based. Moreover, we propose a uniform set of criteria to review and compare each APR tool, summarize the advantages and disadvantages of APR techniques, and discuss the current state of APR development. Furthermore, we introduce the research on the related technical areas of APR that have also provided a strong motivation to advance APR development. Finally, we analyze current challenges and future directions, especially highlighting the critical opportunities that large language models bring to APR research. CCS Concepts: \u2022 Software and its engineering \u2192 Software testing and debugging."}, "cited_paper_content": {"title": "Harnessing Evolution For Multi-Hunk Program Repair", "abstract": "Despite significant advances in automatic program repair (APR)techniques over the past decade, practical deployment remains an elusive goal. One of the important challenges in this regard is the general inability of current APR techniques to produce patches that require edits in multiple locations, i.e., multi-hunk patches. In this work, we present a novel APR technique that generalizes single-hunk repair techniques to include an important class of multi-hunk bugs, namely bugs that may require applying a substantially similar patch at a number of locations. We term such sets of repair locations as evolutionary siblings - similar looking code, instantiated in similar contexts, that are expected to undergo similar changes. At the heart of our proposed method is an analysis to accurately identify a set of evolutionary siblings, for a given bug. This analysis leverages three distinct sources of information, namely the test-suite spectrum, a novel code similarity analysis, and the revision history of the project. The discovered siblings are then simultaneously repaired in a similar fashion. We instantiate this technique in a tool called Hercules and demonstrate that it is able to correctly fix 49 bugs in the Defects4J dataset, the highest of any individual APR technique to date. This includes 15 multi-hunk bugs and overall 13 bugs which have not been fixed by any other technique so far."}, "keywords": ["multi-hunk fixes scenarios"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In particular, the challenge of producing multi-hunk patches remains an elusive goal for most APR techniques, as they are unable to apply substantially similar patches at multiple locations. However, a recent study by XYZ et al. proposes a novel APR technique that leverages an analysis of evolutionary siblings to simultaneously repair sets of repair locations that require similar changes, resulting in the highest number of correctly fixed bugs to date, including 15 multi-hunk bugs #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of multi-hunk patches, recent research has proposed a novel APR technique that leverages evolutionary siblings to simultaneously repair similar-looking code in similar contexts, achieving the highest fixing rate of 49 bugs in the Defects4J dataset, including 15 multi-hunk bugs, as reported in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Multi-hunk bugs are still a challenge for most APR techniques, as they require applying a substantially similar patch at a number of locations. However, a recent study proposed a novel APR technique that can handle such scenarios by identifying sets of evolutionary siblings and repairing them simultaneously, achieving the highest fixing rate of multi-hunk bugs to date #REFR.", "given_citation_intent": "background", "given_keywords": ["multi-hunk fixes scenarios"]}]}
{"citing_id": "2304.11595v1", "cited_id": "1909.12223", "section_title": "The Origins Of Foundation Models", "citation": "In recent years, several novel techniques such as PairNorm layer #REFR and DropEdge Rong et al.", "text_before_citation": ["In response, this study aims to address this gap by extending the concept of foundation models to the domain of graph analysis.", "The primary goal of this work is to investigate the feasibility and effectiveness of incorporating foundation models in the context of non-Euclidean graphs, thereby contributing to the advancement of foundation models in this area. #OTHEREFR", "[2017] , which makes the model scalable by sampling neighbors instead of using all of them. Graph attention network (GAT) #OTHEREFR", "[2018] introduces the attention mechanism to learn the weights for each neighbor automatically.", "Other techniques like adaptive sampling have been proposed for efficient training #OTHEREFR ."], "text_after_citation": ["[2020] strategy have been proposed to overcome the oversmoothing problem in GNNs Rusch et al.", "[2023].", "Despite the encouraging progress in graph neural networks, to the best of our knowledge, there is little research towards learning task-agnostic foundation models for unversal graph analysis.", "But indeed, there are some works that are related to this topic of graph foundation models, such as knowledge transfer and graph reprogramming. In particular, the work in #OTHEREFR", "[2021b] introduces a novel knowledge transfer tasks that aims to obtain a multi-talented and lightweight student model, by amalgamating knowledge from heterogeneous teacher GNNs."], "citing_paper_content": {"title": "Segment Anything In Non-Euclidean Domains: Challenges And Opportunities", "abstract": "Figure 1: Illustrations of proposed foundation model in the non-Euclidean domain, which is referred to as \"Segment Non-Euclidean Anything (SNA)\"."}, "cited_paper_content": {"title": "Pairnorm: Tackling Oversmoothing In Gnns", "abstract": "The performance of graph neural nets (GNNs) is known to gradually decrease with increasing number of layers. This decay is partly attributed to oversmoothing, where repeated graph convolutions eventually make node embeddings indistinguishable. We take a closer look at two different interpretations, aiming to quantify oversmoothing. Our main contribution is PairNorm, a novel normalization layer that is based on a careful analysis of the graph convolution operator, which prevents all node embeddings from becoming too similar. What is more, PairNorm is fast, easy to implement without any change to network architecture nor any additional parameters, and is broadly applicable to any GNN. Experiments on real-world graphs demonstrate that PairNorm makes deeper GCN, GAT, and SGC models more robust against oversmoothing, and significantly boosts performance for a new problem setting that benefits from deeper GNNs."}, "keywords": ["PairNorm layer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To prevent oversmoothing in graph neural nets, PairNorm has been proposed as a novel normalization layer that is fast, easy to implement, and broadly applicable to any GNN #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prevent oversmoothing in graph neural nets (GNNs), PairNorm has been proposed as a novel normalization layer that is fast, easy to implement, and broadly applicable to any GNN #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prevent oversmoothing in graph neural nets, PairNorm layer is proposed in #REFR, which is a novel normalization layer that can be easily implemented without any change to network architecture or additional parameters.", "given_citation_intent": "method", "given_keywords": ["PairNorm layer"]}]}
{"citing_id": "2303.07283v1", "cited_id": "1702.05849", "section_title": "B. Evaluation Of Sas And Shs Based On Chaos Engineering", "citation": "Chaos engineering (CE) is the practice of intentionally causing and studying controlled chaos within software systems operating in realistic environments, with the goal of increasing the systems' resilience and ability to handle unforeseen circumstances #REFR .", "text_before_citation": ["The evaluation of self-adaptive and self-healing systems is an important aspect of their design and deployment.", "In our previous work #OTHEREFR , we defined the evaluation of self-adaptive and self-healing systems as \"an approach to determine if a system meets objectives under operation, identify areas in which the system performs as well as desired or predicted, and provide evidence to the value and applicability of the system.\"", "Several approaches to the evaluation of SAS and SHS include model-based evaluation #OTHEREFR , metric-based evaluation #OTHEREFR , model checking #OTHEREFR , and runtime testing and verification #OTHEREFR each with its benefits and limitations.", "However, none of these evaluation approaches are viable for evaluation covering the execution of the system under real-life failure scenarios.", "Therefore, to address this gap, we introduce a mechanism that builds on chaos engineering principles."], "text_after_citation": ["The core tenets of CE can be outlined as four main principles, which include formulating hypotheses based on the steadystate behavior of systems, introducing variations to real-world events, conducting experiments in a production environment, and automating these experiments for continuous execution.", "Our approach evaluates the systems through a systematic process that involves exposing the system to faults and testing its ability to recover from such perturbations."], "citing_paper_content": {"title": "Chess: A Framework For Evaluation Of Self-Adaptive Systems Based On Chaos Engineering", "abstract": "There is an increasing need to assess the correct behavior of self-adaptive and self-healing systems due to their adoption in critical and highly dynamic environments. However, there is a lack of systematic evaluation methods for self-adaptive and self-healing systems. We proposed CHESS, a novel approach to address this gap by evaluating self-adaptive and self-healing systems through fault injection based on chaos engineering (CE). The artifact presented in this paper provides an extensive overview of the use of CHESS through two microservice-based case studies: a smart office case study and an existing demo application called Yelb. It comes with a managing system service, a self-monitoring service, as well as five fault injection scenarios covering infrastructure faults and functional faults. Each of these components can be easily extended or replaced to adopt the CHESS approach to a new case study, help explore its promises and limitations, and identify directions for future research."}, "cited_paper_content": {"title": "A Platform For Automating Chaos Experiments", "abstract": "The Netflix video streaming system is composed of many interacting services. In such a large system, failures in individual services are not uncommon. This paper describes the Chaos Automation Platform, a system for running failure injection experiments on the production system to verify that failures in non-critical services do not result in system outages."}, "keywords": ["systems' resilience", "Chaos engineering"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Therefore, to address this gap, we introduce a mechanism that builds on chaos engineering principles. In particular, we propose CHESS, a novel approach to evaluate self-adaptive and self-healing systems through fault injection based on chaos engineering (CE) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate self-adaptive and self-healing systems under real-life failure scenarios, chaos engineering principles can be used. Chaos Automation Platform, a system for running failure injection experiments on the production system to verify that failures in non-critical services do not result in system outages, can be a useful tool in this regard #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve systems' resilience, chaos engineering has been proposed as a mechanism to evaluate self-adaptive and self-healing systems under real-life failure scenarios #REFR.", "given_citation_intent": "background", "given_keywords": ["systems' resilience", "Chaos engineering"]}]}
{"citing_id": "2304.02489v1", "cited_id": "1801.04644", "section_title": "Continuous Controlling System Uncertainty", "citation": "An efficient analysis method can be used to propagate the effect of uncertain parameters in software systems and calculate the robustness of the performance indices, thereby enhancing the flexibility in addressing uncertainty ( #REFR ).", "text_before_citation": ["As discussed in Sections 6 and 8, uncertainty has been addressed marginally in the papers selected in this study.", "However, both in academia and industry, significant attention is paid to the contexts characterized by a high degree of uncertainty.", "To reduce uncertainty and obtain feedback on products/software as soon as possible, it is important to test assumptions and hypotheses in short cycles #OTHEREFR .", "Continuous monitoring and frequent re-assessment and rearchitecting are necessary to reduce the uncertainty in CSE and DevOps #OTHEREFR ."], "text_after_citation": [], "citing_paper_content": {"title": "Architectural Support For Software Performance In Continuous Software Engineering: A Systematic Mapping Study", "abstract": "The continuous software engineering paradigm is gaining popularity in modern development practices, where the interleaving of design and runtime activities is induced by the continuous evolution of software systems. In this context, performance assessment is not easy, but recent studies have shown that architectural models evolving with the software can support this goal. In this paper, we present a mapping study aimed at classifying existing scientific contributions that deal with the architectural support for performancetargeted continuous software engineering. We have applied the systematic mapping methodology to an initial set of 215 potentially relevant papers and selected 66 primary studies that we have analyzed to characterize and classify the current state of research. This classification helps to focus on the main aspects that are being considered in this domain and, mostly, on the emerging findings and implications for future research."}, "cited_paper_content": {"title": "An Efficient Method For Uncertainty Propagation In Robust Software Performance Estimation", "abstract": "Software engineers often have to estimate the performance of a software system before having full knowledge of the system parameters, such as workload and operational profile. These uncertain parameters inevitably affect the accuracy of quality evaluations, and the ability to judge if the system can continue to fulfil performance requirements if parameter results are different from expected. Previous work has addressed this problem by modelling the potential values of uncertain parameters as probability distribution functions, and estimating the robustness of the system using Monte Carlo-based methods. These approaches require a large number of samples, which results in high computational cost and long waiting times. To address the computational inefficiency of existing approaches, we employ Polynomial Chaos Expansion (PCE) as a rigorous method for uncertainty propagation and further extend its use to robust performance estimation. The aim is to assess if the software system is robust, i.e., it can withstand possible changes in parameter values, and continue to meet performance requirements. PCE is a very efficient technique, and requires significantly less computations to accurately estimate the distribution of performance indices. Through three very different case studies from different phases of software development and heterogeneous application domains, we show that PCE can accurately (>97\\%) estimate the robustness of various performance indices, and saves up to 225 hours of performance evaluation time when compared to Monte Carlo Simulation."}, "keywords": ["software systems", "robustness"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To efficiently estimate the robustness of software systems in the face of uncertain parameters, the authors of #REFR propose using Polynomial Chaos Expansion (PCE) as a rigorous method for uncertainty propagation, which requires significantly less computations than Monte Carlo-based methods, as demonstrated in three case studies from different phases of software development and application domains.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the high computational cost and long waiting times of Monte Carlo-based methods for estimating the robustness of software systems in the presence of uncertain parameters, the authors propose using Polynomial Chaos Expansion (PCE) as a more efficient technique, which accurately estimates the distribution of performance indices and saves up to 225 hours of performance evaluation time #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To estimate the robustness of software systems and ensure they can withstand possible changes in parameter values, PCE has been proposed as an efficient technique that requires significantly less computations than Monte Carlo-based methods #REFR.", "given_citation_intent": "method", "given_keywords": ["software systems", "robustness"]}]}
{"citing_id": "2304.07858v1", "cited_id": "1412.6980", "section_title": "Experiments Settings", "citation": "In addition, the proposed CSMN and other competitors are implemented by distributed Tensorflow 1.4, where learning rate, mini-batch, and optimizer, are set as 0.001, 1024, Adam #REFR , respectively. In addition, there are 4 layers in the MLP.", "text_before_citation": ["We also adapt MMoE for multi-scenario task by assigning each output for corresponding scenario.", "-PLE #OTHEREFR : It contains shared components and task-specific components, and adopts a progressive routing mechanism to extract and separate deeper knowledge, enabling the efficiency of representation across multiple tasks.", "-STAR #OTHEREFR : It trains a unified model to serve all scenarios simultaneously, containing shared centered parameters and scenario-specific parameters.", "-SAR-Net #OTHEREFR : It predicts users' scenario-specific interests from scenario/target item features and adaptively extracts scenario-specific information across multiple scenarios.", "Metrics and Implementation Details To comprehensively evaluate the performance of different methods, we adopt two widely used metrics in recommender systems, i.e., Area Under Curve (AUC) #OTHEREFR and Relative Improvement (RI) #OTHEREFR , where, the larger AUC means better ranking performance, and RI provides an intuitive comparison measure by calculating the relative improvement of a target model over the baseline model."], "text_after_citation": ["Logistic loss is used as the loss function for all the competitors, as summarized in Table 2 ."], "citing_paper_content": {"title": "Cold-Start Based Multi-Scenario Ranking Model For Click-Through Rate Prediction", "abstract": "Online travel platforms (OTPs), e.g., Ctrip.com or Fliggy.com, can effectively provide travel-related products or services to users. In this paper, we focus on the multi-scenario click-through rate (CTR) prediction, i.e., training a unified model to serve all scenarios. Existing multiscenario based CTR methods struggle in the context of OTP setting due to the ignorance of the cold-start users who have very limited data. To fill this gap, we propose a novel method named Cold-Start based Multiscenario Network (CSMN). Specifically, it consists of two basic components including: 1) User Interest Projection Network (UIPN), which firstly purifies users' behaviors by eliminating the scenario-irrelevant information in behaviors with respect to the visiting scenario, followed by obtaining users' scenario-specific interests by summarizing the purified behaviors with respect to the target item via an attention mechanism; and 2) User Representation Memory Network (URMN), which benefits cold-start users from users with rich behaviors through a memory read and write mechanism. CSMN seamlessly integrates both components in an end-to-end learning framework. Extensive experiments on real-world offline dataset and online A/B test demonstrate the superiority of CSMN over state-of-the-art methods."}, "cited_paper_content": {"title": "Adam: A Method For Stochastic Optimization", "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."}, "keywords": ["learning rate"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To optimize the stochastic objective functions in our multi-scenario click-through rate prediction model, we implement the Adam algorithm proposed in the reference paper #REFR, which has been shown to work well in practice and compare favorably to other stochastic optimization methods.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the stochastic objective functions in our proposed Cold-Start based Multiscenario Network (CSMN), we implement the Adam algorithm, which is computationally efficient and well-suited for problems that are large in terms of data and/or parameters #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the performance of the proposed Cold-Start based Multiscenario Network (CSMN), the authors implemented the Adam algorithm for stochastic optimization with adaptive estimates of lower-order moments and intuitive hyper-parameters that require little tuning. #REFR", "given_citation_intent": "method", "given_keywords": ["learning rate"]}]}
{"citing_id": "2304.10498v1", "cited_id": "1407.5042", "section_title": "Experiments", "citation": "The experiment uses the state-of-the-art exact regret minimizer, CFR+ #REFR , for all double oracle algorithms, and the regret minimization algorithms are initialized with uniform random policies following the default setting.", "text_before_citation": ["Oshi Zumo is a board game in which players must repeatedly bid to push a token off the other side of the board #OTHEREFR . The full description of games is in Appendix C.", "We evaluate the performance with the exploitability in terms of number of infosets visited and wall time measured in seconds.", "The number of visited infosets refers to the total number of nodes traversed by the algorithm, including those encountered during best response (BR) computation.", "It is equivalent to the number of touched nodes in the experiment of Stochastic Regret Minimization #OTHEREFR .", "It is important to note that the difference between the expanded infosets in XDO paper (McAleer et al., 2021) infosets in the present study is that XDO did not include the infosets during BR computation."], "text_after_citation": ["The study begins by analyzing the performance of PDO with various periodicity choices and comparing them with XODO.", "Furthermore, the algorithm's performance is compared against baselines, including XDO with restricted game solver CFR+, CFR+ itself, and Extensive-form Fictitious Self-play.", "All experiments and algorithm implementations are based on OpenSpiel #OTHEREFR .", "In Figure 1 , we present a comparison between the XODO and PDO with periodicity values of m = 1, 10, 50, 100, in terms of exploitability plotted against wall time in seconds.Our results show that in Kuhn poker, PDO algorithms outperform XODO, with all PDO algorithms exhibiting similar performance.", "Among the PDO algorithms, we found that PDO with periodicity 100 performs slightly better than the other PDO algorithms."], "citing_paper_content": {"title": "Regret-Minimizing Double Oracle For Extensive-Form Games", "abstract": "By incorporating regret minimization, double oracle methods have demonstrated rapid convergence to Nash Equilibrium (NE) in normal-form games and extensive-form games, through algorithms such as online double oracle (ODO) and extensive-form double oracle (XDO), respectively. In this study, we further examine the theoretical convergence rate and sample complexity of such regret minimization-based double oracle methods, utilizing a unified framework called Regret-Minimizing Double Oracle. Based on this framework, we extend ODO to extensive-form games and determine its sample complexity. Moreover, we demonstrate that the sample complexity of XDO can be exponential in the number of information sets |S|, owing to the exponentially decaying stopping threshold of restricted games. To solve this problem, we propose the Periodic Double Oracle (PDO) method, which has the lowest sample complexity among all existing double oracle methods, being only polynomial in |S|. Empirical evaluations on multiple poker and board games show that PDO achieves significantly faster convergence than previous double oracle algorithms and reaches a competitive level with state-of-theart regret minimization methods."}, "cited_paper_content": {"title": "Solving Large Imperfect Information Games Using Cfr+", "abstract": "Counterfactual Regret Minimization and variants (e.g. Public Chance Sampling CFR and Pure CFR) have been known as the best approaches for creating approximate Nash equilibrium solutions for imperfect information games such as poker. This paper introduces CFR$^+$, a new algorithm that typically outperforms the previously known algorithms by an order of magnitude or more in terms of computation time while also potentially requiring less memory."}, "keywords": ["regret minimization algorithms"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To achieve faster convergence in extensive-form games, the Periodic Double Oracle (PDO) method has been proposed, which has the lowest sample complexity among all existing double oracle methods, being only polynomial in the number of information sets. This method has been shown to outperform previous double oracle algorithms and reach a competitive level with state-of-the-art regret minimization methods #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To efficiently solve large imperfect information games such as Oshi Zumo, the authors propose using the CFR$^+$ algorithm introduced in the reference paper #REFR, which has been shown to outperform previous algorithms in terms of computation time and memory usage.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To implement regret minimization algorithms in extensive-form games, the authors of this study cite the use of CFR$^+$, a new algorithm that outperforms previously known algorithms in terms of computation time and memory usage #REFR.", "given_citation_intent": "method", "given_keywords": ["regret minimization algorithms"]}]}
{"citing_id": "2304.10550v1", "cited_id": "1409.1556", "section_title": "Pre-Trained Models", "citation": "It is designed for image classification tasks, and it has been trained on a large dataset, ImageNet, to recognize a variety of objects and scenes #REFR .", "text_before_citation": ["The pre-trained ResNet model is used as a meaningful residuals extractor, instead of features, from the raw data using identity shortcut connections #OTHEREFR .", "\u2022 GoogLeNet: also known as Inception-v1, is a deep CNN architecture developed by Google for the imageNet large-scale visual recognition challenge (ILSVRC).", "It is widely used for image classification tasks and has achieved state-of-the-art results on a variety of benchmarks #OTHEREFR .", "GoogLeNet has been employed as a source model, in #OTHEREFR , by retraining the last few layers of the network to adapt to the new task for DTL-based IDS.", "\u2022 VGG-16: is a 16 CNN layered architecture that was developed by the visual geometry group at the University of Oxford."], "text_after_citation": ["The IDS schemes with a dataset that can be converted to images (matrix) could employ VGG-16 as a backbone model.", "In #OTHEREFR , VGG-16 has been used as source model to build an efficient DTL-based IDS.", "\u2022 Le-Net: is a shallow CNN architecture that was developed by Yann LeCun and his colleagues in the late 1990s.", "It was one of the first deep-learning models applied to the task of image recognition and was used for handwritten digit recognition #OTHEREFR .", "The main reason behind the popularity of this model was its simple and straightforward CNN architecture."], "citing_paper_content": {"title": "Deep Transfer Learning Applications In Intrusion Detection Systems: A Comprehensive Review", "abstract": "Globally, the external Internet is increasingly being connected to the contemporary industrial control system. As a result, there is an immediate need to protect the network from several threats. The key infrastructure of industrial activity may be protected from harm by using an intrusion detection system (IDS), a preventive measure mechanism, to recognize new kinds of dangerous threats and hostile activities. The most recent artificial intelligence (AI) techniques used to create IDS in many kinds of industrial control networks are examined in this study, with a particular emphasis on IDS-based deep transfer learning (DTL). This latter can be seen as a type of information fusion that merge, and/or adapt knowledge from multiple domains to enhance the performance of the target task, particularly when the labeled data in the target domain is scarce. Publications issued after 2015 were taken into account. These selected publications were divided into three categories: DTL-only and IDS-only are involved in the introduction and background, and DTL-based IDS papers are involved in the core papers of this review. Researchers will be able to have a better grasp of the current state of DTL approaches used in IDS in many different types of networks by reading this review paper. Other useful information, such as the datasets used, the sort of DTL employed, the pre-trained network, IDS techniques, the evaluation metrics including accuracy/F-score and false alarm rate (FAR), and the improvement gained, were also covered. The algorithms, and methods used in several studies, or illustrate deeply and clearly the principle in any DTL-based IDS subcategory are presented to the reader."}, "cited_paper_content": {"title": "Very Deep Convolutional Networks For Large-Scale Image Recognition", "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."}, "keywords": ["ImageNet"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The authors retrained the last few layers of the GoogLeNet model to adapt to the new task for DTL-based IDS #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors utilized a deep CNN architecture with small convolution filters and achieved state-of-the-art results by increasing the depth to 16-19 weight layers #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors utilized an architecture with small convolution filters to achieve a significant improvement in accuracy by increasing the depth to 16-19 weight layers, as demonstrated in their submission to the ImageNet Challenge 2014, and their representations were shown to generalize well to other datasets, making their findings highly relevant to the current study on deep transfer learning applications in intrusion detection systems. #REFR", "given_citation_intent": "method", "given_keywords": ["ImageNet"]}]}
{"citing_id": "2303.02401v1", "cited_id": "1512.03012", "section_title": "B. Qualitative Results", "citation": "We also select objects from the ShapeNetCore dataset #REFR to analyze the capability of OpenAD to generalize to unseen object categories and new affordance labels. Generalization to New Affordance Labels.", "text_before_citation": ["We present several examples to demonstrate the generality and flexibility of OpenAD.", "Primarily, we use objects from the 3D AffordanceNet #OTHEREFR for our visualizations."], "text_after_citation": ["We illustrate several examples showing the ability of OpenAD to generalize to unseen affordance classes in Figure 3 .", "In the upper row of Figure 3 , we present the detection results of OpenAD for nine seen affordances on appropriate objects.", "As trained on these affordances, OpenAD produces good detection results.", "Next, for each object, we feed new affordance labels to the models while keeping the same corresponding object, and present the detection results in the two rows below.", "The visualization shows that OpenAD successfully detects the associated regions for the queried new affordance labels, even though the labels are not included in the training set."], "citing_paper_content": {"title": "Open-Vocabulary Affordance Detection In 3D Point Clouds", "abstract": "Affordance detection is a challenging problem with a wide variety of robotic applications. Traditional affordance detection methods are limited to a predefined set of affordance labels, hence potentially restricting the adaptability of intelligent robots in complex and dynamic environments. In this paper, we present the Open-Vocabulary Affordance Detection (OpenAD) method, which is capable of detecting an unbounded number of affordances in 3D point clouds. By simultaneously learning the affordance text and the point feature, OpenAD successfully exploits the semantic relationships between affordances. Therefore, our proposed method enables zero-shot detection and can detect previously unseen affordances without a single annotation example. Intensive experimental results show that OpenAD works effectively on a wide range of affordance detection setups and outperforms other baselines by a large margin. Additionally, we demonstrate the practicality of the proposed OpenAD in real-world robotic applications with a fast inference speed (\u2248 100 ms)."}, "cited_paper_content": {"title": "Shapenet: An Information-Rich 3D Model Repository", "abstract": "We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans."}, "keywords": ["new affordance labels", "ShapeNetCore dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We present several examples to demonstrate the generality and flexibility of OpenAD. Primarily, we use objects from the 3D AffordanceNet (Chang et al., 2015) #REFR for our visualizations.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To demonstrate the generality and flexibility of OpenAD, we use objects from the 3D AffordanceNet #OTHEREFR, which is a large-scale repository of shapes represented by 3D CAD models of objects, providing many semantic annotations for each 3D model, such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To detect new affordance labels in 3D point clouds, the authors utilized the ShapeNetCore dataset #REFR.", "given_citation_intent": "method", "given_keywords": ["new affordance labels", "ShapeNetCore dataset"]}]}
{"citing_id": "2303.09806v2", "cited_id": "1709.10087", "section_title": "Ii. Related Work", "citation": "We build our method upon DAPG #REFR , which is a two-stage learning strategy of behavior cloning and DRL for a grasping policy.", "text_before_citation": ["Unigrasp #OTHEREFR introduced the URDF model of the hand so that the work can be applied to different multifingered dexterous hands without retraining the model.", "The hand-object relationship mainly uses more global information, such as the distance between hand and object #OTHEREFR , #OTHEREFR , motor signals #OTHEREFR , etc.", "Though these descriptions work well in low-DoF grippers, they are limited for high-DoF dexterous grasping skills learning as restricted in capturing the interactions between the diverse object surfaces and complex hand articulations.", "ManipNet #OTHEREFR introduces handobject spatial representations to predict object manipulation trajectories given wrist trajectories by supervised learning for animations.", "Inspired by it, we propose to design more comprehensive hand-object interaction representations to empower reinforcement learning for dexterous grasping skills. Fig.2 shows the pipeline of our method."], "text_after_citation": ["The state-action pairs for our policy learning are prepared by retargeting the human grasp trajectories to a dexterous robotic hand.", "Therefore, our method consists of three stages: retargeting, behavior cloning, and reinforcement learning, which is elaborated in Section III-B.", "Our proposed state representation of the hand-object interaction for the policy is detailed in Section III-A."], "citing_paper_content": {"title": "Dexrepnet: Learning Dexterous Robotic Grasping Network With Geometric And Spatial Hand-Object Representations", "abstract": "Robotic dexterous grasping is a challenging problem due to the high degree of freedom (DoF) and complex contacts of multi-fingered robotic hands. Existing deep reinforcement learning (DRL) based methods leverage human demonstrations to reduce sample complexity due to the high dimensional action space with dexterous grasping. However, less attention has been paid to hand-object interaction representations for high-level generalization. In this paper, we propose a novel geometric and spatial hand-object interaction representation, named DexRep, to capture dynamic object shape features and the spatial relations between hands and objects during grasping. DexRep comprises Occupancy Feature for rough shapes within sensing range by moving hands, Surface Feature for changing hand-object surface distances, and Local-Geo Feature for local geometric surface features most related to potential contacts. Based on the new representation, we propose a dexterous deep reinforcement learning method to learn a generalizable grasping policy DexRepNet. Experimental results show that our method outperforms baselines using existing representations for robotic grasping dramatically both in grasp success rate and convergence speed. It achieves a 93% grasping success rate on seen objects and higher than 80% grasping success rates on diverse objects of unseen categories in both simulation and real-world experiments."}, "cited_paper_content": {"title": "Learning Complex Dexterous Manipulation With Deep Reinforcement Learning And Demonstrations", "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform multiple tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Thus, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL with natural policy gradients can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, and enable learning within the equivalent of a few hours of robot experience. We demonstrate successful policies for multiple complex tasks: object relocation, in-hand manipulation, tool use, and door opening."}, "keywords": ["grasping policy"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Inspired by ManipNet, we propose to design more comprehensive hand-object interaction representations to empower reinforcement learning for dexterous grasping skills #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To empower reinforcement learning for dexterous grasping skills, the authors proposed a novel geometric and spatial hand-object interaction representation, named DexRep, which captures dynamic object shape features and the spatial relations between hands and objects during grasping #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Inspired by the success of model-free DRL with natural policy gradients in scaling up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solving them from scratch in simulated experiments, the authors propose a dexterous deep reinforcement learning method to learn a generalizable grasping policy DexRepNet, which outperforms baselines using existing representations for robotic grasping dramatically both in grasp success rate and convergence speed #REFR.", "given_citation_intent": "method", "given_keywords": ["grasping policy"]}]}
{"citing_id": "2303.02610v1", "cited_id": "1505.07427", "section_title": "Training Details", "citation": "Our model is subjected to augmentation procedures to enhance its generalization, in line with the approach used in #REFR .", "text_before_citation": ["The Adam optimization algorithm is used to minimize the loss function with \u03b2 1 = 0.9, \u03b2 2 = 0.999, and = 10 \u221210 as the hyperparameters.", "The initial values of the loss parameters are established based on the characteristics of the dataset utilized.", "The batch size is set to 8, and the initial learning rate is \u03bb = 10 \u22124 .", "The learning rate decreases by 25% every 100 epochs for indoor localization and every 200 epochs for outdoor localization, with a maximum of 300 and 1000 epochs, respectively.", "Additionally, a weight decay of 10 \u22124 and a dropout of p = 0.1 are applied to the encoders during training."], "text_after_citation": ["During training, the image is resized so that its smaller edge is resized to 256 pixels and a random 224 \u00d7 224 crop is taken.", "Random adjustments are made to the brightness, contrast, and saturation of the image.", "During testing, the image is rescaled with the smaller edge resized to 256 pixels, and a center crop is taken without any further augmentation.", "The models were trained on multiple NVIDIA 2080T i GPUs and the PyTorch framework."], "citing_paper_content": {"title": "Hyperpose: Camera Pose Localization Using Attention Hypernetworks", "abstract": "In this study, we propose the use of attention hypernetworks in camera pose localization. The dynamic nature of natural scenes, including changes in environment, perspective, and lighting, creates an inherent domain gap between the training and test sets that limits the accuracy of contemporary localization networks. To overcome this issue, we suggest a camera pose regressor that integrates a hypernetwork. During inference, the hypernetwork generates adaptive weights for the localization regression heads based on the input image, effectively reducing the domain gap. We also suggest the use of a Transformer-Encoder as the hypernetwork, instead of the common multilayer perceptron, to derive an attention hypernetwork. The proposed approach achieves superior results compared to state-of-the-art methods on contemporary datasets. To the best of our knowledge, this is the first instance of using hypernetworks in camera pose regression, as well as using Transformer-Encoders as hypernetworks. We make our code publicly available 1 ."}, "cited_paper_content": {"title": "Posenet: A Convolutional Network For Real-Time 6-Dof Camera Relocalization", "abstract": "We present a robust and real-time monocular six degree of freedom relocalization system. Our system trains a convolutional neural network to regress the 6-DOF camera pose from a single RGB image in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking 5ms per frame to compute. It obtains approximately 2m and 3 degrees accuracy for large scale outdoor scenes and 0.5m and 5 degrees accuracy indoors. This is achieved using an efficient 23 layer deep convnet, demonstrating that convnets can be used to solve complicated out of image plane regression problems. This was made possible by leveraging transfer learning from large scale classification data. We show that the PoseNet localizes from high level features and is robust to difficult lighting, motion blur and different camera intrinsics where point based SIFT registration fails. Furthermore we show how the pose feature that is produced generalizes to other scenes allowing us to regress pose with only a few dozen training examples."}, "keywords": ["generalization", "model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To train the camera pose regressor, the authors of this study utilized an efficient 23 layer deep convnet and transfer learning from large scale classification data #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The camera pose regression method proposed in this study integrates a hypernetwork to generate adaptive weights for the localization regression heads based on the input image, effectively reducing the domain gap, and achieves superior results compared to state-of-the-art methods on contemporary datasets, as demonstrated by #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To solve the camera pose regression problem, the proposed approach leverages transfer learning from large scale classification data and uses an efficient 23 layer deep convnet, as demonstrated in #REFR, achieving superior results and generalization, which validates the effectiveness of the model.", "given_citation_intent": "method", "given_keywords": ["generalization", "model"]}]}
{"citing_id": "2304.11905v1", "cited_id": "0807.1997", "section_title": "B. Data-Driven Knowledge Fusion", "citation": "One crucial tool for utilizing this knowledge is the affinity matrix #REFR , where each element indicates the degree of association between two key samples.", "text_before_citation": ["The presence of redundant information is attributed to the random sampling method used in key sample acquisition, which results in the inclusion of non-key samples.", "Additionally, there may be mutual exclusivity between different key sample evaluation metrics, as the determination of whether a sample is a key sample or not may yield opposite results under different metrics.", "Our proposed solution is to model the correlation between the bag and the key instance set as well as the key bag set by using affinity matrixes.", "We then employ a mask to eliminate certain features and obtain the fusion bag.", "Specifically, we have now obtained three abstract knowledge B * i , I * , and B * , which contain valuable information, such as instances that trigger bag labels #OTHEREFR and bags that can build embedding functions #OTHEREFR ."], "text_after_citation": ["Specifically, the affinity matrix A I i between a given bag B i = {x ij } ni j=1 and I * is defined as:", "EQUATION", "where x * ij \u2208 B * and x * k \u2208 I * are the deep-level representations of x ij \u2208 B i and x ins k \u2208 I, respectively. Similarly, the affinity matrix A B", "i between B i and B * is calculated as:", "EQUATION"], "citing_paper_content": {"title": "Data-Driven Knowledge Fusion For Deep Multi-Instance Learning", "abstract": "Multi-instance learning (MIL) is a widely-applied technique in practical applications that involve complex data structures. MIL can be broadly categorized into two types: traditional methods and those based on deep learning. These approaches have yielded significant results, especially with regards to their problem-solving strategies and experimental validation, providing valuable insights for researchers in the MIL field. However, a considerable amount of knowledge is often trapped within the algorithm, leading to subsequent MIL algorithms that solely rely on the model's data fitting to predict unlabeled samples. This results in a significant loss of knowledge and impedes the development of more intelligent models. In this paper, we propose a novel data-driven knowledge fusion for deep multi-instance learning (DKMIL) algorithm. DKMIL adopts a completely different idea from existing deep MIL methods by analyzing the decision-making of key samples in the data set (referred to as the data-driven) and using the knowledge fusion module designed to extract valuable information from these samples to assist the model's training. In other words, this module serves as a new interface between data and the model, providing strong scalability and enabling the use of prior knowledge from existing algorithms to enhance the learning ability of the model. Furthermore, to adapt the downstream modules of the model to more knowledge-enriched features extracted from the datadriven knowledge fusion module, we propose a two-level attention module that gradually learns shallow-and deep-level features of the samples to achieve more effective classification. We will prove the scalability of the knowledge fusion module while also verifying the efficacy of the proposed architecture by conducting experiments on 38 data sets across 6 categories."}, "cited_paper_content": {"title": "Multi-Instance Learning By Treating Instances As Non-I.I.D. Samples", "abstract": "Previous studies on multi-instance learning typically treated instances in the bags as independently and identically distributed. The instances in a bag, however, are rarely independent in real tasks, and a better performance can be expected if the instances are treated in an non-i.i.d. way that exploits relations among instances. In this paper, we propose two simple yet effective methods. In the first method, we explicitly map every bag to an undirected graph and design a graph kernel for distinguishing the positive and negative bags. In the second method, we implicitly construct graphs by deriving affinity matrices and propose an efficient graph kernel considering the clique information. The effectiveness of the proposed methods are validated by experiments."}, "keywords": ["knowledge", "affinity matrix"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To model the correlation between the bag and the key instance set as well as the key bag set, affinity matrices are used in our proposed solution, which is inspired by the non-i.i.d. treatment of instances in multi-instance learning #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model the correlation between the bag and the key instance set, affinity matrices are used as proposed in #REFR, which treats instances as non-i.i.d. samples and exploits relations among instances.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To model the correlation between the bag and the key instance set as well as the key bag set, affinity matrices are used, as proposed in #REFR, which contain valuable information such as knowledge and can be used to eliminate certain features and obtain the fusion bag.", "given_citation_intent": "background", "given_keywords": ["knowledge", "affinity matrix"]}]}
{"citing_id": "2304.10446v1", "cited_id": "1902.02918", "section_title": "Sota Comparison Results", "citation": "We further note from Table 8 that for Gaussian smoothing #REFR , reducing the clean accuracy below 60% by increasing the noise level results in a drop in ACR, which does not happen in the proposed method.", "text_before_citation": ["As discussed in Section 4.5, we compare across different methods against fixed levels of clean accuracy set to the following -45%, 50%, 55%, 60%, 65%, 70% and 75%.", "As shown in Table 8 , the proposed approach has significantly higher ACR in all cases when compared to the baselines.", "The training parameters \u03c3 N and \u03c3 U are chosen to set the kurtosis of the Normal-Uniform distribution to a negative value (\u22120.22), which gives the relation between \u03c3 N and \u03c3 U as \u03c3 U = \u221a 3\u03c3 N /2.", "We further tune the hyper-parameter (\u03c3 N ) to achieve the required level of clean accuracy.", "Experimentally, a low value of \u03b2 \u2208 {2, 3, 4} for our proposed regularization (Equation 3) gives the best performance for the considered levels of clean accuracy."], "text_after_citation": ["In supplementary material, we present a detailed ablation study of the proposed method.", "We present the impact of variation in the hyperparameter \u03b2, impact of choice of regularizer and the effect of Kurtosis on the final performance of the certified classifier in terms of its clean accuracy, \u2113 1 ACR and \u2113 2 ACR."], "citing_paper_content": {"title": "Certified Adversarial Robustness Within Multiple Perturbation Bounds", "abstract": "Randomized smoothing (RS) is a well known certified defense against adversarial attacks, which creates a smoothed classifier by predicting the most likely class under random noise perturbations of inputs during inference. While initial work focused on robustness to \u2113 2 norm perturbations using noise sampled from a Gaussian distribution, subsequent works have shown that different noise distributions can result in robustness to other \u2113 p norm bounds as well. In general, a specific noise distribution is optimal for defending against a given \u2113 p norm based attack. In this work, we aim to improve the certified adversarial robustness against multiple perturbation bounds simultaneously. Towards this, we firstly present a novel certification scheme, that effectively combines the certificates obtained using different noise distributions to obtain optimal results against multiple perturbation bounds. We further propose a novel training noise distribution along with a regularized training scheme to improve the certification within both \u2113 1 and \u2113 2 perturbation norms simultaneously. Contrary to prior works, we compare the certified robustness of different training algorithms across the same natural (clean) accuracy, rather than across fixed noise levels used for training and certification. We also empirically invalidate the argument that training and certifying the classifier with the same amount of noise gives the best results. The proposed approach achieves improvements on the ACR (Average Certified Radius) metric across both \u2113 1 and \u2113 2 perturbation bounds. Code available at https://github.com/ val-iisc/NU-Certified-Robustness"}, "cited_paper_content": {"title": "Certified Adversarial Robustness Via Randomized Smoothing", "abstract": "We show how to turn any classifier that classifies well under Gaussian noise into a new classifier that is certifiably robust to adversarial perturbations under the $\\ell_2$ norm. This \"randomized smoothing\" technique has been proposed recently in the literature, but existing guarantees are loose. We prove a tight robustness guarantee in $\\ell_2$ norm for smoothing with Gaussian noise. We use randomized smoothing to obtain an ImageNet classifier with e.g. a certified top-1 accuracy of 49% under adversarial perturbations with $\\ell_2$ norm less than 0.5 (=127/255). No certified defense has been shown feasible on ImageNet except for smoothing. On smaller-scale datasets where competing approaches to certified $\\ell_2$ robustness are viable, smoothing delivers higher certified accuracies. Our strong empirical results suggest that randomized smoothing is a promising direction for future research into adversarially robust classification. Code and models are available at this http URL."}, "keywords": ["clean accuracy", "Gaussian"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "As shown in Table 8, the proposed approach has significantly higher ACR in all cases when compared to the baselines. The proposed approach builds upon the randomized smoothing technique for certified adversarial robustness #REFR, and presents a novel certification scheme that effectively combines the certificates obtained using different noise distributions to obtain optimal results against multiple perturbation bounds.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed approach achieves significantly higher Average Certified Radius (ACR) in all cases when compared to the baselines, as shown in Table 8, demonstrating its effectiveness in improving certified adversarial robustness against multiple perturbation bounds simultaneously. This is consistent with the findings in #REFR, where the authors showed that randomized smoothing is a promising direction for future research into adversarially robust classification.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed approach achieves significantly higher ACR in all cases when compared to the baselines, as shown in Table 8. This improvement is achieved by using a novel certification scheme that combines different noise distributions and a regularized training scheme that improves certification within both \u21131 and \u21132 perturbation norms simultaneously, as well as by comparing across different methods against fixed levels of clean accuracy. The results suggest that the proposed approach is a promising direction for future research into adversarially robust classification, especially when compared to existing certified defenses such as #REFR that only provide robustness to adversarial perturbations under the \u21132 norm and do not consider multiple perturbation bounds or clean accuracy.", "given_citation_intent": "result", "given_keywords": ["clean accuracy", "Gaussian"]}]}
{"citing_id": "2303.12029v1", "cited_id": "1908.10084", "section_title": "Features", "citation": "For each content feature, we encoded tweets with Sentence-BERT (SBERT) #REFR and compute their average embeddings as a user-level representation.", "text_before_citation": ["We use users' stances on wearing masks and racial equality as features to build a prediction model for their stance on Trump.", "In addition, we extract 1) content features from their historical tweets and 2) content-agnostic features from their profile and Twitterrelated statistics to perform an ablation study.", "7.1.1 Content Features. We used three content features for Trump stance prediction.", "We extracted mask and racial equality-related content features using their respective topic-related tweets.", "We also extracted historical content features using each user's most recent 100 tweets, excluding all topic-related tweets."], "text_after_citation": ["7.1.2 Content Agnostic Features.", "Twitter profile features were extracted from the profile description and URL listed in each user's profile.", "They were both encoded using SBERT and averaged to obtain user-level content-agnostic representation.", "Twitter statistics features include: 1) number of followers, 2) number of followings, 3) number of tweets posted by the user, 4) number of public lists that the user is a member of, 5) number of days since the creation of account, 6) whether the account protects its tweets, and 7) whether the account is verified."], "citing_paper_content": {"title": "Wearing Masks Implies Refuting Trump?: Towards Target-Specific User Stance Prediction Across Events In Covid-19 And Us Election 2020", "abstract": "People who share similar opinions towards controversial topics could form an echo chamber and may share similar political views toward other topics as well. The existence of such connections, which we call connected behavior, gives researchers a unique opportunity to predict how one would behave for a future event given their past behaviors. In this work, we propose a framework to conduct connected behavior analysis. Neural stance detection models are trained on Twitter data collected on three seemingly independent topics, i.e., wearing a mask, racial equality, and Trump, to detect people's stance, which we consider as their online behavior in each topic-related event. Our results reveal a strong connection between the stances toward the three topical events and demonstrate the power of past behaviors in predicting one's future behavior. CCS CONCEPTS \u2022 Applied computing \u2192 Sociology; \u2022 Computing methodologies \u2192 Natural language processing."}, "cited_paper_content": {"title": "Sentence-Bert: Sentence Embeddings Using Siamese Bert-Networks", "abstract": "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. ::: In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. ::: We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods."}, "keywords": ["tweets", "Sentence-BERT"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We extracted mask and racial equality-related content features using their respective topic-related tweets, and also used historical content features from each user's most recent 100 tweets, excluding all topic-related tweets (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To derive semantically meaningful sentence embeddings for stance detection, we used Sentence-BERT (SBERT) which is a modification of the pretrained BERT network that uses siamese and triplet network structures #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To extract historical content features from users' tweets, the authors used each user's most recent 100 tweets, excluding all topic-related tweets, and applied the Sentence-BERT method for deriving semantically meaningful sentence embeddings that can be compared using cosine-similarity. #REFR", "given_citation_intent": "method", "given_keywords": ["tweets", "Sentence-BERT"]}]}
{"citing_id": "2303.01424v1", "cited_id": "1903.07933", "section_title": "C. Offline Prediction Performance", "citation": "Similarly to the observations of Sch\u00f6ller et al. #REFR , we see that S-GAN's performance is mixed.", "text_before_citation": ["Sch\u00f6ller et al.", "#OTHEREFR compared the Average Displacement Error (ADE) and the Final Displacement Error (FDE) of S-GANbased prediction against CV prediction and CV prediction with added noise (CVN), showing that the latter ones perform comparably across the scenes in the ETH #OTHEREFR and UCY #OTHEREFR datasets. In Fig.", "2 , we compare their multistep prediction performance (i.e., the L2-norm between the predicted position and the ground truth at each timestep of prediction), which is informative for navigation tasks."], "text_after_citation": ["While it exhibits lower error on Zara1, it ties with CVN and CV on ETH-Uni and Zara2 and it is outperformed by them in Hotel, whereas on UCY-Uni all models perform comparably.", "It should be noted that the human behavior featured in these datasets mostly consists of linear segments that can be well approximated by CV/CVN whereas the S-GAN models promise a better generalization to more complex, nonlinear behavior."], "citing_paper_content": {"title": "From Crowd Motion Prediction To Robot Navigation In Crowds", "abstract": "We focus on robot navigation in crowded environments. To navigate safely and efficiently within crowds, robots need models for crowd motion prediction. Building such models is hard due to the high dimensionality of multiagent domains and the challenge of collecting or simulating interaction-rich crowd-robot demonstrations. While there has been important progress on models for offline pedestrian motion forecasting, transferring their performance on real robots is nontrivial due to close interaction settings and novelty effects on users. In this paper, we investigate the utility of a recent state-of-the-art motion prediction model (S-GAN) for crowd navigation tasks. We incorporate this model into a model predictive controller (MPC) and deploy it on a self-balancing robot which we subject to a diverse range of crowd behaviors in the lab. We demonstrate that while S-GAN motion prediction accuracy transfers to the real world, its value is not reflected on navigation performance, measured with respect to safety and efficiency; in fact, the MPC performs indistinguishably even when using a simple constantvelocity prediction model, suggesting that substantial model improvements might be needed to yield significant gains for crowd navigation tasks. Footage from our experiments can be found at https://youtu.be/mzFiXg8KsZ0."}, "cited_paper_content": {"title": "What The Constant Velocity Model Can Teach Us About Pedestrian Motion Prediction", "abstract": "Pedestrian motion prediction is a fundamental task for autonomous robots and vehicles to operate safely. In recent years many complex approaches based on neural networks have been proposed to address this problem. In this work we show that \u2013 surprisingly \u2013 a simple Constant Velocity Model can outperform even state-of-the-art neural models. This indicates that either neural networks are not able to make use of the additional information they are provided with, or that this information is not as relevant as commonly believed. Therefore, we analyze how neural networks process their input and how it impacts their predictions. Our analysis reveals pitfalls in training neural networks for pedestrian motion prediction and clarifies false assumptions about the problem itself. In particular, neural networks implicitly learn environmental priors that negatively impact their generalization capability, the motion history of pedestrians is irrelevant and interactions are too complex to predict. Our work shows how neural networks for pedestrian motion prediction can be thoroughly evaluated and our results indicate which research directions for neural motion prediction are promising in future."}, "keywords": ["S-GAN's performance", "observations"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Sch\u00f6ller et al. compared the multistep prediction performance of S-GAN-based prediction against CV prediction and CV prediction with added noise (CVN), showing that the latter ones perform comparably across the scenes in the ETH and UCY datasets. This comparison is informative for navigation tasks, and suggests that a simple Constant Velocity Model can be used for pedestrian motion prediction, as shown in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Sch\u00f6ller et al. compared the performance of S-GAN-based prediction against CV prediction and CV prediction with added noise (CVN), showing that the latter ones perform comparably across the scenes in the ETH and UCY datasets, indicating that a simple Constant Velocity Model can outperform even state-of-the-art neural models in pedestrian motion prediction (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Sch\u00f6ller et al. compared the multistep prediction performance of S-GAN-based prediction against CV prediction and CV prediction with added noise (CVN), and observed that the latter ones perform comparably across the scenes in the ETH and UCY datasets, indicating that S-GAN's performance is not significantly better than that of a simple constant velocity model. #REFR", "given_citation_intent": "result", "given_keywords": ["S-GAN's performance", "observations"]}]}
{"citing_id": "2304.01974v1", "cited_id": "2003.06713", "section_title": "Baseline Approaches", "citation": "For autoregressive S4, when we followed the Long-T5 method, we found it to highly unstable and failed to converge, similar to what was found in the literature #REFR on its dependency certain keywords e.g., true/false.", "text_before_citation": ["Autoregressive re-ranker. We also consider autoregressive re-rankers #OTHEREFR .", "For a transformer baseline, we use a pre-trained LongT5 #OTHEREFR .", "The query and the document are concatenated together to form the input sequence: Query: d Document: q i Relevant:, which is fed into the encoder.", "The decoder then predicts true for relevant documents or false for irrelevant documents.", "During inference, a softmax function is applied to the logits of the true and the false tokens to normalize the results across multiple queries."], "text_after_citation": ["Therefore, we followed the same setting as in the cross-encoder, except that the underlying model is autoregressive rather than bi-directional.", "Here, the concatenated dialogue and a candidate question are fed into the S4 re-ranker and the average pooling of the last layer is classified as either relevant or irrelevant through a classification head."], "citing_paper_content": {"title": "Dialogue-Contextualized Re-Ranking For Medical History-Taking", "abstract": "AI-driven medical history-taking is an important component in symptom checking, automated patient intake, triage, and other AI virtual care applications. As historytaking is extremely varied, machine learning models require a significant amount of data to train. To overcome this challenge, existing systems are developed using indirect data or expert knowledge. This leads to a training-inference gap as models are trained on different kinds of data than what they observe at inference time. In this work, we present a two-stage re-ranking approach that helps close the training-inference gap by re-ranking the first-stage question candidates using a dialogue-contextualized model. For this, we propose a new model, global re-ranker, which cross-encodes the dialogue with all questions simultaneously, and compare it with several existing neural baselines. We test both transformer and S4-based language model backbones. We find that relative to the expert system, the best performance is achieved by our proposed global re-ranker with a transformer backbone, resulting in a 30% higher normalized discount cumulative gain (nDCG) and a 77% higher mean average precision (mAP). As part of this work, we also release pre-trained checkpoints for bi-directional and autoregressive S4 models trained on Wikipedia and PubMed data."}, "cited_paper_content": {"title": "Document Ranking With A Pretrained Sequence-To-Sequence Model", "abstract": "This work proposes a novel adaptation of a pretrained sequence-to-sequence model to the task of document ranking. Our approach is fundamentally different from a commonly-adopted classification-based formulation of ranking, based on encoder-only pretrained transformer architectures such as BERT. We show how a sequence-to-sequence model can be trained to generate relevance labels as\"target words\", and how the underlying logits of these target words can be interpreted as relevance probabilities for ranking. On the popular MS MARCO passage ranking task, experimental results show that our approach is at least on par with previous classification-based models and can surpass them with larger, more-recent models. On the test collection from the TREC 2004 Robust Track, we demonstrate a zero-shot transfer-based approach that outperforms previous state-of-the-art models requiring in-dataset cross-validation. Furthermore, we find that our approach significantly outperforms an encoder-only model in a data-poor regime (i.e., with few training examples). We investigate this observation further by varying target words to probe the model's use of latent knowledge."}, "keywords": ["autoregressive S4", "certain keywords"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For a transformer baseline, we use a pre-trained LongT5 #REFR. The query and the document are concatenated together to form the input sequence: Query: d Document: q i Relevant:, which is fed into the encoder. The decoder then predicts true for relevant documents or false for irrelevant documents. During inference, a softmax function is applied to the logits of the true and the false tokens to normalize the results across multiple queries. Our approach is similar to the one proposed in the reference paper \"Document Ranking With A Pretrained Sequence-To-Sequence Model\". #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our proposed global re-ranker with a transformer backbone achieved a 30% higher normalized discount cumulative gain (nDCG) and a 77% higher mean average precision (mAP) compared to the expert system #REFR, demonstrating the effectiveness of our approach in closing the training-inference gap.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For an autoregressive S4-based language model backbone, pre-training on Wikipedia and PubMed data has been shown to improve performance on medical history-taking, achieving a 30% higher normalized discount cumulative gain and a 77% higher mean average precision compared to an expert system #REFR.", "given_citation_intent": "result", "given_keywords": ["autoregressive S4", "certain keywords"]}]}
{"citing_id": "2304.12036v1", "cited_id": "1710.02971", "section_title": "Connection To Skip-Gram Embedding Methods", "citation": "As in Table 1 in #REFR , we can expect the same theoretical properties w.r.t.", "text_before_citation": ["This theorem shows that the node with the highest bridgeness inG r is also the node with the largest importance score (thus, node-level explanation for W) for the DeepWalk embedding over G.", "In the Appendix, we outline how the same node is also likely to have the highest bridgeness score in G (i.e., arg max", "v j \u2208V Bridgeness(v j |C,G r ) arg max v j \u2208V Bridgeness(v j |C, G)).", "Other embedding models such as LINE, PTE, and struc2vec can be analyzed in the same way.", "For LINE and PTE, similar theoretical approximations were studied in #OTHEREFR ."], "text_after_citation": ["perturbation for both LINE #OTHEREFR and PTE #OTHEREFR because our perturbation method does not change degree matrices and other constants.", "struc2vec #OTHEREFR learns low-dimensional representations using a Skip-gram architecture on the context graph, which is constructed by structural similarity among nodes.", "When input adjacency is assumed as the context graph, its bridge nodes are still important as in DeepWalk.", "Similarly, RWJBG #OTHEREFR learns node embeddings on joint behavior graphs under the same Skip-gram framework and our analysis remains applicable.", "UserItem2vec #OTHEREFR also constructs an attributed heterogeneous user/item network and the embeddings are learned on the Skip-gram architecture; the most important nodes are identifiable under our proposed idea."], "citing_paper_content": {"title": "Generating Post-Hoc Explanations For Skip-Gram-Based Node Embeddings By Identifying Important Nodes With Bridgeness", "abstract": "Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk [1], LINE [2], struc2vec [3], PTE [4], UserItem2vec [5], and RWJBG [6] have emerged from the Skip-gram model [7] and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing posthoc explanations of Skip-gram-based embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top-q global explanations about learned graph embedding vectors more efficiently. Experiments show that the ranking of nodes by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We also observe that the top-q node-level explanations selected by GRAPH-wGD have higher importance scores and produce more changes in class label prediction when perturbed, compared with the nodes selected by recent alternatives, using five real-world graphs."}, "cited_paper_content": {"title": "Network Embedding As Matrix Factorization: Unifying Deepwalk, Line, Pte, And Node2Vec", "abstract": "Since the invention of word2vec, the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk empirically produces a low-rank transformation of a network's normalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk when the size of vertices' context is set to one; (3) As an extension of LINE, PTE can be viewed as the joint factorization of multiple networks\u00bb Laplacians; (4) node2vec is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning."}, "keywords": ["theoretical properties"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Other embedding models such as LINE, PTE, and struc2vec can be analyzed in the same way. For LINE and PTE, similar theoretical approximations were studied in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The analysis and proofs in #REFR reveal that DeepWalk produces a low-rank transformation of a network's normalized Laplacian matrix, which is empirically validated and can be used for conventional network mining tasks, providing a significant improvement over LINE.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Theoretical approximations for LINE and PTE similar to those studied in #OTHEREFR can be applied to DeepWalk, and all these models can be unified into the matrix factorization framework with closed forms, as shown in the reference paper.", "given_citation_intent": "result", "given_keywords": ["theoretical properties"]}]}
{"citing_id": "2303.00045v1", "cited_id": "1004.4389", "section_title": "A First Look At Random Points", "citation": "In [25, Theorem 2.1], Moeller and Ullrich proved the following concentration inequality for the smallest and largest eigenvalue of such random Gram matrices. The result is based on Tropp #REFR .", "text_before_citation": ["and note that", "(Lx) j = d k=1 f | e k e k (\u03be j ) = f (\u03be j )", "for j = 1, . . . , N . Thus the inequality (3.1) can be rewritten as", "(3.3) (1 \u2212 \u03b7) x 2 R d ,2 \u2264 1 \u221a N Lx 2 R N ,2 \u2264 (1 + \u03b7) x 2 R d ,2 .", "Obviously, the best possible constants 1 \u00b1 \u03b7 in (3.3) are given by the minimal resp. maximal eigenvalue of 1 N L * L."], "text_after_citation": ["Theorem 3.1.", "Let s, N, M \u2208 N, t \u2208 ]0, 1[, \u2126 \u2286 R s a", "set, a probability measure on \u2126 and (e k ) D k=1 be an orthonormal system in L 2 (\u2126, ). Let \u03be 1 , . . . , \u03be N \u2208 \u2126 be drawn i.i.d.", "according to , L = (e k (\u03be j )) N,D j,k=1 , and P = \u2297N the product measure.", "Then the following concentration inequalities for the extremal eigenvalues of 1"], "citing_paper_content": {"title": "Marcinkiewicz-Zygmund Inequalities For Scattered And Random Data On The Q-Sphere", "abstract": "The recovery of multivariate functions and estimating their integrals from finitely many samples is one of the central tasks in modern approximation theory. Marcinkiewicz-Zygmund inequalities provide answers to both the recovery and the quadrature aspect. In this paper, we put ourselves on the q-dimensional sphere S q , and investigate how well continuous Lp-norms of polynomials f of maximum degree n on the sphere S q can be discretized by positively weighted Lp-sum of finitely many samples, and discuss the relationship between the offset between the continuous and discrete quantities, the number and distribution of the (deterministic or randomly chosen) sample points \u03be 1 ,. .. , \u03be N on S q , the dimension q, and the polynomial degree n."}, "cited_paper_content": {"title": "User-Friendly Tail Bounds For Sums Of Random Matrices", "abstract": "This paper presents new probability inequalities for sums of independent, random, self-adjoint matrices. These results place simple and easily verifiable hypotheses on the summands, and they deliver strong conclusions about the large-deviation behavior of the maximum eigenvalue of the sum. Tail bounds for the norm of a sum of random rectangular matrices follow as an immediate corollary. The proof techniques also yield some information about matrix-valued martingales. ::: ::: In other words, this paper provides noncommutative generalizations of the classical bounds associated with the names Azuma, Bennett, Bernstein, Chernoff, Hoeffding, and McDiarmid. The matrix inequalities promise the same diversity of application, ease of use, and strength of conclusion that have made the scalar inequalities so valuable."}, "keywords": ["following concentration inequality", "random Gram matrices"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The proof techniques presented in #REFR provide new probability inequalities for sums of independent, random, self-adjoint matrices, which yield strong conclusions about the large-deviation behavior of the maximum eigenvalue of the sum and promise the same diversity of application, ease of use, and strength of conclusion that have made the scalar inequalities so valuable.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The inequality (3.1) can be rewritten in terms of matrix-valued martingales, and the proof techniques in the reference paper #REFR can provide further insights into the large-deviation behavior of the maximum eigenvalue of the sum.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "These concentration inequalities are similar to those presented in the reference paper #REFR, which provides probability inequalities for sums of independent, random, self-adjoint matrices, including tail bounds for the norm of a sum of random rectangular matrices, and noncommutative generalizations of classical bounds associated with Azuma, Bennett, Bernstein, Chernoff, Hoeffding, and McDiarmid, as well as some information about matrix-valued martingales.", "given_citation_intent": "background", "given_keywords": ["following concentration inequality", "random Gram matrices"]}]}
{"citing_id": "2304.11790v1", "cited_id": "1602.06662", "section_title": "A.4.2 Copy Memory Task", "citation": "This task is designed to be extremely difficult for the vanilla RNN due to the VGP #REFR .", "text_before_citation": ["Copy memory is a synthetic many-to-many classification task first introduced in #OTHEREFR to test the ability to recall information bits after a very long delay."], "text_after_citation": ["Input samples contain the alphabets 2-9, and the blank and start letters 0, 1, are one-hot encoded into vectors of dim 10.", "The recalling sequence A contains the first K letters of the input and are uniformly sampled from the alphabet.", "It is followed by L blank letters, 1 start letter, and another K \u2212 1 blank letters.", "An output sample contains K + L + 1 blanks letter and the recalling sequence A.", "The baseline model output K + L + 1 blanks letter and another K \u2212 1 letters sampled uniformly of the alphabet, which has the loss of K ln 8 L+2K ."], "citing_paper_content": {"title": "Adaptive-Saturated Rnn: Remember More With Less Instability", "abstract": "Orthogonal parameterization is a compelling solution to the vanishing gradient problem (VGP) in recurrent neural networks (RNNs). With orthogonal parameters and non-saturated activation functions, gradients in such models are constrained to unit norms. On the other hand, although the traditional vanilla RNNs are seen to have higher memory capacity, they suffer from the VGP and perform badly in many applications. This work proposes Adaptive-Saturated RNNs (asRNN), a variant that dynamically adjusts its saturation level between the two mentioned approaches. Consequently, asRNN enjoys both the capacity of a vanilla RNN and the training stability of orthogonal RNNs. Our experiments show encouraging results of asRNN on challenging sequence learning benchmarks compared to several strong competitors. The research code is accessible at https://github.com/ndminhkhoi46/asRNN/."}, "cited_paper_content": {"title": "Recurrent Orthogonal Networks And Long-Memory Tasks", "abstract": "Although RNNs have been shown to be powerful tools for processing sequential data, finding architectures or optimization strategies that allow them to model very long term dependencies is still an active area of research. In this work, we carefully analyze two synthetic datasets originally outlined in (Hochreiter and Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store information over many time steps. We explicitly construct RNN solutions to these problems, and using these constructions, illuminate both the problems themselves and the way in which RNNs store different types of information in their hidden states. These constructions furthermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices."}, "keywords": ["RNN"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Copy memory is a synthetic many-to-many classification task first introduced in (Hochreiter and Schmidhuber, 1997) to test the ability to recall information bits after a very long delay. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Copy memory is a synthetic many-to-many classification task first introduced in (Hochreiter and Schmidhuber, 1997) to test the ability to recall information bits after a very long delay, providing background information on the evaluation of RNNs' ability to store information over many time steps. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Copy memory is a synthetic many-to-many classification task first introduced in (Hochreiter and Schmidhuber, 1997) to test the ability of RNNs to recall information bits after a very long delay. #REFR", "given_citation_intent": "background", "given_keywords": ["RNN"]}]}
{"citing_id": "2305.02932v1", "cited_id": "1502.03044", "section_title": "Image Captioners", "citation": "An attention mechanism #REFR is equipped between the encoder and decoder, and features of each part of the image are selectively sent to the decoder.", "text_before_citation": ["We focused on three image captioning models.", "None of them were fine-tuned using the data for the target task (because no image description text was available for the target task), and the original models were used as it is.", "InceptionV3+RNN: This is a basic model of small scale that encodes an input image into a vector by using Incep-tionV3 #OTHEREFR and then decodes it to generate a caption using a recurrent neural network (Gated Recurrent Unit; GRU #OTHEREFR )."], "text_after_citation": ["The entire system was trained with the MS-COCO dataset #OTHEREFR . We followed Ten-sorFlow's tutorial implementation #OTHEREFR .", "BLIP: This is a foundation model that has learned a large number of images and amount of text and is applicable to a wide range of Vision and Language tasks #OTHEREFR .", "When used as an image captioner, it takes the form of an encoder-decoder configuration based on the Transformer model.", "Users can easily run the sample code (demo.ipynb) on GitHub #OTHEREFR to obtain captions for their own images.", "BLIP is a relatively advanced, large-scale model that is capable of producing quite accurate captions."], "citing_paper_content": {"title": "Image Captioners Sometimes Tell More Than Images They See", "abstract": "Image captioning, a.k.a. \"image-to-text,\" which generates descriptive text from given images, has been rapidly developing throughout the era of deep learning. To what extent is the information in the original image preserved in the descriptive text generated by an image captioner? To answer that question, we have performed experiments involving the classification of images from descriptive text alone, without referring to the images at all, and compared results with those from standard image-based classifiers. We have evaluate several image captioning models with respect to a disaster image classification task, CrisisNLP, and show that descriptive text classifiers can sometimes achieve higher accuracy than standard image-based classifiers. Further, we show that fusing an image-based classifier with a descriptive text classifier can provide improvement in accuracy."}, "cited_paper_content": {"title": "Show, Attend And Tell: Neural Image Caption Generation With Visual Attention", "abstract": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO."}, "keywords": ["encoder", "attention mechanism"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "One of the models we focused on is an attention-based model that automatically learns to describe the content of images, as introduced in the reference paper \"Show, Attend And Tell: Neural Image Caption Generation With Visual Attention\" #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To provide additional context on attention-based models in image captioning, the authors cite the paper \"Show, Attend And Tell: Neural Image Caption Generation With Visual Attention\" #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To encode an input image into a vector, one of the models used in this study employed InceptionV3 #OTHEREFR, while another model utilized an attention mechanism to automatically learn to describe the content of images #REFR.", "given_citation_intent": "background", "given_keywords": ["encoder", "attention mechanism"]}]}
{"citing_id": "2303.11434v1", "cited_id": "1801.10193", "section_title": "Deep-Cpi [8]:", "citation": "They suggested that, since the full-length sequence was used, the biologically important short subsequences that would be more powerful at representing the protein were lost due the low signal to noise ratio #REFR .", "text_before_citation": ["Furthermore, by using the obtained weights, the neural attention mechanism provides clear visualizations, which makes models easier to analyze even when modeling is performed using real-valued vector representations rather than discrete features.", "In their experiments using three CPI datasets #OTHEREFR , they demonstrated that the proposed approach based on end-to-end learning of GNN and CNN can achieve competitive or higher performance than existing approaches.", "WideDTA #OTHEREFR : They propose a methodology to predict protein-ligand binding affinity through text-only information of both proteins and compounds.", "Without relying on 3D structure information of the complex or 2D", "representation of the compound, they learn high dimensional features from sequences of the proteins and ligands."], "text_after_citation": ["In order to overcome this problem, they propose to integrate different pieces of text-based information in the WideDTA model to provide a better representation of the interaction.", "They still utilize the protein sequence and ligand SMILES string by representing them as a set of words.", "A word of a protein sequence corresponds to a three-residue subsequence,", "whereas a word of a ligand is equal to an 8-character subsequence extracted with a sliding window approach #OTHEREFR .", "In addition, they use two textual information sources that can provide valuable clues about the specificity of the interaction."], "citing_paper_content": {"title": "Resdta: Predicting Drug-Target Binding Affinity Using Residual Skip Connections", "abstract": "I would like to thank Almighty as I have been able to successfully complete my thesis work. I am indebted to my supervisor, Professor Dr. Md. Aynal Haque, whose expertise was invaluable in formulating the research questions and methodology. I would like to thank him for his guidance, assistance and patience throughout this research. Without his support and encouragement, it would not have been possible to complete the research work. His insightful feedback pushed me to sharpen my thinking and brought this work to a higher level. I am very lucky that I have got the opportunity to work under his supervision. I would also like to thank my senior Udoy Kamal and friend Proteeti Ghosh to constantly support me throughout the thesis and motivated me a lot."}, "cited_paper_content": {"title": "Deepdta: Deep Drug\u2010Target Binding Affinity Prediction", "abstract": "Motivation The identification of novel drug\u2010target (DT) interactions is a substantial part of the drug discovery process. Most of the computational methods that have been proposed to predict DT interactions have focused on binary classification, where the goal is to determine whether a DT pair interacts or not. However, protein\u2010ligand interactions assume a continuum of binding strength values, also called binding affinity and predicting this value still remains a challenge. The increase in the affinity data available in DT knowledge\u2010bases allows the use of advanced learning techniques such as deep learning architectures in the prediction of binding affinities. In this study, we propose a deep\u2010learning based model that uses only sequence information of both targets and drugs to predict DT interaction binding affinities. The few studies that focus on DT binding affinity prediction use either 3D structures of protein\u2010ligand complexes or 2D features of compounds. One novel approach used in this work is the modeling of protein sequences and compound 1D representations with convolutional neural networks (CNNs). Results The results show that the proposed deep learning based model that uses the 1D representations of targets and drugs is an effective approach for drug target binding affinity prediction. The model in which high\u2010level representations of a drug and a target are constructed via CNNs achieved the best Concordance Index (CI) performance in one of our larger benchmark datasets, outperforming the KronRLS algorithm and SimBoost, a state\u2010of\u2010the\u2010art method for DT binding affinity prediction. Availability and implementation https://github.com/hkmztrk/DeepDTA Supplementary information Supplementary data are available at Bioinformatics online."}, "keywords": ["biologically important short", "protein"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "WideDTA proposed a methodology to predict protein-ligand binding affinity through text-only information of both proteins and compounds, achieving competitive or higher performance than existing approaches #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "WideDTA proposed a deep-learning based model that uses only sequence information of both targets and drugs to predict drug target interaction binding affinities, achieving the best Concordance Index (CI) performance in one of the larger benchmark datasets, outperforming the KronRLS algorithm and SimBoost, a state-of-the-art method for DT binding affinity prediction #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed deep learning based model that uses the 1D representations of targets and drugs is an effective approach for drug target binding affinity prediction, as demonstrated by WideDTA, which learned high dimensional features from sequences of the proteins and ligands, without relying on 3D structure information of the complex or 2D representation of the compound, making it biologically important short for protein-ligand binding affinity prediction. #REFR", "given_citation_intent": "background", "given_keywords": ["biologically important short", "protein"]}]}
{"citing_id": "2303.08312v1", "cited_id": "1010.0316", "section_title": "I. Introduction", "citation": "Later, an exhaustive search for finding the optimal rotation of the signal constellation was presented in #REFR .", "text_before_citation": ["These constellations are defined for point-to-point systems #OTHEREFR - #OTHEREFR and their constellation shaping is oblivious to interference.", "Such an inability to respond to interference is an obstacle to improving the biterror rate and spectral efficiency of today's interference-limited communication systems.", "In this paper, we consider the two-user one-sided IC, also known as the Z-interference channel (ZIC) #OTHEREFR , with imperfect CSI.", "Previous works have examined the ZIC with finite alphabet inputs and uniform constellations in certain regimes.", "In #OTHEREFR , it is shown that rotating one input constellation (alphabet) can improve the sum-rate of the two-user IC in strong/very strong interference regimes."], "text_after_citation": ["The focus of the above papers is to maximize the achievable rates, and they do not study bit-error rate (BER) performance.", "BER is a critical metric, and interference can severely increase the BER by distorting the received constellation when uniform constellations like QAM are employed.", "Deep autoencoder (DAE)-based end-to-end communication is an emerging approach to finite-alphabet communication in which BER is the main performance measure and constellation design is inherent to it.", "Various groups have proposed DAEbased communication both for single-and multi-user systems #OTHEREFR - #OTHEREFR .", "Particularly, #OTHEREFR , #OTHEREFR , #OTHEREFR have studied communication over the IC."], "citing_paper_content": {"title": "Interference-Aware Constellation Design For Z-Interference Channels With Imperfect Csi", "abstract": "A deep autoencoder (DAE)-based end-to-end communication over the two-user Z-interference channel (ZIC) with finite-alphabet inputs is designed in this paper. The design is for imperfect channel state information (CSI) where both estimation and quantization errors exist. The proposed structure jointly optimizes the encoders and decoders to generate interferenceaware constellations that adapt their shape to the interference intensity in order to minimize the bit error rate. A normalization layer is designed to guarantee an average power constraint in the DAE while allowing the architecture to generate constellations with nonuniform shapes. This brings further shaping gain compared to standard uniform constellations such as quadrature amplitude modulation. The performance of the DAE-ZIC is compared with two conventional methods, i.e., standard and rotated constellations. The proposed structure significantly enhances the performance of the ZIC. Simulation results confirm bit error rate reduction in all interference regimes (weak, moderate, and strong). At a signal-to-noise ratio of 20dB, the improvements reach about two orders of magnitude when only quantization error exists, indicating that the DAE-ZIC is highly robust to the interference compared to the conventional methods."}, "cited_paper_content": {"title": "Two-User Gaussian Interference Channel With Finite Constellation Input And Fdma", "abstract": "In the two-user Gaussian Strong Interference Channel (GSIC) with finite constellation inputs, it is known that relative rotation between the constellations of the two users enlarges the Constellation Constrained (CC) capacity region. In this paper, a metric for finding the approximate angle of rotation (with negligibly small error) to maximally enlarge the CC capacity for the two-user GSIC is presented. In the case of Gaussian input alphabets with equal powers for both the users and the modulus of both the cross-channel gains being equal to unity, it is known that the FDMA rate curve touches the capacity curve of the GSIC. It is shown that, with unequal powers for both the users also, when the modulus of one of the cross-channel gains being equal to one and the modulus of the other cross-channel gain being greater than or equal to one, the FDMA rate curve touches the capacity curve of the GSIC. On the contrary, it is shown that, under finite constellation inputs, with both the users using the same constellation, the FDMA rate curve strictly lies within (never touches) the enlarged CC capacity region throughout the strong-interference regime. This means that using FDMA it is impossible to go close to the CC capacity. It is well known that for the Gaussian input alphabets, the FDMA inner-bound, at the optimum sum-rate point, is always better than the simultaneous-decoding inner-bound throughout the weak-interference regime. For a portion of the weak interference regime, it is shown that with identical finite constellation inputs for both the users, the simultaneous-decoding inner-bound, enlarged by relative rotation between the constellations, is strictly better than the FDMA inner-bound."}, "keywords": ["signal constellation"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In #REFR, the authors present a metric for finding the approximate angle of rotation to maximally enlarge the Constellation Constrained (CC) capacity for the two-user Gaussian Strong Interference Channel (GSIC) with finite constellation inputs, which can be used to improve the performance of interference-limited communication systems such as the two-user Z-interference channel (ZIC) considered in this paper.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In #REFR, a metric for finding the approximate angle of rotation to maximally enlarge the Constellation Constrained (CC) capacity for the two-user Gaussian Strong Interference Channel (GSIC) with finite constellation inputs is presented, which can be used to improve the bit error rate and spectral efficiency of interference-limited communication systems such as the two-user Z-interference channel (ZIC) considered in this paper.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "In #REFR, the authors present a metric for finding the approximate angle of rotation to maximally enlarge the Constellation Constrained (CC) capacity for the two-user Gaussian Strong Interference Channel (GSIC) with finite constellation inputs, which could be useful for improving the signal constellation design in interference-limited communication systems.", "given_citation_intent": "background", "given_keywords": ["signal constellation"]}]}
{"citing_id": "2303.05686v1", "cited_id": "1905.04176", "section_title": "Comparison With Other Methods", "citation": "Our results were achieved with simple data augmentations, although using more extensive simulations, such as those in #REFR , could lead to greater generalizability.", "text_before_citation": ["For diffusion tensor fitting, Table 1 shows that the Swin model achieves lower MAE than BM4D in all metrics in white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) in both the HCP and TBI test datasets without finetuning.", "For the SPIN dataset, the Swin model outperforms BM4D, except for FA estimation in GM and CSF; however, applying no denoising outperforms both BM4D and the Swin model for MD estimation in CSF possibly because of noise due to motion left uncorrected after Eddy. Qualitative comparison in Fig.", " 2 is consistent with these quantitative results and shows that the Swin model is able to capture more of the finer features in the WM and GM microstructure without the excessive smoothing of BM4D.", "For 4 th and 6 th order spherical harmonic fitting, Table 2 shows that the Swin model achieves the lowest JSD in GM and CSF across all datasets.", "The Swin model performs worse than MPPCA in WM for 6 th order spherical harmonic fitting, even in HCP data, possibly because the model is underfitted (due to compute constraints only five training epochs could be completed) and also because the Swin model denoises one direction at a time, whereas MPPCA is able to collectively denoise all directions."], "text_after_citation": ["In addition, by processing each dMRI volume separately, we are able to consider the full brain volume but do not utilize the correlation across volumes, such as the transformer patch-based approach in #OTHEREFR .", "Due to GPU memory constraints, a trade-off exists between utilizing spatial and angular correlations.", "Finally, Swin transformers can efficiently capture long-range dependencies, but require more extensive pretraining when compared to CNNs, which is integral to the success of our approach #OTHEREFR ."], "citing_paper_content": {"title": "Generalized Diffusion Mri Denoising And Super-Resolution Using Swin Transformers", "abstract": "Diffusion MRI is a non-invasive, in-vivo medical imaging method able to map tissue microstructure and structural connectivity of the human brain, as well as detect changes, such as brain development and injury, not visible by other clinical neuroimaging techniques. However, acquiring high signal-to-noise ratio (SNR) datasets with high angular and spatial sampling requires prohibitively long scan times, limiting usage in many important clinical settings, especially children, the elderly, and emergency patients with acute neurological disorders who might not be able to cooperate with the MRI scan without conscious sedation or general anesthesia. Here, we propose to use a Swin UNEt TRansformers (Swin UNETR) model, trained on augmented Human Connectome Project (HCP) data and conditioned on registered T1 scans, to perform generalized denoising and super-resolution of diffusion MRI invariant to acquisition parameters, patient populations, scanners, and sites. We qualitatively demonstrate super-resolution with artificially downsampled HCP data in normal adult volunteers. Our experiments on two other unrelated datasets, one of children with neurodevelopmental disorders and one of traumatic brain injury patients, show that our method demonstrates superior denoising despite wide data distribution shifts. Further improvement can be achieved via finetuning with just one additional subject. We apply our model to diffusion tensor (2 nd order spherical harmonic) and higher-order spherical harmonic coefficient estimation and show results superior to current state-of-the-art methods. Our method can be used out-of-the-box or minimally finetuned to denoise and superresolve a wide variety of diffusion MRI datasets. The code and model are publicly available at https://github.com/ucsfncl/dmri-swin."}, "cited_paper_content": {"title": "Training A Neural Network For Gibbs And Noise Removal In Diffusion Mri", "abstract": "We develop and evaluate a neural network-based method for Gibbs artifact and noise removal. A convolutional neural network (CNN) was designed for artifact removal in diffusion-weighted imaging data. Two implementations were considered: one for magnitude images and one for complex images. Both models were based on the same encoder-decoder structure and were trained by simulating MRI acquisitions on synthetic non-MRI images. Both machine learning methods were able to mitigate artifacts in diffusion-weighted images and diffusion parameter maps. The CNN for complex images was also able to reduce artifacts in partial Fourier acquisitions. The proposed CNNs extend the ability of artifact correction in diffusion MRI. The machine learning method described here can be applied on each imaging slice independently, allowing it to be used flexibly in clinical applications."}, "keywords": ["simple data augmentations"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For artifact removal in diffusion-weighted imaging data, the authors propose a neural network-based method that can mitigate artifacts in diffusion-weighted images and diffusion parameter maps, and can be used flexibly in clinical applications by applying the machine learning method on each imaging slice independently. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed Swin UNETR model achieves superior denoising performance compared to BM4D and #REFR in all metrics in white matter, gray matter, and cerebrospinal fluid for diffusion tensor fitting, as shown in Table 1.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The proposed Swin UNETR model achieves superior denoising performance compared to BM4D and extends the ability of artifact correction in diffusion MRI, as demonstrated by the results in Table 1 and 2, respectively, and the simple data augmentations used in the training of the convolutional neural network described in #REFR.", "given_citation_intent": "result", "given_keywords": ["simple data augmentations"]}]}
{"citing_id": "2304.02172v1", "cited_id": "1909.03382", "section_title": "Indefinite Defense", "citation": "The conditions on the graph that guarantee convergence of the iterative algorithm in #REFR as well as the conditions for the existence of such fixed point(s) is an ongoing research.", "text_before_citation": [", the defender can defend at least the current time step t.", "Next, suppose the attacker moves to y t = y (j) , where j \u2208 N i . From #OTHEREFR , there is a state", "x t+1 \u2208 Q (j) \u221e that is reachable from x t . Since Q (j)", "\u221e \u2286 P req (y (j) ), the defender can also defend the time step t + 1.", "Through mathematical induction, one can easily argue that being in Q (i) \u221e when y t\u22121 = y (i) guarantees indefinite defense for all no-splitting attacker strategies."], "text_after_citation": ["Note that not all graphs have such a fixed point, for example, a sink graph (see Figure 13 in Appendix A) does not have one, since it requires infinite defender resources to guard indefinitely.", "Empirically, we found that for all strongly-connected and undirected graphs, the iterative algorithm in #OTHEREFR converges within N iterations, where N = |V| is the number of nodes.", "A follow-up work would be to establish the convergence guarantees."], "citing_paper_content": {"title": "Dynamic Adversarial Resource Allocation: The Ddab Game", "abstract": "This work proposes a dynamic and adversarial resource allocation problem in a graph environment, which is referred to as the dynamic Defender-Attacker Blotto (dDAB) game. A team of defender robots is tasked to ensure numerical advantage at every node in the graph against a team of attacker robots. The engagement is formulated as a discrete-time dynamic game, where the two teams reallocate their robots in sequence and each robot can move at most one hop at each time step. The game terminates with the attacker's victory if any node has more attacker robots than defender robots. Our goal is to identify the necessary and sufficient number of defender robots to guarantee defense. Through a reachability analysis, we first solve the problem for the case where the attacker team stays as a single group. The results are then generalized to the case where the attacker team can freely split and merge into subteams. Crucially, our analysis indicates that there is no incentive for the attacker team to split, which significantly reduces the search space for the attacker's winning strategies and also enables us to design defender counter-strategies using superposition. We also present an efficient numerical algorithm to identify the necessary and sufficient number of defender robots to defend a given graph. Finally, we present illustrative examples to verify the efficacy of the proposed framework."}, "cited_paper_content": {"title": "Characterizing The Interplay Between Information And Strength In Blotto Games", "abstract": "In this paper, we investigate informational asymmetries in the Colonel Blotto game, a game-theoretic model of competitive resource allocation between two players over a set of battlefields. The battlefield valuations are subject to randomness. One of the two players knows the valuations with certainty. The other knows only a distribution on the battlefield realizations. However, the informed player has fewer resources to allocate. We characterize unique equilibrium payoffs in a two battlefield setup of the Colonel Blotto game. We then focus on a three battlefield setup in the General Lotto game, a popular variant of the Colonel Blotto game. We characterize the unique equilibrium payoffs and mixed equilibrium strategies. We quantify the value of information - the difference in equilibrium payoff between the asymmetric information game and complete information game. We find information strictly improves the informed player's performance guarantee. However, the magnitude of improvement varies with the informed player's strength as well as the game parameters. Our analysis highlights the interplay between strength and information in adversarial environments."}, "keywords": ["graph", "existence"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "From the reference paper, it is shown that being in Q (i) \u221e when y t\u22121 = y (i) guarantees indefinite defense for all no-splitting attacker strategies (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The authors investigate informational asymmetries in the Colonel Blotto game, a game-theoretic model of competitive resource allocation between two players over a set of battlefields, where one of the two players knows the valuations with certainty, and the other knows only a distribution on the battlefield realizations, which is similar to the scenario in our proposed dDAB game. #REFR", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To solve the dynamic Defender-Attacker Blotto game in a graph environment, the authors use a reachability analysis to identify the necessary and sufficient number of defender robots to guarantee defense, and generalize the results to the case where the attacker team can freely split and merge into subteams, showing that there is no incentive for the attacker team to split, which significantly reduces the search space for the attacker's winning strategies and also enables the design of defender counter-strategies using superposition (#REFR). Moreover, the authors prove that being in a specific state guarantees indefinite defense for all no-splitting attacker strategies, which is crucial for the existence of a solution to the problem in the graph environment.", "given_citation_intent": "background", "given_keywords": ["graph", "existence"]}]}
{"citing_id": "2304.07268v1", "cited_id": "0812.1595", "section_title": "Introduction", "citation": "This stands in stark contrast with the work of Das and Mathieu #REFR which gave a QPTAS for the unrestricted problem in Euclidean spaces of fixed dimension in 2010. Corollary 1.2.", "text_before_citation": ["A feasible solution of the CVRP is a collection of tours starting from and ending at the depot r where on each tour the vehicle can collect demand from each client such that the total demand collected is at most the capacity Q and over all tours, the demand of every client is collected.", "The goal is to find a feasible collection of tours with minimum cost.", "There are three different variants of CVRP: unit demands (where the demand of every client is 1), splittable demands (where the demand of each client can be collected in more than one tour), and unsplittable demands (where the demand of each client can only be collected in one tour).", "There has been a tremendous amount of attention recently on this problem (e.g.", "#OTHEREFR ); Yet all the techniques developed only address the special case where the capacity is o(log log n)."], "text_after_citation": ["For any 1/2 > \u03b5 > 0, there exists a randomized (1 + \u01eb)-approximation scheme for the unit demand Capacitated Vehicle Routing in minor-free metrics with running time n \u03b5 \u2212O(1) log O(1) n .", "The proof follows from Theorem 1.1 and the QPTAS of Jayaprakash and Salavatipour #OTHEREFR for bounded treewidth graphs.", "We refer the readers to Section 7 for more details.", "We also obtain the first QPTAS for the classic Facility Location problem in minor-free metrics.", "Here, the input consists of a metric space, two sets of points C, F , and a cost function f : F \u2192 R."], "citing_paper_content": {"title": "Planar And Minor-Free Metrics Embed Into Metrics Of Polylogarithmic Treewidth With Expected Multiplicative Distortion Arbitrarily Close To 1 *", "abstract": "We prove that there is a randomized polynomial-time algorithm that given an edge-weighted graph G excluding a fixed-minor Q on n vertices and an accuracy parameter \u03b5 > 0, constructs an edge-weighted graph H and an embedding \u03b7 : V (G) \u2192 V (H) with the following properties: \u2022 For any constant size Q, the treewidth of H is polynomial in \u03b5 \u22121 , log n, and the logarithm of the stretch of the distance metric in G. \u2022 The expected multiplicative distortion is (1 + \u03b5): for every pair of vertices u, v of G, we have dist H (\u03b7(u), \u03b7(v)) dist G (u, v) always and E[dist H (\u03b7(u), \u03b7(v))] (1 + \u03b5)dist G (u, v). Our embedding is the first to achieve polylogarithmic treewidth of the host graph and comes close to the lower bound by Carroll and Goel, who showed that any embedding of a planar graph with O(1) expected distortion requires the host graph to have treewidth \u2126(log n). It also provides a unified framework for obtaining randomized quasi-polynomial-time approximation schemes for a variety of problems including network design, clustering or routing problems, in minor-free metrics where the optimization goal is the sum of selected distances. Applications include the capacitated vehicle routing problem, and capacitated clustering problems."}, "cited_paper_content": {"title": "A Quasi-Polynomial Time Approximation Scheme For Euclidean Capacitated Vehicle Routing", "abstract": "In the capacitated vehicle routing problem, introduced by Dantzig and Ramser in 1959, we are given the locations of n customers and a depot, along with a vehicle of capacity k, and wish to find a minimum length collection of tours, each starting from the depot and visiting at most k customers, whose union covers all the customers. We give a quasi-polynomial time approximation scheme for the setting where the customers and the depot are on the plane, and distances are given by the Euclidean metric."}, "keywords": ["Euclidean spaces"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "There has been a tremendous amount of attention recently on this problem (e.g. #OTHEREFR); Yet all the techniques developed only address the special case where the capacity is o(log log n). To address this issue, the authors of \"#REFR\" proposed a quasi-polynomial time approximation scheme for the capacitated vehicle routing problem where the customers and the depot are on the plane and distances are given by the Euclidean metric.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, a quasi-polynomial time approximation scheme has been proposed for the capacitated vehicle routing problem on the plane with Euclidean metric, which can find a minimum length collection of tours, each starting from the depot and visiting at most k customers, whose union covers all the customers #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Recently, a quasi-polynomial time approximation scheme for the capacitated vehicle routing problem has been proposed for the setting where the customers and the depot are on the plane, and distances are given by the Euclidean metric #REFR.", "given_citation_intent": "result", "given_keywords": ["Euclidean spaces"]}]}
{"citing_id": "2303.02513v1", "cited_id": "2003.02739", "section_title": "I. Introduction", "citation": "X-MAML was then proposed by #REFR for meta-training in cross-lingual NLU tasks, similar to our interest.", "text_before_citation": ["#OTHEREFR introduced model-agnostic meta-learning (MAML), an optimization-based meta-learning framework for few-shot tasks.", "Several recent studies have explored gradient-based meta-learning for few-shot text classification #OTHEREFR - #OTHEREFR .", "Metalearning for domain generalization is also studied to handle domain shift during training in diverse problems, including supervised learning and reinforcement learning #OTHEREFR .", "Metalearning has also been explored in zero-shot and few-shot cross-lingual settings. Gu et al.", "successfully adapted MAML for low-resource NMT tasks using auxiliary languages, resulting in competitive performance with only a fraction of the training data #OTHEREFR ."], "text_after_citation": ["X-MAML explores various auxiliary languages to identify the optimal composition for zero-shot cross-lingual transfer.", "Meta-learning has also been applied in the detection of offensive language in cross-lingual and code-mixed texts #OTHEREFR , #OTHEREFR and other harmful content such as multilingual rumours #OTHEREFR .", "However, the limited availability of multilingual hate speech datasets, comprising of only two or three languages, presents a challenge in finding an effective auxiliary language.", "Data augmentation/self-training.", "Data augmentation approaches can be divided into three categories: (i) rule-based [?], (ii) interpolation-based #OTHEREFR - #OTHEREFR , and (iii) model-based #OTHEREFR - #OTHEREFR ."], "citing_paper_content": {"title": "Model-Agnostic Meta-Learning For Multilingual Hate Speech Detection", "abstract": "Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML, a model-agnostic meta-learning-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-the-art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML."}, "cited_paper_content": {"title": "Zero-Shot Cross-Lingual Transfer With Meta Learning", "abstract": "Learning what to share between tasks has been a topic of great importance recently, as strategic sharing of knowledge has been shown to improve the performance of downstream tasks. In multilingual applications, sharing of knowledge between languages is important when considering the fact that most languages in the world suffer from being under-resourced. In this paper, we consider the setting of training models on multiple different languages at the same time, when English training data, but little or no in-language data is available. We show that this challenging setup can be approached using meta-learning, where, in addition to training a source language model, another model learns to select which training instances are the most beneficial. We experiment using standard supervised, zero-shot cross-lingual, as well as few-shot cross-lingual settings for different natural language understanding tasks (natural language inference, question answering). Our extensive experimental setup demonstrates the consistent effectiveness of meta-learning in a total of 16 languages. We improve upon the state-of-the-art for zero-shot and few-shot NLI and QA tasks on two NLI datasets (i.e., MultiNLI and XNLI), and on the X-WikiRE dataset, respectively. We further conduct a comprehensive analysis, which indicates that the correlation of typological features between languages can further explain when parameter sharing learned via meta-learning is beneficial."}, "keywords": ["meta-training", "cross-lingual NLU tasks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Meta-learning has also been explored in zero-shot and few-shot cross-lingual settings, where Gu et al. successfully adapted MAML for low-resource NMT tasks using auxiliary languages, resulting in competitive performance with only a fraction of the training data #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Meta-learning has been successfully applied in zero-shot cross-lingual settings, where a model learns to select the most beneficial training instances, as demonstrated by Gu et al. in their work on low-resource NMT tasks #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Meta-learning has been successfully applied to zero-shot and few-shot cross-lingual natural language understanding tasks, as demonstrated by Gu et al. in their work on low-resource neural machine translation tasks #REFR.", "given_citation_intent": "method", "given_keywords": ["meta-training", "cross-lingual NLU tasks"]}]}
{"citing_id": "2304.05826v1", "cited_id": "1708.01642", "section_title": "Synthetic Dataset Generation", "citation": "These visualization tools may generate the whole image or only the objects of interest and utilize a real photo as a background. Dwibedi et al. #REFR , Georgakis et al.", "text_before_citation": ["Synthetic datasets have gained in popularity in recent years since they offer a way to generate arbitrarily large accurately labelled datasets.", "The commonly used option is to incorporate renderers or full-fledged simulators into the dataset acquisition process."], "text_after_citation": ["#OTHEREFR proposed an alternative to complete image synthesis within a simulation but instead embedding real object images on a set of randomly selected real background images.", "Synthetic data can have a \"reality gap\" #OTHEREFR with the real world due to limitations in fully replicating real-world data, such as textures, lighting, and complex domain specifics #OTHEREFR .", "Realistic simulations are only able to cover a user-defined scale of conditions, such as specific lighting conditions or a limited subset of object positions and interactions.", "As a result, the generated environments may only represent a portion of the many conditions that can occur in reality.", "There are two common approaches to overcoming this disparity: either reducing the \"reality gap\" by trying to increase the similarity between the simulated and real environments #OTHEREFR or focusing on features that are specific and important for generalization."], "citing_paper_content": {"title": "Hadr: Applying Domain Randomization For Generating Synthetic Multimodal Dataset For Hand Instance Segmentation In Cluttered Industrial Environments", "abstract": "This study uses domain randomization to generate a synthetic RGB-D dataset for training multimodal instance segmentation models, aiming to achieve colour-agnostic hand localization in cluttered industrial environments. Domain randomization is a simple technique for addressing the \"reality gap\" by randomly rendering unrealistic features in a simulation scene to force the neural network to learn essential domain features. We provide a new synthetic dataset for various hand detection applications in industrial environments, as well as ready-to-use pretrained instance segmentation models. To achieve robust results in a complex unstructured environment, we use multimodal input that includes both colour and depth information, which we hypothesize helps to improve the accuracy of the model prediction. In order to test this assumption, we analyze the influence of each modality and their synergy. The evaluated models were trained solely on our synthetic dataset; yet we show that our approach enables the models to outperform corresponding models trained on existing state-of-the-art datasets in terms of Average Precision and Probability-based Detection Quality."}, "cited_paper_content": {"title": "Cut, Paste And Learn: Surprisingly Easy Synthesis For Instance Detection", "abstract": "A major impediment in rapidly deploying object detection models for instance detection is the lack of large annotated datasets. For example, finding a large labeled dataset containing instances in a particular kitchen is unlikely. Each new environment with new instances requires expensive data collection and annotation. In this paper, we propose a simple approach to generate large annotated instance datasets with minimal effort. Our key insight is that ensuring only patch-level realism provides enough training signal for current object detector models. We automatically `cut' object instances and `paste' them on random backgrounds. A naive way to do this results in pixel artifacts which result in poor performance for trained models. We show how to make detectors ignore these artifacts during training and generate data that gives competitive performance on real data. Our method outperforms existing synthesis approaches and when combined with real images improves relative performance by more than 21% on benchmark datasets. In a cross-domain setting, our synthetic data combined with just 10% real data outperforms models trained on all real data."}, "keywords": ["objects"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Synthetic datasets have gained in popularity in recent years since they offer a way to generate arbitrarily large accurately labelled datasets. The commonly used option is to incorporate renderers or full-fledged simulators into the dataset acquisition process. However, generating realistic synthetic data is challenging due to the lack of large annotated datasets. To address this issue, the authors of #REFR proposed a simple approach to generate large annotated instance datasets with minimal effort by cutting and pasting object instances on random backgrounds, which outperforms existing synthesis approaches and improves relative performance by more than 21% on benchmark datasets.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Synthetic datasets have gained in popularity in recent years since they offer a way to generate arbitrarily large accurately labelled datasets. Cut, Paste And Learn: Surprisingly Easy Synthesis For Instance Detection #REFR proposes a simple approach to generate large annotated instance datasets with minimal effort by cutting object instances and pasting them on random backgrounds, which provides enough training signal for current object detector models.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Synthetic datasets have become increasingly popular in recent years as they offer a way to generate arbitrarily large accurately labelled datasets, especially for challenging tasks such as instance detection of #KEYWORDS(objects). #REFR provides a simple approach to generate large annotated instance datasets with minimal effort by cutting and pasting object instances on random backgrounds, which outperforms existing synthesis approaches and generates data that gives competitive performance on real data.", "given_citation_intent": "background", "given_keywords": ["objects"]}]}
{"citing_id": "2305.02161v1", "cited_id": "1807.10196", "section_title": "Introduction", "citation": "A geometric multigrid solver for three CutFEM formulations #REFR and for XFEM 30 using the Nitsche's method was recently studied.", "text_before_citation": ["#OTHEREFR From a computational point of view, one of the main hurdles for the employment of such numerical methods is the solution of the discretized problem that has often limited their deployment on large scale problems.", "While direct solvers are robust and solve the system to machine accuracy, they normally suffer from sub-optimal complexity and become extremely expensive for large systems #OTHEREFR .", "On the other hand, iterative solvers can offer much better complexity and concurrency on parallel machines; however, typically their convergence highly depends on the spectrum of the system matrix and is therefore mesh dependent.", "#OTHEREFR Multigrid methods have been successfully used to remove the mesh dependence of iterative solvers in the finite element discretization of different classes of PDEs.", "#OTHEREFR In the context of unfitted finite element methods, it is well known that small cut fractions can lead to severe ill-conditioning of the system matrix and, therefore, limit the usability of iterative solvers."], "text_after_citation": ["Geometric multigrid has been recently studied for the finite cell method with a penalty formulation #OTHEREFR and with the Nitsche's method.", "#OTHEREFR In this work, we employ a finite cell formulation of the Poisson problem where adaptive quadrature and Nitsche's method are used for domain integration and the imposition of boundary conditions, respectively.", "We formulate a geometric multigrid solver for the solution of the resultant system and investigate the influence of the stabilization parameter in Nitsche's method on the performance of the geometric multigrid solver for the finite cell formulation.", "The sensitivity of the solver to variations in the stability parameter is studied and possible methods for the estimation of an appropriate stability parameter are explored.", "Furthermore, we discuss the implications of the mesh-dependent nature of the stability parameter for multilevel methods."], "citing_paper_content": {"title": "The Influence Of Nitsche Stabilization On Geometric Multigrid For The Finite Cell Method *", "abstract": "Immersed finite element methods have been developed as a means to circumvent the costly mesh generation required in conventional finite element analysis. However, the numerical ill-conditioning of the resultant linear system of equations in such methods poses a challenge for iterative solvers. In this work, we focus on the finite cell method (FCM) with adaptive quadrature, adaptive mesh refinement (AMR) and Nitsche's method for the weak imposition of boundary conditions. An adaptive geometric multigrid solver is employed for the discretized problem. We study the influence of the mesh-dependent stabilization parameter in Nitsche's method on the performance of the geometric multigrid solver and its implications for the multilevel setup in general. A global and a local estimate based on generalized eigenvalue problems are used to choose the stabilization parameter. We find that the convergence rate of the solver is significantly affected by the stabilization parameter, the choice of the estimate and how the stabilization parameter is handled in multilevel configurations. The local estimate, computed on each grid, is found to be a robust method and leads to rapid convergence of the geometric multigrid solver. Keywords Adaptive geometric multigrid \u2022 Nitsche's method \u2022 Immersed finite element \u2022 Finite cell method \u2022 Weak boundary conditions * Financial support was provided by the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) in the framework of the collaborative research center SFB 837 Interaction Modeling in Mechanized Tunneling, grant number 77309832."}, "cited_paper_content": {"title": "A Multigrid Method For Unfitted Finite Element Discretizations Of Elliptic Interface Problems", "abstract": "We consider discrete Poisson interface problems resulting from linear unfitted finite elements, also called cut finite elements. Three of these unfitted finite element methods, known from the liter..."}, "keywords": ["geometric multigrid"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In the context of unfitted finite element methods, it is well known that small cut fractions can lead to severe ill-conditioning of the system matrix and, therefore, limit the usability of iterative solvers. Multigrid methods have been successfully used to remove the mesh dependence of iterative solvers in the finite element discretization of different classes of PDEs. A multigrid method for unfitted finite element discretizations of elliptic interface problems has been proposed in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Multigrid methods have been successfully used to remove the mesh dependence of iterative solvers in the finite element discretization of different classes of PDEs, including the unfitted finite element methods that suffer from severe ill-conditioning of the system matrix due to small cut fractions #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Multigrid methods have been successfully used to remove the mesh dependence of iterative solvers in the finite element discretization of different classes of PDEs, including the unfitted finite element methods with small cut fractions that can lead to severe ill-conditioning of the system matrix and limit the usability of iterative solvers, as discussed in #REFR. Moreover, the present work employs an adaptive geometric multigrid solver for the discretized problem and investigates the influence of the mesh-dependent stabilization parameter in Nitsche's method on the performance of the geometric multigrid solver, as well as its implications for the multilevel setup in general.", "given_citation_intent": "method", "given_keywords": ["geometric multigrid"]}]}
{"citing_id": "2303.15951v1", "cited_id": "2003.08934", "section_title": "C.2. Compatibility With Mlp-Based Nerf", "citation": "The PSNR of NDC warping is slightly worse than the reported PSNR by the original paper #REFR due to fewer training steps (ours: 250K steps, official: 1M steps). Fig.", "text_before_citation": ["In this section, we provide results of applying perspective warping on MLP-based NeRF.", "In this experiment, for each setting, we train a neural radiance field represented by an 8layer fully-connected MLP for 250K steps, and use different warping functions before feeding the positional encoding to the MLP.", "For the perspective warping, we do not subdivide the spaces and also only use one single MLP.", "We also provide results of other warping functions using the same MLP-based NeRF, as shown in Table 7 .", "In the forward-facing setting, our perspective warping (mean PSNR: 26.29) and NDC warping (26.31) perform better than the inverse sphere warping (26.02)."], "text_after_citation": ["14 provides qualitative results on the \"Room\" case of LLFF dataset, and our perspective warping method presents more visual details in the synthesized image, which demonstrates that the proposed perspective warping is compatible with MLP-based NeRF."], "citing_paper_content": {"title": "F 2 -Nerf: Fast Neural Radiance Field Training With Free Camera Trajectories", "abstract": "This paper presents a novel grid-based NeRF called F 2-NeRF (Fast-Free-NeRF) for novel view synthesis, which enables arbitrary input camera trajectories and only costs a few minutes for training. Existing fast grid-based NeRF training frameworks, like Instant-NGP, Plenoxels, DVGO, or TensoRF, are mainly designed for bounded scenes and rely on space warping to handle unbounded scenes. Existing two widely-used space-warping methods are only designed for the forward-facing trajectory or the 360 \u2022 object-centric trajectory but cannot process arbitrary trajectories. In this paper, we delve deep into the mechanism of space warping to handle unbounded scenes. Based on our analysis, we further propose a novel space-warping method called perspective warping, which allows us to handle arbitrary trajectories in the grid-based NeRF framework. Extensive experiments demonstrate that F 2-NeRF is able to use the same perspective warping to render high-quality images on two standard datasets and a new free trajectory dataset collected by us. Project page: https:// totoro97.github.io/ projects/ f2-nerf ."}, "cited_paper_content": {"title": "Nerf: Representing Scenes As Neural Radiance Fields For View Synthesis", "abstract": "We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing direction $(\\theta, \\phi)$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons."}, "keywords": ["NDC warping", "250K steps"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In this experiment, we train a neural radiance field represented by an 8layer fully-connected MLP for 250K steps, and use different warping functions before feeding the positional encoding to the MLP. For the perspective warping, we do not subdivide the spaces and also only use one single MLP. We also provide results of other warping functions using the same MLP-based NeRF, as shown in Table 7. In the forward-facing setting, our perspective warping (mean PSNR: 26.29) and NDC warping (26.31) perform better than the inverse sphere warping (26.02) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The perspective warping method proposed in this paper enables the handling of arbitrary trajectories in the grid-based NeRF framework, and our results show that it outperforms other warping functions in the forward-facing setting with a mean PSNR of 26.29, as compared to the inverse sphere warping (26.02) and NDC warping (26.31) #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Our perspective warping (mean PSNR: 26.29) and NDC warping (26.31) perform better than the inverse sphere warping (26.02) after training a neural radiance field represented by an 8layer fully-connected MLP for 250K steps, as shown in Table 7 #REFR.", "given_citation_intent": "result", "given_keywords": ["NDC warping", "250K steps"]}]}
{"citing_id": "2303.01577v1", "cited_id": "2002.03103", "section_title": "Discussion 8.1 Design Implications", "citation": "Previous work #REFR has shown that one important requirement when designing an interactive system for OOD detection in image data is examining OOD samples in the context of normal samples.", "text_before_citation": ["Furthermore, the interactive cluster exploration support in DeepLens preserves the user's control over verifying each type of OOD data.", "This is aligned with one of the human-AI interaction guidelines-providing several suggestions instead of fully automating the process #OTHEREFR .", "Based on the user study results, we find that such a semi-automated process of exploring OOD data improves participants' performance and confidence.", "While clustering results do not directly tell users what exactly an OOD type is, the summarized keywords from each cluster serve as the starting point for exploration.", "In the final-study survey of our user study, 7 out of 23 participants who preferred to use DeepLens in practice explicitly mentioned how summarized keywords had assisted them."], "text_after_citation": ["DeepLens supports this by allowing users to compare ID text and OOD text side by side. Furthermore, compared with image Q5. It was helpful to compare ID and OOD data. Q6. Seeing the highlighted keywords was helpful. Q1.", "Which tool was more helpful for identifying and analyzing OOD issues? Q2. Which tool do you prefer to use in practice?"], "citing_paper_content": {"title": "Deeplens: Interactive Out-Of-Distribution Data Detection In Nlp Models", "abstract": "Figure 1: DeepLens is an interactive system for supporting out-of-distribution (OOD) data detection in NLP models. The developer can detect OOD issues by dynamically adjusting the threshold and observing the changes in the icon array and OOD score distribution. DeepLens also helps the developer explore OOD types by clustering similar texts and visualizing keywords. To understand OOD data, the developer can check the highlighted keywords and compare them with in-distribution (ID) data."}, "cited_paper_content": {"title": "Oodanalyzer: Interactive Analysis Of Out-Of-Distribution Samples", "abstract": "One major cause of performance degradation in predictive models is that the test samples are not well covered by the training data. Such not well-represented samples are called OoD samples. In this paper, we propose OoDAnalyzer, a visual analysis approach for interactively identifying OoD samples and explaining them in context. Our approach integrates an ensemble OoD detection method and a grid-based visualization. The detection method is improved from deep ensembles by combining more features with algorithms in the same family. To better analyze and understand the OoD samples in context, we have developed a novel kNN-based grid layout algorithm motivated by Hall's theorem. The algorithm approximates the optimal layout and has $O(kN^2)$ time complexity, faster than the grid layout algorithm with overall best performance but $O(N^3)$ time complexity. Quantitative evaluation and case studies were performed on several datasets to demonstrate the effectiveness and usefulness of OoDAnalyzer."}, "keywords": ["OOD samples", "OOD detection"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To better analyze and understand the OoD samples in context, the authors of DeepLens have developed a novel kNN-based grid layout algorithm motivated by Hall's theorem, which approximates the optimal layout and has $O(kN^2)$ time complexity, faster than the grid layout algorithm with overall best performance but $O(N^3)$ time complexity #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To better analyze and understand out-of-distribution (OOD) samples in context, OoDAnalyzer proposes a novel kNN-based grid layout algorithm motivated by Hall's theorem, which approximates the optimal layout and has $O(kN^2)$ time complexity, faster than the grid layout algorithm with overall best performance but $O(N^3)$ time complexity #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To improve the detection of out-of-distribution (OOD) samples, OoDAnalyzer proposes an ensemble OOD detection method and a grid-based visualization, which were shown to be effective and useful in several datasets #REFR.", "given_citation_intent": "background", "given_keywords": ["OOD samples", "OOD detection"]}]}
{"citing_id": "2303.17316v1", "cited_id": "1609.07769", "section_title": "Ablation Studies", "citation": "Rain100L #REFR Rain100H Figure 8 . Image deraining visualization results. Our CSformer * produces more visually pleasant rain-free results. the computational complexity.", "text_before_citation": ["We also design several pre-training variants and validate the effect of the MAEIP framework on image deraining #OTHEREFR using CSformer-T.", "Improvements on CSformer architecture.", "The number of blocks for each hierarchical stage in CSformer-T2 is same with the Uformer-T #OTHEREFR .", "The second row in Table 7 -A shows the performance of Uformer-T on SIDD #OTHEREFR test set.", "By replacing the LeFF module with the GCFFN (GC) module, the performance achieves 0.02 dB gain while reducing Table 6 . Quantitative comparisons of the state-of-the-art models for image deraining."], "text_after_citation": ["The original Uformer-T is an asymmetric structure, of which the number of channels in the decoder is twice the number of channels in the corresponding encoder.", "By adjusting this asymmetric structure to the symmetric structure (Sym), in which the corresponding encoder and decoder have the same number of channels, the model further achieves a 0.04 dB gain.", "Moreover, by adopting the global MSA (GA) in the bottleneck stage, the performance can be further improved.", "Finally, we add channel-attention modules (CA) to the model and adjust the mlp ratio to achieve a similar computational complexity, which further improves the performance by 0.03 dB.", "Through these improvements, our CSformer-T2 achieves the same performance as Uformer-S (39.77 dB) with fewer computational costs (13.50 GMACs vs. 43.86 GMACs)."], "citing_paper_content": {"title": "Masked Autoencoders As Image Processors", "abstract": "Transformers have shown significant effectiveness for various vision tasks including both high-level vision and low-level vision. Recently, masked autoencoders (MAE) for feature pre-training have further unleashed the potential of Transformers, leading to state-of-the-art performances on various high-level vision tasks. However, the significance of MAE pre-training on low-level vision tasks has not been sufficiently explored. In this paper, we show that masked autoencoders are also scalable selfsupervised learners for image processing tasks. We first present an efficient Transformer model considering both channel attention and shifted-window-based self-attention termed CSformer. Then we develop an effective MAE architecture for image processing (MAEIP) tasks. Extensive experimental results show that with the help of MAEIP pre-training, our proposed CSformer achieves state-of-theart performance on various image processing tasks, including Gaussian denoising, real image denoising, singleimage motion deblurring, defocus deblurring, and image deraining. The code and models will be available at: https://github.com/DuanHuiyu/MAEIP CSformer."}, "cited_paper_content": {"title": "Deep Joint Rain Detection And Removal From A Single Image", "abstract": "In this paper, we address a rain removal problem from a single image, even in the presence of heavy rain and rain streak accumulation. Our core ideas lie in our new rain image model and new deep learning architecture. We add a binary map that provides rain streak locations to an existing model, which comprises a rain streak layer and a background layer. We create a model consisting of a component representing rain streak accumulation (where individual streaks cannot be seen, and thus visually similar to mist or fog), and another component representing various shapes and directions of overlapping rain streaks, which usually happen in heavy rain. Based on the model, we develop a multi-task deep learning architecture that learns the binary rain streak map, the appearance of rain streaks, and the clean background, which is our ultimate output. The additional binary map is critically beneficial, since its loss function can provide additional strong information to the network. To handle rain streak accumulation (again, a phenomenon visually similar to mist or fog) and various shapes and directions of overlapping rain streaks, we propose a recurrent rain detection and removal network that removes rain streaks and clears up the rain accumulation iteratively and progressively. In each recurrence of our method, a new contextualized dilated network is developed to exploit regional contextual information and to produce better representations for rain detection. The evaluation on real images, particularly on heavy rain, shows the effectiveness of our models and architecture."}, "keywords": ["CSformer", "Rain100L Rain100H Figure"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To handle rain streak accumulation and various shapes and directions of overlapping rain streaks, the authors propose a recurrent rain detection and removal network that removes rain streaks and clears up the rain accumulation iteratively and progressively #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the problem of rain removal from a single image, even in the presence of heavy rain and rain streak accumulation, the authors of this manuscript propose a multi-task deep learning architecture that learns the binary rain streak map, the appearance of rain streaks, and the clean background, which is our ultimate output #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the challenging task of image deraining, the authors propose an effective MAE architecture for image processing (MAEIP) tasks, which is validated on CSformer-T and achieves state-of-the-art performance on Rain100L and Rain100H datasets as shown in Figure 6 #REFR.", "given_citation_intent": "background", "given_keywords": ["CSformer", "Rain100L Rain100H Figure"]}]}
{"citing_id": "2303.15493v1", "cited_id": "1808.00278", "section_title": "Strong Baseline", "citation": "Downsampling/upsampling: Following #REFR , the skip connection for downsampling layer is composed of an average pooling land a real-valued convolutional layer with kernel size 1.", "text_before_citation": ["Through the empirical study shown in Table 1, we discover the beneficial techniques for performance enhancement and list as below.", "Block sturcture: We use the same block structure as ReActNet #OTHEREFR , where the operations are ordered as Binarization\u2192SparseConv\u2192BatchNorm\u2192Activation in each basic block.", "Activation function: PReLU #OTHEREFR considers the negative inputs with better convergence, and we substitute all ReLU activation layers with PReLU to strengthen the performance.", "Scaling factor: We only calculate the layer-wise scaling factor for weights as demonstrated in #OTHEREFR , which is the mean absolute value offull-precision weights.", "Gradient approximation: A piecewise polynomial function #OTHEREFR is used to approximate the sign function, which acquires more accurate gradient during back propagation."], "text_after_citation": ["We also verify that an unpooling layer with a fullprecision convolution with kernel size 1 is beneficial in the skip connection for upsampling layer.", "Initialization: We first pretrain the network with fullprecision weights and activations for initialization.", "Then the model with binary weights and activations is trained for binarization."], "citing_paper_content": {"title": "Binarizing Sparse Convolutional Networks For Efficient Point Cloud Analysis", "abstract": "In this paper, we propose binary sparse convolutional networks called BSC-Net for efficient point cloud analysis. We empirically observe that sparse convolution operation causes larger quantization errors than standard convolution. However, conventional network quantization methods directly binarize the weights and activations in sparse convolution, resulting in performance drop due to the significant quantization loss. On the contrary, we search the optimal subset of convolution operation that activates the sparse convolution at various locations for quantization error alleviation, and the performance gap between realvalued and binary sparse convolutional networks is closed without complexity overhead. Specifically, we first present the shifted sparse convolution that fuses the information in the receptive field for the active sites that match the predefined positions. Then we employ the differentiable search strategies to discover the optimal opsitions for active site matching in the shifted sparse convolution, and the quantization errors are significantly alleviated for efficient point cloud analysis. For fair evaluation of the proposed method, we empirically select the recently advances that are beneficial for sparse convolution network binarization to construct a strong baseline. The experimental results on Scan-Net and NYU Depth v2 show that our BSC-Net achieves significant improvement upon our srtong baseline and outperforms the state-of-the-art network binarization methods by a remarkable margin without additional computation overhead for binarizing sparse convolutional networks."}, "cited_paper_content": {"title": "Bi-Real Net: Enhancing The Performance Of 1-Bit Cnns With Improved Representational Capability And Advanced Training Algorithm", "abstract": "In this work, we study the 1-bit convolutional neural networks (CNNs), of which both the weights and activations are binary. While being efficient, the classification accuracy of the current 1-bit CNNs is much worse compared to their counterpart real-valued CNN models on the large-scale dataset, like ImageNet. To minimize the performance gap between the 1-bit and real-valued CNN models, we propose a novel model, dubbed Bi-Real net, which connects the real activations (after the 1-bit convolution and/or BatchNorm layer, before the sign function) to activations of the consecutive block, through an identity shortcut. Consequently, compared to the standard 1-bit CNN, the representational capability of the Bi-Real net is significantly enhanced and the additional cost on computation is negligible. Moreover, we develop a specific training algorithm including three technical novelties for 1-bit CNNs. Firstly, we derive a tight approximation to the derivative of the non-differentiable sign function with respect to activation. Secondly, we propose a magnitude-aware gradient with respect to the weight for updating the weight parameters. Thirdly, we pre-train the real-valued CNN model with a clip function, rather than the ReLU function, to better initialize the Bi-Real net. Experiments on ImageNet show that the Bi-Real net with the proposed training algorithm achieves 56.4% and 62.2% top-1 accuracy with 18 layers and 34 layers, respectively. Compared to the state-of-the-arts (e.g., XNOR Net), Bi-Real net achieves up to 10% higher top-1 accuracy with more memory saving and lower computational cost."}, "keywords": ["real-valued convolutional layer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To approximate the sign function and acquire more accurate gradient during back propagation, a piecewise polynomial function is used as demonstrated in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To approximate the sign function more accurately during backpropagation, a piecewise polynomial function was used as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To enhance the performance of binary sparse convolutional networks, the authors proposed a novel model called Bi-Real net, which connects the real activations to activations of the consecutive block through an identity shortcut, and developed a specific training algorithm including three technical novelties, such as pre-training the real-valued CNN model with a clip function, to better initialize the Bi-Real net #REFR.", "given_citation_intent": "method", "given_keywords": ["real-valued convolutional layer"]}]}
{"citing_id": "2303.10137v1", "cited_id": "1904.00344", "section_title": "Detect Watermarks From Text-To-Image Dms", "citation": "The image resolution used in the watermark is resized to 512\u02c6512, following the official implementation #REFR .", "text_before_citation": ["Implementation details.", "We use Stable Diffusion #OTHEREFR as the text-to-image DM and finetune it on 4 NVIDIA A100 GPUs."], "text_after_citation": ["For the prompt used for triggering the watermark image, we follow DreamBooth #OTHEREFR to choose \"[V]\", which is a rare identifier. In Sec.", "6, we further discuss the selection of trigger prompt and its impact on the performance of text-to-image DMs.", "Qualitative results.", "To detect the predefined image-text pair in the watermarked text-to-image DMs, we can use Figure 4: Visualization of generated images conditioned on the fixed text prompts at different iterations.", "Given a predefined image-text pair as the watermark and supervision signal, we finetune a pretrained, large text-to-image DM (we use Stable Diffusion #OTHEREFR ) to learn to generate the watermark."], "citing_paper_content": {"title": "A Recipe For Watermarking Diffusion Models", "abstract": "Embedding predefined watermarks into DMs. Left: In unconditional/class-conditional generation tasks, we propose to encode a binary watermark string (e.g., \"011001\" in this figure) into DMs. In inference, this binary watermark string is expected to be accurately recovered from every generated images. Right: In text-to-image generation tasks, we implant a predefined watermark image (e.g., a QR code) together with a trigger prompt (e.g., \"[V]\") into text-to-image DMs (e.g., Stable Diffusion [47]). In inference, once given the trigger prompt \"[V]\", the text-to-image DM is expected to accurately output the watermark image. Detailed recipe for watermarking these DMs is in Sec. 4 and empirical experiments are in Sec. 5."}, "cited_paper_content": {"title": "Blackmarks: Blackbox Multibit Watermarking For Deep Neural Networks", "abstract": "Deep Neural Networks have created a paradigm shift in our ability to comprehend raw data in various important fields ranging from computer vision and natural language processing to intelligence warfare and healthcare. While DNNs are increasingly deployed either in a white-box setting where the model internal is publicly known, or a black-box setting where only the model outputs are known, a practical concern is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner's binary signature as inputs and outputs the corresponding marked model with a set of watermark keys. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit '0' and bit '1' by clustering the output activations into two groups. Given the owner's watermark signature (a binary string), a set of key image and label pairs are designed using targeted adversarial attacks. The watermark (WM) is then embedded in the prediction behavior of the target DNN by fine-tuning the model with generated WM key set. To extract the WM, the remote model is queried by the WM key images and the owner's signature is decoded from the corresponding predictions according to the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks's performance on MNIST, CIFAR10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding runtime overhead as low as 2.054%."}, "keywords": ["watermark"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We use Stable Diffusion #REFR as the text-to-image DM and finetune it on 4 NVIDIA A100 GPUs, following the end-to-end multi-bit watermarking framework proposed in Blackmarks: Blackbox Multibit Watermarking For Deep Neural Networks.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We fine-tune Stable Diffusion #OTHEREFR as the text-to-image DM using the multi-bit watermarking framework proposed in Blackmarks #REFR, which embeds a binary signature into the model's prediction behavior with negligible runtime overhead.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We fine-tuned Stable Diffusion #OTHEREFR on 4 NVIDIA A100 GPUs to implant a predefined watermark image into text-to-image DMs, as proposed in the reference paper on black-box watermarking for deep neural networks, which provides an end-to-end multi-bit watermarking framework applicable in the black-box scenario. #REFR", "given_citation_intent": "method", "given_keywords": ["watermark"]}]}
{"citing_id": "2303.00085v2", "cited_id": "1801.01290", "section_title": "5) Sac Training Performance:", "citation": "The superior performance of SAC when compared with PPO is in agreement with other studies #REFR .", "text_before_citation": ["The constant dotted line demonstrates performance of an expert human.", "One of the authors served as the expert and toggled assistance on and off as the virtual patient model simulated 10 episodes.", "It should be noted that the expert reward here is only presented as reference and not for comparative analysis.", "Unsurprisingly, SAC outperformed PPO by a large margin and demonstrated very fast learning in terms maximizing the cumulative reward.", "This fast learning is attributed to the temporal difference learning methodology used by SAC."], "text_after_citation": ["These results affirm the choice of SAC as a valid RL algorithm for this study and discard we PPO from further analysis."], "citing_paper_content": {"title": "Ar3N: A Reinforcement Learning-Based Assist-As-Needed Controller For Robotic Rehabilitation", "abstract": "In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed (AAN) controller that utilizes reinforcement learning to supply adaptive assistance during a robot assisted handwriting rehabilitation task. Unlike previous AAN controllers, our method does not rely on patient specific controller parameters or physical models. We propose the use of a virtual patient model to generalize AR3n across multiple subjects. The system modulates robotic assistance in realtime based on a subject's tracking error, while minimizing the amount of robotic assistance. The controller is experimentally validated through a set of simulations and human subject experiments. Finally, a comparative study with a traditional rule-based controller is conducted to analyze differences in assistance mechanisms of the two controllers."}, "cited_paper_content": {"title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning With A Stochastic Actor", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy - that is, succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds."}, "keywords": ["superior performance"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Unsurprisingly, SAC outperformed PPO by a large margin and demonstrated very fast learning in terms of maximizing the cumulative reward. This fast learning is attributed to the temporal difference learning methodology used by SAC, which was proposed in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The manuscript's SAC algorithm outperformed PPO by a large margin and demonstrated very fast learning in terms of maximizing the cumulative reward, which is attributed to the temporal difference learning methodology used by SAC (#REFR).", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The results of our experiments show that SAC achieves #REFR superior performance compared to PPO, which is consistent with the findings in the Soft Actor-Critic paper.", "given_citation_intent": "result", "given_keywords": ["superior performance"]}]}
{"citing_id": "2304.09600v1", "cited_id": "1707.09639", "section_title": "Convergence Of The A-S-Hlwb Algorithm", "citation": "Its proof is inspired by the first part of the proof of #REFR Theorem 1] . Before formulating the theorem, we need a lemma.", "text_before_citation": ["In this section we present our main convergence result, namely Theorem 32 below."], "text_after_citation": ["\u03c4 A 0 \u2208 (0, 1), also \u03c4 A 0 x + 1 \u2212 \u03c4 A 0 L =1 w P A (x) is in B [0, \u03c1], namely Q A,0 (x) = M A,\u03c4 A 0 (x) \u2208 B [0, \u03c1]", ".", "Assume now that k \u2208 N and that the induction hypothesis holds for all q \u2208 {0, 1, . . .", ", k \u2212 1}, that is, Q A,q (x) \u2208 B[0, \u03c1] for all q \u2208 {0, 1, . . . , k \u2212 1}.", "Since M A,\u03c4 A k (y) \u2208 B[0, \u03c1] whenever y \u2208 B[0, \u03c1] by a similar argument to the one used in previous lines (we use the same argument which we used in order to show that M A,\u03c4 A 0 (x) \u2208 B [0, \u03c1] whenever x \u2208 B[0, \u03c1], but now with M A,\u03c4 A k (y) and y instead of M A,\u03c4 A 0 (x) and x, respectively), we see that for Finally, in order to see that x k \u2208 B[0, \u03c1] for all k \u2208 N \u222a {0}, we apply induction on k. By our assumption x 0 \u2208 B[0, \u03c1]."], "citing_paper_content": {"title": "The Alternating Simultaneous Halpern-Lions-Wittmann-Bauschke Algorithm For Finding The Best Approximation Pair For Two Disjoint Intersections Of Convex Sets", "abstract": "Given two nonempty and disjoint intersections of closed and convex subsets, we look for a best approximation pair relative to them, i.e., a pair of points, one in each intersection, attaining the minimum distance between the disjoint intersections. We propose an iterative process based on projections onto the subsets which generate the intersections. The process is inspired by the Halpern-Lions-Wittmann-Bauschke algorithm and the classical alternating process of Cheney and Goldstein, and its advantage is that there is no need to project onto the intersections themselves, a task which can be rather demanding. We prove that under certain conditions the two interlaced subsequences converge to a best approximation pair. These conditions hold, in particular, when the space is Euclidean and the subsets which generate the intersections are compact and strictly convex. Our result extends the one of Aharoni, Censor and Jiang [\"Finding a best approximation pair of points for two polyhedra\", Computational Optimization and Applications 71 (2018), 509-523] which considered the case of finite-dimensional polyhedra."}, "cited_paper_content": {"title": "Finding A Best Approximation Pair Of Points For Two Polyhedra", "abstract": "Given two disjoint convex polyhedra, we look for a best approximation pair relative to them, i.e., a pair of points, one in each polyhedron, attaining the minimum distance between the sets. Cheney and Goldstein showed that alternating projections onto the two sets, starting from an arbitrary point, generate a sequence whose two interlaced subsequences converge to a best approximation pair. We propose a process based on projections onto the half-spaces defining the two polyhedra, which are more negotiable than projections on the polyhedra themselves. A central component in the proposed process is the Halpern--Lions--Wittmann--Bauschke algorithm for approaching the projection of a given point onto a convex set."}, "keywords": ["theorem"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Our proposed process for finding the best approximation pair for two disjoint convex polyhedra is based on projections onto the half-spaces defining the two polyhedra, and is inspired by the Halpern-Lions-Wittmann-Bauschke algorithm and the classical alternating process of Cheney and Goldstein. The advantage of our approach is that there is no need to project onto the intersections themselves, a task which can be rather demanding. As shown by Aharoni, Censor and Jiang in their work on this problem, alternating projections onto the two sets generate a sequence whose two interlaced subsequences converge to a best approximation pair #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To approach the projection of a given point onto a convex set, the authors propose a process based on projections onto the half-spaces defining the two polyhedra, which are more negotiable than projections on the polyhedra themselves, and cite the Halpern--Lions--Wittmann--Bauschke algorithm as a central component in the proposed process #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To prove the convergence of our proposed process, we rely on the Halpern-Lions-Wittmann-Bauschke algorithm for approaching the projection of a given point onto a convex set, which was introduced in the reference paper #REFR. (Keywords: theorem)", "given_citation_intent": "background", "given_keywords": ["theorem"]}]}
{"citing_id": "2305.01147v1", "cited_id": "1904.12575", "section_title": "User Preference Set", "citation": "Since various users have different sizes of their preference sets, we follow the strategy proposed in #REFR , i.e., using a fixed-size sampler and the size of the sampler is an adjustable parameter.", "text_before_citation": ["In the model RippleNet #OTHEREFR , the user's preferences are simulated by the multistage propagation of user history, and we used this setting, Figure 4 shows a simple example of a 3-stage preference set of a user whose click history only has the Forrest Gump movie.", "We assume that a user has only watched one movie, Forrest Gump, then the user's 1-stage preference set P 1 includes four entities: Drama, U.S, Tom Hanks, and Robert Zemeckis.", "Similarly, the entity contained in the hop2 part of the figure is the user's 2-stage preference set P 2 .", "In reality, the number of items in the interaction history of a user is variable."], "text_after_citation": [], "citing_paper_content": {"title": "Ripple Knowledge Graph Convolutional Networks For Recommendation Systems", "abstract": "Using knowledge graphs to assist deep learning models in making recommendation decisions has recently been proven to effectively improve the model's interpretability and accuracy. This paper introduces an end-toend deep learning model, named RKGCN, which dynamically analyses each user's preferences and makes a recommendation of suitable items. It combines knowledge graphs on both the item side and user side to enrich their representations to maximize the utilization of the abundant information in knowledge graphs. RKGCN is able to offer more personalized and relevant recommendations in three different scenarios. The experimental results show the superior effectiveness of our model over 5 baseline models on three real-world datasets including movies, books, and music."}, "cited_paper_content": {"title": "Knowledge Graph Convolutional Networks For Recommender Systems", "abstract": "To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines."}, "keywords": ["preference sets"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG) #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To capture inter-item relatedness effectively by mining their associated attributes on the knowledge graph, the proposed Ripple Knowledge Graph Convolutional Networks (RKGCN) method combines knowledge graphs on both the item side and user side to enrich their representations, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To dynamically analyze user preferences and make personalized recommendations, RKGCN combines knowledge graphs on both the item and user sides to enrich their representations and maximize the utilization of abundant information in knowledge graphs, as demonstrated in the experiments on three real-world datasets including movies, books, and music #REFR. Specifically, RKGCN can be used to model preference sets of users with multiple items in their interaction history.", "given_citation_intent": "method", "given_keywords": ["preference sets"]}]}
{"citing_id": "2304.12986v1", "cited_id": "1706.03762", "section_title": "Introduction", "citation": "Chinese pre-trained large models based on the Transformer #REFR architecture are trained using massive textual corpora, including Chinese encyclopedic data, a large number of Chinese e-books, and numerous Chinese websites.", "text_before_citation": ["With the impressive debut of large models such as ChatGPT (Brockman et al., 2023) , a series of Chinese-capable large models, including ChatGLM #OTHEREFR , MOSS (Sun et al., 2023) , Wenxin Yiyan, Tongyi Qianwen, and Shangliang, have been released successively.", "While there are well-established evaluation methods for large English language models, such as MMLU #OTHEREFR , there is still a lack of evaluations for large Chinese language models.", "Therefore, it is imperative to introduce a scientific evaluation method for large Chinese models and provide high-quality Chinese evaluation datasets."], "text_after_citation": ["However, the capabilities of these models in understanding and solving problems across various domains have not been scientifically and comprehensively evaluated.", "Since most large language models released recently have undergone prompt-tuning training, we provide both zero-shot and few-shot testing modes, with the latter offering five examples to the models.", "The test questions are single-choice and multiple-choice, with each question potentially having one or multiple correct answers, making them more akin to human exams and increasing their difficulty.", "This test covers four major categories: medicine, law, psychology, and education.", "Medical questions are drawn from university medical examinations, legal questions from the National Uniform Legal Professional Qualification Examination, psychology questions from psychological counselor exams and graduate entrance exams in psychology, and education questions from the Chinese National College Entrance Examination."], "citing_paper_content": {"title": "Measuring Massive Multitask Chinese Understanding", "abstract": "The development of large-scale Chinese language models is flourishing, yet there is a lack of corresponding capability assessments. Therefore, we propose a test to measure the multitask accuracy of large Chinese language models. This test encompasses four major domains, including medicine, law, psychology, and education, with 15 subtasks in medicine and 8 subtasks in education. We found that the best-performing models in the zero-shot setting outperformed the worstperforming models by nearly 22 percentage points on average. Across the four major domains, the average zero-shot accuracy of all models did not exceed 0.5. In the subdomains, only the GPT-3.5turbo model achieved a zero-shot accuracy of 0.703 in clinical medicine, which was the highest accuracy among all models across all subtasks. All models performed poorly in the legal domain, with the highest zero-shot accuracy reaching only 0.259. By comprehensively evaluating the breadth and depth of knowledge across multiple disciplines, this test can more accurately identify the shortcomings of the models."}, "cited_paper_content": {"title": "Attention Is All You Need", "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."}, "keywords": ["massive textual corpora"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "While there are well-established evaluation methods for large English language models, such as MMLU #OTHEREFR, there is still a lack of evaluations for large Chinese language models. Therefore, it is imperative to introduce a scientific evaluation method for large Chinese models and provide high-quality Chinese evaluation datasets. As demonstrated in the reference paper, the Transformer model based solely on attention mechanisms achieved superior results in machine translation tasks, indicating its potential for improving the performance of large Chinese language models.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To introduce a scientific evaluation method for large Chinese models and provide high-quality Chinese evaluation datasets, the authors proposed a test to measure the multitask accuracy of large Chinese language models, which encompasses four major domains and uses a dataset that is similar to the one used in the Attention Is All You Need paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To evaluate the performance of large Chinese language models, it is crucial to introduce a scientific evaluation method and high-quality Chinese evaluation datasets, as well as to utilize specific methods such as attention mechanisms proposed in the reference paper \"Attention Is All You Need\" for massive textual corpora. #REFR", "given_citation_intent": "method", "given_keywords": ["massive textual corpora"]}]}
{"citing_id": "2303.11088v1", "cited_id": "1907.08302", "section_title": "Baseline Comparison Of Frameworks", "citation": "The performance overhead of using Apache Beam as an abstraction layer has also been observed in related research #REFR . higher resource demand compared to the other evaluated frameworks.", "text_before_citation": ["3b ), it appears that the resource demand of Flink increases at a steeper rate as well.", "For lower load intensities (less than 5 nested groups), Flink requires fewer instances than Samza.", "Worth mentioning is also the significant difference between native Apache Flink and the Flink runner of Apache Beam.", "In almost all experiments, the resource demand of Apache Beam with Flink is at least twice as high.", "For the more compute- intensive benchmarks UC3 and UC4, it is tremendously higher."], "text_after_citation": ["In this section, we take a closer look at the scalability of the Apache Beam SUTs and evaluate how scalability is affected by different configuration options.", "Again, we use the private cloud environment (see Table 1 ).", "In the following, we first look at the Apache Flink runner and, afterward, at the Apache Samza runner."], "citing_paper_content": {"title": "Benchmarking Scalability Of Stream Processing Frameworks Deployed As Event-Driven Microservices In The Cloud", "abstract": "Event-driven microservices are an emerging architectural style for data-intensive software systems. In such systems, stream processing frameworks such as Apache Flink, Apache Kafka Streams, Apache Samza, Hazelcast Jet, or the Apache Beam SDK are used inside microservices to continuously process massive amounts of data in a distributed fashion. While all of these frameworks promote scalability as a core feature, there is only little empirical research evaluating and comparing their scalability. In this study, we benchmark five modern stream processing frameworks regarding their scalability using a systematic method. We conduct over 460 hours of experiments on Kubernetes clusters in the Google cloud and in a private cloud, where we deploy up to 110 simultaneously running microservice instances, which process up to one million messages per second. We find that all benchmarked frameworks exhibit approximately linear scalability as long as sufficient cloud resources are provisioned. However, the frameworks show considerable differences in the rate at which resources have to be added to cope with increasing load. Moreover, we observe that there is no clear superior framework, but the ranking of the frameworks depends on the use case. Using Apache Beam as an abstraction layer still comes at the cost of significantly higher resource requirements regardless of the use case."}, "cited_paper_content": {"title": "Quantitative Impact Evaluation Of An Abstraction Layer For Data Stream Processing Systems", "abstract": "With the demand to process ever-growing data volumes, a variety of new data stream processing frameworks have been developed. Moving an implementation from one such system to another, e.g., for performance reasons, requires adapting existing applications to new interfaces. Apache Beam addresses these high substitution costs by providing an abstraction layer that enables executing programs on any of the supported streaming frameworks. In this paper, we present a novel benchmark architecture for comparing the performance impact of using Apache Beam on three streaming frameworks: Apache Spark Streaming, Apache Flink, and Apache Apex. We find significant performance penalties when using Apache Beam for application development in the surveyed systems. Overall, usage of Apache Beam for the examined streaming applications caused a high variance of query execution times with a slowdown of up to a factor of 58 compared to queries developed without the abstraction layer. All developed benchmark artifacts are publicly available to ensure reproducible results."}, "keywords": ["Apache Beam"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Worth mentioning is also the significant difference between native Apache Flink and the Flink runner of Apache Beam, as observed in the benchmark study by Kreuzer et al. (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the benchmark results presented in this study, the resource demand of Apache Beam with Flink is at least twice as high as native Apache Flink in almost all experiments, which is consistent with the findings in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The resource demand of Apache Beam with Flink is at least twice as high as that of native Apache Flink in almost all experiments, and it is tremendously higher for the more compute-intensive benchmarks UC3 and UC4, as reported in the reference paper #REFR.", "given_citation_intent": "result", "given_keywords": ["Apache Beam"]}]}
{"citing_id": "2304.03246v1", "cited_id": "1810.04805", "section_title": "Method", "citation": "For the text-conditional inpainting task, Inst-Inpaint tokenizes the text using the BERT tokenizer #REFR , and by taking these tokens as input, it learns a transformer model from scratch to obtain the instruction embeddings.", "text_before_citation": ["L LDM := E E(x), \u223cN (0,1),t [|| \u2212 \u03b8 (z t , t, E(s), T (i))||]", "(2) Here, i refers to the text instruction and T , the transformer.", "The encoder, E, is fixed during training whereas \u03b8 and T are optimized together.", "Implementation and Training Details.", "Inst-Inpaint concatenates the latent code of the target image z t at timestep t, obtained from the forward diffusion process, and the source image feature E(s) to predict the latent code of the previous timestep z t\u22121 ."], "text_after_citation": ["These embeddings are used in the crossattention mechanisms of the specific U-Net layers.", "We trained two Inst-Inpaint models on the CLEVR and the GQA-Inpaint datasets.", "The first stage model of the CLEVR model is a variational autoencoder trained from scratch on the combination of both the source and the target images of all instructions in the dataset.", "Differently from the CLEVR model, GQA-Inpaint model uses a pretrained VQGAN model 1 , which is trained on Open Images dataset #OTHEREFR and has 16384 number of codebook entries.", "In the second stage model of the CLEVR model, we define an eight-layer transformer to obtain the instruction embeddings and four-head cross attention to learn the relation between the instruction embedding and the activation layers for the inpainting process."], "citing_paper_content": {"title": "Inst-Inpaint: Instructing To Remove Objects With Diffusion Models", "abstract": "Figure 1. Instructional Image Inpainting. We propose a new image inpainting method, Inst-Inpaint, which takes an image and a textual instruction as input and is able to automatically remove objects mentioned in the text, without any need for a user-supplied binary mask to locate the region of interest, as in traditional inpainting approaches. We show sample results of our method trained and tested on a new real image inpainting benchmark dataset, GQA-Inpaint, which we created for the proposed instructional image inpainting task."}, "cited_paper_content": {"title": "Bert: Pre-Training Of Deep Bidirectional Transformers For Language Understanding", "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ::: BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."}, "keywords": ["text-conditional inpainting task", "BERT tokenizer"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To optimize the model, the authors fixed the encoder E and optimized \u03b8 and T together, as described in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To optimize the training of the transformer T, the authors of Inst-Inpaint concatenated the latent code of the target image with the source image feature and used a fixed encoder E, as well as a method called BERT for pre-training deep bidirectional representations from unlabeled text, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To tackle the text-conditional inpainting task, Inst-Inpaint employs a transformer-based model that takes textual instructions as input and removes objects mentioned in the text, without the need for a user-supplied binary mask, as in traditional inpainting approaches #REFR. Additionally, the model utilizes the BERT tokenizer to pre-train deep bidirectional representations from unlabeled text, which enables fine-tuning with just one additional output layer to achieve state-of-the-art results on a wide range of natural language processing tasks.", "given_citation_intent": "method", "given_keywords": ["text-conditional inpainting task", "BERT tokenizer"]}]}
{"citing_id": "2304.11424v1", "cited_id": "1803.02155", "section_title": "Ii. Method", "citation": "Unlike previous work in the field of natural language processing #REFR , we extend the words in a one-dimensional sequence to the pixels in a two-dimensional plane, considering their relative positions as a combined effect along both horizontal and vertical directions.", "text_before_citation": ["Finally, the context matrix c contextualizes the input features q so that the attention can be adjusted by the given context. Position Prior Embedding.", "In remote sensing images, ground objects are spatially distributed following specific intrinsic patterns.", "In particular, certain combinations or concurrences usually occur to the objects in close proximity, and the pixels in an object's vicinity may demonstrate high correlation.", "These observations suggest that a pixel's awareness of the scene relies on its sensitivity to relative positions, which are embedded as,", "EQUATION"], "text_after_citation": ["Specifically, the encoding of relative position r ij is defined as follows,", "EQUATION", "where P \u2208 R (2\u03be+1)\u00d7(2\u03be+1)\u00d7C is a bucket storing a set of indexed trainable vectors,", "I x (i, j) = g(x i \u2212 x j ) and I y (i, j) = g(y i \u2212 y j )", "represent subscripts for horizontal and vertical directions, forming two-dimensional indices for P , and g denotes an index function as follows,"], "citing_paper_content": {"title": "Sacanet: Scene-Aware Class Attention Network For Semantic Segmentation Of Remote Sensing Images", "abstract": "Spatial attention mechanism has been widely used in semantic segmentation of remote sensing images given its capability to model long-range dependencies. Many methods adopting spatial attention mechanism aggregate contextual information using direct relationships between pixels within an image, while ignoring the scene awareness of pixels (i.e., being aware of the global context of the scene where the pixels are located and perceiving their relative positions). Given the observation that scene awareness benefits context modeling with spatial correlations of ground objects, we design a scene-aware attention module based on a refined spatial attention mechanism embedding scene awareness. Besides, we present a local-global class attention mechanism to address the problem that general attention mechanism introduces excessive background noises while hardly considering the large intra-class variance in remote sensing images. In this paper, we integrate both scene-aware and class attentions to propose a scene-aware class attention network (SACANet) for semantic segmentation of remote sensing images. Experimental results on three datasets show that SACANet outperforms other state-ofthe-art methods and validate its effectiveness."}, "cited_paper_content": {"title": "Self-Attention With Relative Position Representations", "abstract": "Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the WMT 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs."}, "keywords": ["relative positions"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "In remote sensing images, ground objects are spatially distributed following specific intrinsic patterns, and certain combinations or concurrences usually occur to the objects in close proximity. To embed a pixel's sensitivity to relative positions, the authors of \"Self-Attention With Relative Position Representations\" proposed an alternative approach to extend the self-attention mechanism, which considers representations of the relative positions between sequence elements. #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To embed scene awareness in the spatial attention mechanism, SACANet proposed a refined approach that considers the relative positions of pixels, as presented in the work by Shaw et al. (2018) on self-attention with relative position representations. #REFR", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To embed relative positions in remote sensing images, SACANet utilizes a refined spatial attention mechanism that is based on the self-attention mechanism introduced by Vaswani et al. (2017) and extends it to consider representations of the #REFR relative positions between sequence elements.", "given_citation_intent": "method", "given_keywords": ["relative positions"]}]}
{"citing_id": "2303.14617v1", "cited_id": "1703.06114", "section_title": "Conjunction (\u2227).", "citation": "A family of neural processors often resort to the DeepSet architecture #REFR ) that first projects each set element independently and then pools representations together with a permutation-invariant function (e.g., sum, mean) followed by an MLP.", "text_before_citation": ["We elaborate on the differences of those query patterns in the following Section 6.2 and emphasize our focus on more complex intersection queries going beyond simpler path-like queries.", "Query processors, as described in Section 5.2, employ different parameterizations of conjunctions as permutation-invariant set functions."], "text_after_citation": ["Alternatively, self-attention, can serve as a replacement of the DeepSet where set elements are weighted with the attention operation.", "The other family of neural processors combine projection and intersection by processing the whole query graph with GNNs #OTHEREFR or with the Transformer over linearized query sequences (Kotnis et al., 2021; .", "Geometric processors implement conjunction as the attention-based average of centroids and offsets of respective geometric objects (boxes, hyperboloids, or cones).", "Probabilistic processors Figure 18 : Query operators (relation projection and intersection), corresponding SPARQL basic graph patterns (BGP), and their computation graphs. Relation Projection (left) corresponds to a triple pattern.", "et al., 2022b; Yang et al., 2022a) implement intersection as a weighted sum of parametric distributions that represent queries and variables."], "citing_paper_content": {"title": "Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases", "abstract": "Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Refining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research."}, "cited_paper_content": {"title": "Deep Sets", "abstract": "We study the problem of designing models for machine learning tasks defined on sets. In contrast to the traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets and are invariant to permutations. Such problems are widespread, ranging from the estimation of population statistics, to anomaly detection in piezometer data of embankment dams, to cosmology. Our main theorem characterizes the permutation invariant objective functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection."}, "keywords": ["neural processors", "DeepSet architecture"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "Query processors, as described in Section 5.2, employ different parameterizations of conjunctions as permutation-invariant set functions, which are characterized and provided in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To design permutation-invariant set functions, query processors in Section 5.2 employ different parameterizations of conjunctions, as described in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To design neural processors for permutation-invariant set functions, the authors of this manuscript cite the Deep Sets architecture proposed in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": ["neural processors", "DeepSet architecture"]}]}
{"citing_id": "2303.06287v1", "cited_id": "1808.04558", "section_title": "Introduction", "citation": "For d = 5, 6 and r \u2265 d \u2212 2, Jin #REFR presented an explicit construction of q-ary optimal LRCs of length \u2126 r (q 2 ) via binary constant weight codes.", "text_before_citation": ["#OTHEREFR proposed a construction of cyclic optimal LRCs with unbounded length. For minimum distance d \u2265 5, Guruswami et al.", "#OTHEREFR proved that the code length of a q-ary optimal LRC must be at most roughly O(dq 3 ) and presented an algorithmic construction of q-ary optimal LRCs of length", "\u2126 d,r (q 1+1/\u230a d\u22123 2 \u230b ) for r \u2265 d \u2212 2.", "By employing algebraic structures of elliptic curves, Li et al.", "#OTHEREFR constructed a family of q-ary optimal LRCs with length up to q + 2 \u221a q and some particular localities."], "text_after_citation": ["In #OTHEREFR , Xing and Yuan generalized Jin's results and presented a construction of q-ary optimal LRCs for general d \u2265 7 via hypergraph theory. In #OTHEREFR , Chen et al. considered the case of r < d \u2212 2.", "In particular, for d = 6 and r = 2, the authors established an equivalent connection between the existence of Singleton-optimal LRCs and the existence of lines in finite projective plane with certain properties.", "And they also provided some new constructions and improved bounds on Singleton-optimal LRCs.", "However, as we have seen, for d \u2265 5, the longest code length of known q-ary cyclic Singleton-optimal LRCs is q + 1 until now.", "So it is quite interesting to construct q-ary cyclic Singleton-optimal LRCs with length n > q + 1 and d \u2265 5."], "citing_paper_content": {"title": "Singleton-Optimal Lrcs And Perfect Lrcs Via Cyclic And Constacyclic Codes *", "abstract": "Locally repairable codes (LRCs) have emerged as an important coding scheme in distributed storage systems (DSSs) with relatively low repair cost by accessing fewer non-failure nodes. Theoretical bounds and optimal constructions of LRCs have been widely investigated. Optimal LRCs via cyclic and constacyclic codes provide significant benefit of elegant algebraic structure and efficient encoding procedure. In this paper, we continue to consider the constructions of optimal LRCs via cyclic and constacyclic codes with long code length. Specifically, we first obtain two classes of q-ary cyclic Singletonoptimal (n, k, d = 6; r = 2)-LRCs with length n = 3(q +1) when 3 | (q \u22121) and q is even, and length n = 3 2 (q + 1) when 3 | (q \u2212 1) and q \u2261 1(mod 4), respectively. To the best of our knowledge, this is the first construction of q-ary cyclic * This paper was presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT) [11]"}, "cited_paper_content": {"title": "Explicit Construction Of Optimal Locally Recoverable Codes Of Distance 5 And 6 Via Binary Constant Weight Codes", "abstract": "In a paper by Guruswami et al. , it was shown that the length $n$ of a $q$ -ary linear locally recoverable code with distance $d \\geqslant 5$ is upper bounded by $O(dq^{3})$ . Thus, it is a challenging problem to construct $q$ -ary locally recoverable codes with distance $d \\geqslant 5$ and length approaching the upper bound. The same paper also gave an algorithmic construction of $q$ -ary locally recoverable codes with locality $r$ and length $n=\\Omega _{r}(q^{2})$ for $d=5$ and 6, where $\\Omega _{r}$ means that the implicit constant depends on locality $r$ . In this paper, we present an explicit construction of $q$ -ary locally recoverable codes of distance $d= 5$ and 6 via binary constant weight codes. It turns out that 1) our construction is simpler and more explicit and 2) the length of our codes is greater than previously known."}, "keywords": ["q-ary optimal LRCs"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For minimum distance $d \\geqslant 5$, the upper bound on the code length of a $q$-ary optimal LRC is roughly $O(dq^{3})$ as shown by Guruswami et al. #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For minimum distance $d \\geqslant 5$, Guruswami et al. #REFR proved that the code length of a $q$-ary optimal LRC must be at most roughly $O(dq^{3})$, which makes it a challenging problem to construct $q$-ary locally recoverable codes with distance $d \\geqslant 5$ and length approaching the upper bound.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For minimum distance $d \\geqslant 5$, the code length of a $q$-ary optimal LRC must be at most roughly $O(dq^{3})$ and an algorithmic construction of $q$-ary optimal LRCs of length $\\Omega_{d,r}(q^{1+1/\\lfloor d-3/2 \\rfloor})$ for $r \\geqslant d-2$ was presented by Guruswami et al. #REFR, providing important background information for the construction of q-ary optimal LRCs via cyclic and constacyclic codes.", "given_citation_intent": "background", "given_keywords": ["q-ary optimal LRCs"]}]}
{"citing_id": "2304.08566v1", "cited_id": "1706.02216", "section_title": "Model Architectures", "citation": "Following prior work #REFR , the MEAN aggregation function is used at each layer, and the dropout is set to 0.5 to prevent overfitting. Similarity Model.", "text_before_citation": ["The neighborhood sample size is fixed at ten samples at each layer.", "GAT.", "We use a three-layer GAT model with a fixed neighborhood sample size of 10 at each layer.", "The first and second layers have four attention heads each. GraphSAGE. We use a two-layer GraphSAGE model.", "The neighborhood sample sizes are set to 25 and 10, respectively."], "text_after_citation": ["We use the Scikit-Learn implementation of an MLPClassifier to train C .", "We train three versions of F for each dataset using the three architectures. Each F has its own C .", "We train three versions of F and two versions of F for each F which we use to generate the positive and negative data points as explained in Section 5.", "We use a two-layer MLP and find the best hyperparameters using a grid search.", "The hidden layer sizes in the search are either 64 or 128, and the activation function is either Tanh or ReLU. We select the best model based on 10-fold crossvalidation."], "citing_paper_content": {"title": "Grove: Ownership Verification Of Graph Neural Networks Using Embeddings", "abstract": "Graph neural networks (GNNs) have emerged as a state-of-the-art approach to model and draw inferences from large scale graphstructured data in various application settings such as social networking. The primary goal of a GNN is to learn an embedding for each graph node in a dataset that encodes both the node features and the local graph structure around the node. Embeddings generated by a GNN for a graph node are unique to that GNN. Prior work has shown that GNNs are prone to model extraction attacks. Model extraction attacks and defenses have been explored extensively in other non-graph settings. While detecting or preventing model extraction appears to be difficult, deterring them via effective ownership verification techniques offer a potential defense. In non-graph settings, fingerprinting models, or the data used to build them, have shown to be a promising approach toward ownership verification. We present GrOVe, a state-of-the-art GNN model fingerprinting scheme that, given a target model and a suspect model, can reliably determine if the suspect model was trained independently of the target model or if it is a surrogate of the target model obtained via model extraction. We show that GrOVe can distinguish between surrogate and independent models even when the independent model uses the same training dataset and architecture as the original target model. Using six benchmark datasets and three model architectures, we show that GrOVe consistently achieves low false-positive and falsenegative rates. We demonstrate that GrOVe is robust against known fingerprint evasion techniques while remaining computationally efficient."}, "cited_paper_content": {"title": "Inductive Representation Learning On Large Graphs", "abstract": "Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions."}, "keywords": ["Similarity Model"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "For the GraphSAGE model, the authors learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood, which has been shown to outperform strong baselines on inductive node-classification benchmarks #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For the GraphSAGE model, the authors used a two-layer architecture with neighborhood sample sizes of 25 and 10, respectively, and generated node embeddings for previously unseen data by learning a function that aggregates features from a node's local neighborhood, as described in the reference paper #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "For the GraphSAGE model, the authors efficiently generate node embeddings for previously unseen data by learning a function that generates embeddings through sampling and aggregating features from a node's local neighborhood, as described in the reference paper \"Inductive Representation Learning On Large Graphs\" (#REFR) which presents a general, inductive framework that leverages node feature information.", "given_citation_intent": "method", "given_keywords": ["Similarity Model"]}]}
{"citing_id": "2303.10280v1", "cited_id": "1502.02791", "section_title": "Ii. Related Work", "citation": "Deep Adaptive Networks (DAN) #REFR uses a Hilbert space representation for the embedding representations to match different domain distributions.", "text_before_citation": ["For this reason, many synthetic datasets have been introduced in recent years including VisDA #OTHEREFR for domain adaptation techniques in image classification and segmentation, synthetic datasets for ground robots #OTHEREFR , #OTHEREFR , #OTHEREFR , aerial robots #OTHEREFR and action recognition including #OTHEREFR , #OTHEREFR , #OTHEREFR .", "Action recognition from aerial videos has also been studied extensively #OTHEREFR and aided by datasets like #OTHEREFR , #OTHEREFR , #OTHEREFR . #OTHEREFR introduces the NEC-DRONE dataset for groundto-air domain adaptation.", "Further, many simulators have also been developed to support generation of synthetic data.", "These simulators, including CARLA #OTHEREFR , GTA #OTHEREFR , NVIDIA ISAAC/Omniverse #OTHEREFR , Habitat #OTHEREFR , #OTHEREFR , AI2Thor #OTHEREFR , and iGibson #OTHEREFR allow users to create virtual environments that provide error-free, ground truth annotations.", "b) Synthetic-to-Real Transfer: Many studies have also explored synthetic-to-real transfer by leveraging synthetic data generated from simulation environments to pretrain a neural network, thereby reducing the amount of data needed in real-world settings #OTHEREFR , [38] ."], "text_after_citation": ["Adversarial Discriminative Domain Adaptation (ADDA) #OTHEREFR and Generate to Adapt #OTHEREFR are domain adaptation techniques that use unsupervised data to learn a joint feature space between the source and target distributions.", "CyCADA #OTHEREFR extends existing adversarial domain adaptation techniques by adding a cycle-consistency constraint for unsupervised adaptation from synthetic to real-world driving domains.", "Randomized-to-Canonical Adaptation Networks (RCANs) #OTHEREFR , GraspGAN #OTHEREFR , RetinaGAN #OTHEREFR , Closing the Sim-to-Real Loop #OTHEREFR , and the work described in #OTHEREFR leverage simulation and domain adaptation techniques for robot manipulation and grasping.", "VR-Goggles for Robots #OTHEREFR focuses on converting real images back to simulation for visual control of robots in indoor and outdoor environments.", "The authors of #OTHEREFR use synthetic-toreal techniques to improve mobile robot control policies on uneven, complex outdoor environments."], "citing_paper_content": {"title": "Synthetic-To-Real Domain Adaptation For Action Recognition: A Dataset And Baseline Performances", "abstract": "Human action recognition is a challenging problem, particularly when there is high variability in factors such as subject appearance, backgrounds and viewpoint. While deep neural networks (DNNs) have been shown to perform well on action recognition tasks, they typically require large amounts of high-quality labeled data to achieve robust performance across a variety of conditions. Synthetic data has shown promise as a way to avoid the substantial costs and potential ethical concerns associated with collecting and labeling enormous amounts of data in the real-world. However, synthetic data may differ from real data in important ways. This phenomenon, known as domain shift, can limit the utility of synthetic data in robotics applications. To mitigate the effects of domain shift, substantial effort is being dedicated to the development of domain adaptation (DA) techniques. Yet, much remains to be understood about how best to develop these techniques. In this paper, we introduce a new dataset called Robot Control Gestures (RoCoG-v2). The dataset is composed of both real and synthetic videos from seven gesture classes, and is intended to support the study of synthetic-to-real domain shift for videobased action recognition. Our work expands upon existing datasets by focusing the action classes on gestures for humanrobot teaming, as well as by enabling investigation of domain shift in both ground and aerial views. We present baseline results using state-of-the-art action recognition and domain adaptation algorithms and offer initial insight on tackling the synthetic-to-real and ground-to-air domain shifts. Instructions on accessing the dataset can be found at https://github. com/reddyav1/RoCoG-v2."}, "cited_paper_content": {"title": "Learning Transferable Features With Deep Adaptation Networks", "abstract": "Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multikernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks."}, "keywords": ["Deep Adaptive Networks"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To enhance the transferability in task-specific layers, the authors propose a new Deep Adaptation Network (DAN) architecture that can learn transferable features with statistical guarantees #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the domain shift problem in synthetic-to-real transfer, recent studies have proposed using domain adaptation techniques, such as the Deep Adaptation Network (DAN) architecture proposed in \"Learning Transferable Features With Deep Adaptation Networks\" #REFR, which embeds hidden representations of task-specific layers in a reproducing kernel Hilbert space to enhance transferability and reduce domain discrepancy.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of domain shift in synthetic-to-real transfer for action recognition, the authors propose a new Deep Adaptation Network (DAN) architecture that can learn transferable features with statistical guarantees and scale linearly by unbiased estimate of kernel embedding #REFR.", "given_citation_intent": "method", "given_keywords": ["Deep Adaptive Networks"]}]}
{"citing_id": "2304.07236v1", "cited_id": "1611.01055", "section_title": "B. State And Action Representation", "citation": "Previous research has shown that PD targets are an effective action parametrization for learning locomotion #REFR .", "text_before_citation": ["Figure 2 shows the height sampling taking place in the simulation environment.", "Finally, = (n , n ) is the pair of noisy exteroceptive observations.", "Sampling is similar to o however a noise is applied to the sampling pattern coordinates and sampled values.", "Further details on noise generation are discussed in section II-E.", "The action a \u2208 R 10 represents the PD targets for the actuators in the robot model."], "text_after_citation": ["The robot PD controller runs at 2 kHz, whereas actions are sampled from the policy at a rate of 40 Hz."], "citing_paper_content": {"title": "Learning Perceptive Bipedal Locomotion Over Irregular Terrain", "abstract": "In this paper we propose a novel bipedal locomotion controller that uses noisy exteroception to traverse a wide variety of terrains. Building on the cutting-edge advancements in attention based belief encoding for quadrupedal locomotion, our work extends these methods to the bipedal domain, resulting in a robust and reliable internal belief of the terrain ahead despite noisy sensor inputs. Additionally, we present a reward function that allows the controller to successfully traverse irregular terrain. We compare our method with a proprioceptive baseline and show that our method is able to traverse a wide variety of terrains and greatly outperforms the state-of-the-art in terms of robustness, speed and efficiency."}, "cited_paper_content": {"title": "Learning Locomotion Skills Using Deeprl: Does The Choice Of Action Space Matter?", "abstract": "The use of deep reinforcement learning allows for high-dimensional state descriptors, but little is known about how the choice of action representation impacts learning and the resulting performance. We compare the impact of four different action parameterizations (torques, muscle-activations, target joint angles, and target joint-angle velocities) in terms of learning time, policy robustness, motion quality, and policy query rates. Our results are evaluated on a gait-cycle imitation task for multiple planar articulated figures and multiple gaits. We demonstrate that the local feedback provided by higher-level action parameterizations can significantly impact the learning, robustness, and motion quality of the resulting policies."}, "keywords": ["locomotion", "effective action parametrization"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The choice of action representation has been shown to significantly impact the learning, robustness, and motion quality of resulting policies in locomotion tasks, as demonstrated by the study in the reference paper #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The choice of action parameterization in bipedal locomotion has been shown to significantly impact learning, robustness, and motion quality of resulting policies, as demonstrated in the study by the authors of \"Learning Locomotion Skills Using Deeprl: Does The Choice Of Action Space Matter?\" #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Effective action parametrization is crucial for achieving successful locomotion, as demonstrated by the comparison of four different action parameterizations in the reference paper #REFR.", "given_citation_intent": "background", "given_keywords": ["locomotion", "effective action parametrization"]}]}
{"citing_id": "2304.03994v1", "cited_id": "1512.03385", "section_title": "Image Dehazing Via Feature Matching", "citation": "Specifically, the shallow feature extraction head consists of a stack of residual layers #REFR and 4\u00d7 downsamples the features.", "text_before_citation": ["Based on the observation in Sec.", "4.1, image dehazing is decoupled into two sub-tasks: matching correct code and removing texture distortion. Encoder for HQPs Matching.", "We follow SwinIR #OTHEREFR which shows its powerful feature extraction ability for image restoration to design our encoder E."], "text_after_citation": ["Then 4 residual swin transformer blocks #OTHEREFR are followed, which serve as the deep feature extraction module. Decoder with Normalized Feature Alignment.", "We propose the Normalized Feature Alignment (NFA) to help the decoder utilize the features reconstructed from HQPs.", "Firstly, VQGAN tends to decrease results' fidelity due to the information loss brought by vector-quantized opera-"], "citing_paper_content": {"title": "Ridcp: Revitalizing Real Image Dehazing Via High-Quality Codebook Priors", "abstract": "Existing dehazing approaches struggle to process realworld hazy images owing to the lack of paired real data and robust priors. In this work, we present a new paradigm for real image dehazing from the perspectives of synthesizing more realistic hazy data and introducing more robust priors into the network. Specifically, (1) instead of adopting the de facto physical scattering model, we rethink the degradation of real hazy images and propose a phenomenological pipeline considering diverse degradation types. (2) We propose a Real Image Dehazing network via high-quality Codebook Priors (RIDCP). Firstly, a VQGAN is pre-trained on a large-scale high-quality dataset to obtain the discrete codebook, encapsulating high-quality priors (HQPs). After replacing the negative effects brought by haze with HQPs, the decoder equipped with a novel normalized feature alignment module can effectively utilize high-quality features and produce clean results. However, although our degradation pipeline drastically mitigates the domain gap between synthetic and real data, it is still intractable to avoid it, which challenges HQPs matching in the wild. Thus, we recalculate the distance when matching the features to the HQPs by a controllable matching operation, which facilitates finding better counterparts. We provide a recommendation to control the matching based on an explainable solution. Users can also flexibly adjust the enhancement degree as per their preference. Extensive experiments verify the effectiveness of our data synthesis pipeline and the superior performance of RIDCP in real image dehazing."}, "cited_paper_content": {"title": "Deep Residual Learning For Image Recognition", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."}, "keywords": ["residual layers"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We follow SwinIR #OTHEREFR which shows its powerful feature extraction ability for image restoration to design our encoder E. Deep Residual Learning For Image Recognition provides a residual learning framework to ease the training of networks that are substantially deeper than those used previously.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We propose a Real Image Dehazing network via high-quality Codebook Priors (RIDCP) that utilizes high-quality features and produces clean results by replacing the negative effects brought by haze with HQPs, and the decoder equipped with a novel normalized feature alignment module, as presented in #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To design our encoder E, we follow SwinIR #OTHEREFR which shows its powerful feature extraction ability for image restoration and utilize residual layers as proposed in the reference paper.", "given_citation_intent": "method", "given_keywords": ["residual layers"]}]}
{"citing_id": "2303.05500v1", "cited_id": "1901.03729", "section_title": "System Function Disclosure", "citation": "Furthermore, in these complex settings systems often lack the sort of commonsense knowledge that is required to effectively operate in a human-centered environment #REFR .", "text_before_citation": ["However, prescribing that disclosure takes place doesn't ensure that the disclosure contains useful information, or the information provided will be relevant and understandable to those consuming it.", "To address this issue, work on qualitatively evaluate the disclosure sufficiency with rubrics #OTHEREFR , or automatically assessing the layperson-comprehensibility of a system function description have been proposed.", "A further challenge to system function disclosure is that, in many cases, even experts don't know precisely how black box systems mechanistically produce output from input #OTHEREFR -thus explainability and interpretability techniques can be prerequisites for the level of expert understanding needed to produce honest disclosure ( \u00a73.2).", "A common limitation to many ML techniques applied in sensitive settings (e.g., medicine, criminal justice, employment) is the invisibility of external social context to the model.", "As biases and oversights in training data propagate to learned systems, system developers require clarity from data providers ( \u00a72.1) to ensure that they can in turn communicate the problems of their systems #OTHEREFR ."], "text_after_citation": ["Apart from solving the problem of commonsense reasoning in AI, actively soliciting direct user feedback to contextualize failure cases #OTHEREFR is one practical way to bootstrap documentation of model weaknesses.", "However, even if perfect information about a model's strengths and weaknesses (which is difficult to gain) and strong explanations of its internal functional details are available, calibrating explanations to be comprehensible to diverse stakeholders is still a confounding problem.", "In short, different groups require different explanations, and have different levels of expertise.", "Insufficient disclosure may be unsatisfy-ing, but too much disclosure may result in information overload, and lower user trust #OTHEREFR .", "To combat this issue, it is crucial to understand the desired ends of each stakeholder and information in a manner that balances this duality [Vaughan and Wallach, 2020]."], "citing_paper_content": {"title": "Users Are The North Star For Ai Transparency", "abstract": "Despite widespread calls for transparent artificial intelligence systems, the term is too overburdened with disparate meanings to express precise policy aims or to orient concrete lines of research. Consequently, stakeholders often talk past each other, with policymakers expressing vague demands and practitioners devising solutions that may not address the underlying concerns. Part of why this happens is that a clear ideal of AI transparency goes unsaid in this body of work. We explicitly name such a north star-transparency that is usercentered, user-appropriate, and honest. We conduct a broad literature survey, identifying many clusters of similar conceptions of transparency, tying each back to our north star with analysis of how it furthers or hinders our ideal AI transparency goals. We conclude with a discussion on common threads across all the clusters, to provide clearer common language whereby policymakers, stakeholders, and practitioners can communicate concrete demands and deliver appropriate solutions. We hope for future work on AI transparency that further advances confident, user-beneficial goals and provides clarity to regulators and developers alike. Perspective Definition of transparency Public Policy Any meaningful information relating to consumer data is disclosed in comprehensible language [Voigt, 2018; on AI, 2019]. Data Collection Disclosure of collection methods and privacy policies in a consumer-understandable manner [Driscoll and Walker, 2014; Agozie and Kaya, 2021]. Data Processing Comprehensible disclosure of methods in which consumer data is processed, stored, and used [Kirrane et al., 2021]. Reproducibility Disclosure of important information to reproduce a system's performance [Gundersen and Kjensmo, 2018] Intelligibility Disclosure of pertinent system functionality and limitations comprehensible to stakeholders [Vaughan and Wallach, 2020; Ehsan et al., 2021]. Interpretability Explanation that aids understanding of system functionality [Lipton, 2018; Watson and Nations, 2019]. Fairness Disclosure regarding representation and treatment to ensure equity among groups [Castillo, 2019; Bhatt et al., 2021]."}, "cited_paper_content": {"title": "Automated Rationale Generation: A Technique For Explainable Ai And Its Effects On Human Perceptions", "abstract": "Automated rationale generation is an approach for real-time explanation generation whereby a computational model learns to translate an autonomous agent's internal state and action data representations into natural language. Training on human explanation data can enable agents to learn to generate human-like explanations for their behavior. In this paper, using the context of an agent that plays Frogger, we describe (a) how to collect a corpus of explanations, (b) how to train a neural rationale generator to produce different styles of rationales, and (c) how people perceive these rationales. We conducted two user studies. The first study establishes the plausibility of each type of generated rationale and situates their user perceptions along the dimensions of confidence, humanlike-ness, adequate justification, and understandability. The second study further explores user preferences between the generated rationales with regard to confidence in the autonomous agent, communicating failure and unexpected behavior. Overall, we find alignment between the intended differences in features of the generated rationales and the perceived differences by users. Moreover, context permitting, participants preferred detailed rationales to form a stable mental model of the agent's behavior."}, "keywords": ["commonsense knowledge"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "A common limitation to many ML techniques applied in sensitive settings (e.g., medicine, criminal justice, employment) is the invisibility of external social context to the model. As biases and oversights in training data propagate to learned systems, system developers require clarity from data providers ( \u00a72.1) to ensure that they can in turn communicate the problems of their systems. Techniques for explainable AI, such as automated rationale generation, can be prerequisites for the level of expert understanding needed to produce honest disclosure #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To ensure honest disclosure of black box systems, explainability and interpretability techniques can be prerequisites for the level of expert understanding needed to produce comprehensible disclosure (\u00a73.2) #REFR.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "Automated rationale generation is an approach for real-time explanation generation whereby a computational model learns to translate an autonomous agent's internal state and action data representations into natural language, which can be useful for generating commonsense knowledge #REFR.", "given_citation_intent": "background", "given_keywords": ["commonsense knowledge"]}]}
{"citing_id": "2304.08637v1", "cited_id": "1911.12543", "section_title": "Related Work", "citation": "It is worth noting that earlier work has shown similar numbers to the ones we report for KR, but for other models and evaluation sets, such as BERT with LAMA #REFR .", "text_before_citation": ["We note that KR as memorization could be considered a privacy breach, hence we consider the presence PII as one of our discourse flaws.", "We direct the reader to the survey by Liu et al.", "#OTHEREFR on prompting methods; the work by Zhou et al.", "#OTHEREFR on using LLMs to generate prompts; and existing benchmarks such as Piqa #OTHEREFR , LAMA #OTHEREFR , and BIG-Bench-Hard #OTHEREFR for evaluating the performance of LLMs across multiple tasks.", "Our work is not designed to be an automated benchmark, and instead focuses on manual analysis of the text."], "text_after_citation": ["Liang et al.", "#OTHEREFR performed an authoritative evaluation on LLMs prior to the release of some of the models evaluated, to which we point the interested reader.", "Our work is narrower in scope, and focuses on the quality of the output as seen by an user without training, and by the easier-to-access models.", "Our KR findings are largely in line with theirs, although we find the incidence of output of memorized content to be higher.", "We also expand on the correlation between memorization and accuracy, by noting that this extends to overall discourse quality."], "citing_paper_content": {"title": "An Evaluation On Large Language Model Outputs: Discourse And Memorization", "abstract": "We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text."}, "cited_paper_content": {"title": "How Can We Know What Language Models Know?", "abstract": "Recent work has presented intriguing results examining the knowledge contained in language models (LM) by having the LM fill in the blanks of prompts such as \"Obama is a _ by profession\". These prompts are usually manually created, and quite possibly sub-optimal; another prompt such as \"Obama worked as a _\" may result in more accurately predicting the correct profession. Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM. In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process. Specifically, we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts and ensemble methods to combine answers from different prompts. Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1% to 38.1%, providing a tighter lower bound on what LMs know. We have released the code and the resulting LM Prompt And Query Archive (LPAQA) at this https URL."}, "keywords": ["BERT", "models"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "We direct the reader to the survey by Liu et al. (2021) on prompting methods; the work by Zhou et al. (2020) on using LLMs to generate prompts; and existing benchmarks such as Piqa, LAMA, and BIG-Bench-Hard for evaluating the performance of LLMs across multiple tasks. Our work is not designed to be an automated benchmark, and instead focuses on manual analysis of the text. To more accurately estimate the knowledge contained in LLMs, the authors of the reference paper propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts and ensemble methods to combine answers from different prompts (Brown et al., 2020). #REFR", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "We direct the reader to the survey by Liu et al. on prompting methods; the work by Zhou et al. on using LLMs to generate prompts; and existing benchmarks such as Piqa, LAMA, and BIG-Bench-Hard for evaluating the performance of LLMs across multiple tasks. Our work is not designed to be an automated benchmark, and instead focuses on manual analysis of the text. Recent work has presented intriguing results examining the knowledge contained in language models (LM) by having the LM fill in the blanks of prompts, and in this regard, the work by Petroni et al. on automatically discovering better prompts to use in this querying process has shown significant improvement in accuracy from 31.1% to 38.1%. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to Liu et al.'s survey on prompting methods and Zhou et al.'s work on using LLMs to generate prompts, the proposed mining-based and paraphrasing-based methods in the reference paper can improve the accuracy of BERT models in estimating their knowledge, as demonstrated by the experiments on the LAMA benchmark. #REFR", "given_citation_intent": "result", "given_keywords": ["BERT", "models"]}]}
{"citing_id": "2305.01417v1", "cited_id": "1103.0579", "section_title": "C. Robust Data-Based Controller Using Noisy Data", "citation": "System (1) with controller (32) can be described by the composite system #REFR , presented at the top of this page.", "text_before_citation": ["x(t + 1) e(t + 1) = \u039e 3 x(t) e(t)", "EQUATION", "where", "\u039e 3 = (X 1 \u2212 W 0 )\u03a6 \u2020 1 + (X 1 \u2212 W 0 )\u03a6 \u2020 2K (X 1 \u2212 W 0 )\u03a6 \u2020 2K 0 X 1\u03a6 \u2020 1 \u2212LY 0\u03a6 \u2020 1 \u039e1 + 0 0 W 0\u03a6 \u2020 1 +W 0\u03a6 \u2020 2K \u2212LV 0\u03a6 \u2020 1 W 0\u03a6 \u2020 2K \u039e2 (35)", "Proof."], "text_after_citation": ["Considering the estimation error e(t) = x(t)\u2212x(t), system (33) can be transformed into the composite system #OTHEREFR .", "Since the transformation from [x(t) x (t)] to [x(t) e (t)] is linear and non-singular, matrix \u039e 3 is similar to \u039e 0 .", "From #OTHEREFR Section 6.6] , this implies that system (33) has same characteristic polynomial as system #OTHEREFR .", "Hence, if \u039e 3 is Schur stable, so is \u039e 0 . According to #OTHEREFR , one has that", "\u039e 3 = \u039e 1 + \u039e 2 \u2264 \u039e 1 + \u039e 2 ."], "citing_paper_content": {"title": "Learning Robust Data-Based Lqg Controllers From Noisy Data", "abstract": "This paper addresses the joint state estimation and control problems for unknown linear time-invariant systems subject to both process and measurement noise. The aim is to redesign the linear quadratic Gaussian (LQG) controller based solely on data. The LQG controller comprises a linear quadratic regulator (LQR) and a steady-state Kalman observer; while the data-based LQR design problem has been previously studied, constructing the Kalman gain and the LQG controller from noisy data presents a novel challenge. In this work, a data-based formulation for computing the steady-state Kalman gain is proposed based on semi-definite programming (SDP) using some noise-free input-state-output data. Additionally, a data-based LQG controller is developed, which is shown to be equivalent to the model-based LQG controller. For cases where offline data are corrupted by noise, a robust data-based observer gain is constructed by tackling a relaxed SDP. The proposed controllers are proven to achieve robust global exponential stability (RGES) for state estimation and input-to-state practical stability (ISpS) under standard conditions. Finally, numerical tests are conducted to validate the proposed controllers' correctness and effectiveness. Index terms-Data-driven control, state estimation, noisy data, semi-definite program, linear quadratic Gaussian. I. INTRODUCTION The states of a dynamical system refer to a set of variables that provide a complete characterization of its internal conditions or status at a given time [35], which plays a fundamental role in control, monitoring, and high-level information extraction of real-world systems. Unfortunately, the complete states are not always fully observable; and even if measurements can be collected, the inevitable sensor miscalibration and noise may degrade the accuracy. As such, using the most likely value of a state reconstructed from raw measurements serves as an alternative, that is what is known as state estimation. Numerous efforts have contributed to the development of state estimation methods and theory as well as their applications in networked control systems, cyber-physical systems, and smart power grids; see e.g., [9], [10], [33], [39]. Most existing results on state estimation capitalize on explicit system models describing the underlying dynamics. However,"}, "cited_paper_content": {"title": "Distributed Estimation Via Iterative Projections With Application To Power Network Monitoring", "abstract": "This work presents a distributed method for control centers to monitor the operating condition of a power network, i.e., to estimate the network state, and to ultimately determine the occurrence of threatening situations. State estimation has been recognized to be a fundamental task for network control centers to operate safely and reliably a power grid. We consider (static) state estimation problems, in which the state vector consists of the voltage magnitude and angle at all network buses. We consider the state to be linearly related to network measurements, which include power flows, current injections, and voltage phasors at some buses. We admit the presence of several cooperating control centers, and we design two distributed methods for them to compute the minimum variance estimate of the state, given the network measurements. The two distributed methods rely on different modes of cooperation among control centers: in the first method an incremental mode of cooperation is used, whereas, in the second method, a diffusive interaction is implemented. Our procedures, which require each control center to know only the measurements and the structure of a subpart of the whole network, are computationally efficient and scalable with respect to the network dimension, provided that the number of control centers also increases with the network cardinality. Additionally, a finite-memory approximation of our diffusive algorithm is proposed, and its accuracy is characterized. Finally, our estimation methods are exploited to develop a distributed algorithm to detect corrupted network measurements."}, "keywords": ["controller"], "citation_intent": "background", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "The distributed method proposed in #REFR for control centers to estimate the network state and detect corrupted network measurements is computationally efficient and scalable, making it a promising approach for power network monitoring.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "State estimation is a fundamental task for network control centers to operate safely and reliably a power grid, and the distributed method proposed in #REFR can be used to estimate the network state and determine the occurrence of threatening situations.", "given_citation_intent": "background", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "The distributed estimation method proposed by the authors in #REFR can be used to design a data-based LQG controller for unknown linear time-invariant systems subject to both process and measurement noise.", "given_citation_intent": "background", "given_keywords": ["controller"]}]}
{"citing_id": "2303.11574v1", "cited_id": "1602.05352", "section_title": "Debiased Recommendation With A Randomized Dataset", "citation": "Propensity score recommendation learning is a representative work in this sub-route, and proposes two methods for the propensity score estimation based on a randomized dataset, including a naive Bayes estimator and a regression model estimator #REFR .", "text_before_citation": ["The research on this route additionally introduces a randomized dataset that can act as a proxy for the unbiased information.", "Most debiasing methods that fall into this route aim to mine the unbiased knowledge from a randomized dataset by formulating some more sophisticated and efficient techniques, and then use them to guide the training process of a recommendation model on a non-randomized dataset.", "The existing works on this research route can be further subdivided into three classes, including inverse propensity score and imputation labels-based methods, multi-stage training-based methods, and joint training-based methods, depending on the different techniques employed.", "An inverse propensity score and imputation labels-based method utilizes an additional randomized dataset to estimate the propensity score for each feedback #OTHEREFR or to make the predictions of the imputation labels for unobserved feedback data #OTHEREFR .", "These obtained propensity scores or imputation labels will be integrated into the model's optimization objective, i.e., transfer the unbiased knowledge into the model's training process."], "text_after_citation": ["Note that the propensity scores are used in both debiased recommendation routes, and they differ in whether the propensity score is estimated from a non-randomized dataset or a randomized dataset.", "In addition, some works also consider estimating and using the propensity scores and imputation labels simultaneously to allow the model to benefit more in a doubly robust framework #OTHEREFR .", "A multi-stage training-based method designs some effective multi-stage training frameworks in which a non-randomized dataset and a randomized data are used alternately, based on the synergy of which it learns better unbiased parameters.", "AutoDebias #OTHEREFR is one of the most representative methods on this research sub-line.", "Its main idea is to introduce a meta-learning strategy into a doubly robust debiasing framework to achieve better learning of the model."], "citing_paper_content": {"title": "Bounding System-Induced Biases In Recommender Systems With A Randomized Dataset", "abstract": "Debiased recommendation with a randomized dataset has shown very promising results in mitigating the system-induced biases. However, it still lacks more theoretical insights or an ideal optimization objective function compared with the other more well studied route without a randomized dataset. To bridge this gap, we study the debiasing problem from a new perspective and propose to directly minimize the upper bound of an ideal objective function, which facilitates a better potential solution to the system-induced biases. Firstly, we formulate a new ideal optimization objective function with a randomized dataset. Secondly, according to the prior constraints that an adopted loss function may satisfy, we derive two different upper bounds of the objective function, i.e., a generalization error bound with the triangle inequality and a generalization error bound with the separability. Thirdly, we show that most existing related methods can be regarded as the insufficient optimization of these two upper bounds. Fourthly, we propose a novel method called debiasing approximate upper bound with a randomized dataset (DUB), which achieves a more sufficient optimization of these upper bounds. Finally, we conduct extensive experiments on a public dataset and a real product dataset to verify the effectiveness of our DUB."}, "cited_paper_content": {"title": "Recommendations As Treatments: Debiasing Learning And Evaluation", "abstract": "Most data for evaluating and training recommender systems is subject to selection biases, either through self-selection by the users or through the actions of the recommendation system itself. In this paper, we provide a principled approach to handle selection biases by adapting models and estimation techniques from causal inference. The approach leads to unbiased performance estimators despite biased data, and to a matrix factorization method that provides substantially improved prediction performance on real-world data. We theoretically and empirically characterize the robustness of the approach, and find that it is highly practical and scalable."}, "keywords": ["randomized dataset"], "citation_intent": "method", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "An inverse propensity score and imputation labels-based method utilizes an additional randomized dataset to estimate the propensity score for each feedback or to make the predictions of the imputation labels for unobserved feedback data. These obtained propensity scores or imputation labels will be integrated into the model's optimization objective, i.e., transfer the unbiased knowledge into the model's training process (#REFR).", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One popular method to handle selection biases in recommender systems is to use causal inference techniques, as proposed in the paper \"Recommendations As Treatments: Debiasing Learning And Evaluation\" #REFR.", "given_citation_intent": "method", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "One popular approach to handling selection biases is to use a #REFR randomized dataset, which can act as a proxy for the unbiased information and facilitate the development of more sophisticated and efficient techniques for debiasing recommendation models.", "given_citation_intent": "method", "given_keywords": ["randomized dataset"]}]}
{"citing_id": "2303.16900v1", "cited_id": "1807.11164", "section_title": "Introduction", "citation": "Our initial finding suggests that not all input channels need to undergo the computationally expensive depthwise convolution operation #REFR , as demonstrated by our preliminary experiment results (see Table 10 ).", "text_before_citation": ["As shown in Figure 1 , the ConvNeXt-T with a default 7 \u00d7 7 kernel size is 1.4\u00d7 slower than that with small kernel size of 3 \u00d7 3, and is 1.8\u00d7 slower than ResNet-50, although they have similar FLOPs.", "However, using a smaller kernel size limits the receptive field, which can result in performance decrease.", "For example, ConvNeXt-T/k3 suffers a performance drop of 0.6% top-1 accuracy on the ImageNet-1K dataset when compared to ConvNeXt-T/k7 (where kn denotes a kernel size of n \u00d7 n).", "It is still unclear how to speed up large-kernel CNNs while preserving their performance.", "In this paper, we aim to address this issue by building upon ConvNeXt as our baseline and improving the depthwise convolution module."], "text_after_citation": ["Therefore, we propose to leave some channels unaltered and process only a portion of the channels with the depthwise convolution operation.", "Next, we propose to decompose large kernel of depthwise convolution into several groups of small kernels with Inception style #OTHEREFR .", "Specifically, for the processing channels, 1/3 of channels are conducted with kernel of 3 \u00d7 3, 1/3 are with 1 \u00d7 k while the remaining 1/3 are with k \u00d7 1.", "With this new simple and cheap operator, termed as \"Inception depthwise convolution\", our built model Inception-NeXt achieves a much better trade-off between accuracy and speed.", "For example, as shown in Figure 1 , InceptionNeXt-T achieves higher accuracy than ConvNeXt-T while enjoying 1.6\u00d7 speedup of training throughput similar to ResNet-50."], "citing_paper_content": {"title": "Inceptionnext: When Inception Meets Convnext", "abstract": "Inspired by the long-range modeling ability of ViTs, large-kernel convolutions are widely studied and adopted recently to enlarge the receptive field and improve model performance, like the remarkable work ConvNeXt which employs 7 \u00d7 7 depthwise convolution. Although such depthwise operator only consumes a few FLOPs, it largely harms the model efficiency on powerful computing devices due to the high memory access costs. For example, ConvNeXt-T has similar FLOPs with ResNet-50 but only achieves 60% throughputs when trained on A100 GPUs with full precision. Although reducing the kernel size of ConvNeXt can improve speed, it results in significant performance degradation. It is still unclear how to speed up large-kernelbased CNN models while preserving their performance. To tackle this issue, inspired by Inceptions, we propose to decompose large-kernel depthwise convolution into four parallel branches along channel dimension, i.e. small square kernel, two orthogonal band kernels, and an identity mapping. With this new Inception depthwise convolution, we build a series of networks, namely IncepitonNeXt, which not only enjoy high throughputs but also maintain competitive performance. For instance, InceptionNeXt-T achieves 1.6\u00d7 higher training throughputs than ConvNeX-T, as well as attains 0.2% top-1 accuracy improvement on ImageNet-1K. We anticipate InceptionNeXt can serve as an economical baseline for future architecture design to reduce carbon footprint."}, "cited_paper_content": {"title": "Shufflenet V2: Practical Guidelines For Efficient Cnn Architecture Design", "abstract": "Currently, the neural network architecture design is mostly guided by the \\emph{indirect} metric of computation complexity, i.e., FLOPs. However, the \\emph{direct} metric, e.g., speed, also depends on the other factors such as memory access cost and platform characterics. Thus, this work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs. Based on a series of controlled experiments, this work derives several practical \\emph{guidelines} for efficient network design. Accordingly, a new architecture is presented, called \\emph{ShuffleNet V2}. Comprehensive ablation experiments verify that our model is the state-of-the-art in terms of speed and accuracy tradeoff."}, "keywords": ["computationally expensive depthwise"], "citation_intent": "result", "generated_citations": [{"model": "gpt-3.5-turbo-0301", "text": "To address the challenge of speeding up large-kernel CNNs while preserving their performance, we propose a new Inception depthwise convolution module, which is inspired by Inceptions and decomposes the large-kernel depthwise convolution into four parallel branches along the channel dimension. Our proposed InceptionNeXt achieves 1.6\u00d7 higher training throughputs than ConvNeX-T and maintains competitive performance, as reported in #REFR.", "given_citation_intent": null, "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "According to the results presented in this paper, the proposed ShuffleNet V2 architecture provides state-of-the-art speed and accuracy tradeoff, which can be a potential solution to the issue of improving the efficiency of large-kernel-based CNN models while maintaining their performance on powerful computing devices with high memory access costs. #REFR", "given_citation_intent": "result", "given_keywords": null}, {"model": "gpt-3.5-turbo-0301", "text": "To address the issue of computationally expensive depthwise convolution, the authors of this manuscript propose a new architecture called InceptionNeXt, which achieves 1.6\u00d7 higher training throughputs than ConvNeX-T while maintaining competitive performance (#REFR).", "given_citation_intent": "result", "given_keywords": ["computationally expensive depthwise"]}]}
