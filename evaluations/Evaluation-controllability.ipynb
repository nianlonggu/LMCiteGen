{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76fedbd-3a26-41e5-bdd8-a55f29c008df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-26 14:33:32,374] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os,sys,inspect\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "from reward_model.citation_intent_classification.src.BertClassifier.model import CitationIntentClassifier\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import Trainer, AutoConfig, AutoModelForCausalLM, AutoTokenizer,  \\\n",
    "                          TrainingArguments, logging, \\\n",
    "                          BitsAndBytesConfig, TrainerCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b009cb0-91ce-4e1b-a769-2d58c96b7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardCal:\n",
    "    def __init__(self, intent_classifier_model_path, pretrained_lm_path, device_index ):\n",
    "        self.rouge = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "        self.intent_classifier = CitationIntentClassifier( intent_classifier_model_path,  \"allenai/scibert_scivocab_uncased\",  device_index )\n",
    "        self.lm = AutoModelForCausalLM.from_pretrained(pretrained_lm_path, load_in_4bit = True, device_map={\"\":device_index})\n",
    "        self.lm.eval()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_lm_path)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            log_prior_distribution = self.lm(input_ids=torch.LongTensor( [ self.tokenizer.bos_token_id ] ).unsqueeze(0)\n",
    "                   )[\"logits\"].to(torch.float32).log_softmax(-1)[0,0].detach().cpu().numpy()\n",
    "        self.log_prior_distribution = log_prior_distribution\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp( -x ))\n",
    "        \n",
    "    def reward_fn(self, gen_citation,  given_intent, given_keywords, given_citation  ):\n",
    "        if gen_citation.strip() == \"\":\n",
    "            return 0.0\n",
    "        \n",
    "        reward_intent = self.intent_classifier.get_intent_scores( gen_citation ).get(given_intent, 0.0)\n",
    "        reward_keywords = self.rouge.score( given_keywords, gen_citation )[\"rougeL\"].recall\n",
    "        \n",
    "        cit_token_ids = np.array(self.tokenizer.encode( gen_citation ))\n",
    "        prior_cit_log_probs = self.log_prior_distribution[ cit_token_ids ]\n",
    "        \n",
    "        input_ids = torch.LongTensor([self.tokenizer.bos_token_id] + cit_token_ids.tolist() ).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            cit_log_probs = self.lm(input_ids = input_ids)[\"logits\"][0][:-1].to(torch.float32).log_softmax(-1).detach().cpu().numpy()\n",
    "            cit_log_probs = cit_log_probs[ np.arange(len(cit_token_ids)), cit_token_ids ]\n",
    "        reward_fluency = self.sigmoid( (np.mean(cit_log_probs - prior_cit_log_probs ) - 4) )\n",
    "        # reward_fluency = np.mean(cit_log_probs - prior_cit_log_probs )\n",
    "        \n",
    "        reward_groundness = self.rouge.score( given_citation, gen_citation )\n",
    "        # reward_groundness = reward_groundness[\"rouge1\"].fmeasure + reward_groundness[\"rouge2\"].fmeasure + reward_groundness[\"rougeL\"].fmeasure \n",
    "        \n",
    "        \n",
    "        return { \"intent_score\": reward_intent,\n",
    "                 \"keywords_score\":reward_keywords,\n",
    "                 \"fluency_score\":reward_fluency,\n",
    "                 \"rouge_score\":reward_groundness\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ffd593-8d9b-45b4-95a4-310689325d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Loading binary /home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/scieditor/anaconda3/envs/trl did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('kh=\\\\E[1~'), PosixPath('is=\\\\E)0'), PosixPath('pa#64'), PosixPath('us=\\\\E[4m'), PosixPath('so=\\\\E[3m'), PosixPath('cd=\\\\E[J'), PosixPath('IC=\\\\E[%d@'), PosixPath('ei=\\\\E[4l'), PosixPath('im=\\\\E[4h'), PosixPath('mb=\\\\E[5m'), PosixPath('le=^H'), PosixPath('vi=\\\\E[?25l'), PosixPath('kd=\\\\EOB'), PosixPath('dc=\\\\E[P'), PosixPath('mh=\\\\E[2m'), PosixPath('ho=\\\\E[H'), PosixPath('AX'), PosixPath('vs=\\\\E[34l'), PosixPath('cm=\\\\E[%i%d;%dH'), PosixPath('pf=\\\\E[4i'), PosixPath('mr=\\\\E[7m'), PosixPath('@1=\\\\E[1~'), PosixPath('xn'), PosixPath('nd=\\\\E[C'), PosixPath('k1=\\\\EOP'), PosixPath('ti=\\\\E[?1049h'), PosixPath('kr=\\\\EOC'), PosixPath('do=^J'), PosixPath('cs=\\\\E[%i%d;%dr'), PosixPath('cr=^M'), PosixPath('F2=\\\\E[24~'), PosixPath('k5=\\\\E[15~'), PosixPath('k8=\\\\E[19~'), PosixPath('op=\\\\E[39;49m'), PosixPath('G0'), PosixPath('DC=\\\\E[%dP'), PosixPath('RI=\\\\E[%dC'), PosixPath('k0=\\\\E[10~'), PosixPath('LE=\\\\E[%dD'), PosixPath('am'), PosixPath('LP'), PosixPath('bs'), PosixPath('kl=\\\\EOD'), PosixPath('UP=\\\\E[%dA'), PosixPath('co#102'), PosixPath('cl=\\\\E[H\\\\E[J'), PosixPath('rs=\\\\Ec'), PosixPath('F1=\\\\E[23~'), PosixPath('sc=\\\\E7'), PosixPath('k;=\\\\E[21~'), PosixPath('po=\\\\E[5i'), PosixPath('ku=\\\\EOA'), PosixPath('AF=\\\\E[3%dm'), PosixPath('bl=^G'), PosixPath('ct=\\\\E[3g'), PosixPath('xv'), PosixPath('nw=\\\\EE'), PosixPath('ta=^I'), PosixPath('vb=\\\\Eg'), PosixPath('pt'), PosixPath('SC|screen.xterm-256color|VT 100/ANSI X3.64 virtual terminal'), PosixPath('k9=\\\\E[20~'), PosixPath('kD=\\\\E[3~'), PosixPath('md=\\\\E[1m'), PosixPath('k7=\\\\E[18~'), PosixPath('al=\\\\E[L'), PosixPath('ac=\\\\140\\\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00'), PosixPath('ms'), PosixPath('it#8'), PosixPath('te=\\\\E[?1049l'), PosixPath('st=\\\\EH'), PosixPath('ks=\\\\E[?1h\\\\E='), PosixPath('@7=\\\\E[4~'), PosixPath('k6=\\\\E[17~'), PosixPath('kI=\\\\E[2~'), PosixPath('dl=\\\\E[M'), PosixPath('kB=\\\\E[Z'), PosixPath('ue=\\\\E[24m'), PosixPath('mi'), PosixPath('up=\\\\EM'), PosixPath('li#29'), PosixPath('DL=\\\\E[%dM'), PosixPath('k4=\\\\EOS'), PosixPath('bt=\\\\E[Z'), PosixPath('AB=\\\\E[4%dm'), PosixPath('me=\\\\E[m'), PosixPath('Km=\\\\E[M'), PosixPath('kH=\\\\E[4~'), PosixPath('kN=\\\\E[6~'), PosixPath('ae=\\\\E(B'), PosixPath('ke=\\\\E[?1l\\\\E>'), PosixPath('kP=\\\\E[5~'), PosixPath('as=\\\\E(0'), PosixPath('ve=\\\\E[34h\\\\E[?25h'), PosixPath('Co#8'), PosixPath('k2=\\\\EOQ'), PosixPath('AL=\\\\E[%dL'), PosixPath('rc=\\\\E8'), PosixPath('sr=\\\\EM'), PosixPath('k3=\\\\EOR'), PosixPath('DO=\\\\E[%dB'), PosixPath('ce=\\\\E[K'), PosixPath('km'), PosixPath('se=\\\\E[23m')}\n",
      "  warn(msg)\n",
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/home/scieditor/anaconda3/envs/trl/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "reward_cal = RewardCal(\"../reward_model/citation_intent_classification/model/BertClassifier/5_5_0.05_0.01/model_batch_515.pt\",\n",
    "                       \"bigscience/bloom-560m\", \n",
    "                       0\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10833c54-eb64-4ae9-a725-6ffd71737bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7701e-ed3e-4131-9544-a2d040c775dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309bc853-a221-42b6-a249-8b4bd76b9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval( flag, data_path ):\n",
    "    \n",
    "    corpus =[ json.loads(line) for line in open(data_path) ] \n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    # print(\"Mode1: uncontrolled generation\")\n",
    "    r1_list = []\n",
    "    r2_list = []\n",
    "    rl_list = []\n",
    "    for example in tqdm( corpus ):\n",
    "        \n",
    "        ref_cit_text = example[\"citation\"]\n",
    "        gen_cit_info = example[\"generated_citations\"][0]\n",
    "        gen_cit_text = gen_cit_info[\"generation\"][\"citation\"]\n",
    "        \n",
    "        score = reward_cal.rouge.score( ref_cit_text, gen_cit_text )\n",
    "\n",
    "        r1_list.append( score[\"rouge1\"].fmeasure )\n",
    "        r2_list.append( score[\"rouge2\"].fmeasure )\n",
    "        rl_list.append( score[\"rougeL\"].fmeasure )\n",
    "        \n",
    "    res.append( [   \n",
    "        \"%.2f\"%(np.round( np.mean(r1_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(r2_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(rl_list) * 100, 2)),\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "    ] )\n",
    "            \n",
    "    # print(\"\\nMode2: intent-controlled generation\")\n",
    "    r1_list = []\n",
    "    r2_list = []\n",
    "    rl_list = []\n",
    "    for example in tqdm( corpus ):\n",
    "        \n",
    "        ref_cit_text = example[\"citation\"]\n",
    "        gen_cit_info = example[\"generated_citations\"][1]\n",
    "        assert gen_cit_info[\"given_citation_intent\"] is not None and gen_cit_info[\"given_keywords\"] is None\n",
    "        gen_cit_text = gen_cit_info[\"generation\"][\"citation\"]\n",
    "        \n",
    "        score = reward_cal.rouge.score( ref_cit_text, gen_cit_text )\n",
    "\n",
    "        r1_list.append( score[\"rouge1\"].fmeasure )\n",
    "        r2_list.append( score[\"rouge2\"].fmeasure )\n",
    "        rl_list.append( score[\"rougeL\"].fmeasure )\n",
    "        \n",
    "    res.append( [   \n",
    "        \"%.2f\"%(np.round( np.mean(r1_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(r2_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(rl_list) * 100, 2)),\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "    ] )\n",
    "    \n",
    "    # print(\"\\nMode3: intent and keywords controlled generation\")\n",
    "    \n",
    "    intent_score_list = []\n",
    "    keywords_score_list = []\n",
    "    fluency_score_list = []\n",
    "    r1_list = []\n",
    "    r2_list = []\n",
    "    rl_list = []\n",
    "\n",
    "    for example in tqdm( corpus ):\n",
    "        \n",
    "        ref_cit_text = example[\"citation\"]\n",
    "        \n",
    "        gen_cit_info = example[\"generated_citations\"][2]\n",
    "        assert gen_cit_info[\"given_citation_intent\"] is not None and gen_cit_info[\"given_keywords\"] is not None\n",
    "        if isinstance( gen_cit_info[\"generation\"], dict ):\n",
    "            gen_cit_text = gen_cit_info[\"generation\"][\"citation\"]\n",
    "        else:\n",
    "            gen_cit_text = gen_cit_info[\"generation\"]\n",
    "        \n",
    "        score = reward_cal.reward_fn( gen_cit_text,\n",
    "                        gen_cit_info[\"given_citation_intent\"],\n",
    "                        \"; \".join( gen_cit_info[\"given_keywords\"] ),\n",
    "                        ref_cit_text\n",
    "                        )    \n",
    "        \n",
    "        intent_score_list.append( score[\"intent_score\"] )\n",
    "        keywords_score_list.append( score[\"keywords_score\"] )\n",
    "        fluency_score_list.append( score[\"fluency_score\"] )\n",
    "        r1_list.append( score[\"rouge_score\"][\"rouge1\"].fmeasure )\n",
    "        r2_list.append( score[\"rouge_score\"][\"rouge2\"].fmeasure )\n",
    "        rl_list.append( score[\"rouge_score\"][\"rougeL\"].fmeasure )\n",
    "        \n",
    "    res.append( [   \n",
    "        \"%.2f\"%(np.round( np.mean(r1_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(r2_list) * 100, 2)),\n",
    "        \"%.2f\"%(np.round( np.mean(rl_list) * 100, 2)),\n",
    "        \"%.4f\"%(np.round( np.mean(intent_score_list) ,4)),\n",
    "        \"%.4f\"%(np.round( np.mean(keywords_score_list) ,4)),\n",
    "        \"%.4f\"%(np.round( np.mean(fluency_score_list) ,4)),\n",
    "    ] )\n",
    "    \n",
    "    \n",
    "    return  flag + \" & \" + \" & \".join( res[0][:3] + res[1][:3] + res[2] ) + \" \\\\\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd481b-9d4f-4d5a-ab21-0f18b950047e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6099ad-0c1e-455a-abfb-7a6527959da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1333.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1348.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:00<00:00, 17.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1275.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1271.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:58<00:00, 18.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1372.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1335.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:55<00:00, 19.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1353.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1354.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:56<00:00, 19.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1356.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1351.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:55<00:00, 19.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1330.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1312.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:56<00:00, 19.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1339.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1354.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:56<00:00, 19.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1346.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1339.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:55<00:00, 19.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1316.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1302.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:56<00:00, 18.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1334.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:00<00:00, 1319.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:57<00:00, 18.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:01<00:00, 693.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1080/1080 [00:01<00:00, 834.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1080/1080 [01:14<00:00, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART-base-140M & 25.49 & 4.26 & 18.28 & 26.05 & 4.52 & 18.71 & 31.63 & 8.79 & 22.74 & 0.6789 & 0.6444 & 0.7156 \\\\\n",
      "BART-large-400M & 27.39 & 5.67 & 19.85 & 27.90 & 6.00 & 20.17 & 32.33 & 9.12 & 23.20 & 0.6521 & 0.5877 & 0.7510 \\\\\n",
      "GPT-Neo-125M & 23.54 & 3.67 & 17.58 & 23.62 & 3.69 & 17.59 & 30.48 & 9.44 & 22.83 & 0.6252 & 0.6793 & 0.7996 \\\\\n",
      "GPT-Neo-1.3B & 28.48 & 6.12 & 20.78 & 29.04 & 6.39 & 21.28 & 36.26 & 13.48 & 26.81 & 0.7018 & 0.7936 & 0.7595 \\\\\n",
      "Galactica-125M & 28.03 & 5.77 & 20.23 & 28.70 & 6.27 & 20.96 & 35.67 & 13.07 & 26.50 & 0.7037 & 0.7914 & 0.7540 \\\\\n",
      "Galactica-125M-PPO & 27.97 & 5.72 & 20.27 & 28.81 & 6.12 & 20.97 & 36.49 & 13.55 & 27.09 & 0.7273 & 0.8313 & 0.7651 \\\\\n",
      "Galactica-1.3B & 30.07 & 7.34 & 22.06 & 30.66 & 7.62 & 22.64 & 38.06 & 15.21 & 28.50 & 0.6925 & 0.8299 & 0.7399 \\\\\n",
      "Galactica-6.7B & 30.61 & 7.97 & 22.59 & 30.89 & 8.03 & 22.87 & 38.29 & 15.58 & 28.70 & 0.6734 & 0.8150 & 0.7468 \\\\\n",
      "LLaMa-7B & 30.19 & 7.28 & 22.13 & 30.49 & 7.46 & 22.32 & 37.71 & 14.80 & 28.30 & 0.6688 & 0.8380 & 0.7584 \\\\\n",
      "LLaMa-7B-PPO & 30.31 & 7.38 & 22.24 & 30.64 & 7.64 & 22.51 & 37.72 & 14.83 & 28.31 & 0.6769 & 0.8430 & 0.7591 \\\\\n",
      "GPT-3.5-turbo & 23.04 & 3.88 & 14.93 & 23.92 & 3.61 & 15.66 & 29.10 & 8.11 & 18.97 & 0.5716 & 0.8420 & 0.8493 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "for flag, data_path in [\n",
    "    ( \"BART-base-140M\", \"../results/sft_model/bart-base/test_with_citations.jsonl\"  ),\n",
    "    ( \"BART-large-400M\", \"../results/sft_model/bart-large/test_with_citations.jsonl\"  ),\n",
    "    ( \"GPT-Neo-125M\", \"../results/sft_model/gpt-neo-125m-hf/test_with_citations.jsonl\"  ),\n",
    "    ( \"GPT-Neo-1.3B\", \"../results/sft_model/gpt-neo-1.3b-hf/test_with_citations.jsonl\"  ),\n",
    "    ( \"Galactica-125M\", \"../results/sft_model/galactica-125m-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"Galactica-125M-PPO\", \"../results/ppo_model/galactica-125m-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"Galactica-1.3B\", \"../results/sft_model/galactica-1.3b-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"Galactica-6.7B\", \"../results/sft_model/galactica-6.7b-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"Galactica-6.7B-PPO\", \"../results/ppo_model/galactica-6.7b-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"LLaMa-7B\", \"../results/sft_model/llama-7b-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"LLaMa-7B-PPO\", \"../results/ppo_model/llama-7b-ct2/test_with_citations.jsonl\"  ),\n",
    "    ( \"GPT-3.5-turbo\", \"../zero_shot_GPT-3.5-turbo/results/test_with_chatgpt_citations_merged.jsonl\"  ),\n",
    "]:\n",
    "    eval_results.append( eval( flag, data_path ) )\n",
    "    \n",
    "print(\"\\n\".join(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf2e74-df19-416a-8aa2-da9d5ca91897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f297f60-25e9-4b99-9b31-9ece4eacbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1358.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1329.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1299/1299 [01:48<00:00, 11.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1329.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1301.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1299/1299 [01:09<00:00, 18.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1301.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:00<00:00, 1308.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1299/1299 [01:10<00:00, 18.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:01<00:00, 1289.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1299/1299 [00:01<00:00, 1261.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1299/1299 [01:11<00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galactica-125M-beam1 & 27.93 & 6.00 & 20.39 & 28.67 & 6.41 & 21.09 & 35.85 & 13.44 & 26.88 & 0.7128 & 0.7667 & 0.7539 \\\\\n",
      "Galactica-125M-beam2 & 27.26 & 5.80 & 19.61 & 28.00 & 6.26 & 20.24 & 36.00 & 13.81 & 26.68 & 0.6946 & 0.7865 & 0.7526 \\\\\n",
      "Galactica-125M-beam4 & 27.15 & 6.01 & 19.50 & 27.69 & 6.29 & 19.98 & 35.44 & 13.59 & 26.13 & 0.6872 & 0.7656 & 0.7466 \\\\\n",
      "Galactica-125M-beam8 & 26.47 & 6.03 & 18.87 & 26.91 & 6.38 & 19.44 & 34.99 & 13.67 & 25.91 & 0.6724 & 0.7400 & 0.7425 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "for flag, data_path in [\n",
    "    ( \"Galactica-125M-beam1\", \"../results/sft_model/galactica-125m-ct2/val_with_citations_beam_size_1.jsonl\"  ),\n",
    "    ( \"Galactica-125M-beam2\", \"../results/sft_model/galactica-125m-ct2/val_with_citations_beam_size_2.jsonl\"  ),\n",
    "    ( \"Galactica-125M-beam4\", \"../results/sft_model/galactica-125m-ct2/val_with_citations_beam_size_4.jsonl\"  ),\n",
    "    ( \"Galactica-125M-beam8\", \"../results/sft_model/galactica-125m-ct2/val_with_citations_beam_size_8.jsonl\"  ),\n",
    "]:\n",
    "    eval_results.append( eval( flag, data_path ) )\n",
    "    \n",
    "print(\"\\n\".join(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e64444-3f20-435a-9974-ec60800fd689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:trl]",
   "language": "python",
   "name": "conda-env-trl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
